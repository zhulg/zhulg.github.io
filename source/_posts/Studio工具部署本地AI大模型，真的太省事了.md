---
title: Studio工具部署本地AI大模型，真的太省事了
tags: 
  - AI
  - 技术成长
categories: AI
abbrlink: 87fa9ee5
date: 2025-01-01 11:12:50
---

普通人如何部署自己的本地大模型，如何用Studio工具部署本地AI大模型。

前面写过[AI时代：玩AI却不懂一点原理，真的靠谱吗？](http://mp.weixin.qq.com/s?__biz=MzIzNDA3MzA3MQ==&mid=2464356719&idx=1&sn=6df620a76eabec6d4fe8566ab33d95ad&chksm=ffec47efc89bcef95afddf24c3b8eafbcc606e3cc82f8670fa810344b1deb084afbd116fdfe5&scene=21#wechat_redirect)的基础篇，也说过这类的文章我后边会持续输出，核心目标帮助技术人、对AI感兴趣的读者，可以用一种比较轻松和漫谈的形式理解，并给大家一些学习和玩AI的方法。今天先介绍下普通人如何部署自己的本地大模型。

*你可能会问：为什么要自己部署本地大模型？*

我想可能有这几个原因，看看是否准确：

1. 如果你不会科学上网，是不是访问其他国外模型基本没法用，相关速度也不是快，即便科学上网，有些模型是不是还要付费订阅高级版。

   

2. 自己是不是有些东西不想直接公开去给到大模型，害怕隐私和知识产品被大模型收集学到。

   

3. 在某个垂直领域，是不是想训练自己的大模型，然后结合自己的产品和业务来使用。



如果现在可以帮助普通人，像安装一个电脑软件一样通过简单操作，就可以运行自己的本地大模型，在自己电脑上免费使用，速度也快，也不怕自己隐私，这个是不是能满足大部分人需要了。

今天我想给大家推荐一个比 Ollama 更加清爽的工具：**LM Studio（**如果你还不熟悉 Ollama，它其实是一个用于安装和管理大模型的工具）， LM Studio 不仅对普通用户友好，技术人员也友好，方便地安装大模型。它提供了开发模式，让技术人员能深入了解相关参数。在用户界面方面，LM Studio 相比 Ollama 也更为出色。



## 针对普通人用：话不多说，直接下载

打开下载地址https://lmstudio.ai/ 下载自己电脑对应操作系统，可以看到现在MAC上的用户可以安装苹果进行优化过的MLX模型。

![图片](https://raw.githubusercontent.com/zhulg/allpic/master/640-20250101111437107)

下载前看下自己电脑配置，大部分电脑是没问题，可以下载一些小的模型就好,mac的话要M1以上的电脑。

![图片](https://raw.githubusercontent.com/zhulg/allpic/master/640-20250101111437429)

下载后，就可以打开LM Studio来进行相关模型的下载，安装后可以通过左侧的搜索来找对应的模型下载，下载后可以运行对应的模型就可以直接使用了，看起来很简单。

![图片](https://raw.githubusercontent.com/zhulg/allpic/master/640-20250101111515167)

但是...

在安装后开始搜索模型时候，列表可以看到，但无法进行下载模型。这个时候不要慌，因为https://huggingface.co/ 在国内是无法访问的。

![图片](https://raw.githubusercontent.com/zhulg/allpic/master/640-20250101111438109)

即便也有科学上网了，但是在软件内部获取模型的是通过https方式来访问的，全局代理也没有过去。

**怎么办，只能找国内的同步的镜像了，可以使用 hf-mirror.com，用于镜像 huggingface.co 域名，这样对应的模型就可以正常下载。**

我是MAC电脑，通过vscode和其他编辑器sublime text这些都可以，打开显示包内容用vscode打开文件，全局替换 huggingface.co，将 LM Studio 程序中所有使用到 huggingface.co链接的地方都搜索出来，用 hf-mirror.com 来替换，大概有5百多处（替换完后记得保存和重启软件，已经验证过没问题），如果是win用户也一样，直接找到软件安装地址，打开资源文件全局替换即可。

过了这个，就可以方便下载模型了，模型的选择可以看自己的电脑配置，其实LM studio也会根据电脑配置推荐，mac用户建议可以使用MLX的在mac上体验会更快，主要自己电脑配置要M1以上的电脑。

![图片](https://raw.githubusercontent.com/zhulg/allpic/master/640-20250101111530635)

模型下载完后，根据指引就可以直接进行加载了。

![图片](https://raw.githubusercontent.com/zhulg/allpic/master/640-20250101111541805)

模型加载后，就可以新建对话，先来进行个测试，在我箭头指示地方可以加载下载的离线模型，并开启对话。

![图片](https://raw.githubusercontent.com/zhulg/allpic/master/640-20250101111647590)

这样本地的模型就可以正常运行了，你可以跟他对话，来辅助你日常相关的工作内容，这个比较适合普通人，快速搭建自己本地的大模型。



针对互联网人：想多一些理解和使用大模型

大部分互联网和技术人，这个安装和使用的过程应该很简单，在搜索的列表里也可以看到市面上各家相关的大模型，都可以去下载尝试和对比。我们在上边也看到了这么多大模型，各种参数不同的大模型，以及大模型的相关格式，这些我们是否清楚相关的概念和原理？

我们在下载模型的时候，可以看到有标识大模型参数的B，比如Llama-3.2 1B ，Llama-3.2 2B ,  这些B代表着大模型的参数，那参数到底在大模型里是什么意思？理解这些参数可以更好地理解大模型。

这些参数以Billion为单位，刚才我下载的 Llama-3.2 1B 这意味着这个模型包含大约10亿个参数，而一个参数通常是模型的权重或偏置值，这些值在训练过程中被调整以使模型能够更好地进行预测，参数越多最后相关的结果就越准确，

比如在图形识别中可能就有百万计的参数来学习图像中的不同特征，如形状、大小、纹理、颜色等等，从而实现准确识别和分类。

这些参数不仅仅是数值，也是在训练过程中学习到并自动产生，这就需要海量的数据，产生的参数代表了模型如何理解和区分不同的输入数据，根据这些上亿维度的参数来最终给出相关预测的结果。

随着训练的深入，机器人不断调整这些参数，从而变得更加聪明，能够更好地完成任务，比如识别猫和狗，或者理解人类的对话。



总结下：概念和使用

整体通俗理解下，大模型和参数，大模型就是一个聪明的大脑，它通过观察大量数据图片、文字等你想让他学的一切，根据你让他学的东西，来转化成相关的参数（也就是数字，因为机器只认数字），每个参数帮助它理解数据的不同方面，比如颜色、形状或语言的含义。根据大量的数据训练的深入，不断产生、优化、调整这些参数，大脑就越聪明，能够更好地完成给他的命令。

普通人如果想玩AI大模型，使用 LM Studio 也是个不错的选择，可以安装和尝试多个模型在自己电脑上，这样隐私和你想问的问题也就更安全，速度也更快。

**互联网人来说，特别技术人也可以使用他提供的本地server和 lms log stream 在命令行 来看相关模型日志。**
