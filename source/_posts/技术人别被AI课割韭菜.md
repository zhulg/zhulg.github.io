---
title: 技术人别被AI课割韭菜
tags: 技术成长
categories: 技术成长
abbrlink: f452b115
date: 2024-08-29 08:17:13
---

这篇文章，或许会引起那些专门售卖AI课程者的不满。我要强调，这里说的是那些纯粹割韭菜的AI课，真正有深度和干货的课程自然另当别论。

作为技术人，你是否已经注意到这些现象？这些课程大多打着“大模型”的旗号，内容却五花八门，从AI写作、AI作图、AI编程到用AI快速赚钱等等，无所不包。

仔细分析这些课程，会发现大多数内容浅显，仅停留在表面应用。课程或许教你如何使用提示词、如何做个图、通过比喻讲解一些模棱两可原理，或教你输出一些文章，整体来看虎头蛇尾。

这些课程通常存在以下几个问题：

1. 内容浅显：大多数课程只讲解基础概念，缺乏深入的技术原理和流程环节。

2. 缺乏实践：很多课程没有实际项目的指导，或者仅通过简单例子介绍AI工具的使用。

3. 误导性宣传：有的课程夸大效果，贩卖焦虑，吸引对AI感兴趣的技术人，实际操作远非如此。

例如，之前有新闻报道某些利用AI课虚头大肆卖课割韭菜的事件，某清华教授靠卖AI课狂赚上亿，然而他本人却是门外汉，靠的就是营销割小白韭菜。

图片


**这些课程是否一无是处？也不尽然。**

对于小白用户，如果想快速了解某些概念，利用现有的AI模型和工具制作图像、视频，这些课程可能会提高工作效率。如果你懒得查资料且有经济条件购买，这类课程也许有帮助。

但对于技术人来说，这类课程并不建议。你需要防止这些课程误导你对AI和大模型产生错误认识。

仅知道概念、会使用ChatGPT等AI模型，对于技术人来说远远不够。非技术人如果掌握了提示词的使用，可能比你还会操作，毕竟现在国内也有很多出名的大模型产品，包括百度的文心一言、字节的抖音豆包大模型、腾讯的混元大模型、百川智能的百川大模型、Kimi和科大讯飞的星火大模型等等，一些写作类用户可能使用的更为溜一些。

技术人学习大模型技术，可以结合自己的情况和发展方向选择一些入门基础课程。以下是我认为需要学习和了解的内容：

首先，如果你是计算机专业出身或从事技术工作，应了解数学、统计学和编程语言。大模型时代使用较多的是Python语言，但语言只是工具，不要局限于此。

了解AI大模型的相关名词和概念，它们之间的关联和关系，比如以下这些术语：

• AI (Artificial Intelligence): 模拟人类智能的计算机系统。

• Machine Learning (ML): 通过数据训练模型，使计算机能够自动学习和改进。

• Deep Learning: 使用神经网络进行的机器学习，通常具有多层架构。

• Neural Network: 模仿人脑结构的计算模型，用于识别模式和预测。

• Natural Language Processing (NLP): 计算机处理和理解人类语言的技术。

• Training Data: 用于训练机器学习模型的数据集。

• Model: 通过训练算法从数据中学到的数学表示，用于预测或分类。

• Algorithm: 一组用于解决特定问题的规则或步骤。

• Transformer: 现代NLP中的重要模型架构，依赖于自注意力机制。

• GPT (Generative Pre-trained Transformer): 一种生成式预训练语言模型，用于生成文本。

其次，了解原理后，需要深入学习大模型所使用的相关技术，如神经网络、卷积神经网络（CNN）、循环神经网络（RNN）、生成对抗网络（GAN），以及用于文本处理的NLP、图像识别的计算机视觉。深入理解Transformer模型的结构和工作原理，学习大模型的训练方法和技巧，如分布式训练、混合精度训练等，学习如何优化大模型的性能和调优超参数。

### 最重要的事，自己动手实践。
可以搭建一些开源大模型，用本地的CPU进行部署，学习API相关调用，进行数据准备和预处理、模型推理和结果解析等操作。通过这些实践，你会对大模型有更深入的理解。对于技术人来说，这还只是知道大模型在每个步骤大概的工作方式。

技术人学习AI大模型，先理解其工作原理，再去做开源模型部署和调参数以及服务的对接，确实大多数技术人不从事底层大模型开发，但在应用层开发和使用大模型技术时，要多要思考大模型技术如何服务于当前的产品，并与未来的产品业务形态结合，提高效率。

技术人不要被市面上贩卖焦虑的AI韭菜课所迷惑。 任何技术都有连续性，不是凭空冒出来的新技术，脚踏实地学习技术本质才能实现更多的结合与创新。