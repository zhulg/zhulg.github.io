{"pages":[{"path":"/404.html","date":"05-05","excerpt":""},{"path":"about/index.html","date":"07-07","excerpt":""},{"path":"books/index.html","date":"07-07","excerpt":""},{"path":"categories/index.html","date":"07-07","excerpt":""},{"path":"links/index.html","date":"07-07","excerpt":""},{"path":"repository/index.html","date":"07-07","excerpt":""},{"path":"tags/index.html","date":"07-07","excerpt":""}],"posts":[{"title":"教师工具集，专为教育工作者打造的免费工具导航站","text":"作为一名开发者，我身边有很多从事教育工作的朋友。每次和他们聊天，我总能深切地感受到一个普遍的“痛”：我们这个时代不缺好工具，但缺的是找到好工具的时间。 你是不是也经历过这样的场景？ 为了准备一堂重要的公开课，你可能需要： 打开A网站，寻找精美的PPT模板； 切换到B网站，使用AI工具润色讲稿，思考如何把知识点讲得更有趣； 在C、D、E网站之间反复横跳，只为找到一张高清、无版权的教学配图； 最后，你可能还想用F工具，做一个吸引学生注意力的开场小视频…… 一堂课下来，你的浏览器收藏夹又增加了十几个新网址，但宝贵的备课时间也在无数次的“搜索-注册-试用”中悄然流逝。 我们需要的，或许不是又一个“革命性”的工具，而是一个能把所有好工具都收纳整齐的“私人工具箱”。 正是基于这个想法，我利用业余时间，开发并搭建了一个完全免费的网站——“教师工具集” (Teacher Toolset)。 网站地址: https://www.teacher-toolset.online/ 它不是一个需要你学习的复杂软件，恰恰相反，它的唯一目的，就是让你“即用即走”，在最短的时间内，找到最适合你当前教学场景的那个工具。 场景一：当你要准备一节公开课公开课是展现教学功底的舞台，每一个细节都想尽善尽美。这个网站的【创作工具】和【AI工具】分类，就是你的“军火库”。 想让PPT制作更高效？ 你可以找到像 Gamma 这样的AI工具，只需输入你的课程大纲，它就能在几分钟内为你生成一套设计精良、图文并茂的演示文稿。 需要一张独特的配图？ 【创作工具】里的 Midjourney for Educators 能帮你用AI画出任何你想象中的教学场景，告别千篇一律的素材库。 想用视频开场？ Synthesia for Teachers 可以让你用AI数字人快速生成一个欢迎视频或课程介绍，给学生带来耳目一新的感觉。 场景二：当你想让日常备课更轻松日复一日的备课工作，最需要的就是“效率”。网站的【AI工具】分类，就像你的智能备课助理。 没灵感时：MagicSchool.ai 或 Teacherbot 能帮你快速生成教学大纲、课堂活动点子，甚至是期末评语。 写讲稿时：ChatGPT for Education 或 Gemini for Education 是你最好的文字润色伙伴，帮你把晦涩的知识点变得通俗易懂。 需要分层教学？ Diffit 这个工具能将同一份阅读材料，一键适配成不同难度的版本，轻松满足不同学生的学习需求。 场景三：当你需要管理班级或评估学生教学不只在课堂。网站的【教学管理】和【评估】分类，也能帮你处理繁杂的课后工作。 想快速出几套练习题？ Quizgecko 这样的AI出题工具，可以根据你指定的知识点，自动生成选择题、填空题，省去大量手动录入的时间。 需要与学生协作？ 【协作】分类下的工具能帮你组织在线讨论或小组项目。 我的初心：用技术为教育做一点小事你可能会好奇，我为什么要做这样一个网站。 其实很简单。我看到我身边的老师朋友们，他们对教育充满热情，却常常被这些琐碎的、重复性的技术工作所累。他们是教育的专家，却不应该是“搜寻工具”的专家。 作为一个从技术中获益的开发者，我总想着，能不能用我的专业能力，为他们做一点实实在在的贡献？ 于是，“教师工具集”诞生了。我没有想过用它来盈利，它现在、未来都会是一个完全免费、无广告的纯粹的资源导航站。我所做的，就是持续地关注教育科技的最新动态，将那些真正好用、能提升效率的工具，一个个筛选、整理、收录进来。 邀请你，成为这个“工具箱”的共建者这个网站还很简单，但它是一个开放的、正在成长的生态。 我真诚地邀请每一位看到这篇文章的老师，来体验一下这个小小的网站。希望它能像一个安静的图书管理员，在你需要的时候，帮你快速找到那一本你最想看的书。 如果你在使用中发现任何问题，或者有更好的工具推荐，都非常欢迎你通过网站上的提交收录方式进行提交。 让我们一起，把这个“教师工具箱”建设得越来越好用，让技术真正成为我们教育工作中的得力助手，而不是负担。","path":"posts/9bac213c.html","date":"11-07","excerpt":"","tags":[{"name":"教师工具","slug":"教师工具","permalink":"https://zhulg.github.io/tags/教师工具/"},{"name":"教育信息化","slug":"教育信息化","permalink":"https://zhulg.github.io/tags/教育信息化/"},{"name":"AI教育","slug":"AI教育","permalink":"https://zhulg.github.io/tags/AI教育/"},{"name":"效率工具","slug":"效率工具","permalink":"https://zhulg.github.io/tags/效率工具/"},{"name":"教学资源","slug":"教学资源","permalink":"https://zhulg.github.io/tags/教学资源/"}]},{"title":"N8N教程：搭建公众号自动化写作工作流完整指南","text":"最近我用N8N搭建了一套公众号自动化写作系统，效率提升得让我自己都惊讶——从选题到成稿，整个流程压缩到了几分钟。 具体来说，我只需要输入一个内容主题，系统就能自动完成：文章撰写、爆款标题生成、配图匹配、排版美化，最后直接推送到公众号草稿箱。我要做的，只是最后检查一遍，点击发布。 虽然技术上完全可以实现批量自动发布，但考虑到内容质量和平台规则，我还是保留了人工审核这一步——毕竟，好内容值得多一分关。 N8N到底是什么？N8N 是一款强大的可视化自动化工具。你可以把它想象成一个“数字流程的乐高积木盒”。通过拖拽不同的功能“节点”（例如数据处理、网络请求、AI模型调用等），你可以将过去需要编写大量代码才能实现的复杂任务，用一个清晰的工作流连接起来，快速实现功能。 最棒的是，N8N 对新手非常友好，不一定需要编写代码，会拖拽和理解节点之间的数据传递就足够了。当然，对于高手，它也允许你在关键节点写入自定义代码，实现更复杂、更个性化的业务逻辑。 为什么要用N8N实现自动化写作？在深入搭建步骤之前，我们先明确这个工作流解决了哪些痛点： 时间成本：从构思、写作、找图到排版，一篇文章耗时巨大。 创意瓶颈：有时难以想出吸引人的标题和切入点。 重复劳动：每次都要手动调整格式、上传图片、复制粘贴。 我们的目标就是将这些重复且耗时的环节交给机器，让我们能专注于最有价值的“创意”和“审核”工作。 如何搭建：核心步骤详解首先，你需要在本地或服务器上安装 N8N。官方文档提供了详细的 npx 和 docker 安装方式，过程非常简单，这里不再赘述。 我们直接进入核心，分享这个自动化工作流中关键节点的搭建思路。 步骤1：启动工作流并接收主题在本地打开 N8N (例如 http://localhost:5678/)，你会看到一个空白的画板。我们的第一步是创建一个 Manual（手动）或 Webhook 触发器。在这里，我们使用一个 Chat Message 节点，它会弹出一个对话框，让我们能够方便地输入本次写作的核心主题。 步骤2：创建核心AI Agent并配置大模型AI Agent 是整个工作流的大脑。在 N8N 中，一个 Agent 节点集成了大模型（Chat Mode）、记忆（Memory）、工具（Tools）等能力。 添加大模型：在 Agent 节点中，点击 “Chat Mode” 添加一个大模型。N8N 支持 OpenAI、Gemini、Ollama 等多种模型。我这里选择的是 Gemini，因为它提供了慷慨的免费额度，足以满足日常使用。 配置API Key：你需要去你选择的大模型平台（如 Google AI Studio）获取 API Key，并将其添加到 N8N 的凭证库中。这样，N8N 就能代表你调用大模型的能力了。 步骤3：设定System Message（系统提示词）这是最关键的一步，它决定了 AI 的表现。System Message 就像是给 AI 下达的“岗位职责说明书”。 我的原则是：尽可能把任务描述清楚，让 AI 一次性输出结构化的数据。这样可以省去后续大量的数据处理节点。 我的 System Message 核心内容如下： 12345你是一个资深的公众号文章专家，擅长撰写爆款技术教程。请根据用户提供的主题，完成以下任务：1. 生成一个吸引人的文章标题。2. 撰写一篇约800字的文章正文，结构清晰，包含引言、核心步骤和总结。3. 根据文章内容，提炼出一个适合用作AI绘画封面图的英文Prompt。4. 将以上所有内容，以一个完整的JSON格式返回，格式为：&#123;&quot;title&quot;: &quot;文章标题&quot;, &quot;content&quot;: &quot;文章正文...&quot;, &quot;image_prompt&quot;: &quot;英文绘画提示词&quot;&#125; 这一步完成后，我们就从 AI 那里得到了所有需要的原始素材：标题、正文、图片描述。 步骤4：调用文生图API，生成封面图拿到 image_prompt 后，我们用一个 HTTP Request 节点来调用 AI 绘画模型的 API。 这里我使用的是阿里云百炼的通义文生图接口，同样有免费额度。配置方法类似： 在阿里云获取 API-Key 并添加到 N8N 凭证库。 在 HTTP Request 节点中，设置好请求的 URL、Method (POST)，并按照其 API 文档，将 image_prompt 作为参数传入请求体 (Body) 中。 执行成功后，这个节点会返回一个包含图片 URL 的数据，我们将其保存下来用于下一步。 步骤5：安装社区节点，上传素材到公众号为了和微信公众号后台交互，我们需要一个强大的“连接器”。 安装社区节点：在 N8N 的设置 (Settings) -&gt; 社区节点 (Community Nodes) 中，搜索并安装 n8n-nodes-wechat-offiaccount。这个节点包提供了非常完善的公众号操作功能。 配置公众号凭证：你需要先在公众号后台的“基本配置”中找到自己的 AppID 和 AppSecret，并添加到这个社区节点的凭证中。 上传图片素材：使用该节点包中的“新增素材”功能，将上一步获取的图片 URL 上传到公众号的素材库，从而得到一个 thumb_media_id。 步骤6：整合内容并提交草稿这是最后的临门一脚。我们使用“新增图文草稿”节点，将之前准备好的所有材料组装起来。 一个常见的“坑”是，直接提交的文本内容排版可能会很乱。我们需要在提交前对内容进行转义处理，确保格式正确。在最终提交的 JSON 数据中，content 字段需要特殊处理： 123456789101112[ &#123; \"article_type\": \"news\", \"title\": \"&#123;&#123; $('AI Agent').item.json.output.title &#125;&#125;\", \"author\": \"良技漫谈\", \"content\": \"&#123;&#123; $json.data ? $json.data.replace(/\\/g, '\\\\').replace(/\"/g, '\\\"').replace(/\\n/g, '\\n') : '' &#125;&#125;\", \"thumb_media_id\": \"&#123;&#123; $('提交素材到公众号').item.json.media_id &#125;&#125;\", \"show_cover_pic\": 1, \"need_open_comment\": 1, \"only_fans_can_comment\": 0 &#125;] 执行这个节点后，一篇包含标题、作者、正文和封面图的文章就自动出现在你的公众号草稿箱里了！ 总结：自动化不是终点，而是创作的“加速器”通过这套 N8N 工作流，我将过去需要数小时的重复性劳动——写作、构思、配图、排版——压缩到了几分钟。这并不意味着创作的结束，恰恰相反，它让我能将更多精力投入到最有价值的环节：创意构思、事实核查和内容润色，确保每一篇文章都兼具效率与品质。 如果你也对提升内容创作效率感兴趣，不妨尝试用 N8N 搭建一套属于你自己的自动化流程。它还可以扩展到更多场景，比如： 热点选题：定时抓取行业新闻网站，让 AI 自动分析并生成选题建议。 智能配图：根据文章段落内容，自动生成并插入多张相关的说明性图片。 数据驱动优化：将已发布文章的阅读数据（如阅读量、点赞数）回传到 N8N，让 AI 分析爆款规律，从而指导未来的创作方向。 自动化不是为了取代思考，而是为了给思考插上翅膀。希望这篇指南能为你打开一扇新的大门。","path":"posts/52630d3b.html","date":"11-03","excerpt":"","tags":[{"name":"效率工具","slug":"效率工具","permalink":"https://zhulg.github.io/tags/效率工具/"},{"name":"N8N","slug":"N8N","permalink":"https://zhulg.github.io/tags/N8N/"},{"name":"自动化工作流","slug":"自动化工作流","permalink":"https://zhulg.github.io/tags/自动化工作流/"},{"name":"AIGC","slug":"AIGC","permalink":"https://zhulg.github.io/tags/AIGC/"},{"name":"公众号运营","slug":"公众号运营","permalink":"https://zhulg.github.io/tags/公众号运营/"},{"name":"Gemini","slug":"Gemini","permalink":"https://zhulg.github.io/tags/Gemini/"}]},{"title":"可以展示照片的浏览器tab页插件:《NewTab时光》发布","text":"起因：那些照片背后的温度每天我们都在电脑前工作、学习，屏幕上堆满了窗口、任务、文件。可偶尔，当我看到一张家人的合照、一次旅行的瞬间，或者那只睡在沙发上的猫，我会突然想起生活里那些被遗忘的温柔。 于是我就想：能不能让每次打开浏览器新标签页，都能看到这些瞬间？既治愈，又私密。不依赖网络，不用上传到任何地方。 这就是我开始开发 NewTab 时光 的原因。 开发初衷：安全地“重温”生活很多壁纸或新标签页插件虽然好看，但都依赖云端加载，甚至要求登录。我不想让私人照片离开自己的电脑。我希望有一个属于每个人自己的小角落，只展示属于“我”的回忆。 所以我决定开发一个完全本地运行的新标签页插件。在 NewTab 时光 里，你只需选择一个照片文件夹，它就能自动在本地轮播这些照片，无上传、无采集，纯粹、安心。 功能亮点：简洁而温暖 🌅 本地加载，更安心：图片不上传云端，100%保护隐私。 🖼️ 多图轮播切换：自动播放你最爱的照片，让浏览器也有温度。 ✨ 极简界面：干净自然，不干扰日常浏览。 🎞️ 柔和动画过渡：切换时流畅自然，轻盈不突兀。 ⚙️ 轻量设计：占用资源极少，启动即展示。 使用场景：工作与生活的治愈间隙在忙碌的一天里，当我在写代码或查资料时，打开新标签页看到家人的笑容、旅途的风景，那种片刻的治愈就像生活轻轻地对你说：“放松一下。” 也有朋友告诉我，他们用它展示孩子成长的照片、用它回忆旅行、甚至用它做“心愿相册”。每一次打开浏览器，都是一次和记忆的相遇。 安装体验你可以直接在 Chrome 应用商店安装：👉 NewTab 时光 - Chrome Web Store 点击安装后，只需选择你的照片文件夹上传喜欢的找，即可体验属于你的“浏览器时光”。如果无法安装可以找我要软件包，通过关注公众号联系我。 为什么我做这个插件我一直相信，技术不仅仅是冷冰冰的工具，它也可以承载温度，让我们与生活的关系变得美好！ NewTab 时光 对我来说，不只是一个插件，更像是一种“数字温情”的表达。在AI、效率、自动化的浪潮里，它提醒我别忘了生活的光——那些属于家的、笑容的、平凡的片刻。 生活，也该有柔光有时候，我们需要的不只是效率，还有一点温柔。希望这款小插件，也能在你的日常里，带来片刻的宁静与微笑！在你被工作中疲惫不堪时，可以从这些照片中获得温柔的力量！","path":"posts/40058c60.html","date":"10-18","excerpt":"","tags":[{"name":"Chrome插件","slug":"Chrome插件","permalink":"https://zhulg.github.io/tags/Chrome插件/"},{"name":"浏览器壁纸","slug":"浏览器壁纸","permalink":"https://zhulg.github.io/tags/浏览器壁纸/"},{"name":"隐私保护","slug":"隐私保护","permalink":"https://zhulg.github.io/tags/隐私保护/"},{"name":"New Tab","slug":"New-Tab","permalink":"https://zhulg.github.io/tags/New-Tab/"},{"name":"家人照片","slug":"家人照片","permalink":"https://zhulg.github.io/tags/家人照片/"}]},{"title":"Vibe Coding普通人也可以学的编程技能","text":"Vibe Coding：用自然语言创造软件的新方式自从 2023 年 AI 技术爆发以来，“AI 编程” 已经从实验室话题，变成了很多人日常使用的能力。 过去，写代码是程序员的专属领域，门槛高、技术性强。但今天，AI 工具让普通人也能快速构建出能运行的产品。 有个朋友最近在做产品原型验证，他把收集到的数据丢给 AI，仅用简单的对话方式，AI 就帮他自动生成了表格和可运行的脚本。他惊叹地说：“我只是描述了需求，结果 AI 就把数据和 demo 都整好了——这还要什么程序员？” 这正是如今兴起的概念——Vibe Coding。 一、什么是 Vibe Coding？简单来说，Vibe Coding 是一种 用自然语言与 AI 协作开发的方式。你不需要掌握复杂的语法，也不用规划系统架构，只要清楚地描述需求，AI 就能帮你完成从代码到产品的转化。 它不是追求代码的优雅或架构的精致，而是追求 “快速把想法变成可用的结果”。这对普通人来说，是第一次能“用说的方式写代码”。 二、为什么现在必须开始学习 Vibe Coding？观察身边的人就能发现变化：写作、资料查找、甚至创意生成，大家都不再依赖搜索引擎，而是直接和 AI 对话。 在各行各业，这种趋势更明显。比如自媒体创作者，他们用 AI 自动转录音频、提炼金句、生成脚本；设计师只需一句话就能让图片自动修复；数据分析师用自然语言让 AI 生成表格模板。 而这些操作，本质上都属于 Vibe Coding 的实践——用对话的方式完成原本需要写代码的事。 如果你还没开始，这意味着你正在错过一个生产力迁移的窗口期。今天会“调度 AI”的人拥有优势，明天这可能就成了每个人的标配能力。 三、Vibe Coding 的核心：清晰描述需求很多人抱怨 “AI 不好用”“生成的结果不准”，其实问题往往出在描述不清。 AI 的理解来自语义，而非逻辑。因此，想让它理解你，你必须学会把模糊的想法变成清晰的任务： 输入是什么？ 输出是什么样？ 成功的标准是什么？ 有哪些不要出现的内容？ 这些都属于 Vibe Coding 的基本功。描述得越清楚，AI 执行得越准确。 四、普通人如何开始 Vibe Coding？Vibe Coding 并不是程序员的专属技能。它更像是一种“把需求说清楚，让AI帮你实现”的能力。 以下是几个简单的练习方向： 1. 从生活出发想分类硬盘照片？让 AI 帮你写脚本按日期或人物自动整理。想汇总账单？用 Vibe Coding 生成能读取文件并统计数据的脚本。 2. 从工作出发自动化重复操作，如导表、清洗数据、生成报告。让 AI 生成专属的小工具，提高效率。 3. 积累工具库每解决一个问题，把提示词、代码、踩过的坑都记录下来，慢慢形成自己的“AI 工具库”或“Vibe 模板库”。这些是属于你个人的生产力资产。 五、遇到问题怎么办？AI 并非完美的程序员。你可能会遇到报错或逻辑不符的问题。解决方法是 把错误、目标、尝试过程一起交给 AI，让它重新分析你的需求。 如果仍然无解，那就拆解任务：不要让它一次写完整功能，而是让它先写“读取文件”的部分，再写“分类逻辑”，逐步组合成最终版本。 这其实就是 Vibe Coding 的精髓——分步构建、逐步协作。 六、写在最后Vibe Coding 并不是取代程序员的魔法，而是一种新的编程思维。它让编程门槛大幅降低，让更多人能直接把想法变成现实。 无论你是否懂代码，都可以从日常问题入手，通过与 AI 的协作，打造属于自己的工具。 而 N8N 正是实现这种 “Vibe Coding” 理念的绝佳平台。如果你想看一个完整的实战案例，了解如何将一个想法通过可视化拖拽变为强大的自动化流程，可以阅读我的这篇《N8N教程：搭建公众号自动化写作工作流完整指南》。越早开始，你就越早积累属于自己的模板、脚本和经验。 而对于技术人来说，Vibe Coding 更像是一次效率革命——你能更快验证想法，更快产出结果，更快进入创造的状态。 未来，人与 AI 协作的方式会越来越自然。当你习惯了 Vibe Coding，你会发现：只用几句自然语言，也能让 AI 成为你的得力伙伴。","path":"posts/4a3d5e89.html","date":"10-18","excerpt":"","tags":[{"name":"AI编程","slug":"AI编程","permalink":"https://zhulg.github.io/tags/AI编程/"},{"name":"Vibe Coding","slug":"Vibe-Coding","permalink":"https://zhulg.github.io/tags/Vibe-Coding/"},{"name":"自然语言编程","slug":"自然语言编程","permalink":"https://zhulg.github.io/tags/自然语言编程/"},{"name":"自动化","slug":"自动化","permalink":"https://zhulg.github.io/tags/自动化/"},{"name":"Prompt工程","slug":"Prompt工程","permalink":"https://zhulg.github.io/tags/Prompt工程/"}]},{"title":"2025年，普通人如何在1个月内熟练使用AI","text":"2025年一定是AI领域齐头并进之年，AI基础大模型的突破不再是几个月的周期，已经到了按月周刷新速度。 从春节期间DeepSeek的爆火可以看出，国内大模型的技术也迅速实现了弯道超车，从技术创新另开辟新道，突破技术封锁。一举成名的同时，给ChatGPT也带来了不少压力,这场AI大战，谁主沉浮？ 你刚唱罢我登场的感觉，现在ChatGPT-5也会马上发布，DeepSeek也迎头赶上，Qwen也在憋大招。技术的迭代和推理能力的提升，带来了前所未有的应用创新，AI的落地速度远超我们的想象。 2025刚刚开始，AI的创新发展已经让普通人应接不暇，如果对AI的学习的话，不知道有没有这种感觉。AI学不完，根本学不完，今天学的技能，明天很可能就被新的AI能力所替代。 AI的应用场景也正在悄然渗透到各行各业，并逐步改变我们的生活和工作方式。尽管看起来还没超级应用出现，但我觉得，这样的应用会在不久的将来遍布各行各业。它们将充分发挥大模型的优势，在各个垂直领域做到极致，而我们每个人，都有机会成为这一革命的参与者。 对于普通人，如何在1个月内熟练使用AI？ 想分享下自己的一些看法，经过最近的AI研究学习，AI发展很快，想在一个月内掌握AI，普通人不可能在各个领域的运用都能掌握，要选择自己业务方向来结合AI。（今天分享主要针对普通人使用AI，非IT技术人） 基础原理和概念我们想学习和使用好AI，就需要先进行对他的原理和概念要有所了解，可以花一周左右时间来研究。 知道AI的一些关键名词概念，知道大语言模型、多模态、数据、算力、算法、预训练等，了解来龙去脉当做历史来知道，可能不需要太过技术性深入，但要知道目前的AI是怎么训练出如此智能的，围绕AI的这些概念是指的什么、他的智能是怎么经过大量知识收集学习和训练而来，有些不智能的地方你要知道为什么有幻觉情况 这样有了原理性认识，无论AI再怎么发展，你也知道他原理，对他的理解和使用也能足够认知，知道他强大的地方，也知道他目前的能力缺陷。 AI使用场景和选择普通人对AI的使用要选择直接感兴趣和自己所在行业的业务有充分结合的地方。先举个例子，如果你是一个设计师主要做一些图形的设计，那你用AI的地方，可能就是如何通过AI来帮你做一些设计灵感，绘图帮助，以及哪些在你们专业里特定的协作工作来让AI。 AI可以在各个领域发挥能力，但也一定是所在这个行业的人更具备充分挖掘和使用他的能力，否则你连行业名词都无法描述，AI也就给不出更专业的协助。 目前AI的场景很多，比如文案类工作、媒体类工作、图形类工作、编程类工作这里会有很多的垂直赛道。拿文案类来说，他会涉及到教学教案，工作计划，活动方案、自媒体文章，行政通知类等等，这些场景的选择每一个行业都有一些差异。比如你做营销类文案，就要考虑行业信息，读者受众，语言风格等因素，要把这些知识给到AI，当把给你生成相关文案时，你需要引导和修改一起完善，把他当做你的助手，发挥他的能力，这样用AI才是最有效的。 这个场景的选择和使用可能需要磨合个1-2周的时间，当你想要通过AI获得有效的帮助时，要学会提示词技巧，并进行使用的总结，什么样的描述和专业prompt能获得最专业的指导，可以每天进行使用验证。 瞄准一个AI赛道深入学习AI学习的选择不要过多涉足赛道，尝试后瞄准一个AI赛道，你可以选择文案、也可以选择AI绘画、可以选择视频制作、也可以选择AI编程赛道，如果你有音乐感兴趣可以选择音乐结合AI。 切记，不要觉得AI绘画好看，就扑到绘画来玩，视频好玩就扑到AI视频上，要选择自己喜欢赛道深入学习，如何制作出更高级的一般人做不出来的，才是AI结合兴趣使用之路，否则简单的描述，只能产生一些玩一玩的作品，当AI新的应用出来后，这些技能可能一文不值。 深入学习要对这个赛道内的动态和使用方式充分了解，最重要的是实践，能直接为你产生收益或者提效的，如果对做互联网产品感兴趣，可以学习AI编程，这样进入这个领域就不要看其他AI赛道，但要关注AI基础模型的发展。 现在应用层的AI工具也比较多了，而且也比较好上手，花上一周时间完全可以入门，剩下就是在使用的过程中进行熟练挖掘，现在无论是ChatGPT还是DeepSeek都是你很好的学习助手，你不知道的一些AI工具也完全可以通过他来获得。 比如我问他我想学AI绘画，你可以通过问他来获得相关应用推荐。一定是根据自己的行业来选择学习，瞄准赛道。 不被夸大的AI能力误导虽然AI的能力在快速进化，但我们也要清醒地认识到，目前确实存在一些泡沫，无论是资本的助推，还是媒体的过度宣传，都会让人误以为AI的能力无所不能。然而，AI的实际应用能力确实正在稳步提升，且不断创新。 对于普通人来说，学会AI的关键，是找到与自己业务最紧密结合的方向，发挥AI在自己擅长领域的最大效能。AI的提效功能已经在各行各业落地，并且在短短一个月内，你完全有可能通过深入学习，找到自己与AI结合的独特路径。 重要的是，不要被夸大的信息所干扰，频繁切换赛道。你对自己的行业已经有了深刻的理解和经验，借助AI，你能够在现有基础上再次提升自己的竞争力和创造力。","path":"posts/4b7fcf21.html","date":"07-21","excerpt":"","tags":[{"name":"AI","slug":"AI","permalink":"https://zhulg.github.io/tags/AI/"}]},{"title":"实测 Google Gemini CLI：从安装到使用体验，AI 命令行也开始卷起来了","text":"Google这两天刚推出了Gemini CLI，它是一个基于 Gemini 模型构建的 AI 命令行助手（Agent），支持本地运行、插件拓展，还能调用 Gemini 2.5 Pro 模型。重点是免费使用，限额相当豪横，卷的起飞的节奏。 说起命令行的工具，可能更适合技术人员使用，使用起来也很高效，想起当时Chatgpt刚刚爆火的时候，各种登录不上，网络无法连接，地区封号等，于是我也写了个基于ChatGpt的CLI工具，可以直接访问大模型API，直接有效，深受好评！ 无图无真相，截个图: 运行截图： 不自恋了，今天看看现在Google现在推出的 gemini CLI 效果到底如何。 官方介绍： 使用gemini CLI, 我们只需使用个人 Google 帐户登录即可获得免费的 Gemini Code Assist 许可证，同时也打通了 Gemini Code Assist 也可以在vscode里安装插件来使用。 最吸引我们的应该是这个图，允许访问 Gemini 2.5 Pro 及其庞大的 100 万个令牌上下文窗口，提供了业界最高的限额，每分钟 60 个模型请求，每天 1,000 个请求，均免费。 这个对于目前在使用付费版的AI工具来说最为吸引人，还付什么费用。这真正卷起来，对个人使用者来说也是白嫖了。 1. 快速安装Gemini 安装步骤：命令行运行该命令即可，当然npm是需要安装过的。 1npm install -g @google/gemini-cli 安装完成，可以选择自己登录方式，如官网介绍，直接使用google账号进行登录； 登录成功后，可以通过 / 来查看相关的菜单使用说明，比如：设置自己喜欢的Theme 可以在命令行执行gemini来看下效果： 比如，查看目前Gemini可用的工具：输入框输入 /tools 2. 实测：生成一个设计师个人介绍网页 我们先让他实现个人介绍的网页，告诉他这个是为一名设计师来设计的网页，必然需要的效果要好一些。 先在自己命令行下，创建对应的目录： 12mkdir testGeminicd testGemini 然后我们执行 gemini命令，把我们需要的需求直接输入，当然如果我们的prompt简单，那是无法让他完我们很好的设计。所以基于他强大的token能力，我们先让写prompt然后再进行让他代码实现。 12345678910111213141516171819202122232425262728293031323334353637383940 请帮我为一位设计师生成一个完整的个人介绍网页，包含内容文案、网页结构建议和代码实现。设计师擅长品牌设计、UI/UX、网页视觉，熟练使用 Photoshop、Figma、Illustrator，注重极简美学和用户体验。设计风格要求：整体视觉简洁、清新、克制主色调为“豆沙绿”（偏柔和自然的绿色系）字体现代、留白充分，具备高级感页面结构包括：顶部导航栏：左侧为个人 logo 或名字，右侧为导航链接（如“关于我 / 项目 / 联系我”）自我介绍区：圆形头像一句简洁的个人定位（如“热爱极简的 UI 设计师”）一段不超过 120 字的自我简介（自然、亲切，突出设计理念和经验）技能展示区：用图标或小标签的形式展示常用工具（Photoshop、Figma、Illustrator）强项（品牌设计 / UI 设计 / 视觉表达等）项目展示区：展示 3~6 个代表性项目，每个项目包含：项目名、一句话说明、我的角色、缩略图（可占位）排版美观，可卡片式或网格展示联系我模块：邮箱地址、Behance / Dribbble / GitHub 链接可选微信二维码（打赏或合作联系），加一句简洁友好的提示语，如“欢迎交流合作 👋”技术要求：使用 HTML + TailwindCSS（或 React + TailwindCSS）实现页面需要响应式设计，在移动端和桌面端都美观易读添加轻微的动画效果（如卡片悬浮、淡入动画等，可使用 Framer Motion 或 CSS）输出内容请包括：一段适合放网页上的“个人简介文案”一组技能/工具标签内容三个示例项目的介绍（项目名 + 简要描述 + 我的角色）网页代码实现（HTML 或 React，配合 TailwindCSS）自定义豆沙绿配色方案（Tailwind 的自定义颜色变量）若支持，添加打赏/联系合作二维码模块（占位图即可） 执行中间我们需要确认下即可。 最后生成的效果如下： 3. 文件操作能力： 这个应该是google的基因和强项，涉及搜索，抓取和总结能力。 提示失败，需要安全验证，我们先试用另外一篇文章看看。 做这个验证，其实我们就可以通过命令行来批量操作，很多东西就可以实现。（懂技术就应该能领悟到我们可以用这个来做什么） 4.代码定位修复能力 我们通过@来在当前目录下，告诉gemini CLI 需要把我们之前的页面的元素进行修改，查找和定位能力应该也比较快和准。 当然这对于 Gemini 2.5 Pro 代码能力来说应该是小菜一碟。 4. 验证情况总结 整体来看，Gemini CLI 作为一个开源的 AI 命令行助手，已经展示出不俗的潜力，特别是在代码生成、本地文件操作、插件扩展等方面，体现出了 CLI 工具的独特优势。 不过，结合实际体验，也暴露出一些不足之处： 在生成网页代码等任务时，响应时间较长，虽然这是大模型“深度思考”的副作用，但相比 Cursor 等现有工具，速度感受上明显要慢一拍。 Gemini CLI 支持通过 @文件路径 操作本地文件，这本应是命令行工具的一大优势，但在我测试过程中，频繁操作时偶尔会出现界面卡顿甚至中断的情况，影响使用流畅性。 部分功能尚未开放或不稳定，例如文档中提到的 MCP接入，目前尚未成功验证，工具也偶尔报错或无响应。作为刚发布的版本，Gemini CLI 还需要时间完善生态和稳定性。 尽管如此，我依然认为它是一个值得关注的新工具： CLI 工具的使用门槛虽然比 Web 高一点，但对于习惯终端工作的开发者来说，Gemini CLI 是一个极具潜力的 AI 助手。 它的开源策略、大模型接入能力、插件化扩展方向，技术人员的使用，相信****终端里的 AI 智能体，也是未来的一种技术流的交互方式。**** CLI的方向就是一个让技术人员用起来更爽，操作更直接，命令行有自己的独特优势，虽然有一些小小失望，但相信gemini CLI会快速壮大，相信Google的技术实力，也相信他的开源必将更多人参与贡献。","path":"posts/e3022ca1.html","date":"07-19","excerpt":"","tags":[{"name":"AI","slug":"AI","permalink":"https://zhulg.github.io/tags/AI/"}]},{"title":"写给普通人的DeepSeek介绍和使用，以及DeepSeek是不是抄袭了ChatGPT?","text":"DeepSeek不需要使用科学上网，普通人就可以使用，模型也是开源的，不用付费，而且APP现在在国内应用商店可以直接下载，这样就更容易被大众和普通人所使用，也难怪被推到了APP下载排行第一。 春节期间DeepSeek的火爆程度，普通人应该也都刷到了相关新闻。在走亲访友期间，也有不少亲戚询问 “DeepSeek这个到底是什么厉害的东西，抖音和新闻上铺天盖地宣传，听说超过了美国…” 简单来说是基于人工智能技术做的一个智能助手，可以帮助解答和解决一些你想知道的问题。当然，我这个回答比较通俗和简单，而DeepSeek做的远不止这些。也不是简单的问答，更多会在行业里进行场景重构(这个后边进行分享，不在本文展开) 至于说超过美国，他们指的是openAI的ChatGPT吧，如果从技术角度看DeepSeek确实已经与ChatGPT不分上下，但是openAI的chatGPT是不开源的，也需要科学上网，很多人都无法使用。 普通人怎么使用？在开始使用DeepSeek之前，需要做一些最基础准备工作，确保你使用的是支持互联网连接的设备，无论是手机还是电脑，都能轻松接入DeepSeek的世界。账号信息准备好常用的邮箱地址或手机号码，用于注册和验证你的DeepSeek账号（直接用手机号注册最推荐）。 注册方式：DeepSeek提供了多种注册方式，打开DeepSeek官网 https://www.deepseek.com 可以使用微信直接登录，或者手机号进行注册和登录，和使用其他软件没什么区别，注册下即可。 如何使用 DeepSeek基础操作：登录 DeepSeek 打开DeepSeek官网或相关入口，在登录页面输入你的邮箱/手机号和密码，点击“登录”按钮。 进入主界面：登录后，你将看到DeepSeek的主界面，这里包括对话框、功能菜单和个人中心，界面友好，操作直观。 使用的领域举例在自媒体领域进行创作并给与相关的指导建议： 你可以这样问DeepSeek，“我是一名自媒体创作者，我想做心理疗愈方面相关文章，你有什么好的建议” ，当然也可以换成其他你的领域，我是XXX,我想xxx, 希望你给我XXXX。 类似的行业，你可以做教育学习、美食烹饪、转绘视频等等。 比如：我想为家人做年夜饭，你有什么好建议？你可以这样问DeepSeek，正常情况下，他要比ChatGPT可能更懂中文。 如果你在其他行业和领域，比如金融，营销行业、销售、行政都可以使用deepSeek来进行帮助，提高工作效率。 DeepSeek是不是抄袭了ChatGPT ？接下来聊下很多人最近开黑DeepSeek，由于DeepSeek的预训练费用比较低，而最终的效果却与ChatGPT不分上下，这让国外耗费大量资金投入的就很尴尬。 由于模型开源，对中文语境下的表现也尤为出色，能够更好地理解和生成中文文本，对国内用户也友好，无需进行科学上网，对API提供的费用也比较低，所以质疑声也很多。 技术上的效果已经与ChatGPT持平，而比较质疑的是通过蒸馏的技术抄袭了ChatGPT, 对这个观点我们算不算抄袭？ 在大模型领域业界的蒸馏技术可以通俗理解为知识传递。是不是抄袭ChatGPT，为什么有人这么说？ 因为有人认为是DeepSeek通过对ChatGPT的回答来进行数据的训练和学习。 在大模型领域大家对数据的收集过程都会有涉及也很难界定，本身生成式AI就是学习和训练出来的，况且目前DeepSeek也是完全开源的，所有人能下载就能训练部署和使用，就更谈不上抄袭了，难道开源的DeepSeek抄袭了闭源的ChatGPT? 也有人说DeepSeek黑了ChatGPT的服务器…进行了抄袭，这个就更不可能了。一切的回应我觉得，完全开源就能说明一切了。至于蒸馏技术那家的大模型也不敢说没有收集或获取过未被授权的数据而已。 目前DeepSeek还在快速的发展壮大中，在使用中也会经常出现“服务器繁忙，请稍后再试”的情况，这个因为最近访问量太大，也有一些被大洋彼岸攻击的情况，这种情况下可以多次尝试或者注册多个账号进行重试下。 相信DeepSeek的出现，为国产AI的发展也注入了新的活力，也给普通人使用AI提效带来了新的机会，更多的使用我后边也会给大家分享，让在每一个领域的人都能从AI技术中取得收获。 除了直接使用像DeepSeek这样的大模型工具，我们还可以通过N8N这样的自动化平台，将它与其他工具（如AI绘画、公众号后台）串联起来，构建更强大的工作流。如果你对此感兴趣，可以深入阅读我的这篇实战教程：《N8N教程：搭建公众号自动化写作工作流完整指南》。","path":"posts/5d1bba58.html","date":"02-09","excerpt":"","tags":[{"name":"AI","slug":"AI","permalink":"https://zhulg.github.io/tags/AI/"},{"name":"DeepSeek","slug":"DeepSeek","permalink":"https://zhulg.github.io/tags/DeepSeek/"}]},{"title":"AI编程很厉害，普通人来抢程序员饭碗行不行","text":"众所周知，过去的2024年AI发展迅速，2025年也必将是AI驱动行业变革之年。 在AI编程也行业正经历一场前所未有的变革，从代码自动补全Copilot到Cursor、Windsurf编程工具的诞生，AI编程已经可以让普通用户和电脑小白通过自然语言编写出各种应用。 我们也看到市面很多普通人也使用AI编程也开发出来一些简单应用，AI编程看起来确实很厉害，也有很多小白跃跃欲试，使用AI编程，来抢程序员饭碗行不行？ 如果你是非开发人员，比如普通人、设计师、产品人员、运营人员肯定有这样的想法，毕竟最近的某款补光灯让很多人知道了AI编程厉害… 今天正好有时间来写下，既然AI编程这么厉害，普通人来抢程序员的饭碗到底行不行？ 关于AI编程原理先不要着急，我们先看下AI编程原理，先用技术人的话来讲，核心原理还是基于深度学习和自然语言处理技术，通过大量的数据训练模型，使其能够理解和生成代码。如果用通俗直白点的话来讲，他是经过抄袭、或者说学习了众多相关的代码之后，通过概率方式来组合生成你想要的代码。 所以，了解了原理大概也就能理解他为什么让你感觉很厉害，当你觉得他写代码很厉害的地方，大概率是你的知识盲区，或者没有这么做过。 AI编程局限性上边了解了AI编程的原理，我们来看看AI编程有哪些局限性，或者从技术人的角度看他到底能做哪些。 编程工作不仅是代码的堆砌，更是对复杂业务逻辑的实现，AI可以生成代码，但它无法真正理解业务需求背后的逻辑和场景。编程工作包括对业务的需求分析、结合业务的架构设计、数据结构的抽象、模块间协作及可维护性，从软件工程来讲更多是需求设计，代码也只是实现的一部分。 而仅仅代码实现这部分，也需要通盘考虑模块内和模块之间的结构化的设计工作，其中也包括模型实现中的算法、性能、交互、用户体验等的设计和艺术工作。 通过编程实现一款产品，需要的是对业务领域知识和代码设计经验的完美结合，二者缺一不可，而AI只能根据已有数据生成内容，对真正在形成产品中的业务理解、架构设计、全局链路性能优化、创新能力就会显得不足。 AI编程强大的地方首先AI编程实际是一个编程的工具，而不是一个程序员的角色。 AI编程强大地方可以帮我们通过简单的文字描述生成代码，这绝对是极大地降低了编程的入门门槛。对于没有编程经验的普通人来说，能快速实现一些基础的功能，也可以生成APP和应用，可以体验下做个小产品的感觉。 在没有AI编程之前的一些个性化的小需求，过去可能投入和产出不成正比，也就没人愿意投入去做，但现在通过使用AI编程，也可以做出一些来。 AI编程也可以让普通人学会编程，帮助初学者理解代码的逻辑和结构，提供即时反馈，极大地提升学习效率，可以快速学会和认识编程语言。 普通人要不要抢程序员的饭碗？如果你认真读了上边的内容，相信心里已经有一些答案了。 AI的发展可以在很多行业里进行提升效率，而且是指数级的，但每一个行业都有自己的经验和壁垒，通过一个AI编程是不是就能杀到这个程序员的行业里？ 可能你看到过市面上很多在宣讲不会编程也做出很多产品的，不可否认，这类产品大多是营销远远要比产品要好。本质上，许多自媒体和营销号不断宣传AI编程替代人类程序员的说法，或者用AI编程工具做出一个前端小产品，这种无非更多是试图吸引用户尝试他们推广的工具或课程。你为什么很少看用AI编程做出一个后端系统的产品？（大部分是前端一些基础应用、或者原来已有应用的重新复刻）。 AI编程出现虽然降低了编程的门槛，但依然需要一定的编程基础，比如：懂原理、会操作工具，一些组件原理、明白代码含义，能否给出行业里的prompt、架构设计、代码和性能优化思路、当生成的代码有问题、当工具陷入AI幻觉和怪圈时，能否给AI工具指出代码问题也很关键。 如果有了上边的一些基础底子，通过使用AI编程工具来做一些产品也是非常不错的，但绝大部分普通人更应该要做的事是应该先了解AI，如何让AI在自己的行业去更好结合，而不要进入到自己不熟悉的编程赛道。 如果普通人就对AI编程感兴趣，觉得很有意思，我觉得可以从这些方面入手，试试看，看是否真适合自己：先学基础知识，知道用什么开发语言做什么事情，大概看懂代码逻辑、掌握AI工具的使用技巧，然后通过使用工具锻炼自己问题解决能力，你要学习能够自己查找错误并理解代码的运作机制，目的是为了学会验证AI的输出结果，防止进入AI幻觉和绕弯弯，并能根据实际需求来进行调整和优化技术方案。 写在最后：AI编程的确很厉害，它可以帮助普通人快速生成代码，提高工作效率，但目前看取代不了经验丰富的程序员，能取代的是一些基础的功能开发，不拥抱AI提效的程序员，以及对初级工程师、实习岗会确实会有一些冲击。 那普通人使用AI编程能不能抢掉程序员的饭碗？首先，看看是否自己具备一些行业基础知识，学习能力、编程思维，以及复刻的产品本身是否有价值。最好不要轻信一些营销号的夸大宣传，如果觉得自己就是可以，那可以先实践用起来AI编程，做一些产品试试看，是否跟一些自媒体宣传的那么简单。 对程序员来说，编程远不止写代码，更多的是思考、设计、优化、创新，AI编程必将可以成为程序员的得力助手，但程序员的需求分析和设计、创造力、架构优化、问题解决能力及创新思维，依然是无法被替代的核心竞争力。 而将AI与自动化工具结合，是发挥这种核心竞争力的绝佳方式。如果你想了解如何将AI能力落地到一个具体的自动化流程中，可以阅读我的这篇实战教程：《N8N教程：搭建公众号自动化写作工作流完整指南》。","path":"posts/c753d3ed.html","date":"02-06","excerpt":"","tags":[{"name":"AI","slug":"AI","permalink":"https://zhulg.github.io/tags/AI/"},{"name":"程序员","slug":"程序员","permalink":"https://zhulg.github.io/tags/程序员/"}]},{"title":"2025年IT就业会一直崩溃溃吗？说下我的看法","text":"从2024年，IT行业的就业问题似乎成了一个热门话题，2025年IT就业会一直崩溃溃吗？ 我不记得今年什么时候开始，身边越来越多互联网圈的朋友开始“空窗”，时不时有人问有没有推荐的岗位。起初还没当回事，但从下半年开始，这种现象变得越发明显。 最近，学计算机的亲戚都来咨询实习机会，孩子明年大学毕业，而今年实习却变得难上加难。企业招聘越发谨慎，尤其在市场竞争激烈的背景下，招聘变得更挑剔，直接上手、无需培养的即战力更受青睐。这难免让计算机专业的应届生也面临了更大的挑战。 再加上IT行业招聘中的大龄、薪资性价比问题，让很多今年失业的人感到失望和迷茫。这种情况也让大家感慨，IT就业真的崩溃了… 经济下行与技术节点的冲击但我认为，这并不是崩溃，而是行业发展到了新旧交替的节点。 的确，今年的IT行业不好过。经济下行，公司裁员频频，市场上的求职者激增。而从技术发展看，互联网基建趋于成熟，行业正处于一个新的阶段。这种双重压力下，让很多人产生了行业崩溃的感觉。 这一阶段，伴随着洗牌、更新迭代，无论是技术还是从业者，都会经历一次重新定位的过程。 从IT行业发展来看，这背后既有危机，也孕育着新的机会。 IT行业的过去与现在回顾过去，IT行业经历了从传统互联网到移动互联网的十几年发展。从最近10几年来看，当年移动端崛起开始，我在那个时候也是刚毕业没多久，赶上了移动互联网最好的时代，那时市场上的人才供不应求，甚至HR会直接到我们公司楼下“挖人”（这个是真实的情况），当年需求旺盛，技术门槛高，造就了那个风口上的黄金时代。 但随着时间推移，行业逐渐饱和。IT培训机构大量涌现，非科班出身的从业者加入，加上技术基建的成熟，入门门槛被进一步拉低。于是，供需关系改变，薪资水平被压缩，行业逐步趋于平稳。 然而，这并不意味着行业没有机会，而是要求我们重新审视自己的定位和技能，IT行业本身就是活到老学到老的行业，也必须跟上技术和基建的升级迭代。 更新迭代，抓住机会2024年，AI技术的崛起成为焦点。尽管有人认为AI会取代程序员、设计师等岗位，但我更愿意把AI视为一项工具，而非威胁。 AI的发展速度确实惊人，但本质上它仍然依赖于现有的数据和规则，推理、创造能力尚无法完全取代专业技术人才。这意味着，我们要学会利用AI，提升自己的竞争力，而不是被焦虑裹挟。 最近自媒体热炒的“5分钟写一个APP”、“使用AI做副业月入五位数”之类的噱头，实际上只是AI在已有技术上的应用展示。真正有价值的东西，不会通过这样的方式简单呈现。这些东西商业价值有多大，还是自媒体的自嗨博眼球的获取流量的手段？更有甚的通过浮夸的言论更多是营造焦虑，忽悠非专业人士。 对于专业的IT人来说，真正的机会，是如何利用AI工具为自己的业务赋能，如何通过AI改变现有的生产力。 未来的路：背水一战，迎接AI时代面对当前的就业困境，无论你是空窗期还是在职，都要坚信：IT行业并未崩溃，危机中仍有机会。 尤其是对于空窗期的朋友，我的建议是投入AI技术的学习中。学习并不意味着放弃已有技术（硬跨行业跨端学AI不可取），而是通过AI来更高效地运用和驾驭自己的核心能力，在自己熟悉的行业经验里，通过AI来一次升级与迭代的过程。 行业的变革从来不是毁灭，而是新旧交替的必经阶段。IT行业有天然的学习优势，对技术工具学习和迭代有很强的适应力，但不要故步自封，仍坚持一些基础工作，而是转变思维利用AI创造更多价值，用好这个工具，因为未来还是属于那些愿意接受学习、善于应用新技术的人。 写在最后无论如何，2024年IT行业有点难，2025年IT行业无需被所谓的崩溃论吓倒，坚定信心，拥抱变化，跟随技术发展，顺应市场需求，IT人依然大有可为！","path":"posts/dff848a0.html","date":"01-16","excerpt":"","tags":[{"name":"IT","slug":"IT","permalink":"https://zhulg.github.io/tags/IT/"},{"name":"技术人","slug":"技术人","permalink":"https://zhulg.github.io/tags/技术人/"}]},{"title":"护眼助手成功上架！在线安装或找我要软件，免费提供","text":"前两天，写了文章买了个护眼显示器后，却逼我写了一个护眼软件，总结了下这个护眼插件当时为什么要做的初衷，今天看已经通过chrome应用商店的审核正式上架，终于可直接安装了。（中间开发账号付费5美元也是一波三折，还好都搞定） 刚上架看到有10个用户安装体验（无任何推广），也可能是新账号提交的软件，平台有推荐吧。 如果大家有和我一样，平常看文档比较多，比如PDF文件、电子教程等通常这种情况下，刻板的阅读色可能一会眼睛就不舒服了，无论你买的是不是护眼屏幕，可能都有眼睛不舒服情况，无法找到一种护眼色来让眼睛舒服些。 比如这个场景，没有使用前： 打开护眼模式后： 因为这个软件开发的背景就是我这个护眼屏无法让我眼睛舒服的阅读下开发的。 看视频的时候也可以很好支持，特意查了下通过颜色和滤镜是真的可以降低眼疲劳的程度的。 另外场景，比如晚上你在加班，家人在休息完全可以自定义，把强光过滤，亲身体验过还是不错的。 另外这个软件也有为防止长时间对着电脑的人设计的提醒功能，可以设置间隔、倒计时方式。这个对打工人太友好了，为了自己健康有必要设置个间隔提醒，过段时间来个提醒也不错。 安装问题目前软件已经上架，可以直接到chrome商店搜索 EyeCare Assistant ，找到该插件直接点击安装即可。 安装地址： https://chromewebstore.google.com/detail/eyecare-assistant/ofaccdedcjcdbkjgjepbnacoekoeoepf 如果无法科学上网，没发访问这个地址的怎么办？ 可以关注私信我下或者关注回复护眼助手，免费获取该软件哈。 安装的时候如果有出现这个提示，不用慌，这个是平台的安全提示，跟软件无关。 出现这个情况的主要原因官方也做解释如下图（软件的开发都已经遵循了开发者要求，可放心安装） 如果通过在线安装的，发现在看电子书，用浏览器打开本地PDF时发现护眼模式无法在本地PDF生效，可以等新版本更新即可。 这个问题也是我刚发现的，在开发模式下对本地打开的文件是可以通过file://协议支持的，而在应用商店安装后，由于安全问题，需要在软件里添加支持的权限才能支持本地打开的，也可以直接找我要更新包即可。 体验反馈如果和我也一样长时间电脑工作者，即便买了护眼显示器，还是觉得屏幕不舒服的可以安装体验下，相信你会用上，特别是在看文档、看视频、阅读的时候，软件做的比较赶，2天左右时间，但满足目前需求使用了。","path":"posts/b249306e.html","date":"01-10","excerpt":"","tags":[{"name":"chrome","slug":"chrome","permalink":"https://zhulg.github.io/tags/chrome/"},{"name":"插件开发","slug":"插件开发","permalink":"https://zhulg.github.io/tags/插件开发/"}]},{"title":"买了个护眼显示器后，却逼我写了一个护眼软件","text":"最近花了2天时间写了个护眼的插件，插件核心功能，就是为了保护眼睛，在上网中找到适合你自己舒服的阅读色，使用了8种业界公认的护眼色，也支持自定义护眼色，由于自我感觉这个插件太好，提交了chrome 插件商店，搜索”护眼助手”可以找到. 插件核心功能，就是为了保护眼睛，在上网中找到适合你自己舒服的阅读色，使用了8种业界公认的护眼色，也支持自定义护眼色，添加了休息提醒，支持间隔和倒计时提醒，可以自定义提醒内容（当个平常重要事情提醒也支持），出发点就是保护长时间上网用眼以及长时间久坐的人，打工人必备。 最重要的一点，感觉比我买这个所谓可以调色护眼的显示器好太多了~（请允许我自夸….），读者朋友等这块应用审核通过后，在浏览器安装体验，先看下这个应用的界面。 来总结分享下这个突如其来的过程最近看一些文档和PDF的东西比较多，主要是一些线性代数和大模型的一些文档，需要一边看可能一边又个操作的过程，有时眼睛还比较累，且需要来回切换屏幕。于是开始找一个竖屏的显示器，同时又希望能对看文档或者PDF文件时，对眼睛有不错护眼的功能，至少让眼睛舒服一些吧。 通过各种搜索，买了一个台显示器支持竖屏和电子书模式，在这就不说那个显示器了。因为好像这个卖点的显示器也就那几款。 其他方面竖屏这些当然还是不错的，其中有电子书模式支持，我就兴致勃勃的打开PDF文档，感觉这个应该会不错，开始使用时才意识到广告宣传这个东西太忽然，遥遥领先其实很多真的是宣传成分，就个人体验看屏幕生硬，导致我怎么调亮度和色彩都不能让我适应，一度怀疑这个是我眼睛的问题…. 为什么这么不舒服，赶紧切回了正常模式，彻底放弃了电子书模式。 心想这护眼到底提现在哪里，都在广告里啊，真假护眼不知道，但是我眼睛看这个是真不舒服，特别周六的上午阳光照进来，一些阳光打在屏幕上，此时正在看PDF文档。 这种强光下，加上pdf强光下，很难长时间看下去，决定不忍了，开始写一个护眼的插件，至少让眼睛看屏幕舒服，不刺眼吧。我在网上先搜索下也问了ChatGPT确认这些护眼色可以让眼睛舒服减少一些眼疲劳的情况。那这个就好说了。 先把关键的颜色找好，确保是对眼睛是有效果也是护眼的色值，减少蓝光刺激的颜色，于是就是软件里这8种的色值。 代码构建过程剩下就是构建相关代码了，为什么用插件实现，因为我大部分场景都是浏览器，也通过chrome浏览器阅读PDF和电子书，这个场景最多，用插件设置护眼色在大部分浏览器都能用。 其实写完这个护眼色调整后，一下子调了几小时，其中尽管有AI协助，但也因为AI他的幻觉问题，导致一些逻辑进入死循环，这也是生成式AI的现状。已经有得东西他模仿和总结很快，但出现bug解决和优化，让产品达到商业化产品，目前还需要人的经验来处理bug和优化解决。回头再说这个过程，想用好他还是需要人的经验和引导。 由于太专注，几个小时没活动，起来腰酸背疼，今天又加了个消息提醒的功能，可以设置提醒方式，也可以自定义，这样至少自己不会久坐，时间长了休息下眼睛活动下身体也还是很有必要的。 好了，今天先写到这，如果审核没什么问题到时读者朋友可以去安装，体验下。 先看下效果图吧 1.阅读的时候： 2.上网的时候可以设置： 3.看视频的时候: *自己感觉还是不错，这两天有点用习惯了，关闭护眼模式还真不习惯起来了~ 后边大家使用有问题，也可以提出交流、建议哈~ *","path":"posts/170e7a4b.html","date":"01-07","excerpt":"","tags":[{"name":"前端","slug":"前端","permalink":"https://zhulg.github.io/tags/前端/"},{"name":"chrome","slug":"chrome","permalink":"https://zhulg.github.io/tags/chrome/"}]},{"title":"如何构建大模型应用？一文搞懂LangChain和RAG的原理和使用","text":"目前ChatGPT、AIGC各种应用如火如荼，技术人如何使用大模服务自己的业务，如何构建大模型应用？一文搞懂LangChain和RAG的原理和使用，文中附带相关代码可以更好的理解其中的定义。 我今天通过LangChain框架，一起看下如何简化大模型应用的开发，介绍下实际的工作场景。如果你也在做大模型开发，或者正在为如何切入这一领域而苦恼，欢迎在评论区与我们分享你的想法和经验。 langchain是什么?大模型应用开发里，langchain是一个开源的框架，专门为帮助开发者构建基于大语言模型的应用程序。通俗来讲，他负责与大模型来交互，也方便提供大模型做不到的事情。 为什么用LangChain如上边说的他作为与大模型的交互桥梁，因为大模型核心工作是作为推理和内容生成，只具备底座模型。而在真实产品中要集成和使用大模型，还要牵涉到大量的私有数据和工作要做。 如图： 如果从图上看，可能也还有疑惑，服务端也是可以直接掉LLM的对吗？ 没错。实际上是可以直接调用大模型的API. 比如openAI也提供的有接口。 但是，由于大模型有这么多，国内外成千上万，也不可能把大模型自己的API都学一遍吧？完全可以使用langchain抽象出来的接口来对接大模型。 更核心的原因是，很多大模型是无法做到的工作，比如大模型无法联网、查询私有数据库、怎么调用第三方API获取数据，大模型token限制，私有化模型调用。 这些在业务使用中大模型本身是不具备的，也不是大模型强行，大模型功能是专注推理和生成。 通俗来讲，就是大模型已经很强，但是需要我们把私有的数据、知识、客观事实提供给他，让他正确的变强，这个交互过程就有langchain来做（所以他不仅仅是个包装来调用LLM的框架）。 Langchain通过简化与语言模型的交互以及整合其他工具（如搜索、数据库和API）来实现复杂的应用逻辑，看下这个框架的构成： 有了基本概念，看下通过langchain的使用场景大概就好理解了，一些场景如下： 聊天机器人类：支持多轮上下文对话，利用langchain提供的记忆模块 自动化工作流：如客户支持、内容生成等，基于chain的设计 搜索与问答总结类：结合文档检索和生成模型，实现更准确的问答，RAG的设计 对于开发者来说，通过langchain来开发大模型应用，可以简化很多接口的封装，langchain已经提供很多抽象，同时在向量数据库、数据存储上都有比较好的接口了，其中RAG也在langchain里有对应的设计。 RAG是什么?RAG是 LangChain 支持的一种关键技术模式，上边介绍的在使用langchain时一种比较场景的场景，在做知识检索类回答类应用时候被大量使用。单独来说一下，就是RAG技术在目前大模型中还是使用比较多的场景，他可以基于本地数据、文档和大模型来结合使用。 先来看下RAG技术的定义和构成，RAG 是一种利用检索增强生成的技术框架。它将信息检索和生成模型（LLM）结合在一起，解决大模型在特定领域的回答和一些幻觉的解决，不同于模型的微调，让回答在垂直领域更专业。 工作的基本流程： 检索（Retrieval）：从外部知识库（如向量数据库、文档存储）中检索与问题相关的信息。通过向量化查询找到最相关的文档或片段。 增强（Augmented）：将检索到的信息作为上下文，提供给生成模型（如 GPT）进行辅助。 生成（Generation）：基于检索到的上下文和原始输入，生成更加准确和上下文相关的回答。 RAG的使用就是为了让大模型的回答更准确，更实时和专业，根据前面介绍的langchain和RAG的定义，通过一个举例来说明下使用。 举个例子，说明怎么使用了解大模型开发的应该知道，无论是openai的API还是其他家的，都会有token的限制，这样我们在与大模型对话时候，就不能超过最大的token限制，如果一本书有几百页，我们如何能通过大模型快速找出这本书的某一处内容，还要自然回答，如果是直接搜素（比如使用es）那肯定比较生硬。 第一步: LangChain 的向量存储功能，将文档文本加载并存储为向量。具体需要做的是对文档内容进行分隔，embedding后存入向量数据库，目的是能够通过向量找到对应相似度，为后续搜索做准备。（这些都可以LangChain提供的组件来实现） 第二步： 这幅图来说明通过RAG的一个工作流程，通过查询向量数据库，从向量数据库中检索相关内容，将检索到的上下文和用户问题结合，给到了LLM，最终生成具体的答案。 如果我们用代码来模拟下看，这个对技术人来说，更容易理解（非技术可以忽略）看下边的代码来说明langchain和RAG的使用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960from langchain.vectorstores import Chromafrom langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.llms import OpenAIfrom langchain.chains import RetrievalQAfrom langchain.prompts import PromptTemplatefrom langchain.text_splitter import CharacterTextSplitterfrom langchain.document_loaders import TextLoader# 设置 API 密钥（需要替换为你的 OpenAI API 密钥）import osos.environ[&quot;OPENAI_API_KEY&quot;] = &quot;your-openai-api-key&quot;# 1. 准备文档内容# 假设我们有一个文本文件 data.txt，包含需要存储的知识loader = TextLoader(&quot;data.txt&quot;)documents = loader.load()# 将文档分割为更小的片段以适配向量化text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)split_docs = text_splitter.split_documents(documents)# 2. 创建向量数据库embeddings = OpenAIEmbeddings()vectorstore = Chroma.from_documents(split_docs, embeddings, persist_directory=&quot;./chroma_db&quot;)# 3. 初始化检索器和大模型retriever = vectorstore.as_retriever(search_kwargs=&#123;&quot;k&quot;: 3&#125;) # 检索相关性最高的3个片段llm = OpenAI(model=&quot;gpt-4&quot;)# 4. 定义提示模板prompt_template = PromptTemplate( input_variables=[&quot;context&quot;, &quot;question&quot;], template=&quot;&quot;&quot; You are an intelligent assistant. Based on the following context: &#123;context&#125; Please answer the question: &#123;question&#125; &quot;&quot;&quot;)# 5. 构建 RAG 流程qa_chain = RetrievalQA.from_chain_type( llm=llm, retriever=retriever, return_source_documents=True, chain_type_kwargs=&#123;&quot;prompt&quot;: prompt_template&#125;)# 6. 查询query = &quot;What is the main benefit of using RAG with LLMs?&quot;result = qa_chain(&#123;&quot;query&quot;: query&#125;)# 输出结果print(&quot;Answer:&quot;)print(result[&quot;result&quot;])# 如果需要查看检索到的上下文print(&quot;\\\\nSource Documents:&quot;)for doc in result[&quot;source_documents&quot;]: print(doc.page_content) 以上介绍了用langchain来做大模型开发的使用，主要是理解langchain提供的一些抽象和功能，使用langchain能做的还有更多内容，后边在对langchain的使用做一些分享，今天文章是先有个概貌的理解。 ps: 后边一些代码的讲解和一些AI电子版的书籍会在视频号上进行分享，公众号的内容还是以概念和漫谈形式来写，也适合碎片化阅读习惯。","path":"posts/e93d67e9.html","date":"01-06","excerpt":"","tags":[{"name":"AI","slug":"AI","permalink":"https://zhulg.github.io/tags/AI/"},{"name":"大模型","slug":"大模型","permalink":"https://zhulg.github.io/tags/大模型/"},{"name":"LangChain","slug":"LangChain","permalink":"https://zhulg.github.io/tags/LangChain/"},{"name":"RAG","slug":"RAG","permalink":"https://zhulg.github.io/tags/RAG/"}]},{"title":"从0到1，如何快速上架一款chrome插件","text":"如何快速上架chrome插件? 如何搞定chrome开发者注册？本文来进行详细的讲解一下，方便国内开发轻松上架插件。 前两天上架了个护眼助手的插件，有读者私信问上架这个国内能否访问，目前因为是google的chrome商店，如果没有科学上网，确实无法访问。（需要的话可以关注公众号，回复护眼助手即可获取软件，到时添加在chrome浏览器就行。如果使用微软Edge浏览器的，等审核通过也可以安装） 今天快速介绍下，怎么从0到1上架一块插件软件，就上架来说要比Android 和iOS的审核和填写的东西要少一些。我快速介绍下给想尝试这个插件开发的读者。也顺便说一下，如果你想开发一些插件来赚钱的话，也是可以的，回头再介绍这块，先说下如何从0上架一款插件。 开发账号准备开发插件本身不难，会JS技术并能解决用户痛点这些就可以了，上架插件就需要先有账号，用来管理你的插件后台，提交和版本更新的管理后台。 我知道很多人就卡在这一步，先注册为chrome应用开发者地址： https://chrome.google.com/webstore/devconsole/ 注册开发者账号的门槛就是需要支付5美元注册费。 这个是一次性支付，但支付是个问题，他不支持国内支付方式，需要有美国信用卡，目前支持的有通过 GPay 支付 Google 开发者账号的注册费用，或使用带有以下徽标的信用卡或借记卡： Mastercard Visa American Express Discover（仅限美国） Visa Electron（美国以外的国家/地区） 是不是有点头大了？ 如果没有海外信用卡或者Gpay这个基本上就没法支付，我这边也是在经过对比后选择了WildCard，他可以支持海外很多支付，下边的海外支付都支持。（我之前也用过depay就是每月有月费，不如这个划算） 可以注册后就有了一张虚拟信用卡可以用于支付了，wildcard他支持微信和支付宝充值也比较方便。这个开卡是有费用的可以开2年或3年（这卡没有月租这点还是划算的），开卡时可以使用我的个人邀请码: LJMT，就是良技漫谈的首字母，你会有个9折优惠。 这个开卡后，可以微信支付宝支付充值，然后去chrome插件后台填写自己的虚拟卡号支付即可。（有问题可以私下我） 上架应用开发账号开通后，就可以有插件后台了，去上传自己的插件就好。 上传插件包后，就是需要把软件的相关介绍、软件包后台的各种尺寸的图片进行准备 需要特别强调的是度及软件的权限要说明，这个说不清楚的话可能会影响审核，整过程没有过多的负责，审核也还好，1-2天就会通过，如果使用的权限越多，审核时间也就会越长。 如果是第一次上架，需要准备对应的预览图，后台各种尺寸的图，供后台展现和用户安装时使用，如果上架过APP，那这个也很简单。 另外推荐一个icon的网站，https://hotpot.ai/icon-resizer 如果不太会自己切图，可以使用这个免费网站。 好了，其他就是软件自己开发好，测试完没问题按我上边的步骤上传等待审核结果，就可以了。 最后一些话如果上架过程中有问题可以进行交流，整体看比较麻烦的是开发账号支付5美元问题，其他对技术人来说都会比较简单。 如果你有好的想法和提效的都可以用插件来实现，而且插件也可以作为打造个人产品的一种方式，就入手来说比上架android和iOS的审核要简单太多。 技术人凡事就要多尝试，很多起飞的产品都是来自一个很小的mvp，多做一些产品和商业化的尝试，对技术方向掌握和运用也非常有利，学习新东西的速度也会越来越快！","path":"posts/5e8ea077.html","date":"01-05","excerpt":"","tags":[{"name":"chrome","slug":"chrome","permalink":"https://zhulg.github.io/tags/chrome/"}]},{"title":"为什么Boss上那么多已读不回?","text":"为什么Boss上那么多已读不回？ 我最近跟一个做HR的朋友聊了下这个现象，写这篇文章喜欢对大家有所帮助。 临近年底，公司一般这个时候开始做年底总结、来年业务规划和预算。与此同时，也就会有些预期业绩和业务调整，裁员也常常发生 ，年底的离职潮也逐渐涌现。 和往年相比，今年明显能感受到，身边开始看机会的人越来越多了。交流中也时常听到抱怨，“不是我不够优秀，而是简历投了根本没人回！” 有人说：“如果不招人，那为什么要挂出JD ？”还有人说发起几百个沟通，得到的回复寥寥无几，有时是猎头礼貌回一句您不合适，大多数时候则直接是已读不回。也有人开始怀疑，是不是自己的简历格式出了问题？ 我最近专门找了一位做HR的朋友聊了聊，从她那了解的情况中大概有这么种，也给出了一些建议我整理出来分享。以Boss来举例，这个目前可能是最火爆的求职平台了（从他近几年的营收情况看） 平台收费模式据说回复率数据大概是这个样子，准确度无法严格求证，但可以说明问题，大概80-90%的简历是已读不回，5%左右简历会得到礼貌拒绝，另外有5%左右的简历才有机会进入面试。 为什么这么不喜欢回复？因为回复也是要花钱的，严格来说也不是boss们不礼貌。 HR如果要回复简历，往往需要支付一定费用，而这些费用通常是按次数收费的。这里面从发布JD，到沟通聊天，有包月套餐，有畅聊包，计费给你整的明明白白，也就是说，HR必须精打细算地选择哪些简历值得回复，对于那些明显不符合岗位要求的求职者，也就真的是不想花钱，或者她的畅聊包或者次数用完了。 了解了平台模式，大概上边的回复率数据，我估计也就是差不多这样的概率了。 简历太多，不是你不优秀除了收费机制的影响，另一大原因就是HR每天面对海量简历时，根本没时间看完简历，这个真的是要拼幸运和拼打招呼的频率了，也不是你不优秀，第一步是能被看到简历。 我的HR朋友告诉我，有时她一个岗位，每天有几百个打招呼和信息，而她一个人根本没办法逐一阅读所有简历。大部分情况下，HR只能筛选那些排名靠前的简历，而这些简历往往是通过平台会员或者付费服务排上来的有些是通过推荐算法来的，所谓推荐算法无非是求职者购买服务包之类，看到没现在求职都卷的狠…. 你可能还问有得打招呼的都是已读了，可以幻想起下一步的沟通交流了，而根据她的描述由于消息太多时候可以批量已读，也就是求职者觉得已读了，但仍然没回复，写也可能简历太多被一键标记已读了。 从简历和打招呼优化了解了这些客观原因后，求职时我们也得从自身开始，把简历和打招呼方式优化好，做到能挤到10%的行列里，毕竟现在大环境下，市场上人多。boss们是用户，而求职者只是商品，就必须把自己的商品打磨好，让用户能看到先。 从朋友那得到信息和建议也分享给大家： 先从自己简历上优化，突出价值能提供什么给boss，过往战绩是什么，核心本领是什么，如果没有大厂背景，切记只描述工作，要突出他人亮点，这些亮点能对应JD。 一些硬性规定，比如学历（尽管有时她也反对，但老板定的），年龄，行业背景匹配，这个要求求职者不盲目投递，看好一些硬性要求，一般会写在JD或者提炼出核心关键词里体现。 薪资问题，有得20-30K的，其实只能给到22k左右，30-40K给的其实是33左右，真实情况，按她的说法现在人多岗少，除非这个岗位她招不到人。所以打招呼时薪资有可能也会跟他们不匹配，导致没法回复你，求职者看好自己的薪资区间在打招呼，打招呼也突出重点，自己做什么，工作经验，希望薪资，尽量建设模板打招呼方式，言简意赅一句话说明白。 还有一点建议，没有及时回复的，多找2个HR，这个公司可能不是一个HR，或者有其他HR也在负责这个岗，那就多打招呼。还有，如果这个boss平台没有回复的，你可以去其他招聘平台，找到这个公司的HR继续打招呼。核心，就是多些打招呼入口，增加看到你消息的概率。 最后一些话目前大环境影响经济下行，失业情况变多，作为求职者，我们在投递简历时，往往并不了解招聘平台背后的规则，也无法完全理解HR筛选简历的逻辑。简历被“已读”后的状态，给了我们一线希望，但也别过度期待，保持平常心才是最重要的。 不妨从简历和自我介绍的优化开始，提升自己的竞争力。除了平台投递，寻求朋友推荐也是一个非常实用的方式。如今，许多猎头和招聘人员的工作压力也不小，很多企业开始依赖内推来寻找人才。因此，通过熟人推荐和内推的渠道，仍然是许多求职者脱颖而出的捷径。 面对“已读不回”这种情况，虽然它可能给求职者带来心理上的负担，但一旦理解了这些背后的机制，就能更轻松地放下心态。 最重要的是，给自己信心，多尝试不同的应聘机会。在这段求职的空窗期，也不妨把精力放在提升自己身上，提升能力、学习新技能，扩展自己的人脉网络，也不把所有希望寄托在招聘平台上。 保持平和的心态，做好自己的提升工作，给自己一些时间，一定能找到最适合自己的工作。","path":"posts/7f92c8fb.html","date":"01-04","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"}]},{"title":"Screenity让视频录制变得简单免费,github Star 13K技术背书","text":"今天我要推荐给你一款绝对让你眼前一亮的录屏工具，Screenity，我最近也在使用，录制课程，培训讲解，视频画中画都支持。 无论你是开发者、产品经理、教师，自媒体内容创作者，在工作中总会遇到录屏的需求。可是，市面上的录屏软件大多存在功能限制，很多需要付费解锁高级功能，甚至有的还要求你充会员才能使用完整版。更别提那些软件菜单复杂、操作繁琐，让普通人看了头大的情况了… 它不仅支持多种录制选项，也可以后期编辑和标注功能，帮助你轻松录制、编辑和导出专业级视频效果。 最重要的是，它完全免费、无需注册（因为代码是开源的），就让你用得安心，省心！ 先看下作者信息这个软件的作者也是一位厉害的美女开发alyssaxuu，她身兼多职也是一名连续创业者，从她的github上可以看到一些信息，她这款软件目前在github上已经13K star。 在 Chrome Web Store 上，已经获得了 200,000+ 安装量，评分也比较高，用户也给出了极高的评价。 产品核心功能市面上很多视频制作，特别是知识讲解类视频制作，一般比较有名的有obs、screen studio 这2个如果使用过的应该知道，obs的操作上多少有些繁琐，但也比较稳定，screen studio 是在mac 上使用比较多的，最后导出视频就需要有付费账号了。 Screenity，不错的地方就是开源、免费，操作简单，就一般制作视频讲解、录制足够用了！ 你可以录制屏幕、摄像头和音频，可以直接录制中音频录入，有丰富的注释功能，允许你在录制过程中添加文本、箭头、高亮、绘图。还支持模糊模式，比如你在录制视频中有些区域不想公开，比如你的密码，界面上个人隐私等信息。 录制中，你可以独立控制麦克风音频和系统音频，这对于做产品演示、技术讲解等场景非常实用。你可以选择只录制麦克风音频，或者录制系统音频，甚至可以使用“按键录音”模式，这样就可以避免背景噪音干扰，确保录音清晰可听。 比如这个图上你可以设置模糊部分，保护隐私。 也可以在屏幕上随时进行标注，想要强调某个操作步骤？用画笔圈出重点；想要展示一个流程？加上箭头引导。支持实时绘制、添加文字，让你的录制更加生动、直观，绝对让人眼前一亮。 总结下功能，就是你看到市面上制作的录制讲解类、培训授课类的视频的功能它都支持，而且操作交互简单！ 提供编辑，导出免费如果用过其他录屏的话，可能就知道很多在这一步要不就是让付费，要不就是高分辨率导出让冲会员，或者给你视频加上水印。。。 而这个完全不限制，代码都是开源的，就不用担心啦，视频在录制时可以自己选择4K，1080等，高清程度也不用担心，妥妥够用。 可以看右边的菜单，可以对视频进行裁剪和处理，当然如果是深加工可以进行用剪映来做处理，就录制来说这个已经完全够用了。 安装简单前面说了，这个软件是通过浏览器插件方式提供，所以安装简单，直接添加插件，就可以体验，目前支持中文语言，作者已支持多种语言，chrome插件商店直接安装，或者这个地址打开： https://chromewebstore.google.com/detail/screenity-screen-recorder/kbbdabhdfibnancpjfhlkhafgdilcnji?hl=en 写给技术人这个开源的项目地址： https://github.com/alyssaxuu/screenity 技术人可以从里面看下载源码，自己也可以定制需求开发，最近也看到作者有在做链接共享，视频编辑器的一些功能，有兴趣也可以下载源码去学习~","path":"posts/6f586b6b.html","date":"01-03","excerpt":"","tags":[{"name":"Tools","slug":"Tools","permalink":"https://zhulg.github.io/tags/Tools/"},{"name":"录屏工具","slug":"录屏工具","permalink":"https://zhulg.github.io/tags/录屏工具/"}]},{"title":"人生建议，技术人一定要学AI大模型，时代已来！","text":"2025年，建议所有技术人、互联网人尽快把AI学起来，用在自己的工作或者生活里，跟随技术和时代的变革。 在之前的文章中，我提到过为什么每个技术人都应该拥抱AI。而今天的重点是分享如何快速入门AI大模型技术。无论你是前端、后端工程师，还是对互联网技术感兴趣的读者，都希望能从这篇文章中获得一些有价值的启发。 先说个题外话：最近，我的文章更新频率有所降低，一方面是因为纯技术类的内容流量确实不高，读者反馈也较少；不管如何我会继续分享原创内容，给大家带来有价值的技术与成长干货分享。 回到正题，最近我重新投入到AI的学习中，这也是今天这篇文章的主旨——分享我最近一些入门的经验和知识。如果你是技术人，尤其是互联网从业者，现在就开始学习AI大模型技术，真的是给你的人生一个重要建议！（毕竟几年前感兴趣学习了机器学习和推荐相关知识，后边忙其他方向也就没继续…）也不要觉得AI底层技术很难学，关键在于怎么一点点啃理论并和项目验证结合来练。 你可能会觉得我有些夸张，但实际上，就现在技术行业特别是互联网软件行业，已经有大量的技术在持续降低门槛、人员裁减也基本成为常态。没办法新业务和技术难度都在减弱，如果还坚守在原有的阵地，可能也不是一个更好的选择，AI时代，一切发展太快，现在在去找一些基础开发、前端开发特别是网页类，这些低门槛工作完全可AI实现….技术人应该觉醒了。 是不是AI时代，所有的程序员会淘汰？绝对不是。 更有一些外行说所有人都跨行都来学编程？这个也不现实的，技术人也不用怕，里面还是有一定的门槛的，即便是AI时代，想跨行来做还是要有些基础知识和理论的，否则也无法结合AI来编程。 说了这么多，目的是想打消技术人过度的焦虑，然后找对方法，来提升自己。 技术人怎么学？那作为技术人，我觉得我们要做使用AI、调教AI的人，而不是被AI代替的人，用好AI这个智能工具服务更多业务。 最好不要通过学习通过各种工具怎么生成图片、怎么生成视频，加一些特效，这些技能不是不可以学，作为技术人不应该重点学这些，因为这些东西门槛低，不能构成技术人的护城河。随着普及会会变成2000年左右的打字员一样的工种，技术人的核心要学怎么结合AI生产自己行业的工具，调优工具，而不是使用工具。 所以，如果上边我说的这个话你有共鸣，那我最近在重新学习的AI相关东西你应该也能领悟，我们先来思考下这几个问题。 AI大模型本质是什么？大模型的本质是一种统计推理的工具，通过在大规模数据上进行训练，内化并表达出广泛的知识和技能。它们具备高度的通用性和适应性，可以通过适当的调优应对多种任务，并展示出一定的类推理能力。 如果我们想做一些AI大模型的工作，这里面当然会有很多方向可做, 我觉得可以选取一个自己感兴趣的。所有这些的一切就是先从大模型的工作原理来开始。 之前写的文章，大模型里相关文章有原理的漫谈，AI时代：玩AI却不懂一点原理，真的靠谱吗？这个也是相关的原理构成，大概原理知道后，就可以开始把组成的某一个部分开始进行理解。 学习方法建议：个人的建议，如果之前不是机器学习方向的，很可能就被概念和名词就会卡住，以为最近开始的学习来讲，不用怕，那个不懂学习那个，然后慢慢拼凑出一个概貌。学习最重要的途径，就是直接尝试做，遇到卡住的地方，再寻找方法补足技能，再尝试，如此循环。 比较核心一点，不要上来就勇猛的学各种书籍，比如机器学习、线性代数、微积分、离散数学，如果是学生阶段那没错，如果是已经工作的建议还是先把大模型相关操作和原理开始，遇到什么不清楚就查什么，然后继续，这样比直接啃基础反而快一些，但基础这些还是要啃。这些东西别指望一看就懂，一看就会，先吃一点，那个概念原理不清楚就去查，然后继续往下走，比如一些算法怎能也想不通，先跳过。然后空闲就把线性代数、离散数学、这些学一些。 方法有了，给大家分享下最近根据原理来重新学习的一些书籍和知识, 比如从transformer原理看，可能会遇到一些向量问题、机器学习问题，如果对向量不熟，可能就得查一下线性代数，如果对训练的过程不懂，就看下机器学习监督学习、无监督学习、强化学习这些概念。 路线上可以从入门开始：1.大语言模型的基础知识和常见术语和原理开始，最重要的是实际操作。 2.可以在本地环境搭建开源模型的推理环境。 3.了解下大模型的应用开发框架（ LangChain、Dify）Prompt 工程、 RAG、Agent 等大模型应用开发范式 4.大模型的训练微调、数据工程、推理优化，训练自己业务行业的大模型。 总之就是围绕怎么训练一个自己的大模型，这里面可能就会涉及上面的一系列问题，也需要补充各种理论基础，编程语言（比如对python）深度学习框架 PyTorch、TensorFlow等、分布式训练、模型调优等等。 上边提到的知识点都可以在网上找到不错的教程，推荐openai gpt和 llama 来开展学习，毕竟国内很多的大模型都也是套壳llama的。 自己在看的资料：这块的资料很多，我一般不怎么推荐，因为每个人的学习方法不同，可以结合自己来，我目前在看的一些资料比如机器学习的经典可以看看周志华的机器学习，当成工具来查阅，其他的就是上边说的线性代数、离散数学，目前还没有进入深水区后边会继续分享，先推荐必学平台和书籍： https://learn.deeplearning.ai/ 吴恩达（Andrew Ng）创办里面有很多教程 另外2本必看的书籍推荐： https://llmbook-zh.github.io/ 《大语言模型》 https://zh.d2l.ai/ 《动手学深度学习》 掌握了这些基础理论后，最好的学习方式就是动手实践。将大模型的能力与自动化工具结合，是快速创造价值的捷径。我最近就通过N8N搭建了一套自动化写作流程，你可以从这篇详细的教程中获得启发：《N8N教程：搭建公众号自动化写作工作流完整指南》。","path":"posts/94f0a6b4.html","date":"01-02","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"},{"name":"AI","slug":"AI","permalink":"https://zhulg.github.io/tags/AI/"}]},{"title":"用LM Studio工具部署本地AI大模型，真的太省事了","text":"普通人如何部署自己的本地大模型，如何用Studio工具部署本地AI大模型。 前面写过AI时代：玩AI却不懂一点原理，真的靠谱吗？的基础篇，也说过这类的文章我后边会持续输出，核心目标帮助技术人、对AI感兴趣的读者，可以用一种比较轻松和漫谈的形式理解，并给大家一些学习和玩AI的方法。今天先介绍下普通人如何部署自己的本地大模型。 你可能会问：为什么要自己部署本地大模型？ 我想可能有这几个原因，看看是否准确： 如果你不会科学上网，是不是访问其他国外模型基本没法用，相关速度也不是快，即便科学上网，有些模型是不是还要付费订阅高级版。 自己是不是有些东西不想直接公开去给到大模型，害怕隐私和知识产品被大模型收集学到。 在某个垂直领域，是不是想训练自己的大模型，然后结合自己的产品和业务来使用。 如果现在可以帮助普通人，像安装一个电脑软件一样通过简单操作，就可以运行自己的本地大模型，在自己电脑上免费使用，速度也快，也不怕自己隐私，这个是不是能满足大部分人需要了。 今天我想给大家推荐一个比 Ollama 更加清爽的工具：LM Studio（如果你还不熟悉 Ollama，它其实是一个用于安装和管理大模型的工具）， LM Studio 不仅对普通用户友好，技术人员也友好，方便地安装大模型。它提供了开发模式，让技术人员能深入了解相关参数。在用户界面方面，LM Studio 相比 Ollama 也更为出色。 针对普通人用：话不多说，直接下载打开下载地址https://lmstudio.ai/ 下载自己电脑对应操作系统，可以看到现在MAC上的用户可以安装苹果进行优化过的MLX模型。 下载前看下自己电脑配置，大部分电脑是没问题，可以下载一些小的模型就好,mac的话要M1以上的电脑。 下载后，就可以打开LM Studio来进行相关模型的下载，安装后可以通过左侧的搜索来找对应的模型下载，下载后可以运行对应的模型就可以直接使用了，看起来很简单。 但是… 在安装后开始搜索模型时候，列表可以看到，但无法进行下载模型。这个时候不要慌，因为https://huggingface.co/ 在国内是无法访问的。 即便也有科学上网了，但是在软件内部获取模型的是通过https方式来访问的，全局代理也没有过去。 怎么办，只能找国内的同步的镜像了，可以使用 hf-mirror.com，用于镜像 huggingface.co 域名，这样对应的模型就可以正常下载。 我是MAC电脑，通过vscode和其他编辑器sublime text这些都可以，打开显示包内容用vscode打开文件，全局替换 huggingface.co，将 LM Studio 程序中所有使用到 huggingface.co链接的地方都搜索出来，用 hf-mirror.com 来替换，大概有5百多处（替换完后记得保存和重启软件，已经验证过没问题），如果是win用户也一样，直接找到软件安装地址，打开资源文件全局替换即可。 过了这个，就可以方便下载模型了，模型的选择可以看自己的电脑配置，其实LM studio也会根据电脑配置推荐，mac用户建议可以使用MLX的在mac上体验会更快，主要自己电脑配置要M1以上的电脑。 模型下载完后，根据指引就可以直接进行加载了。 模型加载后，就可以新建对话，先来进行个测试，在我箭头指示地方可以加载下载的离线模型，并开启对话。 这样本地的模型就可以正常运行了，你可以跟他对话，来辅助你日常相关的工作内容，这个比较适合普通人，快速搭建自己本地的大模型。 针对互联网人：想多一些理解和使用大模型 大部分互联网和技术人，这个安装和使用的过程应该很简单，在搜索的列表里也可以看到市面上各家相关的大模型，都可以去下载尝试和对比。我们在上边也看到了这么多大模型，各种参数不同的大模型，以及大模型的相关格式，这些我们是否清楚相关的概念和原理？ 我们在下载模型的时候，可以看到有标识大模型参数的B，比如Llama-3.2 1B ，Llama-3.2 2B , 这些B代表着大模型的参数，那参数到底在大模型里是什么意思？理解这些参数可以更好地理解大模型。 这些参数以Billion为单位，刚才我下载的 Llama-3.2 1B 这意味着这个模型包含大约10亿个参数，而一个参数通常是模型的权重或偏置值，这些值在训练过程中被调整以使模型能够更好地进行预测，参数越多最后相关的结果就越准确， 比如在图形识别中可能就有百万计的参数来学习图像中的不同特征，如形状、大小、纹理、颜色等等，从而实现准确识别和分类。 这些参数不仅仅是数值，也是在训练过程中学习到并自动产生，这就需要海量的数据，产生的参数代表了模型如何理解和区分不同的输入数据，根据这些上亿维度的参数来最终给出相关预测的结果。 随着训练的深入，机器人不断调整这些参数，从而变得更加聪明，能够更好地完成任务，比如识别猫和狗，或者理解人类的对话。 总结下：概念和使用 整体通俗理解下，大模型和参数，大模型就是一个聪明的大脑，它通过观察大量数据图片、文字等你想让他学的一切，根据你让他学的东西，来转化成相关的参数（也就是数字，因为机器只认数字），每个参数帮助它理解数据的不同方面，比如颜色、形状或语言的含义。根据大量的数据训练的深入，不断产生、优化、调整这些参数，大脑就越聪明，能够更好地完成给他的命令。 普通人如果想玩AI大模型，使用 LM Studio 也是个不错的选择，可以安装和尝试多个模型在自己电脑上，这样隐私和你想问的问题也就更安全，速度也更快。 互联网人来说，特别技术人也可以使用他提供的本地server和 lms log stream 在命令行 来看相关模型日志。","path":"posts/87fa9ee5.html","date":"01-01","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"},{"name":"AI","slug":"AI","permalink":"https://zhulg.github.io/tags/AI/"}]},{"title":"AI时代，只学1项技能，就学会提问","text":"前两天朋友私信我，问普通人在AI时代下的相关问题，他这个问题我之前也有过思考，在以往的文章里也表达过相关的观点。 他具体问题是这样的：现在AI这么火，我们普通人怎么学习AI，不被这个时代淘汰” 。 坦白讲这个问题很大，但也看得出，现在很多人也感受到AI浪潮下的机遇和焦虑。他的焦虑，不知道是不是看到网上到处售卖AI学习课的缘故…（另声明，本人不售卖AI课，可免费提供粉丝AI相关帮助） 我的回答是：AI是个工具，这个工具要给你所在行业来结合起来使用。怎么结合，用你所在领域的知识、经验提问给AI，刨根问底，找出最满意的答案。 之所以这样回答，是因为很多行业不同，业务和商业模式是不一样的，真正用好AI是和行业结合起来。因为AI绝不仅仅是现在市面上，教大家做个图片、制作个视频，换个声音这些操作，真正威力是大家如何使用AI来提高工作效率，渗透在自己行业里，把复杂的东西交给AI，把智能化交给AI，让自己闲下来，让企业效率也提升。 回到正题，现在信息大爆炸又有了生成式AI的协助，对于普通人，如果必须要会一种技能的话，我觉得是要学会提问，当然也可以提问给AI。不要觉得提问题简单，还要学会提问的技能？之前我也这么认为…从来没觉得提问问题还有专门的书籍（后边介绍） 为什么提问这么重要呢？ 其实，不管是面对AI，还是面对生活中的各种挑战，提问能力决定了你能从这个世界获取多少有效的信息和知识。 提问比告知更能解决问题，它能帮你明确方向，剖析问题，甚至打开新的思路，就像我前面提到的，AI固然强大，但如果你不会提问，给它再多的数据，它也只能给你一些表面答案，无法给出你深入的回答，况且ChatGPT有时给你的答案也是东拼西揍。 能提问出好的问题，才有价值现在信息太泛滥了，网上也有太多的文章是AI写的，有时你难以分辨真假，尽信书，不如无书。虽然，我们的知识的获取变得前所未有的容易，只要打开手机，似乎任何问题的答案都能找到。 但你有没有发现，获取答案的速度在不断提高，思考的深度却在不断下降？也许你会感叹，自己搜到了成千上万条答案，却依然解决不了实际问题。原因很简单，不是信息不够多，而是你没问对问题，没有经过思考的提问，回答的垃圾信息也就很多。 知识会贬值，但好问题永远有价值。 随着时间推移，很多知识会变得过时，但一个好的问题却可以引发持续的思考、探讨，甚至带来创新的突破。正是因为这个原因，提问能力在未来社会变得愈发重要。 想象一下，未来的你不仅需要知道如何回答问题，更需要懂得如何提出更有挑战性、更具创新性的问题，也可能是一个持续努力的方向。 学会批判性思维的提问学会提问，就要说到批判性思维了。 学会提问，问出好的问题，首先你得有足够的知识储备和批判性思维。如果你对一个领域一无所知，这就不可能提出有深度的问题了，没有相关知识储备，你可能都不知道如何问别人，导致没有问题，有没有感同身受的感觉？ 知识是基础，批判性思维是方法，两者结合才能真正让你在复杂信息背景中提出好问题。 批判性思维不仅仅是质疑别人的观点，找出漏洞给别人抬杠…..而是一种系统化的思考方式。它要求你在面对信息时，能够独立分析、鉴别，得出自己的见解。而这些见解，往往就是好问题的来源。 你可以提问题给大模型，他肯定不会烦你，要通过批判性思维去使用AI，提出深思熟虑的问题，结果自然会更加精准。好的提问，其实就是AI提示词（prompt）的核心部分之一。掌握好这个提问的技能，在AI时代你可能会发现自己能够学到几乎所有所需的知识。 举个例子，如果你在一个技术领域已经积累了丰富的经验，那么当你面对新的挑战时，你可以提出一些基于实际需求的问题，比如：“这个技术解决方案能否提升用户体验？” ，“有哪些潜在的改进空间？”，这些问题不仅源于你的知识，更源于你对现有信息的批判性分析。当然，你在其他行业的，只要有专业经验和知识AI也不会轻易骗得了你，你用自己的专业知识尽情去提问他，直到问到准确满意的答案。 怎么让自己有批判性思维的能力？ 个人觉得，可以这样锻炼，这个是之前网上看到的一些关于批判性思维的提问方式，比如：当你看到一件事情时候先问自己：“这是真的吗？”尝试找到支持或反驳的信息，确保自己做出的判断是基于事实而不是主观感受。这个方案对吗？有没有更好的方案？下一步如何做？等等类似的问题，锻炼自己具备这些批判思维的能力。 使用过诺基亚手机时代的话，应该就知道当年手机市场基本被诺基亚、黑莓等传统手机霸主占据。当时的手机设计围绕着物理按键和小屏幕展开，很多人认为这就是手机的未来，乔布斯采访时候有提到过，手机一定要有实体键盘吗？这也就是一种批判性思维的提问，也是触摸屏随之彻底颠覆了手机行业的创新。 还有一本比较好的书，也是个人看过的《学会提问》，可以学习提问，也可以学习英文，我买的双语版本，这本书作者是[美]尼尔·布朗(Neil Browne) ，斯图尔特·基利 ，我买的12版，推荐给大家可以看看，如下图： 最后，AI时代下，我觉得也不要太被网上的一些信息所焦虑，要锻炼自己的批判性思维，学会提问很重要。把问题提问给AI，获取你对应行业的经验和方法，每个行业领域不一样，但提问的思维是一样的。也特别强调下，我们互联网人更要学习这种提问的思维，这也是行业创新的必备技能。 学会了如何提问，下一步就是将这种能力与强大的自动化工具结合起来。最近，我将这个理念付诸实践，撰写了一篇关于如何使用N8N搭建自动化写作流程的详细教程，可以帮你将好的“问题”一键变为完整的文章草稿，感兴趣的读者可以进一步阅读：《N8N教程：搭建公众号自动化写作工作流完整指南》。","path":"posts/b59faea6.html","date":"12-31","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"},{"name":"AI","slug":"AI","permalink":"https://zhulg.github.io/tags/AI/"}]},{"title":"技术人在数字化转型中如何为企业赋能","text":"在当下，数字化转型已成为众多企业生存与发展的关键路径。这不仅仅是工具或流程的变革，更是企业在思维认知上的彻底转型。数字化的核心是思维方式的改变，而不是简单的工具更新。 技术驱动数字化转型的关键角色 数字化转型的成败并非单纯的技术问题，但技术确实是其中不可或缺的推动者。技术的作用不仅仅是优化系统，更在于帮助企业将业务模式和技术手段紧密结合，实现降本、增效、提质，并最终反哺业务成长。 作为技术人，参与数字化转型的核心在于具备数字化思维和技术素养，同时深入了解企业的业务需求，找到技术与业务的最佳结合点。这不仅需要对现有业务的深度理解，更需要在转型过程中，通过技术手段推动企业向前发展。 技术如何赋能企业数字化转型 技术的价值往往体现在业务结果上。如果我们从业务结果倒推，哪些因素会影响业务的成功？这些就是技术人员需要重点关注并优化的环节。以下是我认为技术在数字化转型中能够发挥作用的几个关键领域： 生产和销售链路的优化生产和销售环节往往是一个比较重要的，直接与公司的收益最相关，这种存量业务模式相对成熟且重复性较高，技术可以通过自动化、智能化手段来降低成本、提高效率。 比如，使用技术为销售人员提高客户识别、跟踪、获客、销售分析等等，生产过程中用技术改造流程，AI识别协助等，通过技术投入从而大幅提升企业的市场竞争力。 产品服务价值的提升产品服务价值链的延伸是技术发挥创新力的另一个重要领域。技术不仅能帮助企业优化现有产品，还能通过技术创新扩大服务的增量空间，通过这些服务价值给企业带来额外的收益。 比如，利用技术优化客户服务体验、通过技术投入服务潜在客户的产品、提升品牌价值，以及实现企业社会责任目标，这些都能够为企业带来长期的市场效益。 企业智能化体系的建设企业智能化体系是数字化转型的核心，也是技术最为集中发挥作用的领域。从基础设施建设到云服务、大数据、人工智能的应用，技术人员不仅需要实现企业现有业务的数字化，还要建立一个智能化的生态系统，内部链接员工，外部连接客户与合作伙伴，实现真正的互联互通与数据驱动决策。 数字化转型是一个复杂而长期的过程，企业必须根据实际情况，分阶段推进智能化建设。技术人在这个过程中，需要明确自己的阶段性目标，确保每一步都为企业的长远发展提供技术支持。 技术人定位与价值 归根结底，技术人的价值在于如何通过降本、增效、提质和反哺来助力企业成长。 降本增效方面，技术通过合理的资源配置和数据化管理，帮助企业优化决策。 在提升质量方面，技术可以通过数据分析、产品检测等手段，确保业务的高效运行。 而反哺业务的关键，则在于如何利用大数据和AI等先进技术手段，从沉淀的数据中提取洞察，助力业务持续增长。 数字化转型是一个复杂的过程，也是企业寻求新发展的必经之路，技术人也应当在这个过程中找到自己的定位，发挥最大价值，推动企业在新时代中实现新的突破。 以上讲的都是漫谈的形式，由于时间问题并没有详细展开来讲。有数字化方面感兴趣朋友可以评论发表你的思考、看法，也可私下欢迎交流~","path":"posts/6e29db15.html","date":"12-30","excerpt":"","tags":[{"name":"数字化","slug":"数字化","permalink":"https://zhulg.github.io/tags/数字化/"}]},{"title":"学python，拥抱ai：吴恩达Python初级课让你轻松上手编程","text":"在近年来AI应用的爆发下，一跃冲到了排行榜的首位。随着AI技术的快速进步，加上ChatGPT等智能工具的推动，编程正逐步迈向“自然语言编程”的新时代，门槛越来越低，人人皆可成为开发者。 今天，我花了一小时左右看了吴恩达老师的《AI Python for Beginners》课程（地址在文末），看下来非常推荐给没有编程背景的职场人士、学生，以及会计、金融、行政等领域的从业者来学习了解python。尽管是初级课程，也比较适合程序员来学习吴恩达老师的深入浅出教学风格。 吴恩达老师是斯坦福大学的教授，还是全球人工智能领域的领军人物。他曾担任Google大脑的负责人，并在百度担任过首席科学家，拥有丰富的行业经验。 课程基础有趣视频里吴恩达老师也讲了他的观点，为什么其他行业人也建议学，十年前可能不建议其他行业来学，而现在因为有了生成式AI，有了助手，编程更简单了。 非常欣赏这种大师级的人来做一些看似基础的课程，也往往能把一些基础的课，生动的讲给非计算机行业的人这个才是厉害的。视频里先从什么是计算机编程来讲起，并结合日常的例子来说明。 题外话，你可能看到我截图的视频是有中文字幕的，这个建议安装个沉浸式翻译插件就好了，适合英语不好的自动就翻译了（但我建议听原版讲解）。 视频里也重点提到在AI的协助下可以把每个行业要做的事情步骤告诉AI，通过生成代码，来提高自己的工作效率。 ** AI 配合教学视频在讲解能了解Python 基础知识，不仅能快速了解编程概念，python里的变量、函数、循环、数据结构基础语法，能快速知道编程最核心基础是什么样子的。 通过和大模型的结合调用，可以了解一些基本的调用关系，这样通过python的简单语法代码来调用LLM，也就能搞清楚AI 智能体（ai agent）是在说什么。比如下图这个，其实就是通过设置变量后，调用LLM来生产结果，这样多个调用过程结合起来就是AI agent. 如果是非计算机行业，可以慢慢看，每一步骤都有一些可执行的操作，跟着视频来做。 比如下边这个图，中间其实就是一个编辑器，你可以直接修改代码，然后点击运行，这个里面也配置了生成式的chat工具，可以通过对话来指引你程序错误的地方。 写在最后 整体看这个视频教程非常适合新手来学习，不仅了解python的最最基础语法，也能体验和LLM来一起结合调用的体验。 当然这个虽然是大师的课程，如果想进一步学习的话，还是建议针对系统学习python开发语言，python入门简单，通过了解基础语法和生成式AI的结合，你至少要能看懂代码，然后让chatgpt来进行协助，这样很快一款真正的产品才能快速诞生。 这个课程地址： https://learn.deeplearning.ai/courses/ai-python-for-beginners","path":"posts/5d7e12b8.html","date":"12-28","excerpt":"","tags":[{"name":"AI","slug":"AI","permalink":"https://zhulg.github.io/tags/AI/"},{"name":"python","slug":"python","permalink":"https://zhulg.github.io/tags/python/"}]},{"title":"互联网小生意平台推荐，思考适合你的副业机会","text":"前几天写了一篇关于互联网人尽早找到自己一人能做的小生意，尽早觉醒：找到自己一人能做的互联网生意 收到不少读者私信和评论关于小生意怎么做，能感觉到大家对于如何开启小生意及如何利用好互联网平台这块充满兴趣。 尤其是针对设计、技术等互联网行业同学，这块的读者今天重点介绍一些相关副业平台，可以从这些平台上做一些自己的小生意赚钱，或者从这些平台需求痛点上能否给你带来思考，也看看这些外面的世界和平台能否给你带来一些需求灵感，找到自己的一些小生意。 通过这些小生意平台，可以尝试增加收入，更重要的是观察思考找到适合自己的发展方向和副业机会。 先看一些设计类的平台吧，这些平台好的设计都能给我们生活中带来一些色彩（我知道这些设计类平台，是因为有时候我也会看下好的设计和配色如何用技术在应用里呈现），如果设计类同学还知道更多平台，可以补充到评论里，分享使人进步。 设计类平台Dribbble这个在设计圈应该都知道，通过展示作品集吸引客户，可以自己设计挂上该平台，可接单赚钱，适合平面设计、UI/UX设计等领域。 官方地址: https://dribbble.com 99designs 设计师可以参与设计比赛，可以参加比赛获取奖金，也可以直接接设计订单，logo设计，食品包装、书籍封面等等。 官方地址: https://99designs.com Behance全球设计师展示作品集的平台，也提供工作机会的板块，网站的愿景也写的比较明确，帮助招聘人员和创作者通过创意展示来找到彼此联系。 官方地址: https://www.behance.net Creative Market这个网站比较出名设计素材交易平台，适合设计师可以在这里出售自己设计的数字产品，如字体、图标、网站模板，虚拟商品，可以直接上架售卖。 官方地址: https://creativemarket.com 国内的这类平台，有站酷 、花瓣网、稿定网、包图等，整体上比较有浓浓的商业气息，个人不是很喜欢，有兴趣的设计师可以自行对比。 技术类平台建议首先尝试国外的一些平台，尤其是对于技术人员来说，国外的机会相对更多，回报也更可观。相比之下，国内的平台竞争激烈，出价较低，可能并不值得你投入过多的时间和精力放在互卷上，还有可能缺乏创新的东西上。 GitHub Sponsors开源项目资助平台，说白了就说通过自己维护开源项目来接受大赏，维护开源项目可以是代码，也可以是文档等，而且目前平台没有抽成，100%给参与的维护者，需要开通sponsors，参与开源项目维护。 官方地址: https://github.com/sponsors Toptal这个平台适合比较有经验的程序员，从网站介绍也可以看到，当然给的薪资也不低，他的核心理念就是提供专业领域的顶级自由职业者，除了技术，也有设计，金融类项目。 官方地址: https://www.toptal.com Upwork如同网站口号，“How work should work” 他是美国的一个自由职业平台号称全球第一，说白了外包平台，提供有设计、开发、市场营销等，可以在这个上边找到对应的开发需求，比如app开发国内已经趋于饱和下，在全球来接单显然更有优势一些。 官方地址：https://www.upwork.com/ Freelancer规模上和Upwork不分上下，也是为自由工作者提供工作机会，还是外包服务平台，除了技术类，也有其他设计、工程类，科学、营销等，程序员的话可以提供定制软件开发、网站构建、应用开发等接全球各地的项目，其中技术类也有前后端项目，具体可以根据自己技术来找工作。 官方地址：https://www.freelancer.com/ Stack Overflow Jobs这个比较适合程序员来通过Stack Overflow上的工作板块寻找远程兼职工作，这个因为可以面向全球，你可以有选择有目标来进行投递，保持技术连续性，另外也发现一下国外都在做什么应用，我随便搜索了下android这个岗位，发现也是有不少的。 也说下国内的相关平台吧，猿急送，程序员可以通过接单为客户提供定制开发，也可以通过查看需求自己是否来接单，猪八戒网，里面比较多各种门类，整体来说就是有人发需求有人来接，整体来看就是我之前讲的内外套路外行，互相糊弄的居多。 写在最后介绍这些小生意平台，不是鼓励大家都来接单赚钱，我觉得更多是帮助大家打开一些思路和点子，更好的结合自己优势和兴趣发现生意。 把自己的一份时间和付出服务于更多的人，同时给自己带来盈利。之前有提过知识付费，现在也有一些这样的平台，也适合非互联网行业的人，大家都可以直接参与进去售卖所在行业知识和经验。 希望以上这些小平台能给大家带来一些观察和思考。","path":"posts/e3b99003.html","date":"12-28","excerpt":"","tags":[{"name":"互联网副业","slug":"互联网副业","permalink":"https://zhulg.github.io/tags/互联网副业/"}]},{"title":"互联网人必备！draw.io：免费好用的作图神器","text":"今天要给大家推荐一个超级好用的作图神器——draw.io，特别适合各行各业，尤其是我们互联网行业的朋友们，简直是作图的必备工具。 为什么说它是神器？因为draw.io支持在线使用，不需要安装繁琐的软件，打开网页就能直接使用。如果你更喜欢在本地操作，它也提供了PC安装包。支持多种存储方式、可以本地导入导出，轻松导出为图片或其他文件格式。 最重要的一点，*称之为神器的核心原因就是：功能强大、操作便捷，而且完全免费，无任何套路！*** 对互联网人来说，无论是制作产品原型图、流程图、架构图，还是项目管理图，draw.io 都不在话下，轻松拿捏。 1. 下载或直接打开在线使用直接打开网站https://draw.io/ 即可，如果想把自己历史作图文件进行保存，建议和github一起来结合（我是一直这么使用），这样源文件也进行了保存。当然也支持多种存储方式。 如果想直接安装软件在自己的电脑上，去https://www.drawio.com/ 下载即可 你会从下载地址看到有windows、Mac版本，选择自己要下载的安装即可。 如果你想学习下构建这个桌面软件的源代码，也是可以的。从这个工程下可以链接到draw.io的代码（适合技术人员关注） 轻松上手 如果你喜欢使用本地版本，安装后打开可以设置语言，方便英语不熟悉的同学使用。下面这个图可以设置对应的语言选择。 打开后可以创建作图，可以建立空白工程做图，也可以从模板里进行选择。 以时序图为例，可以轻松拖拽，傻瓜式操作，到这你可能已经能看到很多比较漂亮的图，之前网上可能见到过的，这里面都有配图和操作。 下面这个图的效果是不是在一些技术博客经常看到，你可能不知道怎么做的，有这个工具你也就知道怎么做了。 也提供有丰富的多种元素供添加和使用： 支持多种导出 做好图后直接选择导出方式，可以把需要的图导到本地，导出的同时可以选择必要的设置，使导出的图更加漂亮一些。 导出的一些效果图，这些是我之前的一些老图（看效果即可不用关注内容） 技术细节时序图： 商务类图：","path":"posts/4b03ee24.html","date":"12-27","excerpt":"","tags":[{"name":"作图工具","slug":"作图工具","permalink":"https://zhulg.github.io/tags/作图工具/"}]},{"title":"从0到1，用Rust轻松制作电子书","text":"在之前的文章《经济下行的时候，这些行业可能会更好》中，我简单提到过用 Rust 做电子书，有收到读者朋友的私信，问怎么做电子书。今天正好有空，就来快速为大家做一个详细的介绍。 制作电子书其实用途广泛，不仅可以用于技术文档、用户手册、教程等，还可以应用于文学创作。如果你有想法写小说或者做知识付费，电子书也是一个不错的切入点。特别是知识付费领域，通过小范围试水电子书，收集读者反馈，进一步打磨内容，最后也可以出版成书。 好了，有点扯远了，我们重点先说下怎么用Rust做电子书。 1. 环境准备我们准备用Rust来创建电子书，首先，需要安装有Rust的环境，Rust环境安装也比较简单打开官方地址，复制安装命令安装即可。 1curl --proto &apos;=https&apos; --tlsv1.2 -sSf https://sh.rustup.rs | sh 其次，需要对Markdown语法了解，如果不了解的可以看下，强烈推荐所有人来学。很多精美的排版和插图都可以通过md语法来实现，现在更有md的编辑器，稍微了解配合编辑器就能如虎添翼了。 如果有不熟悉markdown可以到这个网站来学习了解下，https://www.markdownguide.org/ ，也可以其他中文网站了解。 2. 安装使用介绍下我们做电子书的主角mdBook，一款由rust实现的开源软件，可以进行文档生成，搜索，语法高亮，生产的电子书可以支持在PC、和移动设备打开使用。 通过cargo来安装 1cargo install mdbook 安装成功，可以进行创建 1mdbook init my-first-book 创建过程中可以起名字，创建完成后到该文件目录下 12cd my-first-bookmdbook serve --open 打开地址http://localhost:3000/ ，可以看到创建的电子书模板已经打开了，尽管内容还是空的，但电子书的结构已经有了，左边导航，右边文章内容，以及搜索框。 剩下就是我们写电子书的内容了。 3. 写电子书内容在创建的电子书工程下，会看到src文件目录、book.toml配置文件、book目录，我们先关注电子书的内容src目录 12├── SUMMARY.md└── chapter_1.md SUMMARY.md 里打开可以看到就是左侧的导航配置，比如对应的章节配置在这个文件里，chapter_1.md就是对应的章节内容 12# Summary- [Chapter 1](./chapter_1.md) 可以对chapter_1.md进行内容写作，就可以形成对应的电子书的内容了。 比如这个我复制了个内容，修改了章节命名，然后重新刷新即可看到内容。 4. 部署电子书制作完后，编译后会发现在book的目录下会有编译好的文件，可以通过GitHub Pages上这样完全可以免费，也可以支持远程别人打开和阅读。","path":"posts/4f00c682.html","date":"12-26","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"}]},{"title":"技术人必修课：锻炼自己的商业思维","text":"在技术人职业生涯中，前期大家一直崇拜技术，视技术为自己绝对的核心竞争力。这个没错，也是技术人的本分，但是技术人也要锻炼自己的商业思维。 “商业思维通常指在经营管理过程中，以市场作导向，以客户需求为中心，将资源、产品或服务转化为可持续商业价值的方法的能力”。 那技术人的商业思维是什么？直白点来讲，就是能看透并利用技术产生商业价值，让技术从幕后到前台，用技术赚到钱的思维能力。当然这个前提是合法合规，不能歪门邪道，否则不叫商业思维，叫非法谋取利益。 为什么技术人要锻炼商业思维呢，因为利用好自身技术并结合商业思维更能理解赚钱路子。具备商业思维不仅能帮助你理解好公司产品和业务模式。对后续自己创业或者开启副业都有帮助。 有没有遇到过这种情况，想必一定有的，比如：刚搭建好的系统架构和模块设计，突然业务需求或者市场模式发生了变化，不得不改造及扩展。有时改动还比较大，想想为什么，市场的本质就是变化和波动，我们设计的模块是不是符合真实业务和商业模式？早期做打车平台设计只有出租车，后边有了快车、专车，豪华车等等车型运营，技术平台设计也就要扩展适配运营。这些其实不仅仅是技术上的问题，更是你对业务和商业思维的缺乏思考，没有一定的商业思维和意识，技术设计也会存在局限性。 在公司还有一些试错成本，那如果自己出来创业呢，只有技术，没有商业思维，那创业想必也是必死无疑。 从小事上培养商业思维我们做技术的很容易陷入到技术和代码的“死胡同”，埋头苦干却缺少抬头看路的情况，同样商业思维的锻炼应该是从身边的小事或者从自己实现的产品里多一些观察和思考，刻意锻炼自己的商业思维敏感度。 举个例子，吃饭时候观察下那些生意火爆的店都常常存在排队，那他们火的原因是什么，好吃？一定有这个因素，但肯定还有其他的，地段、定价、口碑，营销、服务等等，能否分析和总结出这些小店的成功因素。你去理发店可能会更有感触，理发店核心是做出漂亮的发型，同样除核心竞争力还有哪些因素促使一家店经久不衰，这些背后因素能否发现或者正确找出成功关键点，逐渐培养自己对商业机会的敏感度。 当前短视频和直播带货也比较热，有没有想过，这背后是不是有一整套的商业逻辑和生态，在如此火热的时代下，作为技术人，你有哪些思考。 自己也加入视频创作和直播？不反对，但是你可能也知道现在做的成功概率及能否做的起来。 用技术人的商业思维，应该是如何服务这些群体。 就犹如刘强东先生之前说过，大部分中国人赚钱方式别人怎么做，我也来跟。记得他举了个”犹太人开加油站的故事“，别人是通过有了一家加油站后，做了加油站旁边的配套项目，而不是我们看到加油站赚钱，就跟风在旁边都开起加油站来。。。 如果我们不思考，不具备一定商业思维，直接跟进，那就和上边例子一样，况且自己不擅长也肯定赚不到钱。 那我们技术人正确思维和做法是利用技术优势做为他们生态提供者参与进来，做配套项目，做衍生产品，这样你前期独一份的时候就能快速赚到钱。 从实际工作中切入锻炼从自己的工作场景和项目中找到切入点，锻炼自己商业思维，先从小的、具体的业务问题入手。比如，想想你所参与的项目，它服务的目的是什么？用户需要什么？公司是怎么靠这个项目盈利的？需求背后原因是什么？ 这些问题看似基础，但往往被我们技术人所忽视，当你开始思考这些问题的时候，其实就是在培养商业思维了。 理解公司如何运作，客户为什么愿意为你的技术方案买单，是商业思维的第一步。通过参与项目需求讨论，多和产品、市场同事沟通，逐渐摸清业务背后的逻辑。这里要啰嗦下，我们技术人有时不愿意和市场或者销售来做更多沟通大家语言多少有些不理解，但技术人想让自己提升，想锻炼商业思维，就要多接触市场这些人，多聊对自己打开技术外的思维非常重要。 如果上边能做到理解和领悟，那你在实施中通过让技术和商业目标结合就会更加合理和自然，你可以提出改进建议，不仅仅是基于技术上的提升，还要考虑这个改进能不能为公司带来更多收益或降低成本。或者，在开发新功能时，提前想到客户需求的变化，设计更灵活、可扩展的架构。这些都是用技术去服务商业的实际例子，这些做对了公司不仅降本增效，自己的商业思维和技术结合的能力也就大大提升。 技术和商业双向奔赴作为技术人，其实商业思维和技术能力是相辅相成的。你会发现，当你具备了商业思维之后，原本那些看似枯燥的项目、代码实现逻辑，他们背后都藏着商业逻辑和运营管理因素。 有了商业思维，做技术决策时就避免埋头苦干，而是能更清楚地知道，为什么要这么设计？为什么要花这么多时间优化？项目的商业价值在哪里？钱到底是怎么赚的？这些问题不再模糊，而是变得具体起来。 平日里还要多跟非技术背景的人交流，这点也很重要。他们的想法往往能帮你跳出技术的框架，拓宽你的视野。无论你是准备自己创业，还是继续在公司深耕，商业思维加上技术的组合拳，能让你在任何情况下都游刃有余。 如果你一直关注自己商业思维锻炼，你会慢慢发现一些商机，也就知道如何用技术以及该不该把它来实现，这样一来，你的职业选择和发展空间也会越来越广阔。","path":"posts/adbd9bd2.html","date":"12-07","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"}]},{"title":"后端工程师，必须掌握的8大技能","text":"在之前的文章介绍过全栈工程师的练就之路，《全栈工程师，练就之路：如何学，如何做》今天展开来看下，最近几年比较流行的后端开发技能，也看看还有哪些没有掌握的后端技能。 1. 编程语言适合后端开发的编程语言，也是目前比较应用广泛的， Java、GO、Python、Rust 我推荐这4种，但也有node.js 和PHP、Kotlin这些（毕竟今天我主要讲主流和流行的后端技能）也有一些应用在使用，目前占比不大。 java后端开发尤其是Spring框架下还是被大量应用所使用，GO因其高并发性能，在微服务和高并发场景下广泛使用，python不仅在脚本使用，大量AI和机器学习类也广泛应用。rust在后端方面以安全和高性能著称，在后端、区块链应用也有巨大优势。 2. API相关开发 具备能对接口设计和开发的能力，能对业务进行抽象定义，把业务转为为数据结构和表结构的设计能力。 RESTful API ,设计清晰、易扩展的API接口 gRPC：适合高性能微服务通信，是开源的远程过程调用（RPC）框架 GraphQL 既是一种用于 API 的查询语言也是一个满足你数据查询的运行时。 3. 数据库相关技能关系型数据库：肯定是MySQL、以及PostgreSQL、Oracle等关系型数据库，具备理解SQL语法、查询优化和数据库设计核心技能。其他的NoSQL数据库：如MongoDB、Redis、Cassandra等，适合处理大规模数据、高并发读写。 4. 框架化应用技能 • Spring Boot/Cloud (Java)：用于快速构建独立、生产相关Spring的应用，应用最广泛的框架 • Django/Flask (Python)：一个全功能和轻量级的Web框架，适用于python开发 • Express (Node.js)：简洁且强大的Web框架，也比较常用 5. 消息队列系统技能RabbitMQ 其设计偏向于消息传递的可靠性和灵活性，RabbitMQ 以队列为中心，消息通过交换器（Exchange）发送到不同的队列。 Kafka 一个分布式流式处理平台，基于Zookeeper协调的分布式消息系统，可以实时发布、订阅、存储和处理数据流，适用于大规模数据处理和日志管理。 6.docker容器化技术Docker 容器化技术，能够创建、管理和部署容器化应用，简化了应用环境配置问题，打包成为镜像。 Kubernetes 用于大规模容器编排和管理 7.代码管理和自动化部署类Git命令后操作、GitHub、GitLab 的使用。 CI/CD工具,如Jenkins、GitLab CI，能够持续集成与交付。 自动化部署类，熟悉AWS、Azure、Google Cloud等云服务，这块其实有部分是和运维同事重叠的技术能力，了解即可。 8.架构、性能、安全类技能这类技能要根据具体的编程语言、应用规模相结合在整体来做，并在日常中学习和锻炼的技能。 架构类，如何架构微服务、单体架构的区别与使用场景，具体开发中的设计模式应用，架构原则的遵循。 应用中性能的调优，数据库查询和缓存的优化，对组件安全方面合理选择，语言和框架安全类的日常关注、能从整体考虑系统的扩展、健壮性的掌控能力。 其他一些技能在后端开发中，日常问题的分析和定位能力，如何通过问题发现架构和设计的本质缺陷。 如何优化分层和系统设计降低应用耦合，如何通过上线前合理规划架构和设计，上线后的日志监测和报警、服务的自恢复、降级策略的制定。 写在最后后端的技能也在不停迭代和更新，熟练运用现在比较流行的后端技术，清楚知道使用场景，并保持学习，从整体上来用合适的技术选择结合业务场景来确保后端服务的稳定，并保持自己在后端技术迭代升级。 PS: 也欢迎大家评论和交流~ 更多文章也可关注微信公号：良技漫谈","path":"posts/f82f20d4.html","date":"12-02","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"}]},{"title":"失业潮下，互联网人如何面对，给自己留好后路","text":"在全球经济下行的大背景下，失业潮正以不可阻挡的势头席卷而来，任何行业都很难幸免。 互联网行业，曾经风光无限，如今也显得步履维艰。随着基建生态成熟，资本退潮，市场存量博弈愈发激烈，裁员的阴影也笼罩着一线大厂。从阿里的“瘦身”到腾讯的“断臂”，一波波暗流涌动的裁员潮已在行业内频繁上演，小公司的日子就更不必多言。 面对这样的现实，越来越多的互联网人被迫直面失业，身边的同事、朋友大家也不把失业当成需要隐瞒的秘密，而是大家互相调侃，并能冷静应对的常态。 当失业情况成为常态，我们该如何面对、以及如何为未来做好准备，给自己留好退路。 冷静面对提前规划先看一组网上相关数据情况，作为参考。仅在2023以来，阿里巴巴、腾讯、百度，字节、京东企业的裁员人数已超过数万，在有一些中小互联网，数据可能比这个要多。这里面无论你是资深技术专家还是初入职场的新人，可能都无法置身事外，这个曾经风光无限的行业，如今正遭遇前所未有的寒冬。 失业，特别是突如其来的裁员，往往让人猝不及防，在面对这场互联网行业的“生存游戏”时，最重要的是保持冷静，接受变化。互联网行业的周期性波动早已不是新闻，失业不过是其中的一部分。与其一味抗拒，不如学会接受现实，并将其视为一次重新出发的机会。 提前规划经济生活确保稳定，避免高负债，谨慎对待信用卡、贷款等消费方式，确保自己有足够的紧急储蓄，以应对未来几个月的生活支出，让自己保持不慌 ，如果有房贷这个可能要考虑能否提前偿还一部分，减少月供，毕竟现在利率存款也很低（提前还贷这块仅个人建议，慎重参考） 经济上的从容，可以在失业时，给我们不慌的勇气，可以有时间去调整和重新规划未来。 打造自己“不可替代性“面对失业潮，唯一不变的就是不断提升自我，增强自身在职场上的竞争力。互联网行业瞬息万变，只有持续学习和更新技能，才能在这个残酷的行业中保持“不可替代性”。 这里不可替代性，不是指让技术做防御性代码编程，让产品做互撕，做部门刺头对做外沟通、互抢资源，这些low的操作，也是不提倡，也不会长久，害人害己。 不可替代是要跟随公司业务，积极尝试利用新技术提升自己和公司效率，比如多接触AI、区块链、大模型如何为公司业务结合和创新，多学习产品思维，商业思维为业务出谋划策，同时深入到技术深水区，解决其他人无法搞定的事情技术或者能力，无论你是技术、产品、运营、设计，是否具备自己是支柱的能力，没有就向公司支柱者学习，打造不可替代性。 副业B计划如果今天通知你裁员离岗， 明天你是否有有自己的副业、有自己工作的B计划、谋生的后路？ 大家都困难的时候，也往往会有新领域进入的机会，发挥自己的优势，能否多次出卖自己时间的能力，我写的有篇找到自己能做的生意就是这个意思。自媒体、直播，技能分享、结合新模式让自己经验技能服务更多人，换来自己的副业。 如果你在互联网行业待的久，也积累了一定的行业经验和资源，不妨考虑创业。但要注意少投入交学费心态来进行，即便失败不影响自己生活。互联网低门槛、高传播性加上自己在这个圈子的技术、产品、资源的理解，也是尝试的，在寒冬的同时也一定有新的模式和机遇产生，也许是你找到新的大陆。 学习提升认知积极参与技术社群、线上线下的行业活动，适当扩展自己在行业的影响力。这个时代不营销自己，会很吃亏。这个只有自己吃过亏，你才能真正理解我说的，毕竟我曾经也吃过。 向身边优秀的人学习，他们的思路和认知可能一针见血能帮忙你指点迷津，有些问题和困难在自己的认知层面你是找不到答案的。 可以多请教行业内资深人事，保持沟通，了解行业趋势与动向。通过他们的经验与建议，你可以更好地规划未来的发展方向。 保持平常心往往行业困境中也一定蕴藏着新的生机，如果我们尽早做好准备、持续提升，失业潮不仅仅是一场挑战，更是一次重新审视自身、调整发展方向的契机，我之前文章专门写过。 相信再漫长的冬季也终将过去，而春天的曙光必然会到来。保持平常心，熬过寒冬，未雨绸缪，给自己留好退路。","path":"posts/80da3ca2.html","date":"12-02","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"}]},{"title":"技术人必读：在数字化转型中如何为企业赋能","text":"在当下，数字化转型已成为众多企业生存与发展的关键路径。这不仅仅是工具或流程的变革，更是企业在思维认知上的彻底转型。数字化的核心是思维方式的改变，而不是简单的工具更新。 一， 技术驱动数字化转型的关键角色数字化转型的成败并非单纯的技术问题，但技术确实是其中不可或缺的推动者。技术的作用不仅仅是优化系统，更在于帮助企业将业务模式和技术手段紧密结合，实现降本、增效、提质，并最终反哺业务成长。 作为技术人，参与数字化转型的核心在于具备数字化思维和技术素养，同时深入了解企业的业务需求，找到技术与业务的最佳结合点。这不仅需要对现有业务的深度理解，更需要在转型过程中，通过技术手段推动企业向前发展。 二，技术如何赋能企业数字化转型技术的价值往往体现在业务结果上。如果我们从业务结果倒推，哪些因素会影响业务的成功？这些就是技术人员需要重点关注并优化的环节。以下是我认为技术在数字化转型中能够发挥作用的几个关键领域： 1. 生产和销售链路的优化生产和销售环节往往是一个比较重要的，直接与公司的收益最相关，这种存量业务模式相对成熟且重复性较高，技术可以通过自动化、智能化手段来降低成本、提高效率。比如，使用技术为销售人员提搞客户识别、跟踪、获客、销售分析等等，生产过程中用技术改造流程，AI识别协助等，通过技术投入从而大幅提升企业的市场竞争力。 2. 产品服务价值的提升产品服务价值链的延伸是技术发挥创新力的另一个重要领域。技术不仅能帮助企业优化现有产品，还能通过技术创新扩大服务的增量空间。例如，利用技术优化客户服务体验、提升品牌价值，以及实现企业社会责任目标，这些都能够为企业带来长期的市场效益。 3. 企业智能化体系的建设企业智能化体系是数字化转型的核心，也是技术最为集中发挥作用的领域。从基础设施建设到云服务、大数据、人工智能的应用，技术人员不仅需要实现企业现有业务的数字化，还要建立一个智能化的生态系统，内部链接员工，外部连接客户与合作伙伴，实现真正的互联互通与数据驱动决策。 数字化转型是一个复杂而长期的过程，企业必须根据实际情况，分阶段推进智能化建设。技术人在这个过程中，需要明确自己的阶段性目标，确保每一步都为企业的长远发展提供技术支持。 总结：定位与价值归根结底，技术人的价值在于如何通过降本、增效、提质和反哺来助力企业成长。降本增效方面，技术通过合理的资源配置和数据化管理，帮助企业优化决策；在提升质量方面，技术可以通过数据分析、产品检测等手段，确保业务的高效运行；而反哺业务的关键，则在于如何利用大数据和AI等先进技术手段，从沉淀的数据中提取洞察，助力业务持续增长。 数字化转型是企业发展的必经之路，技术人也应当在这个过程中找到自己的定位，发挥最大价值，推动企业在新时代中实现新的突破。","path":"posts/7c7de3fd.html","date":"11-27","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"}]},{"title":"互联网技术人表达力提升：3个珍藏方法，快速见效！","text":"在技术的世界中，逻辑是至高无上的法则；而在现实中，表达能力则是成功的关键。 互联网技术人员在与他人沟通时，常常听到被戏称为“说人话”或“听不懂”。这种现象反映出他们在表达中使用了过多的技术术语和专业痕迹，而又缺乏必要的表达锻炼，导致外行人难以理解。 尤其在与业务人员和运营人员的沟通中，缺乏产品人员的协作，问题更为突出。 互联网技术人，如果想在职业生涯中全方位提升自己，其中表达能力也是重要的软实力，他也等同于你的技术硬实力，二者都要强，尽量不要存在短板。 无论在技术团队管理中，或者自己技术答辩、日常工作与业务和产品人员沟通中，良好的表达能力都会帮助推动项目进展，赢得支持。当然互撕除外，话说回来，就算互撕，你是不是也要有很好的表达能力，不至于说出的话，让别人无法信服吧。 自己也是从一线技术小白一路摸索过来，到带领技术团队后，很多技术人身上也看到过自己当年的身影，特别在表达这块，或多或少是技术理工男的天性，大家都不擅长表达。在团队内也常分享或者逼迫他们去表达自己，从讲解技术入手，组织定期轮流分享来锻炼大家表达能力。 除此之外，也分享自己摸索的锻炼表达能力的方法，这些适用于所有人。（特别使用互联网技术人，因为我曾经也是纯粹的技术男，也是这样锻炼自己的，不妨试一试） 方法一：刻意总结和提炼这个可能很多人知道这个道理，但不一定会实战，或者总结不出来核心东西。其实，道理很简单，如果别人给你讲了一个故事，一个事情、一部电影、一项技术等等。你能否从他们讲的故事中总结出来他要表达的东西？ 你可能会用几个短语来描述，或者又开始长篇叙述，一定是这样的，不信你可以试一试？（这些都不是好的表达方式） 刚开始，可以把这个故事进行提炼，用自己的表达方式在2，3句话内，抓住重点来总结，如果说不明白，那就尝试写下来，用文字来表达出来。然后与这个故事或事情的讲述人来核对看看。 反复锻炼，自己的表达能力无形中就会提升。 方法二：多阅读写思考道理很简单，就是鹦鹉学舌。 绝大部分人没有一开始就特别会表达，天赋除外，多阅读是最有效锻炼自己表达能力的方式，看起来一个是读，一个是说有点不相关。 事实并非如此，在阅读别人的文章时候，有可能写的内容你是知道的，比如，对于技术人来说，如果一篇技术文章你也知道原理，但是能否表达的跟别人写出来的文字表达更通俗易懂，好的文章一定是读完豁然开朗，这里面也一定有优秀的表达艺术。 从阅读中，看别人怎么表达，同样一句意思，别人用的为何如此恰到好处，模仿和学习这些文字的表达方式。阅读后，把自己的思考和想法写下来，坚持写思考和想法。 阅读多了知道别人怎么表达，思考写多了就把自己的表达思维也就更加清晰了，我记得TED上也有人分享过类似的方法。 方法三：借助AI 工具这个是最近发现非常高效的方法，无论是总结提炼还是你自己写文章，ChatGPT有个强大的能力，优化语句，这个其实在锻炼自己表达时非常有帮助。 你可能满头大汗写了自己的总结、发言稿、分享材料，可能写的过程中你自己都觉得不通顺、词不达意，更何况这东西是你要表达给别人的。。。没关系，先自己写出来。 写完后，把自己的草稿文字和要表达的要求告诉GPT来协助优化，来看看他对某段话的表达方式，跟你草稿区别在哪里，问什么他优化的更通顺。 通过对比和取舍你应该能从中学到好的表达方式，这个对表达的提升非常有帮助，与此同时也要注意防止AI的机器化，否则你的文章可能是空洞和无味，要学会取长补短的能力。","path":"posts/da6a9067.html","date":"11-27","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"}]},{"title":"2024年Rust的八大应用领域","text":"Rust的八大用途你了解多少呢？| 良技漫谈介绍下Rust的主要应用场景，特别是第8点目前也有不少在应用。 1. 系统编程：Rust 因其内存安全性和高性能，适用于开发 操作系统、设备驱动、底层库和系统服务。 2. 高性能网络开发：Rust 常用于构建 高性能、低延迟的网络服务器和分布式系统。 3. 嵌入式与物联网 (IoT)：Rust 的资源效率和跨平台特性，使其非常适合用于开发嵌入式设备固件和物联网应用。 4. WebAssembly和前端开发： 支持将代码编译成 WebAssembly (Wasm)，在浏览器中以接近原生速度运行，适合开发高性能前端Web 应用和浏览器扩展。 5. 命令行工具开发 (CLI)：Rust 的高效性能和良好的跨平台支持，使其成为开发命令行工具 (CLI) 的理想语言，最近也有很多基于rust重新的好佣的命令行工具。 6. 区块链与加密货币：Rust 因其内存安全性和高并发处理能力，被广泛应用于区块链技术开发，包括智能合约、加密钱包、去中心化交易平台。 7. 游戏开发：Rust 的 并发处理和图形处理能力，使其在高性能跨平台游戏开发中表现出色。 8. 其他领域：Rust 在桌面应用、跨平台移动端底层组件开发、人工智能 (AI)、数据科学和音视频处理等领域逐渐得到应用，以完全和高效性能被广泛多领域选用。","path":"posts/7c9bf2c4.html","date":"09-18","excerpt":"","tags":[{"name":"Rust","slug":"Rust","permalink":"https://zhulg.github.io/tags/Rust/"}]},{"title":"用2个重要途径，打造自己技术影响力","text":"对于绝大多数技术人来说，往往会忽略自己在行业里的影响力，更多是埋头在自己所在的技术领域里，专注于解决具体问题、提升技术能力。 然而，在现在高速发展且高度内卷的时代下，单纯拥有技术实力可能并不足以让你脱颖而出，亦或许在短期内有不错的成就，但如果没有影响力支持，这些成绩也可能难以转化为持续的发展优势。 影响力对技术人来说，实际上是一种无形的资产。它不仅能为你带来更多的机会，还能激励你不断学习和提升自己。 技术影响力技术影响力都有哪些 ，本质是什么。 技术影响力可以是行业内的关注度，能否被行业里大家所熟知，技术相关点能否被大家认同，技术方案能否被大家认同等。其本质是技术影响力能否被影响他人决策和思考的能力（当然是最佳实践方面相关） 例如，通过对某一技术的深入理解和讲解，你可以在技术圈内扩大自己的影响力。这种影响力不仅可以在团队或公司内部建立权威和信任，还能在更广泛的社区中得到认可，进而形成对你个人品牌的强大支持。 如何打造影响力持续输出和分享有价值的内容，技术使用，问题分析和定位、架构设计和思考。 尝试下写作和演讲。 写作的锻炼可以从技术文档的翻译，技术方案的整理，能否被别人轻易理解和认同代表着自己写作表达和总结能力的提升，持续写作和输出。而当你逐渐掌握了写作的技巧，原创内容的输出将成为你个人品牌的一部分 。有时你会的技术和你涉及的技术方案，不一定能用文字很好的写的出来，写的出来不一定能让其他人看的懂知道你在说什么。不信的话，你可以尝试来写下，一个好的技术文档输出也绝对需要多次的打磨的。 我们写作时用心投入，结合例子让别人能快速理解，是自己的原创，不要一顿操作和转载，自己也没有消化。要对内容负责，坚持这样的写作态度才能吸引并引起读者的共鸣。还有个技巧，当写作的时候看看能否用一句最少得字数，清晰的表达出对应的技术方案，这些锻炼都有助于对文字总结概括能力的培养，我们称之为”能写“。写作的平台上可以自己建立博客，公众号、视频媒体等，看自己喜欢那种。也不要把时间对花在了影响力打造上，这样你技术钻研的时间也会很少，会变成技术人眼中的”很能说“，要追寻技术和影响力的平衡点。 技术人演讲，不仅能把自己技能分享输出扩大自己影响力，演讲的准备工作也是对自己知识点提升的重要手段，绝对是一举得到的收益。演讲不仅需要对掌握的知识的概括和总结，还需要有良好的表达能力。要成为一名优秀的技术演讲者，关键在于反复练习和精心准备，那种表达是别人容易听懂的，哪些是不需要反复啰嗦，需要精简的，如何在有效限的时间内，提炼出最核心的内容，并用简洁有力的语言表达出来。也可以多听下别人的演讲，比如TED上技术人演讲，学习他们的表达方式和逻辑结构，从魔法加自己的练习，敢于在公众面前发表自己的技术观点，可以在小组内进行技术分享，公司呢，外部社区，慢慢就会提高自己的技术演讲能力了。另外，每次在演讲后自己可以从侧面关注下听众的反馈，复盘自己的演讲，哪些点讲的不好，哪些地方需要观众互动，那个例子举的还不够贴近等等，复盘是为了下次更好。 长期主义打造自己的技术力一定是从小范围开始并努力扩大，同时也是一件需要技术人坚持的长期主义。 有时我们被工作压的没有时间进行自我总结和分享，就更别谈尝试做技术影响力的事情了，能把当天工作做完就不错了。但作为技术人我们需要把抽时间来把自己影响力，自己的技术品牌持续维护起来，这样才能让让自己进入良性循环，毕竟除了上班打工也要把自己技能让等多人知道，为后续自己副业和人脉做准备。 影响力的积累是一个长期的过程，需要耐心和毅力，无论是进行写作还是一些演讲或者公开教程，都需要一点点积累，持续分享和帮助更多的人，把这件事作为长期主义来坚持。即使短期内效果不显著，也不要放弃。坚持做正确的事情，将影响力转化为职业生涯的强大助力，也是每个技术人应当追求的目标。 写在最后影响力的建立是技术人职业发展的关键环节，它不仅反映了个人的价值，也总结和传递了自己的知识和经验，同时也是技术宣传的重要手段。每一次用心的输出和分享，都是在帮助更多的人。 真正的影响力，也不在于一朝一夕，而在于我们在不断成长中，始终如一的付出与坚持。","path":"posts/c0234e14.html","date":"09-06","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"}]},{"title":"技术人别被AI课割韭菜","text":"这篇文章，或许会引起那些专门售卖AI课程者的不满。我要强调，这里说的是那些纯粹割韭菜的AI课，真正有深度和干货的课程自然另当别论。 作为技术人，你是否已经注意到这些现象？这些课程大多打着“大模型”的旗号，内容却五花八门，从AI写作、AI作图、AI编程到用AI快速赚钱等等，无所不包。 仔细分析这些课程，会发现大多数内容浅显，仅停留在表面应用。课程或许教你如何使用提示词、如何做个图、通过比喻讲解一些模棱两可原理，或教你输出一些文章，整体来看虎头蛇尾。 这些课程通常存在以下几个问题： 内容浅显：大多数课程只讲解基础概念，缺乏深入的技术原理和流程环节。 缺乏实践：很多课程没有实际项目的指导，或者仅通过简单例子介绍AI工具的使用。 误导性宣传：有的课程夸大效果，贩卖焦虑，吸引对AI感兴趣的技术人，实际操作远非如此。 例如，之前有新闻报道某些利用AI课虚头大肆卖课割韭菜的事件，某清华教授靠卖AI课狂赚上亿，然而他本人却是门外汉，靠的就是营销割小白韭菜。 图片 这些课程是否一无是处？也不尽然。 对于小白用户，如果想快速了解某些概念，利用现有的AI模型和工具制作图像、视频，这些课程可能会提高工作效率。如果你懒得查资料且有经济条件购买，这类课程也许有帮助。 但对于技术人来说，这类课程并不建议。你需要防止这些课程误导你对AI和大模型产生错误认识。 仅知道概念、会使用ChatGPT等AI模型，对于技术人来说远远不够。非技术人如果掌握了提示词的使用，可能比你还会操作，毕竟现在国内也有很多出名的大模型产品，包括百度的文心一言、字节的抖音豆包大模型、腾讯的混元大模型、百川智能的百川大模型、Kimi和科大讯飞的星火大模型等等，一些写作类用户可能使用的更为溜一些。 技术人学习大模型技术，可以结合自己的情况和发展方向选择一些入门基础课程。以下是我认为需要学习和了解的内容： 首先，如果你是计算机专业出身或从事技术工作，应了解数学、统计学和编程语言。大模型时代使用较多的是Python语言，但语言只是工具，不要局限于此。 了解AI大模型的相关名词和概念，它们之间的关联和关系，比如以下这些术语： • AI (Artificial Intelligence): 模拟人类智能的计算机系统。 • Machine Learning (ML): 通过数据训练模型，使计算机能够自动学习和改进。 • Deep Learning: 使用神经网络进行的机器学习，通常具有多层架构。 • Neural Network: 模仿人脑结构的计算模型，用于识别模式和预测。 • Natural Language Processing (NLP): 计算机处理和理解人类语言的技术。 • Training Data: 用于训练机器学习模型的数据集。 • Model: 通过训练算法从数据中学到的数学表示，用于预测或分类。 • Algorithm: 一组用于解决特定问题的规则或步骤。 • Transformer: 现代NLP中的重要模型架构，依赖于自注意力机制。 • GPT (Generative Pre-trained Transformer): 一种生成式预训练语言模型，用于生成文本。 其次，了解原理后，需要深入学习大模型所使用的相关技术，如神经网络、卷积神经网络（CNN）、循环神经网络（RNN）、生成对抗网络（GAN），以及用于文本处理的NLP、图像识别的计算机视觉。深入理解Transformer模型的结构和工作原理，学习大模型的训练方法和技巧，如分布式训练、混合精度训练等，学习如何优化大模型的性能和调优超参数。 最重要的事，自己动手实践。可以搭建一些开源大模型，用本地的CPU进行部署，学习API相关调用，进行数据准备和预处理、模型推理和结果解析等操作。通过这些实践，你会对大模型有更深入的理解。对于技术人来说，这还只是知道大模型在每个步骤大概的工作方式。 技术人学习AI大模型，先理解其工作原理，再去做开源模型部署和调参数以及服务的对接，确实大多数技术人不从事底层大模型开发，但在应用层开发和使用大模型技术时，要多要思考大模型技术如何服务于当前的产品，并与未来的产品业务形态结合，提高效率。 技术人不要被市面上贩卖焦虑的AI韭菜课所迷惑。 任何技术都有连续性，不是凭空冒出来的新技术，脚踏实地学习技术本质才能实现更多的结合与创新。 与其花费时间和金钱在这些课程上，不如动手实践一个能真正提升效率的自动化项目。例如，你可以参考我最近发布的《N8N教程：搭建公众号自动化写作工作流完整指南》，亲手搭建一个属于自己的AIGC工具，这远比听课更有价值。","path":"posts/f452b115.html","date":"08-29","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"}]},{"title":"尽早觉醒：找到自己一人能做的互联网生意","text":"没有经历过裁员的职场是不完美的。 无论何种原因经历次裁员，可能对心智都是一次提升，前面也写过技术人怎么利用空窗期的文章技术人的空窗期，你的涅槃重生。经历过裁员的时候难免感到复杂和沉重。离开的背后，不仅有情感的波动，还有对未来的深深焦虑。 当你被通知离职的那一刻，情绪复杂得难以描述。但是，当冷静下来，你会意识到，职场就是一个大染缸，个人的价值往往被淹没在复杂的分工和协作中，逐渐失去了话语权。 在这样的环境下，早日觉醒，找到自己一人能做的互联网生意比什么都重要，毕竟打工的风险也不小。 互联网的机遇我们生活在一个充满机会的时代，互联网为每个人提供了一个可以大展拳脚的舞台。无论你是程序员、设计师，还是其他领域的专业人士，只要你有点子、有执行力，就有可能通过互联网打造出属于自己的一片天地。 移动互联网时代许多人通过创业实现财务自由的，他们可能只是做了一个小小的网站，或开发了一款简洁但实用的应用，就这样一步步积累财富，最终实现了阶层跃迁。但这条路并非一帆风顺，成功的背后，是无数次的失败和坚持。互联网的世界瞬息万变，只有那些能够快速适应、不断学习的人，才能真正抓住机遇，脱颖而出。 为什么？ 因为互联网的诱惑也是巨大的，你有没有注意到，我们身边包括自己，也常常陷入在社交媒体上，刷短视频、看无聊的资讯，时间一晃而过，什么也没得到？这些看似无害的娱乐，其实是在悄悄蚕食我们的注意力和斗志，让我们逐渐迷失方向。我们必须清醒，主动掌控自己的时间和精力，把注意力集中在能带来实际收益的事情上。 从技术到产品到生意作为一名技术人，我曾经也接外包项目，感觉这是技术变现最好的方式。 毕竟，看上去是最实际的。但事实证明，这条路并没有我想象的那么简单。接外包不仅需要你有深厚的技术功底，更需要你能跟客户进行有效的沟通，还要应对各种突发的需求变化，还有可能最后的薪资以各种理由拿不到，还有很多时候，甲方的要求难以预料，而内部的协作也不尽如人意，搞得人筋疲力尽。还有你帮朋友忙实现了些功能，但聊钱时候又碍于面子，自己也没分成。。 接外包这种方式虽然能赚点钱，但很难长久，也没有持续的积累，你也不知道你下个项目是什么行业，什么需求，来了就接，你技术也没有深度的。 相反，我发现，如果我们通过技术产品化，自己做点小生意，反而更容易在长久的时间里积累财富。 为什么这么说呢？因为通过技术产品化，你不仅可以积累知识，还能把知识转化为产品，形成自己的竞争优势。这种优势，一旦建立起来，就是别人难以轻易复制的壁垒。 比如，早些年在移动互联网早期非常火热，自己开发了一些APP的工具类应用，这些工具类应用比较有长尾收益，虽然当时看起来很小，但是一些广告收入，一些付费用户还是可以源源不断，也算是工资外的第一桶小金。做自己的一个产品，哪怕小只要持续打磨，在某一个垂直赛道做好，那么在国内这么大的用户基数下，也是可以分一杯羹的。特别是现在AI可以做到辅助你代码，那有些不熟悉的业务领域你也是可以进入的，一旦在这些垂直赛道和传统行业进行数字化、互联网化的同时，你一定可以找到自己的小生意。 写到这，可能会有人反驳，你说的一些产品市场上已经有很多了，自己再去做毫无意义。但我想告诉你的是，只有亲自去实践，你才能发现那些不为人知的细节，找到属于自己的市场空隙，比如，你做一款产品你就知道那个地区用户最多，那个时间段，什么年龄用户最活跃等等，实践中获得的经验，尝试做自己的生意，哪怕在小，也要尽早做起来（AI时代，利用工具自己完全可以是一个团队）。如果你想了解如何利用N8N这样的自动化工具，将AI能力落地到具体的写作场景，实现“一人团队”的效率提升，可以参考我的这篇教程：《N8N教程：搭建公众号自动化写作工作流完整指南》。因为这产品只属于你，变做边改。 觉醒和行动在这个充满机遇与挑战的互联网时代，早点醒悟，真的很重要。 不要总想着依赖团队或者等什么大平台来拯救你，机会是靠自己去找的。别盲目跟风去追那些看似宏大的项目，脚踏实地，先从一个小生意做起。通过不断学习和积累，你会发现，渐渐地，你就拥有了属于自己的核心竞争力。 行动起来，去找到那个你一个人也能干的互联网生意。 探索、尝试，不断提升自己。别怕一开始很烂，要边做边改，要有信心持续完善，毕竟这生意属于你自己，也可能带来长尾收益。最重要的是，从中你会有不一样的收获，这也许会成为你未来成功的基石。","path":"posts/d8de0f99.html","date":"08-29","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"}]},{"title":"技术人要重视写作能力","text":"技术人要重视自己起来写作能力的培养 可观来讲，技术人大部分是偏理科的这部分人，某种程度来讲，大家擅长代码的编写，而又不擅长于写作，无论是从技术博客到用于日报，周报的汇报材料，相比代码书写可能就不是那么轻松。 那技术人写作能力该不该刻意练习下？答案是肯定的，犹如你代码的写作能力，是需要锻炼起来的，先来看看写作都有哪些好处。 技术人写作好处在高效学习方法里，你可能听说过费曼学习方法，他简单来说，就是当你学习到新知识后，你要能用最简单的话语和描述，向别人清楚地介绍出来，来检验自己是否理解和掌握。 记得大学时候遇到一个教网络通信的一个教授说，他也是构建我国互联网通信方面的鼻祖人物，他在课堂上经常给我们讲：检验自己是否掌握知识，最好办法就是你给别人介绍时，要达到如同介绍我中午吃了什么饭一样，自己清楚明了，还要别人能听懂。 听起来话很简单，但他说的意思其实就是费曼学习方法，这里面包含了多个层面的能力锻炼 知识的总结表达能力 把知识传播给他人 一个非常好的学习方法 一个好的总结和表达能力也是需要通过练习和思考的过程，写作无疑是一个非常好的方式，首先需要把相关技术进行概括和总结，用抽象和简练的文字表达出来。这个过程说起来简单，但是当你实践并尝试写作进行总结和概括时，就需要你深入的理解技术对应的点，点与点关系、到面、面和面直接的关系。 当把一个复杂的技术能通过总结提炼写下来后，通过自己思考，去繁化简把最容易懂的东西呈现出来时，这也跟后来学习的人一个莫大的帮助，把技术传播下去。 如果前面2个环节已经做到，那详细这这块你的知识点和技能的掌握一定时一个深入的层次了。 除此之外，技术人写作能力在问题表达，进度汇报，述职方面等也有很大的帮助，虽有干的好的不如写的好，这样有些方面的贬义评价，但是作为正直的技术人，除了要干的好，也要锻炼自己写做能力，特别写小作文能力，这方面也要客观的学会写作表达。 技术人怎么练习起来写作先从一点点练习起来，从日报，从当天计划开始写起，总结和记录自己要做目标、计划、步骤。 从日常思考和向上汇报练习写作的能力，了解写作受众时谁，目标群体是谁，所要写的内容大纲是什么，结构是什么样的，要表达和输出的思想是什么，写作前思考这些点后再动起来。 写作的工具和辅助你呈现的数据，画图，图表，AI工具需要知道，这些能帮助你提升效率，并在写作呈现上更生动 写作风格上，更要注重语言的简练，能清晰准确表达，对复杂的技术术语能呈现出对应的例子，抽象原理，使枯燥的技术能表达有趣和易懂 写作内容上，要具备技术原理的深度，刨根问底，对原理和技术细节要负责，更不要网上拿来主义，缺少验证，不要产生垃圾技术文章，那写作也就没有意义了。 最重要的事要写作起来，思考起来，写作可以锻炼和进步，哪怕一开始写的巨烂无比，加持写加持改进才是最快的练习起来的方式。","path":"posts/7a5a1805.html","date":"08-21","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"}]},{"title":"2024年客户端、前端开发，这些赛道值得你关注","text":"首先，这篇文章没有任何广告，只是给目前前端开发、客户端开发伙伴们的一些个人思考和建议。 前几年，移动互联网如火如荼，给大家在吃住行方面带来了巨大的便利，也改变了大家的生活方式。外卖、打车、支付、金融等应用极大地方便了人们的日常生活。 特别是客户端开发的岗位，前几年由于开发需求旺盛，薪资非常可观。但随着移动APP生态的完善，APP的需求也接近饱和，进入了维护期。许多资深前端工程师、客户端Android、iOS、Flutter工程师由于种种原因，职业发展也进入了瓶颈期。一方面担心失业问题，另一方面市场上的新岗位也不如以前多。 人通常都是有惰性的，即便知道这个行业在走下坡路，可能还是不好轻易的做出改变和尝试新赛道 确实转型新赛道来进行开发，也有一些学习成本，那我们要尽可能选择适合自己的技术栈，能快速切入的一些领域。 先尝试的学习和用起来，看看实际写起来是怎么样子的，了解岗位薪资和赛道人数。 就比如之前做J2EE(现在很少听这个名字了)开发大火时期，业余里进行了Android、iOS研究，没想到在1-2年内业余薪资迅速远远超过了主业工资2倍，且大量移动岗位冒出，那怎么办，放弃J2EE, 顺应时代趋势来开发啊。 目前，互联网可以说处于Web3.0阶段，这个时期或未来的发展如何，可以看到的是区块链和大模型AI行业。今天先看一下前端和客户端技术人员在区块链行业有哪些可以做的事情。 这里的区块链指的是区块链相关的开发岗位有哪些可以切入的，也是政府支持和开展的 图片引用：https://www.gov.cn/ 2025年初步形成支撑区块链发展标准体系 上海启动首批国资国企区块链创新应用场景建设 区块链技术是一种分布式账本技术，可以让信息记录更加安全、透明和不可篡改。从官方发布的信息看，技术可以应用于许多领域，比如共识机制、分布式应用、智能合约、数据上链等。 那适合前端和客户端开发，又比较好进行切入，或者可以先尝试起来的区块链开发岗都有哪些，薪资如何，我觉得可以从这些方面进行尝试： DAPP开发 如果你是做前端开发的JavaScript、React、vue不在话下，那可以直接来构建DApp的前端部分，并结合Web3.js或Ethers.js进行智能合约交互。Web3.js 用于与以太坊区块链进行交互，支持发送交易、调用智能合约等操作。Ethers.js 功能类似于Web3.js，但更加现代化和模块化。 如果你是客户端开发其实也可以进行DAPP来开发，通过WalletConnect协议，开发支持移动设备的DApp开发，这些都可以沿用一些移动开发的经验。与智能合约进行交互，这部分学习和你在移动开发中与后端API交互的经验相似。 智能合约开发无论前端还是客户端如果接触了区块链还可以进行智能合约的开发，可以理解它是自动执行合约条款的代码，运行在区块链上，确保交易的透明和安全。 智能合约编写语言，主要有Solidity：是太坊及其兼容区块链平台，Rust ：用于Polkadot、Solana区块链平台的智能合约开发，这个可能需要学习一下Solidity, rust语言了。 如果是前端和客户端开发，这2个语言学习起来还是比较容易的，语法也比较类似 Solidity也有JavaScript的借鉴，rust也是跟kotlin、swift有相似之处。 其他区块链开发还有一些区块链的其他开发方向，比如共识算法、公链开发等。这些需要较高的技术功底，涉及密码学和安全学，可能不太适合目前前端、客户端开发的技术基础。 DAPP开发和智能合约开发比较适合前端、客户端开发人员尝试切换赛道、可以在业余时间进行学习和研究，而且行业薪资待遇不错，业内人数也不拥挤。长远看，这是一种技术趋势和应用创新，从上方官方新闻也可以看的出。 思考总结以上就是对前端、客户端开发，比较低成本切换到区块链岗位赛道的建议，可以业余尝试和了解，多学总是没有坏处的。 技术不是一成不变的，业务需求也是一直变革，前端、客户端开发还是要做好未雨绸缪提升自己技术力。 切换技术赛道和岗位时，还是要结合自身的技术栈来适应技术潮流，提升竞争力，拓宽自己的岗位选择。","path":"posts/9826b570.html","date":"08-19","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"}]},{"title":"技术管理，要用人之长","text":"在技术团队的管理中，我们常常希望团队能够更符合自己的价值观，在用人方面也更倾向于选择与自己脾气秉性相投的人。 这种想法很自然，但它也容易让管理者掉入一个陷阱：总是想尽办法去改变团队成员的某个“缺点”，试图让团队成员在性格上趋于一致。然而，这样的团队往往缺少灵气，而改变的结果也常常适得其反。（这里所说的“缺点”，并不是指这些人能力不足或不能胜任工作，而更多是每个人独特的特点或性格因素。） 自己之前也犯过类似错误，随着团队管理经验磨炼，我们要发挥团队最大战斗力，最重要的在于发现和利用团队成员的长处，而不是执着于修补他们的短板。 从“改造人”到“成就人”技术团队就像一片森林，每棵树都有自己的形状和特点。有的高大挺拔，有的矮小结实，各有各的用处。作为技术管理者，你是选择硬生生地把这些树都修剪成一样的模样，还是让它们各自生长，发挥所长？ 当你试图改变某个工程师的短处，比如让一个不擅长沟通的人变得能说会道，你可能会发现，这个过程不仅让他痛苦，也让你头疼。因为短板往往是根深蒂固的特质，并不容易被改变。结果，搞不好你花了大力气，他却失去了本来的优势——那个他最擅长的领域反倒退步了。 试图改造别人，往往是一条崎岖不平的路。与其逼迫每个人去做自己不擅长的事，不如看看他们究竟有什么特长，然后把这些特长发挥出来。这样，你不仅能看到更好的结果，团队的士气也会随之提升。 现实例子说到管理团队，举个例子，如果做为管理者带过团队，你可能也有共鸣，比如有两位主管，A和B。他们的管理方式截然不同。 A主管是个严谨的人，凡事都喜欢亲力亲为。他的团队成员几乎没有什么决策空间，因为A主管总是喜欢把关每个细节。他常常告诉团队成员：“你这样不行，那样也不对。有些可能也是自己不擅长的领域，但成员碍于面子不想反驳，久而久之，团队里的人都觉得压力山大，干劲儿被磨得差不多了，创新的火花也渐渐熄灭了。（某种程度的一言堂） B主管呢，他的做法则显得更加轻松。他会先了解每个团队成员的优点，然后有针对性地安排任务。B主管喜欢说：“你在这方面很有一套，试试看能不能搞出点新东西。”在他的团队里，大家自由发挥，气氛活跃。于是，团队成员的积极性高了，项目进度和质量也都相当不错。 两个不同的管理方式，带来了截然不同的结果。A主管执着于修正下属的缺点，结果使得团队士气低落，项目进展不顺；而B主管则注重挖掘和利用下属的长处，团队反而呈现出一片生机勃勃的景象。 用人之长提升团队作为技术管理者，你的任务不仅仅是指挥和监督，更重要的是发现团队成员的优势，并把这些优势最大化。一个好的管理者，像是一名园丁，懂得如何修剪树木让它们更好地生长，而不是强迫它们长成同一个模样。 在识别团队成员的长处时，要多观察他们的工作表现，听听他们对工作的想法和建议。有人喜欢钻研技术，有人擅长团队协作，还有人对项目管理得心应手。找到这些优势后，你要做的就是把他们放在合适的位置上，让他们在擅长的领域内发光发热。 举个例子，对于那些技术能力超强的工程师，给他们挑战性的任务，同时提供一定的自由度，让他们可以发挥创造力。而对于那些沟通能力强的成员，可以让他们负责跨部门的协调工作，确保团队和其他部门的顺畅合作。 用人之长提升管理技术管理是一门艺术，而不是一门科学。管理者的职责，不是强行让每个成员变得“完美”，而是要发现每个人的长处，并加以利用。就像一支乐队，各种乐器各司其职，才能奏出和谐的乐章。 当你放下改造他人的执念，(只要不是他无法胜任问题)，都应转而专注于如何让每个人都在自己擅长的领域发光，你会发现，团队的效率提高了，氛围也好了。这样的团队，不仅能在技术上有所突破，更能在项目中取得成功。","path":"posts/34ec9bec.html","date":"08-18","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"}]},{"title":"告别焦虑，技术人的“慢功夫”哲学","text":"告别焦虑，技术人的“慢功夫”哲学我们现在处一个快节奏的时代，每一个行业都在高速发展，我们也常常被告知要抓住每一个机会，快速成长，迅速成功。但对许多技术人来说，所谓的“快”，有时反而会让我们失去平衡，陷入焦虑和迷茫， 常常又进入事倍功半的困境。 之前遇到过一位刚入行不久的年轻技术人，他一脸焦虑地问我：“如果我现在不快点提高，是不是以后就没机会了？他同事只比他大1岁就已经P7了，心里充满了压力，害怕自己到那个年龄也达不到P7。。。担心自己成长太慢了。 这种情况并不罕见。在技术领域，很多人都经历过类似的心境：希望自己能够迅速成功，但现实却常常让人感到沮丧。 我觉得真正的成功往往需要时间的积累和经验的沉淀，不要忽略重要的职业成长哲学——“慢功夫”。 什么是“慢功夫”？我觉得“慢功夫”并不是指要拖延时间，而是一种深刻的成长观念。 我们在职业发展中，有些人技术人能早早财务自由，有些能有好的机会进入大厂，这里面有自身的能力和努力，但也一定有运气，所以不要焦虑自己没能达到一定的薪资，没有进入好的大厂，一定要有自己的节奏，时间的积累和持续的努力才是成功的关键，更要从内心坚定自己。 从内心摆脱焦虑如前面说到的例子，很多技术人知道这行前期薪资高付出也需要多，而在职业初期都会面临巨大的压力，他们常常担心，如果在毕业后的头几年没有迅速提升自己，那么未来的职业生涯将会受到严重影响。这种焦虑感让他们在短时间内急于求成，结果往往是事倍功半，甚至可能导致职业倦怠。 摆脱这种焦虑的有效方法之一就是接受“慢功夫”的哲学。认识到成功需要时间，并且在职业发展中保持耐心，会帮助你在长期中找到自己的节奏。 真正的技术成就往往不是一蹴而就，而是经过不断的实践和学习才，还有运气，在运气没来之前只管坚持正确的努力，从内心要认定这件事。 慢慢地，你会发现，职业的高度并不完全取决于短期的表现，而是源于持续的积累和深度的成长。 选择合适的榜样在职业发展过程中， 在寻找职业发展的方向时，选择合适的榜样至关重要。不要过分崇拜那些在年轻时就取得巨大成功的偶像。虽然他们的成就令人钦佩，但这种极端个例并不适用于每个人。 相反，选择一些经历丰富、成功稳重的前辈作为榜样会更有帮助。例如，巴菲特和芒格等人虽然在年轻时并未显著成名，但他们的职业生涯却是通过长期的积累和稳步的前行获得成功的。这样的榜样能够给予你更为实际的职业发展思路，帮助你在漫长的职业道路上保持坚定的信心。 一些慢功夫个人建议1. 一天一点，慢慢积累：不用急着去掌握所有新技术，也不用担心自己今天还不够“厉害”。每天学习一点新东西，哪怕只是一个新函数、一段代码优化，日积月累，你会发现自己其实进步了很多。关键是保持好奇心和学习的动力，慢慢来，一切都会水到渠成。 2. 给自己留点喘息的时间：工作不是马拉松，一口气跑到终点可不是好主意。每天工作之余，给自己留点休息的时间，哪怕只是出门散散步、泡杯咖啡，都是让大脑放松的好方法。要知道，休息也是一种生产力，反而能让你在工作中更加高效。 3. 别急着和别人比：你周围可能有一些同事看起来特别牛，年纪轻轻就拿到了高薪或升职。这种时候，别让自己陷入“别人的成功就是自己的失败”这种心态里。每个人都有自己的节奏，有些人跑得快，有些人走得稳，而最后能坚持到终点的，往往是那些知道自己步伐的人。 4. 坚持做让自己有成就感的事： 这点科学家颜宁在一个采访视频里也提到过，她也是这样的，要用一点点的成就感正向激励自己，这点比较重要。在工作中找到一些让自己感到开心、有成就感的事情。可能是解决了一个困扰已久的bug，或者是学会了一个新技术。只要你能从工作中找到这种“小确幸”，你就会慢慢培养出对工作的热爱，而这种热爱，会成为你持续前进的动力。 5. 给未来留点耐心：成功不是今天努力，明天就立刻能看到结果的事情。要相信，时间会给你回报。那些看似微不足道的努力，日后都会转化为你的竞争力。所以，给自己多点耐心，稳步前进，你会发现，未来的路其实会越走越宽。 总结虽然我前面提到过，“慢功夫”要坚持并等待机会，但并不意味着就等机会来敲门，它更像是一种有意识的选择——不慌不忙地提升自己，在每一步中都积累经验。 成功就像是一道慢火煮的好菜，需要时间来慢慢熬制。与其急功近利，不如踏踏实实地专注于眼前的每一项技能，不断学习，积累经验。给自己设立一个长期的目标，培养出足够的耐心，关注自己的成长，这样才能在未来的职业道路上走得更稳、更远。","path":"posts/fe63084d.html","date":"08-17","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"}]},{"title":"全栈工程师-基础：共识算法知多少","text":"共识算法，简单理解是通过算法让参与其中成员共同达成共识。 在计算机里共识算法主要在分布式系统中通过参与之中的节点，对数据或者状态达成一致的方法。 那是不是可以理解为参与人，按照认可的规则来就好。 你可能会想到，那石头剪刀布游戏，参与方也认同这个规则算法，这个算不算共识算法？ 不算。 虽然它涉及多个参与者之间的决策过程，但它的目的是决定一个赢家，而不是在分布式系统中达成一致的状态。 共识算法强调什么 一致性：确保所有节点在任何时间点都能对某一状态或数据达成一致。 容错性：能够容忍一定数量的节点故障或恶意节点的存在，并且系统仍然能够正常运行。 去中心化：没有单一的控制节点，所有节点都平等参与共识过程。 安全性：防止恶意节点的攻击，确保数据的完整性和不可篡改性。 其实这些核心也正是在分布式系统里的最基本保障。 有了大概的理解和概念后，看看现在常用的共识算法都有哪些，这些共识算法不会进行详细展开，因为每一种共识算法，都有复杂的算法基础和相关论文支持，根据汇总的常用算法可以进行深入论文学习。 共识算法有哪些工作量证明（PoW）： 参与者通过解决复杂问题（如数学难题）来证明他们的工作量，从而获得权利执行某些操作。这种方法确保系统不易被攻击。 例如用于防止垃圾邮件和保护分布式网络的安全性。 权益证明（PoS）： 持有更多资源（通常是加密货币）的用户，拥有更大的影响力和决策权。这种方法可以确保系统参与者有利益维护系统的稳定和安全。 最常见应用于加密货币的区块链网络中，如以太坊的Casper协议，通过持有以太币来参与验证和安全维护网络。 委托权益证明（DPoS）： 用户通过投票选出少数代表（通常是验证者）来执行决策，以提高系统的效率和扩展性。 应用场景例子：用于去中心化的社交媒体平台，如Steemit，用户可以通过持有代币来投票选择内容和平台发展方向的代表。 拜占庭容错（BFT）： 系统通过多轮投票确保即使在存在恶意节点的情况下也能达成一致，增强系统的安全性和可靠性。 广泛用于航空航天、军事和金融领域的分布式系统，确保在存在恶意节点的情况下系统仍能正常运行。 实用拜占庭容错（PBFT）： 预选的节点通过多轮投票快速达成共识，适用于需要高效和低延迟的分布式系统。 应用场景例子：企业内部的分布式数据库管理系统，如Ripple的XRP Ledger，通过PBFT算法快速确认和执行跨国支付交易。 以下这几个更多用在区块链相关的共识算法上，可以稍微了解下证明容量（PoC）、证明燃烧（PoB）和证明时间和空间（PoST）是共识算法，通过提供存储空间、销毁资源或等待时间来获得操作权。PoC鼓励资源共享，PoB减少资源供应防止滥用，PoST结合存储和时间增加系统安全性，确保资源公平分配。这些算法在区块链和其他分布式系统中广泛应用，如分布式存储、在线服务和云存储。 如前面介绍，共识算法的核心是确保分布式系统中各个节点达成一致，即使有部分节点可能出现故障或恶意行为，基于这些特性，常常在区块链、分布式数据库、云存储等领域使用。有这么一个基础，对后续一些共识领域的理解还是很有帮助的，当然每一个共识算法在具体应用中都需要深入研究和学习，我们文中介绍更多还是先有个核心原理和概念的认知。","path":"posts/68935246.html","date":"07-30","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"技术人的空窗期,你的涅槃重生","text":"最近几个月，之前的同事们陆续打听有没有在招人，有没有职位空缺，他们有大厂的技术大牛，也有小公司的技术负责人。 很明显，他们并不是在找更好的跳槽机会，而是遇到了空窗期在找一份稳定踏实的工作，这种无奈和焦虑深深地触动了我，也想写一下自己对这块的一个思考。 每个技术人或早或晚都会经历职业生涯中的空窗期，包括自己。 这个空窗期可能会突如其来：比如你负责的项目要突然终止，曾经投入的工作不再需要你，曾经引以为傲的技能变得陈旧过时，然后，你可能会经历长期找不到合适工作的焦虑，看到新技术层出不穷却无力跟上的无助，甚至面对亲朋好友对你职业前景的担忧。这种空窗期就像一片无边无际的黑暗，把你推向深渊，击垮你的自信心。每一次面试的失败都像是一次次否定，让你陷入无尽的自我怀疑之中。 这一切可能措手不及，同时也残酷无比，这个时期，除了要给自己打气，更要换一种思路来看待这个过程。 空窗期可能是你的最低谷期，但如果利用得好，这段时间恰恰是你涅槃重生的关键。想一想，在这段时间里，你被迫停下来思考，重新评估自己的目标和方向。虽然这是一个痛苦的过程，但也是一次难得的自我认知之旅。你要反思自己为何会陷入这样的困境，自己真正热爱的是什么，自己究竟想要的是什么。 在这个过程中，你心理承受着巨大的冲击，焦虑和抑郁时常来袭，仿佛身处无尽的黑暗。然而，正是在这段黑暗中，你将学会了如何与自己对话，如何面对自己的内心。通过深刻的思考和内在的认知调整，你会发现那些曾经模糊不清的目标逐渐变得清晰而坚定。 空窗期不仅是心理的磨砺，更是意志的锤炼。很多时候，最终拼的不是智商，而是意志力。通过日复一日的坚持，每一次小小的进步，都在无形中为你积蓄力量。你逐渐学会如何更高效地学习新技术，如何更敏锐地捕捉行业动态，如何更智慧地应对职业的挑战。 乔布斯曾被自己创办的苹果公司解雇。在那段低谷期，他创办了NeXT和Pixar，不断尝试和创新，最终以更强大的姿态回归苹果，带领公司走向巅峰。正是那段空窗期，给了他重新思考和调整的机会，让他能够以新的视角和更深的洞察力面对未来的挑战。 要成功渡过空窗期，并迎来职业生涯的新起点，这里有几个自己心得思考不妨一起试试： 持续学习并更新技能：利用这段时间，系统地学习新技术，更新自己的知识储备。可以通过在线课程、技术论坛、阅读专业书籍等途径来充实自己。 多交流摸清行业需求：分享彼此的困惑和经验，相互鼓励，摸清行业需求，帮助彼此度过难关。 坚持完成小目标：通过每天的努力，一步步接近自己的大目标。小目标的实现不仅能带来成就感，还能不断激励你前行。 保持积极的心态：相信自己终将渡过难关，迎来新的机遇。积极的心态能帮助你更好地面对挑战，找到解决问题的办法。 技术人的空窗期，不是失败的象征，而是重生的序曲，这段时间是提升自己的宝贵机会。 最后，无论空窗期有多长，都不要放弃对未来的希望。利用这段时间好好充实自己，重新找到自己的方向和热情。 相信自己，每一个低谷都是为了迎接更高的山峰，每一段黑暗都是为了见到更亮的光明。技术人的空窗期，正是你涅槃重生的最好时机。 “沉舟侧畔千帆过，病树前头万木春。”当你度过了这段空窗期，你会发现自己如凤凰般涅槃重生，迎来了一个崭新的起点。","path":"posts/de2623a0.html","date":"07-30","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"}]},{"title":"想成为技术架构师？这些核心能力你是否已经具备","text":"技术架构师在软件系统开发中扮演着重要的角色，决定了用什么技术、如何架构设计系统、技术攻关、方案选型等 如同建造高楼大厦，需要安全可靠的图纸和精准无误的规划设计，都离不开架构师的规划建设能力。 为保证系统稳定可靠，要成为技术架构师需要更要从各个方面练就自己，先来看看架构师职责，以及要具备哪些能力。 架构师核心职责有哪些 负责软件系统整体架构设计、技术和组件选型、模块间通信管理、数据模型设计等。 围绕系统的架构、扩展性、稳定性、技术攻关、安全性等方面进行开展工作，确保系统整体完善水平。 通过与业务的深入学习，促使业务和技术的结合，合理架构并设计出符合产品所需要的最优方案。 具备的核心能力 无论是负责系统的整体架构师，还是在细分领域做架构师，比如后端架构师、前端架构师、客户端架构师，他们的基础核心能力是相通的。 01 理论基础 很多做技术的，无论现在所处的阶段，初级还是中高级、架构师都需要基本扎实的基础，这个犹如地基，地基不稳，很多时候高楼大厦也是很难拔地而起的。 成为技术架构师前，通常需要大量的基础编程积累，在基础编程工作时候要熟知计算机的基础知识。 这些核心基础包括数据结构、网络传输原理、系统运行原理、控件生命周期、内存管理、IO读写等等。 如果觉得比较抽象，不妨先从相关图书了解，比如数据结构与算法、操作系统、网络传输、编译原理、图形渲染、算法、linux操作、软件工程等。 消化掉这些基础科目后能满足最基础知识储备，后续可以针对具体领域进行深入学习。 02 编程能力 要成为技术架构师，首先要有扎实的编程能力，虽不可能掌握所有的开发语言来进行编程，但任何一门优秀的开发语言都是相似的。 编程能力，换句话来说就是使用开发语言解决业务问题的能力。 在系统构成的整体上，至少要熟练应用一门语言来进行深入编程，可以是后端、前端、移动端、数据、AI领域等。 我说的是要深入一门语言的编程，并熟知该语言的设计和编译原理。 从语言的设计源码层面理解，可以是JAVA、GO、Kotlin、OC、Swift、Rust、JavaScript、Flutter、Dart等。 理解面向对象、函数式、声明式等不同的编程范式，能够根据实际问题选择最适合的编程范式。 编程时具备算法和数据结构的使用，代码是否可读、可维护、可测试、参与开源项目代码贡献、关注编程思维的提升。 具备宽泛和深入的编程能力，广度上理解各种语言解决的问题和适合的业务场景，深度上掌握编程实施、结构设计和算法应用。 03 架构设计能力 架构师的职责中，设计高效、可扩展、易于维护的系统架构是至关重要的。 具备好的架构设计能力是需要编程和常用设计原则、设计模式、业务规则、引擎算法等相结合的。 需要知道对应的SOLID是什么？ 23种设计模式有哪些，他们的使用场景有哪些？ 模块之间的解耦怎么做、模块化怎么搭建、组件化又是什么？ 在整体设计上，如何做分层设计、业务层、数据层、适配层，模块设计上如何划分通用模块、业务组件、数据组件、模块间如何通信、数据库上如何做主从，如何处理并发、如何处理大规模数据访问。 前端领域架构师要考虑同样问题分层设计、模块化划分、同时考虑前端页面的可插拔功能建设，组件化，动态配置、内存、性能优化、自修复自升级等。 想成为架构师，可以对比看看是否这些架构设计能力目前的掌握了解程度。 当然这里面的每一项能力都需要日积月累，刻意练习，不可忽视细节，但也不能陷入细节之中 架构设计能力关注整个系统全局的建设视野，同时关注核心重要的细节。 04 业务理解能力 软件架构设计都离不开对业务的深入理解和预见能力，否则设计出的软件产品可能是一塌糊涂。 做好业务的学习和理解，可以多深入一线体验业务和产品，结合实际业务流程来对产品进行方案架构设计。 提高业务理解能力，要主动和业务产品人员一起多交流和反馈，确保技术和业务之间的信息畅通，结合业务提前考虑对应的技术方案预研工作。 在充分理解业务的基础上，从中抽象梳理出对应的技术架构方案。 在落地架构设计时，从业务实际情况做出规划、折中技术架构方案，不过度设计。 这些能力都需要对业务发展的充分理解和认识。","path":"posts/667740ac.html","date":"07-24","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"}]},{"title":"技术重构何时做，为什么做要想清楚","text":"技术重构何时做，为什么做要想清楚代码重构（Refactoring）是指在不改变代码外部行为的前提下，对代码内部结构进行调整，以提高代码的可读性、可维护性和可扩展性。 重构的目标是让代码变得更简洁、更优雅、更容易理解和修改 重构不难，何时做，以及为什么要做要想清楚，不要为了重构而重构、不为了KPI 夸大事实来重构。 何时进行代码重构1.交付快慢123当写一个需求发现代码新增量比较大，代码编写比较多扩展一个功能发现要改动范围比较多，涉及多个文件或者类 可能要考虑是否原来的代码没有基建，造成重复增加代码。 扩展的功能没有模块化、没有分层、要反复改动多处。 交付缓慢，当代码变得难以理解和维护且错误频出时，可能就是重构的最佳时机 2.使用体验12当使用产品时卡顿、不流畅，页面加载时间比较长使用中应用频繁出错、页面出错，内存读写等问题 可能需要看下卡顿的原因，性能问题、渲染问题、数据量过大造成请求缓慢等问题，可能来源于代码的效率低下、资源的过度消耗等。 当系统体验已经严重影响用户了，就需要重构提高系统的响应速度和稳定性 3.需求变化12当需求或者业务发生变化时，代码无法通过相关配置进行快速开发为满足需求变化，需要改动大的模块进行调整，牵一发而动全身的代码调整代价 需要从架构设计、模块耦合、数据隔离等方面来判断造成代码耦合度高，不能快速响应业务和需求变化的原因。 更好地适应新的需求变化，此时进行重构，确保系统的灵活性和可扩展性 4.技术问题123当原有的系统使用框架、组件在开发需求中不能满足新的呈现形式当老的控件开发速度缓慢、还有相关老技术所暴露的安全隐患类问题 需要评估老技术的局限性，并判断新技术的稳定性、快捷性，能从效率和稳定性上改善老系统 如果系统依赖于过时的技术，此时需要重构来升级技术、确保系统安全和可维护性。 5.团队人员变化12当团队人员发生变化，老的系统、代码无人知晓和熟悉新人不知道原来逻辑，要看懂别人代码、维护代码成本都会比较高 当对系统的代码不熟悉，新的扩展和改动逻辑都会是比较危险的事情，可能里面一些坑因为不知道逻辑，导致系统频繁出错。 此时进行重构可以帮助新成员更快地上手业务、梳理代码逻辑，同时熟悉到系统间关联代码。","path":"posts/39b94e3a.html","date":"07-14","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"}]},{"title":"35岁+技术人成长和思考","text":"35岁+技术人成长和思考当前经济下新业务增长放缓，企业降本增效、裁员风波频发，技术人年龄增长、生活和家庭责任亦愈加繁重，房子、车子等等这些方面的压力迎面而来。 在这种不确定性中，技术人如何找到自己的定位、如何稳定情绪并做到坚定信念、如何持续迭代自己的技能与知识，直面所谓的35岁+危机，破解焦虑，实现个人与职业的持续成长，以下几个方面可以与大家一起思考和共勉。 1.认知和调整最近技术圈整体现状来看，如果目前的工作让你疲惫不堪的在苟且偷生、或者已经经历了大礼包的洗礼、亦或正在不被重用、边缘化，或者PUA等等。 首先，需要意识到这些变化并不是个人失败的象征（如果你浑水摸鱼，这个无解), 而是行业整体环境的反映，欣然接受这一现实也没有什么不好意思，更不要怀疑自己的能力。 其次，静下心享受这个过程，调整我们的职业期望和目标，仔细审视自己的职业发展路径是否与当前市场的需求和技术发展的趋势相匹配，所面对的人和事，自己是否有迭代优化的地方 调整心态练就在逆境中前进的能力，对正确的事继续坚持，对不足进行挖掘和复盘，把不足写下来，疯狂练起来。 最后，无论遇到什么样的问题和挑战，都不能忘记技术人的价值不仅仅在于掌握的技术和解决的问题，更在于我们的思考方式对问题认知和理解。 调整心态，忘记不公、做到及时止损，顺应趋势的努力，思考如何将过去的经验学习和新业务结合起来。你可以用技术降维打击创新业务，同时也要接触多思维方式，避免一条道轴到底。 2.技能与学习技术的进步日新月异，在技术行业专业技能的迭代和更新至关重要的，持续学习新东西的前提是有足够的兴趣，并了解新技术带来哪些生成力的提升，以及对目前的业务和项目有哪些提升，学习成本如何、能否与业务进行结合，在持续提升技术的同时，需要认清自身的局限性，以及错误的观念，先来审视一下。 补足基础：在技术领域，所有的创新和开发语言的迭代，都离不开行业基础，因此你的基础需要扎实，在学习任何新技术时，先把已有的基础掌握了，不要盲目认为新技术、换技术栈就可以能学的很好。 当你计算机基础功底不够时，任何新的技术都不是能快速学习和掌握的，即便掌握也是在皮毛层进行应用，因此当原理不清，学习原理，基础不会，学习基础，补足基础能力。 保持技术热爱：35岁+技术人大概率经历过早期互联网1.0红利，到移动互联网黄金时代2.0，再到目前眼下互联网3.0 、AI、区块链、 web3.0 、以OpenAI为代表的大模型技术、智能驾驶等等。 所有新的技术都不会以断层的形式横空出世，都会在原有基础上更新和迭代，包括各种开发语言 Java go kotlin swift flutter rust Typescript 以及仓颉语言等等，他用似曾相识的语法和各有千秋的创新来解决面临的问题，从并发，从速度，从内存等等。 怎么做是不是全学一遍？不是。 需要对一种语言进行深入学习，同时对新语言和框架能从原理认识和学习，在足够深度下涉猎广度的学习，语言只是工具，数据结构和问题解决思路才是核心。 不要断层式学习要持续学习，当你见过足够多各有千秋语言，对各种框架设计足够理解，保持新技术学习和理解，学习新东西的速度也会更快和轻松，万变不离其宗。 3.软硬实力这个年龄的技术人大多已经具备了不错的硬实力，也就是专业技术领域，架构设计等，技术人需要具备的能力，但软实力在这个年龄段又也是必须的， 技术人更应该注重自己软技能的历练。 沟通能力能够清晰、准确地表达自己的想法，同时也要善于倾听他人的观点。核心要能能清晰表达与非技术人员进行沟通和交流，能让他们听懂你语言和表达，注意用非技术语言陈述。 团队协作在项目开发过程中，团队协作尤为重要，技术人员需要具备良好的团队精神，能够和团队成员有效合作，共同完成任务，多学他人的优点，多看别人优势。 问题解决这个年龄的技术人，在看到问题时，更多需要关注问题产生的原因，通过问题现象挖掘本质，总结产生问题的周边防范措施，不仅仅是在解决在某一个问题上。 业务和产品思维无论在不在技术管理岗或者产品岗，这个阶段都需要具备产品思维，理解产品的需求，知道如何利用技术来实现产品的价值，理解业务的运作模式，知道如何利用技术来推动业务的发展。 汇报和向上管理向上汇报要提炼出核心的东东，具备总结能力、抽象能力，有一定的思考和吹泡泡(ppt)能力，满足向上管理需要，上级没时间从长篇大论里提炼信息，需要浓缩在PPT里进行呈现汇报。 尽管多数技术人鄙视这种文化，但现实中你还是要具备ppt的汇报总结能力。 向上管理更多是主动反馈和汇报，事事有回应 ，件件有着落 ，定期向上级报告工作进度和结果，理解和支持上级的决策。 哪怕是你遇到上级很傻的决定，或许有你看不到的背景和信息，就坚定的支持（威胁你的合法利益的除外），给上级提供正确解决方案建立信任（如果上级已经看你不顺眼，开始穿小鞋，那也就没必要自作多情，及时止损） 无论何时得罪你上级可能不是明智的，但也不是陪着老板一起瞎搞，至少要做一个正直的技术人，不作恶，在明显的错误决策下，也要给出一些合理建议出来。 4.职业发展这个年龄的技术人可能也会从3个方面发展，一个是技术专家路线，一个是技术管理路线，一个是其他路线。其他路线可能是换赛道、创业、新的铁人三项等等。(如果不知道什么新铁人三项，就忽略说明不适合) 专家路线深耕技术领域。虽然国内最早有35+一道坎，技术人也是青春饭说法，但身边一些技术大牛也有不少40+，这个说明国内行业也在慢慢变化，愿意走专家路线的就不要担心年龄，十年如一日的技能、经验，也一定可以在这个行业行的通。 但也要警惕自己理论专家，脱离实际业务和场景，只忽悠老板的专家，这样就只剩下现在我们认为的”专家”了。 管理路线管理路线并不是要放弃技术，更多要具备自己技术判断力，问题定位能力，人员协调组织效率最大好，以团队的力量完成整体项目。 初期需要从0-1的技术攻坚能力，后期需要足够的团队人员管理能力，需要技术突破时也依旧能顶得上。 其他路线对技术人来说也是不错的选择，工作只是生活的一小部分，技术人不要固执的死磕一个领域，或缺先尝试也是不错的选择，相信你身边也会有工作赛道切换后生活更多彩的人，跟随内心勇于尝试。 无论专家路线、管理路线，其他路线，核心都要把事情做好，知道自己的目标和方向，想想1年后，2年后你要做成什么样子，为你希望的样子现在需要做些什么。 把你想成为的样子写下来，把要分解的事情写下来，把要做的事情执行起来，如果预期结果不是你要的，定期纠偏复盘重新来过。 5.健康生活如果现在还能保持上学期间的体重，大概率是比较自律、生活规律的技术人，毕竟在技术圈子里大家早出晚归，缺乏锻炼的大有人在，职业属性颈椎病，鼠标手、三高、前列腺等等，大部分还是长期电脑前久坐导致 体重和运动到了这个年龄了身体管理需要提上日程，技术圈高工作强度也是很容易肥胖产生，并为健康埋下隐患。控制体重进行减肥，这个过程一定会很痛苦，可以尝试一下： 找一个健身博主跟随练习，坚持下去 黄瓜、西红柿、生菜可以大量吃，控制油糖摄入 每天坚持饭后半小时运动，公司爬楼梯，跑步，跳绳等有氧运动 按照这个操作，先坚持1月看看，以个人经验，3个月拿掉30斤以上体重已完全可能，需要注意是坚持运动，控制碳水摄入，但不是不吃碳水，当碳水摄入太少，期间掉头发这种情况也是真实存在。 充足休息保证充足的休息时间，遇到事不要影响到睡眠，这个很难，可以通过分散精力方式，实在不行把自己累起来，跑跑步，运动起来，累了相对好入睡一些，如果睡眠不足，可能你效率和反应都会随之降低。 6.坚持执行所以这些说起来简单，道理也显而易见，但执行起来也并非容易。 特别年龄的增长心态的变化、情绪的稳定都需要极强的定力，除此之外家庭生活的压力也要关注和调节，保持内心平静。 到了这个年龄，意志力与世俗对抗显得格外珍贵，如果要健康，就练起来，能力不足就补起来，抵制不住娱乐陋习就卸掉你那无聊某音某手APP。 很多人和多事会给你挫败，如果实在难以控制，就不如躺平歇一会，给自己个期限，歇完马上重新雄起。","path":"posts/a07268b7.html","date":"07-13","excerpt":"","tags":[{"name":"技术成长","slug":"技术成长","permalink":"https://zhulg.github.io/tags/技术成长/"}]},{"title":"A Rust CLI-Based Chat Tool Utilizing the ChatGPT API","text":"ChatGPT CLI A tool for chatting using the ChatGPT API, written in Rust CLI.You can use this tool to chat, just by setting your API Key. You can modify the API domain and other API parameters when you start the chat. The source code will be shared in the article for reference. Why create ChatGPT CLI If you can access the network through VPN, you can watch this video to learn more. （若文中视频&amp;图片无法显示，请科学上网查看：推荐工具） Introduction to the core code 首先构建命令行工具和信息：let matches = Command::new(“ChatGPT CLI”).使用 clap 库创建一个命令行工具，其中包含多个命令行参数（如 DomainName，APIKey 等）和一个命令行帮助信息 12345678910111213141516171819let matches = Command::new(&quot;ChatGPT CLI&quot;) .author(&quot;lg.json@gmail.com&quot;) .version(&quot;1.0.0&quot;) .about( &quot;x\\n ChatGPT CLI Create by zhulg (lg.json@gmail.com) | 1.You just need to input your api key, the cli version V0.1.1 | | 2.No need access internet with VPN, and just enjoy it. | | 3.If you want to use it in China, you can use my api key. | | |-------------------------------------------------------------------|&quot;, ) .arg( Arg::new(&quot;DomainName&quot;) .action(ArgAction::Set) .short(&apos;d&apos;) .long(&quot;Domain&quot;) .default_value(&quot;api.openai.com&quot;) .help(&quot;Sets the API Domain name.&quot;), ) 支持自定义API域名和API密钥，支持从命令行参数或环境变量中设置密钥 12345678910111213141516fn read_api_key() -&gt; String &#123; // If the OPENAI_API_KEY environment variable is not set, // ask the user to input the API key and save it to the // environment variables for future use. let api_key = env::var(&quot;OPENAI_API_KEY&quot;).unwrap_or_else(|_| &#123; console::set_colors_enabled(true); let prompt_style = Style::new().yellow(); let api_key: String = Input::new() .with_prompt(prompt_style.apply_to(&quot;Input your API key&quot;).to_string()) .interact_text() .unwrap(); env::set_var(&quot;OPENAI_API_KEY&quot;, &amp;api_key); api_key &#125;); api_key&#125; 通过控制台输入一个消息并回车，该CLI会将该消息发送给OpenAI GPT-3.5-turbo模型，并显示该模型返回的响应消息 1234567891011121314let response = client .post(url) .header(&quot;Content-Type&quot;, &quot;application/json&quot;) .header(&quot;Authorization&quot;, format!(&quot;Bearer &#123;&#125;&quot;, api_key)) .json(&amp;json!(&#123; &quot;model&quot;: &quot;gpt-3.5-turbo&quot;, &quot;max_tokens&quot;: max_tokens.parse::&lt;i32&gt;().unwrap(), &quot;temperature&quot;: 0.5 , &quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: line&#125;] &#125;)) .send() .await? .json::&lt;Value&gt;() .await?; Installsource code build code 1cargo build cd target/debug 1./chatgpt_rust Other Install If you have Rust installed, you can install the CLI using cargo: 1cargo install chatgpt_rust Usage Linux/MacOS Run the following command in your terminal: 1chatgpt_rust （若文中图片无法显示，请科学上网查看：推荐工具） chatgpt_rust –help 12345678910111213141516 ChatGPT CLI Create by zhulg (lg.json@gmail.com) | 1.You just need to input your api key, the cli version | | 2.No need access internet with VPN, and just enjoy it. | | 3.If you want to use it in China, you can use my api key. | | --------------------------------------------------------- |Usage: chatgpt_rust [OPTIONS]Options: -d, --Domain &lt;DomainName&gt; Sets the API Domain name. [default: api.openai.com] -k, --key &lt;APIKey&gt; Sets the API key. If not provided, the cli will ask for it, You can also set the OPENAI_API_KEY environment variable. [default: ] -t, --tokens &lt;max_tokens&gt; sets the max_tokens, default is 1000 [default: 1000] -h, --help Print help -V, --version Print version Option: Set your ‘OPENAI_API_KEY’ Environment Variable using zsh, No set will ask the user to input the API key in the terminal. Run the following command in your terminal, replacing yourkey with your API key. 1echo &quot;export OPENAI_API_KEY=&apos;yourkey&apos;&quot; &gt;&gt; ~/.zshrc Update the shell with the new variable: 1source ~/.zshrc Confirm that you have set your environment variable using the following command. 1echo $OPENAI_API_KEY The value of your API key will be the resulting output. Source codeSourceCode","path":"posts/dca54e0f.html","date":"03-15","excerpt":"","tags":[{"name":"AI","slug":"AI","permalink":"https://zhulg.github.io/tags/AI/"},{"name":"ChatGPT","slug":"ChatGPT","permalink":"https://zhulg.github.io/tags/ChatGPT/"}]},{"title":"ChatGPT API介绍及使用","text":"ChatGPT API介绍和使用 ChatGPT API的发布，可以让大家快速使用，不仅可以搭建类似ChatGPT应用，还可以通过API制作自己的应用、接入自己的产品、快速拥有强大的AI能力。 本文介绍ChatGPT API如何使用、API key的创建，请求花费、定价规则、运行官方起名应用快速入门ChatGPT API 的使用。 ChatGPT API 介绍 先看下张图：从这图上官方正式介绍，可以使用API方式接入ChatGPT到自己的应用里了，这不仅仅对开发者，更多对不懂开发的人也可以通过自然语言及指令接入自己应用中。（若文中图片无法显示，请科学上网查看：推荐工具） API更新介绍：这里说到gpt-3.5-turbo是ChatGPT产品中使用的相同模型，但其价格为每1k tokens为0.002美元，相当于每100万token只需要2美元。 比我们现有的GPT-3.5模型便宜10倍，这是3月1号最新官网介绍。 Tokens是什么 API计费单位。 一次提问怎么计费 : 问题tokens + 答案tokens 具体来讲，在模型里它指系统将句子和单词分解成的文本块，以便预测接下来应该输出什么文本。根据 OpenAI 官方文档显示，“ChatGPT is great!”这组单词需要六个 token，它的 API 将其分解为“Chat”、“G”、“PT”、“is”、“great”和“!”。与此同时，OpenAI 还专门提供了一个用于检查解释一串文本需要多少 token 的工具，并表示，按照一般的经验来看，在英语中“一个 token 通常对应大约 4 个字符” 1000个tokens大概750个单词 如何预估tokens: 提供了技术tokens的方法，可以参考理解tokens的计算： 创建账号和API Key 第一步我们需要登录openAI并注册账号，没有的需要先进行注册 (如果国内无法注册，可以看下方邮件地址邮件我）注册的账号里会先送有18美元，可以对基本的API测试和使用足够了。 第二步，通过账号登录后进行API key的创建，可以通过个人中心 View API keys来创建，点击创建即可。也可以通过QuickStart里的demo一步步创建。都是可以的，创建好要记得保存下来，后边将不会全部显示了，如果忘记需要移除再次创建。 使用API 为了快速演示，使用curl来进行访问接口。 国内的朋友一定要记得科学上网，这个接口否则无法访问（代理一定要设置好，否则接口是无法访问的），我这里验证了后对API返回的数据也进行各说明，如图，返回的接口里有API给的信息和这次请求的花费。 返回的数据包括了此次请求花费显示： 官方也提供了其他语言的SDK，你都可以快速接入。 应用演示 运行官方的例子，可以通过代码和页面来查看具体API的使用方法。可以使用node来进行运行起来，并查看具体的代码, 运行后如图： 这个demo 通过npm install 之后可以快速启动起来。官方也提供了其他产品接入的演示。希望给大家带来更多整合应用的灵感。 这个demo的运行需要注意，一个是node的版本不要太低18之后最好，其次访问时还是要科学上网。（有任何代理和账号注册问题都可以邮件我）","path":"posts/c22af37b.html","date":"03-10","excerpt":"","tags":[{"name":"ChatGPT","slug":"ChatGPT","permalink":"https://zhulg.github.io/tags/ChatGPT/"}]},{"title":"Damus Android版APK下载包Amethyst","text":"Damus是一个建立在去中心化网络上的社交软件，目前iOS可以通过appstore直接下载使用。 Android版是需要通过googleplay下载Amethyst，国内Android手机由于周知原因，无法直接安装，特提供安装包供大家下载安装。 Amethyst安装包下载： 点击下载获取该Android版本安装包：Amethyst 安装包点击下载 pc上直接点击下载，手机上通过浏览器打开再点击。 下载安装到Androids手机即可，如有问题可邮件(lg.json@gmail.com) 单独再提供安装包 （若文中图片无法显示，请科学上网查看：推荐工具） 安装后登陆： 进入后，先创建公钥，如图所示进入后在登录页面，选择创建进入即可，会自动生成对应的私钥。 私钥获取： 第一次创建后，点击左上角头像»Profile »长按***复制私钥。 自动复制到剪贴板（目前没任何提示）粘贴后可查看，请安全保存后边用于登录账号。 私钥登录： 保存好的私钥后，选择登出APP后，通过私钥再次登陆，这样就可以使用了。 个人中心有公钥显示，可以选择分享，分享给他人进行关注（朋友圈那一串串的符合） 私钥用来登录自己的账号，保存好！！ 其他： 到这一步可以查看了正常使用了，可以搜索关注我 npub1z40ckftt5tq70uqvtng4jz6lv34am6k85vkzlrgfzqs22rkrqjyqkga4cj 后边头像更换、发贴添加节点闪电网络等，进去后自己玩即可有问题可以邮件私信。","path":"posts/f235cc57.html","date":"02-03","excerpt":"","tags":[{"name":"Android","slug":"Android","permalink":"https://zhulg.github.io/tags/Android/"},{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Rust CLI反编译Android APK","text":"Rust-CLI使用 Rust提供了比较好的CLI接口,可以快速的编写CLI应用, 用于日常的工具类使用 Android 反编译APK的过程，可以通过Rust来整合成命令行一步完成, 整合其中出来过程, 来应用Rust CLI的实践 目的熟悉Rust CLI来编写应用，并通过命令行自动化反编译APK几个过程，作为日常工具提效 编写准备： 反编译APK依赖的必要库： 123d2j-dex2jarjd-cliApktool 应用该库使用为最新版本，如果有不支持兼容的需要确认Java使用的相关版本即可。 Rust CLI 编写依赖的库： 12345clap consoleexecute indicatiftext2art 这些库的使用方式和说明可在crates.io查到说明 代码解析： 编写CLI处理接口： 1234567891011121314151617let matches = Command::new(\"Decompile APK\") .author(\"lg.json@gmail.com\") .version(\"1.0.0\") .about(\"ApkDecompiler for Android, create by Spark Coding BU\") .arg( Arg::new(\"file\") .action(ArgAction::Set) .short('f') .long(\"file\") .default_value(\"-\") .help(\"The path to your apk.\"), ) .after_help( \"Longer explanation to appear after the options when \\ displaying the help information from --help or -h\", ) .get_matches(); Command使用的是clap来创建， 通过Arg创建对应的参数和应用，可以创建读个arg进行添加。 读取CLI的输入参数： 12345let file_path = match matches.get_one::&lt;String&gt;(\"file\") &#123; Some(it) =&gt; it, _ =&gt; return, &#125;; let apk_path = PathBuf::from(file_path); 开始执行: 123456789pub fn start_decompile(&amp;self) -&gt; Result&lt;()&gt; &#123; self.show_tools_info()?; self.create_output_dir()?; self.start_dex2jar()?; self.start_decompile_class()?; self.start_decompile_res()?; self.open_output()?;\\ Ok(())&#125; 开始执行会显示工具对应的信息，创建文件输出的地址，开始解析对应的包 举例命令行的创建： 1234567891011121314///use dex2jar get APK's jar in output_path pub fn start_dex2jar(&amp;self) -&gt; Result&lt;()&gt; &#123; let mut command = Command::new(\"sh\"); command .arg(self.exe_dir.join(\"lib/dex2jar/d2j-dex2jar.sh\")) .arg(\"-f\") .arg(&amp;self.apk_path) .arg(\"-o\") .arg(self.output_path.join(\"app.jar\")); execute_state(command, \"dex2jar\"); Ok(()) &#125; 工程注意点： 121.使用build.rs在构建前需要把代码依赖的lib库拷到对应的target下，这里使用了构建脚本, 具体参见代码工程2.如何使用cli的执行状态，来显示处理过程, 是CLI下常用的工具 最终工具处理效果： （文中图片无法显示，请科学上网查看：推荐工具） 源码地址： 源码 Github地址 使用方式：./apkdecompiler -f ./test.apk 12345678910111213 _____ _ _____ _ _ / ____| | | | __ \\ (_)| || (___ _ __ __ _ _ __ | | __ | | | | ___ ___ ___ _ __ ___ _ __ _ | | ___ _ __ \\___ \\ | &apos;_ \\ / _` || &apos;__|| |/ / | | | | / _ \\ / __| / _ \\ | &apos;_ ` _ \\ | &apos;_ \\ | || | / _ \\| &apos;__| ____) || |_) || (_| || | | &lt; | |__| || __/| (__ | (_) || | | | | || |_) || || || __/| ||_____/ | .__/ \\__,_||_| |_|\\_\\ |_____/ \\___| \\___| \\___/ |_| |_| |_|| .__/ |_||_| \\___||_| | | | | |_| |_|begin del old file...in /Users/developer/apkdecompiler/output✅ create ouput:/Users/developer/apkdecompiler/output✅ dex2jar...done✅ decompile class...done✅ decompile Resource...done","path":"posts/b176cd6e.html","date":"11-06","excerpt":"","tags":[{"name":"Rust","slug":"Rust","permalink":"https://zhulg.github.io/tags/Rust/"}]},{"title":"iOS集成Rust使用","text":"iOS调用Rust一，开发环境： 确保xcode开发环境，推荐官方文档, 安装即可 rust开发环境 xcode及iOS调试设备 末尾附带demo工程源码，供初学者集成原理学习使用（简单步骤有省略，有疑问可邮件我） 二，添加rust交叉编译 同android一样，可以添加支持ios的编译 1rustup target add aarch64-apple-ios x86_64-apple-ios 初始化 cargo-lipo : 这个create可以编译rs为iOS需要的库 1cargo install cargo-lipo 三，创建工程 这里的rs代码直接 (参考了mozilla的例子，只为测试验证集成过程） 创建iOS基本工程，并创建rust的库工程，可以创建lib，也可以直接rs工程。 （一套rust代码，提供多个平台，那一般可以创建lib库，这样rust工程来调试后，统一对外提供lib库代码，由lib库代码编译对应的so,或者.a文件) 1cargo new Rust_iOS --lib 这里使用 Rust_iOS 作为为iOS工程提供的rust 库代码，通过 cargo-lipo 编译出.a的库文件，为ios工程进行调用。 rust代码添加 在lib.rs里添加下边代码 123456789101112131415161718192021222324252627use std::ffi::&#123;CStr, CString&#125;;use std::os::raw::c_char;//#[no_mangle] 告诉编译器不要破坏函数名，确保函数名称被导入到 C 文件//extern 告诉 Rust 编译器方法将要在 Rust 以外的地方调用，要确保其按照 C 的调用规则编译。#[no_mangle]pub extern \"C\" fn rust_greeting(to: *const c_char) -&gt; *mut c_char &#123; let c_str = unsafe &#123; CStr::from_ptr(to) &#125;; let recipient = match c_str.to_str() &#123; Err(_) =&gt; \"there\", Ok(string) =&gt; string, &#125;; CString::new(\"Hello \".to_owned() + recipient) .unwrap() .into_raw()&#125;#[no_mangle]pub extern \"C\" fn rust_greeting_free(s: *mut c_char) &#123; unsafe &#123; if s.is_null() &#123; return; &#125; CString::from_raw(s) &#125;;&#125; greetings.h ：src下添加一个名为 greetings.h 的新文件，来定义一下 C 接口，iOS调用的Rust函数在这里定义 123#include &lt;stdint.h&gt;const char* rust_greeting(const char* to);void rust_greeting_free(char *); Cargo.toml定义编译类型： staticlib 编译会生成 .a 文件（在 Linux 和 MacOS 上），或 .lib 文件（在 Windows 上）。 123[lib]name = &quot;greetings&quot;crate-type = [&quot;staticlib&quot;, &quot;cdylib&quot;] 编译成静态库: 1cargo lipo --release 构建产物位置在 target/下，通用 iOS 库的位置在 /target/universal/release/libRust_iOS.a 四，iOS工程引入Rust库：导入 libRust_iOS.a 库: 创建demo ios 工程, 导入 libRust_iOS.a 库（从rust工程找到，直接拖进入工程target下general） 链接 libresolv.tbd。 点击 Linked Frameworks 列表底部的 + 并在搜索框中键入 libresolv。 选择 libresolv.tbd bridging header创建： 创建之前先把之前定义在rust工程里的.h文件引入过来，这个.h文件是rust代码调用的声明入口(File\\Add files to“iOSIntegratingRust” ) 创建bridging header： File\\New\\File..。 从提供的选项中选择 iOS Source Header File 并选择 Next。 将文件命名为 Greetings-Bridging-Header.h 并选择 Create 引入greetings.h 1234#ifndef Greetings_Bridging_Header_h#define Greetings_Bridging_Header_h#import \"greetings.h\"#endif iOS Build Settings: 设置Objective-C Bridging Header链接要的.h文件， 工程 target 里打开 Build Settings 选项卡。 将 Objective-C Bridging Header设置为$(PROJECT_DIR)/Greetings-Bridging-Header.h （要看自己.h所在的位置） 设置 Xcode 要链接 Rust 库的路径， Build Settings 中 Library Search Paths中设置 $(PROJECT_DIR)/../Rust_iOS/target/universal/release (要看自己库实际位置) 五，iOS代码调用： 从刚demo工程里新建一个 swift 文件，命名为 RustGreetings 123456789import Foundationclass RustGreetings &#123; func sayHello(to: String) -&gt; String &#123; let result = rust_greeting(to) let swift_result = String(cString: result!) rust_greeting_free(UnsafeMutablePointer(mutating: result)) return swift_result &#125;&#125; ViewController.swift里 添加代码验证调用 123456override func viewDidLoad() &#123; super.viewDidLoad() // Do any additional setup after loading the view. let rustGreetings = RustGreetings() print(\"\\(rustGreetings.sayHello(to: \"world\"))\")&#125; 例子只验证rust调用使用的过程 源码下载 ，有问题邮件我lg.json@gmail.com","path":"posts/e04cad1e.html","date":"10-23","excerpt":"","tags":[{"name":"Rust","slug":"Rust","permalink":"https://zhulg.github.io/tags/Rust/"}]},{"title":"Android集成Rust使用","text":"Andorid调用Rust 目前rust在移动端上的应用，一般作为应用sdk的提供，供各端使用，目前飞书底层使用Rust编写通用组件。 末尾附带该使用Rust工程源码，供初学者集成原理学习使用（简单步骤有省略，有疑问可邮件我） 一，开发环境： 确保rust开发环境，推荐官方文档, 安装即可 Android相关开发环境，需要NDK的下载安装 环境变量的配置，为命令行使用提供全局环境 开发工具： 如果对android studio比较熟悉，可安装rust插件 （若文中图片无法显示，请科学上网查看：推荐工具） 安装完毕，对Rust Toolchain 位置进行配置确认，否则可能对rs文件无法识别，就无法愉快使用studio编写rust VScode: 推荐使用编写rust代码。 二，创建Android工程: 与普通Android工程创建一样，创建Empty Activity 先编译通过该空工程 三，添加rust lib库： 进入到刚创建的AndroidIntegratingRust工程下 使用rust Cargo创建 lib库：1Cargo new rust_lib --lib 创建成功后会有rust_lib库，结构如下： 123456789101112131415161718192021├── app│ ├── build│ ├── build.gradle│ ├── libs│ ├── proguard-rules.pro│ └── src├── build│ └── kotlin├── build.gradle├── gradle│ └── wrapper├── gradle.properties├── gradlew├── gradlew.bat├── local.properties├── rust_lib //位置在这│ ├── Cargo.lock│ ├── Cargo.toml│ ├── src│ └── target└── settings.gradle 编辑Cargo.toml 输入目前需要的jni库依赖, https://crates.io/地址下确认版本, create-type 填写cdylib 动态链接库 1234567[lib]name = \"rust_lib\"crate-type = [\"cdylib\"][dependencies]jni = \"0.20.0\" 配置要编译so的linker及target 这个在rust_lib下创建.cargo目录，添加config.toml配置文件 填入linker对应的ndk地址： 12345[target.aarch64-linux-android]linker = \"/Users/android-sdk-macosx/ndk-bundle/toolchains/llvm/prebuilt/darwin-x86_64/bin/aarch64-linux-android21-clang++\"[target.armv7-linux-androideabi]linker = \"/Users/android-sdk-macosx/ndk-bundle/toolchains/llvm/prebuilt/darwin-x86_64/bin/armv7a-linux-androideabi21-clang++\" ps: 这是我的mac上ndk所在位置，参考Android官方ndk文档。 准备编译rust代码为so的环境已经准备完 四，开始编写Android和Rust代码： 创建Android代码, RustGreetings类， 使用kotlin所以用external声明JNI函数 123456789class RustGreetings &#123; fun sayHello(to: String): String &#123; return greeting(to) &#125; companion object &#123; @JvmStatic external fun greeting(pattern: String): String &#125;&#125; 在Rust lib库下，编写对应的JNI函数映射，从create.io下可以看到有关JNI的使用，代码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849use jni::JNIEnv;// These objects are what you should use as arguments to your native// function. They carry extra lifetime information to prevent them escaping// this context and getting used after being GC'd.use jni::objects::&#123;JClass, JString&#125;;// This is just a pointer. We'll be returning it from our function. We// can't return one of the objects with lifetime information because the// lifetime checker won't let us.use jni::sys::jstring;// This keeps Rust from \"mangling\" the name and making it unique for this// crate.#[no_mangle]pub extern \"system\" fn Java_com_android_integratingrust_RustGreetings_greeting( env: JNIEnv, // This is the class that owns our static method. It's not going to be used, // but still must be present to match the expected signature of a static // native method. class: JClass, input: JString,) -&gt; jstring &#123; // First, we have to get the string out of Java. Check out the `strings` // module for more info on how this works. let mut input: String = env .get_string(input) .expect(\"Couldn't get java string!\") .into(); input = append_string(&amp;input); // Then we have to create a new Java string to return. Again, more info // in the `strings` module. let output = env .new_string(format!(\"Hello, &#123;&#125;!\", input)) .expect(\"Couldn't create java string!\"); // Finally, extract the raw pointer to return. output.into_raw()&#125;//============== rust code ===============fn append_string(value: &amp;str) -&gt; String &#123; let mut origin = String::from(value); origin.push_str(\"this is Rust\"); return origin;&#125; 五，编译Rust代码为so 编译之前确认之前rust环境是可以使用的了，且要看下rustup target 下是否已经有要交叉编译的工具了。 rustc –print target-list | grep android 可以查看相关android 交叉编译工具,（我们demo之前在配置target时，使用了32和64位的ARM CPU 架构linker） 123456aarch64-linux-androidarm-linux-androideabiarmv7-linux-androideabii686-linux-androidthumbv7neon-linux-androideabix86_64-linux-android 如果没有安装，需要安装下对应的 1rustup target add aarch64-linux-android armv7-linux-androideabi rustup show 可以看到当前rust开发语言环境，包括 （installed targets for active toolchain） rustup target list可以查看到那些已经安装和rust支持的。 执行编译 到rust_lib目录下执行编译 1cargo build --target aarch64-linux-android --release 编译成功到target目录下release下去查看对应的so文件 123456789101112131415161718.├── CACHEDIR.TAG├── aarch64-linux-android│ ├── CACHEDIR.TAG│ └── release├── armv7-linux-androideabi│ ├── CACHEDIR.TAG│ └── release├── debug│ ├── build│ ├── deps│ ├── examples│ └── incremental└── release ├── build ├── deps ├── examples └── incremental 使用rust代码运行工程 copy 对应的so文件到 Android工程下src/main/libs下 在Android工程下build.gradle下记得引用so为jniLibs 12345sourceSets &#123; main &#123; jniLibs.srcDirs = [&apos;src/main/libs&apos;] &#125;&#125; 至此，应该可以直接运行看效果了，如果有需帮助可以邮件我，或者下载源码 地址","path":"posts/fc64e719.html","date":"10-19","excerpt":"","tags":[{"name":"Rust","slug":"Rust","permalink":"https://zhulg.github.io/tags/Rust/"}]},{"title":"Rust学习精简笔记总结(三)","text":"Rust精简笔记第3部分 继续整理rust笔记，过程会发现一些rust盲区理解，可深入源码学习, 从笔记知识点映射背后源码定义。 参考The Rust Programming Language &amp; Rust in Action 十一，指针&amp;智能指针 指针是一个包含内存地址的变量的通用概念， 智能指针（smart pointers）是一类数据结构，他们的表现类似指针，但是也拥有额外的元数据和功能 智能指针通常使用结构体实现，智能指针其实现了 Deref 和 Drop trait(离开作用域时运行的代码) 1. Box 用于在堆上分配值:1let b = Box::new(1); 2. Rc 引用计数智能指针: Rc 只能用于单线程场景 123//Rc::clone 只会增加引用计数, 这样a,b都是指向1 let a = Rc::new(1); let b = Rc::clone(&amp;a); 3. RefCell&lt;T&gt; 和内部可变性模式: RefCell&lt;T&gt; 代表其数据的唯一的所有权, 他具有如下特点: 1234567891011// 在任意给定时刻，只能拥有一个可变引用或任意数量的不可变引用 之一（而不是两者）。//引用必须总是有效的。 let num = 1; let r1 = RefCell::new(1); // Ref - 只有一个不可变借用 let r2 = r1.borrow(); // RefMut - mutable 可变借用 let r3 = r1.borrow_mut(); // RefMut - 可变借用 let r4 = r1.borrow_mut(); 内部可变性（Interior mutability): 是Rust 中的一个设计模式，它允许你即使在有不可变引用时也可以改变数据。 实现是通过不可变的Rc&lt;T&gt;, 此时的T的类型为RefCell&lt;T&gt;， 即结合成Rc&lt;RefCell&lt;T&gt;&gt; 来实现内部可变性，而外部是无法修改的。 let value = Rc::new(RefCell::new(5)) 完整例子如下： 123456789101112131415161718192021222324#[derive(Debug)]enum List &#123; Cons(Rc&lt;RefCell&lt;i32&gt;&gt;, Rc&lt;List&gt;), Nil,&#125;use crate::List::&#123;Cons, Nil&#125;;use std::cell::RefCell;use std::rc::Rc;fn main() &#123; let value = Rc::new(RefCell::new(5)); let a = Rc::new(Cons(Rc::clone(&amp;value), Rc::new(Nil))); let b = Cons(Rc::new(RefCell::new(3)), Rc::clone(&amp;a)); let c = Cons(Rc::new(RefCell::new(4)), Rc::clone(&amp;a)); *value.borrow_mut() += 10; println!(\"a after = &#123;:?&#125;\", a); println!(\"b after = &#123;:?&#125;\", b); println!(\"c after = &#123;:?&#125;\", c);&#125; 十二，使用和引用模块代码： 模块的创建和引用 1234567891011121314151617181920fn some_function() &#123;&#125;mod outer_module &#123; // private module pub mod inner_module &#123; // public module pub fn inner_public_function() &#123; super::super::some_function(); &#125; fn inner_private_function() &#123;&#125; &#125;&#125;fn main() &#123; // 绝对路径 从 crate 根开始，以 crate 名或者字面值 crate 开头。 crate::outer_module::inner_module::inner_public_function(); // 相对路径（relative path）从当前模块开始，以 self、super 或当前模块的标识符开头。 outer_module::inner_module::inner_public_function(); // 使用 use 关键字将路径引入作用域 use outer_module::inner_module; inner_module::inner_public_function();&#125;","path":"posts/15eb29eb.html","date":"10-16","excerpt":"","tags":[{"name":"Rust","slug":"Rust","permalink":"https://zhulg.github.io/tags/Rust/"}]},{"title":"Rust学习精简笔记总结(二)","text":"Rust精简笔记第2部分 继续Rust基础知识点总结，趁假期回顾学习 参考The Rust Programming Language &amp; Rust in Action 八，泛型、Trait、生命周期泛型： 函数定义中使用泛型 1234fn largest&lt;T&gt;(list: &amp;[T]) -&gt; T &#123;&#125;//函数 largest 有泛型类型 T。它有个参数 list，其类型是元素为 T 的 slice。largest 函数的返回值类型也是 T//类型参数声明位于函数名称与参数列表中间的尖括号 &lt;&gt; 结构体定义中的泛型 123456789struct Point&lt;T&gt; &#123; x: T, y: T,&#125;fn main() &#123; let integer = Point &#123; x: 5, y: 10 &#125;; let float = Point &#123; x: 1.0, y: 4.0 &#125;;&#125; 枚举定义中的泛型 123456789enum Option&lt;T&gt; &#123; Some(T), None,&#125;enum Result&lt;T, E&gt; &#123; Ok(T), Err(E),&#125; 方法定义中的泛型 12345678910111213141516struct Point&lt;T&gt; &#123; x: T, y: T,&#125;impl&lt;T&gt; Point&lt;T&gt; &#123; fn x(&amp;self) -&gt; &amp;T &#123; &amp;self.x &#125;&#125;fn main() &#123; let p = Point &#123; x: 5, y: 10 &#125;; println!(\"p.x = &#123;&#125;\", p.x());&#125; Trait： 通过 trait 以一种抽象的方式定义共享的行为,trait 类似于其他语言中的接口，但也不完全一样. 12345678910111213141516171819202122232425262728293031//定义 trait Summary ,定义summarize调取-&gt;summarize_author默认方法，达到调用默认行为，区分开实现trait的的定义pub trait Summary &#123; fn summarize_author(&amp;self) -&gt; String; fn summarize(&amp;self) -&gt; String &#123; format!(\"(Read more from &#123;&#125;...)\", self.summarize_author()) &#125;&#125;pub struct Tweet &#123; pub username: String, pub content: String, pub reply: bool, pub retweet: bool,&#125;//实现 trait Summaryimpl Summary for Tweet &#123; fn summarize_author(&amp;self) -&gt; String &#123; format!(\"@&#123;&#125;\", self.username) &#125;&#125;fn main() &#123; let tweet = Tweet &#123; username: String::from(\"horse_ebooks\"), content: String::from(\"of course, as you probably already know, people\"), reply: false, retweet: false, &#125;; println!(\"1 new tweet: &#123;&#125;\", tweet.summarize());&#125; trait 作为参数： 1234// 方法接收是实现了 trait Summary的类型pub fn notify(item: &amp;impl Summary) &#123; println!(\"Breaking news! &#123;&#125;\", item.summarize());&#125; Trait Bound： impl Trait 适用于短小的例子。trait bound 则适用于更复杂的场景，trait bound 与泛型参数声明在一起，位于尖括号中的冒号后面。 12345//使用相同类型的trait可以转换成下边的更简单写法pub fn notify(item1: &amp;impl Summary, item2: &amp;impl Summary) &#123;&#125;// trait Bound的写法pub fn notify&lt;T: Summary&gt;(item1: &amp;T, item2: &amp;T) &#123;&#125; 通过 + 指定多个 trait bound: 1pub fn notify&lt;T: Summary + Display&gt;(item: &amp;T) &#123;&#125; 通过 where 简化 trait bound： 每个泛型有其自己的 trait bound，所以有多个泛型参数的函数在名称和参数列表之间会有很长的 trait bound 信息，这使得函数签名难以阅读 12345fn some_function&lt;T, U&gt;(t: &amp;T, u: &amp;U) -&gt; i32 where T: Display + Clone, U: Clone + Debug&#123;&#125; 声明周期： Rust 中的每一个引用都有其 生命周期（lifetime），也就是引用保持有效的作用域，Rust 编译器有一个借用检查器（borrow checker）它比较作用域来确保所有的借用都是有效的 函数签名中的生命周期注解： 1234567891011121314fn longest&lt;'a&gt;(x: &amp;'a str, y: &amp;'a str) -&gt; &amp;'a str &#123; if x.len() &gt; y.len() &#123; x &#125; else &#123; y &#125;&#125;fn main() &#123; let string1 = String::from(\"abcd\"); let string2 = \"xyz\"; let result = longest(string1.as_str(), string2); println!(\"The longest string is &#123;&#125;\", result);&#125; 参数声明周期使用方法，或者靠编译器提示添加。 123&amp;i32 // 引用, 没有生命周期参数的 i32 的引用&amp;'a i32 // 带有显式生命周期的引用 ，一个有叫做 'a 的生命周期参数的 i32 的引用&amp;'a mut i32 // 带有显式生命周期的可变引用 一个生命周期也是 'a 的 i32 的可变引用 结构体定义中的生命周期注解： 12345678910struct ImportantExcerpt&lt;'a&gt; &#123; part: &amp;'a str,&#125;fn main() &#123; let novel = String::from(\"Call me Ishmael. Some years ago...\"); let first_sentence = novel.split('.').next().expect(\"Could not find a '.'\"); let i = ImportantExcerpt &#123; part: first_sentence, &#125;;&#125; 静态生命周期: 生命周期能够存活于整个程序期间。所有的字符串字面值都拥有 ‘static 生命周期 1let s: &amp;'static str = \"I have a static lifetime.\"; 九，集合：vector: 类型是 Vec 在内存中彼此相邻地排列所有的值, vector 只能储存相同类型的值 12345// Vec::new 创建let v: Vec&lt;i32&gt; = Vec::new();v.push(2);v.push(4);let x = v.pop(); 初始值来创建一个 Vec : 12let v = vec![1, 2, 3]; 读取 vector 的元素: 使用 &amp;[index] 返回一个引用, 或者使用 get 方法以索引作为参数来返回一个 Option&lt;&amp;T&gt;。 1234567891011fn main() &#123; let v = vec![1, 2, 3, 4, 5]; let third: &amp;i32 = &amp;v[2]; println!(\"The third element is &#123;&#125;\", third); match v.get(2) &#123; Some(third) =&gt; println!(\"The third element is &#123;&#125;\", third), None =&gt; println!(\"There is no third element.\"), &#125;&#125; 使用枚举来储存多种类型: 创建一个储存枚举值的 vector，这样最终就能够通过vector存储实际是不同类型的值了 123456789101112 fn main() &#123; enum SpreadsheetCell &#123; Int(i32), Float(f64), Text(String), &#125; let row = vec![ SpreadsheetCell::Int(3), SpreadsheetCell::Text(String::from(\"blue\")), SpreadsheetCell::Float(10.12), ];&#125; HashMap123456let mut scores = HashMap::new();scores.insert(String::from(\"Blue\"), 10); //插入//只在键没有对应值时插入scores.entry(String::from(\"Yellow\")).or_insert(50);scores.entry(String::from(\"Blue\")).or_insert(50);println!(\"&#123;:?&#125;\", scores); more： https://doc.rust-lang.org/std/collections/index.html 十，函数、闭包、迭代器函数： 函数的定义方式及在结构体实现里关联函数，关联函数与方法的使用区别 123456789101112131415161718192021use std::primitive;struct Point &#123; x: i32, y: i32,&#125;impl Point &#123; // 关联函数(没有self相关参数) fn new(x: i32, y: i32) -&gt; Point &#123; Point &#123; x: x, y: y &#125; &#125; // 方法(参数为&amp;self，是个隐示的，调用时无需传递表明是该类型而已） fn get_x(&amp;self) -&gt; i32 &#123; self.x &#125;&#125;fn main() &#123; //关联函数使用:: 方法使用类型.方法，如Point::new, point.get_x let point = Point::new(5, 6); println!(\"get x=&#123;&#125;\", point.get_x());&#125; 闭包： 闭包（closures）是可以保存在一个变量中或作为参数传递给其他函数的匿名函数。 闭包的定义以一对竖线（|）开始，在竖线中指定闭包的参数 1234fn add_one_v1 (x: u32) -&gt; u32 &#123; x + 1 &#125; //函数的定义let add_one_v2 = |x: u32| -&gt; u32 &#123; x + 1 &#125;; // 完整标注的闭包定义let add_one_v3 = |x| &#123; x + 1 &#125;; // 闭包定义中省略了类型注解let add_one_v4 = |x| x + 1 ; // 闭包体只有一行,去掉了大括号 闭包会捕获其环境: 可以捕获其环境并访问其被定义的作用域的变量。如下边 x 并不是 equal_to_x 的一个参数，equal_to_x 闭包也被允许使用变量 x，因为它与 equal_to_x 定义于相同的作用域 1234567fn main() &#123; let x = 4; let equal_to_x = |z| z == x; let y = 4; assert!(equal_to_x(y));&#125; 当闭包从环境中捕获一个值，闭包会在闭包体中储存这个值以供使用，这会使用内存并产生额外的开销。 闭包可以通过三种方式捕获其环境，他们直接对应函数的三种获取参数的方式：获取所有权，可变借用和不可变借用。 123FnOnce 消费从周围作用域捕获的变量，闭包周围的作用域被称为其 环境，environment。为了消费捕获到的变量，闭包必须获取其所有权并在定义闭包时将其移动进闭包。其名称的 Once 部分代表了闭包不能多次获取相同变量的所有权的事实，所以它只能被调用一次FnMut 获取可变的借用值所以可以改变其环境Fn 从其环境获取不可变的借用值 由于所有闭包都可以被调用至少一次，所以所有闭包都实现了 FnOnce .大部分需要指定一个 Fn 系列 trait bound 的时候，可以从 Fn 开始，而编译器会根据闭包体中的情况告诉你是否需要 FnMut 或 FnOnce。 带有泛型和 Fn trait 的闭包: 可以创建一个存放闭包和调用闭包结果的结构体, 目的：结构体只会在需要结果时执行闭包，并会缓存结果值，再次调用闭包可以复用该值. 1234567struct Cacher&lt;T&gt;where T: Fn(u32) -&gt; u32,&#123; calculation: T, value: Option&lt;u32&gt;,&#125; 创建Cache的结构体，泛型T类型使用where 声明类型为闭包，结构体包含一个闭包，和一个用于存放闭包返回的值的u32类型，因为有可能第一次没有缓存，所有使用Option的类型。即可能是some(u32) 或者None 官方完整例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162use std::thread;use std::time::Duration;struct Cacher&lt;T&gt;where T: Fn(u32) -&gt; u32,&#123; calculation: T, value: Option&lt;u32&gt;,&#125;impl&lt;T&gt; Cacher&lt;T&gt;where T: Fn(u32) -&gt; u32,&#123; fn new(calculation: T) -&gt; Cacher&lt;T&gt; &#123; Cacher &#123; calculation, value: None, &#125; &#125; fn value(&amp;mut self, arg: u32) -&gt; u32 &#123; match self.value &#123; Some(v) =&gt; v, None =&gt; &#123; let v = (self.calculation)(arg); self.value = Some(v); v &#125; &#125; &#125;&#125;fn generate_workout(intensity: u32, random_number: u32) &#123; let mut expensive_result = Cacher::new(|num| &#123; println!(\"calculating slowly...\"); thread::sleep(Duration::from_secs(2)); num &#125;); if intensity &lt; 25 &#123; println!(\"Today, do &#123;&#125; pushups!\", expensive_result.value(intensity)); println!(\"Next, do &#123;&#125; situps!\", expensive_result.value(intensity)); &#125; else &#123; if random_number == 3 &#123; println!(\"Take a break today! Remember to stay hydrated!\"); &#125; else &#123; println!( \"Today, run for &#123;&#125; minutes!\", expensive_result.value(intensity) ); &#125; &#125;&#125;fn main() &#123; let simulated_user_specified_value = 10; let simulated_random_number = 7; generate_workout(simulated_user_specified_value, simulated_random_number);&#125; a.这样可以起到了使用结构体缓存了闭包执行的结果，会先从结构体里查找缓存的值，没有再计算。b.同理也可以改造value的类型为HashMap, 可以通过key来找值，避免返回之前计算的始终同一个值。 iterator: 迭代器（iterator):负责遍历序列中的每一项和决定序列何时结束的逻辑。 1234let v1 = vec![1, 2, 3];let v1_iter = v1.iter();let total: i32 = v1_iter.sum();println!(\"value = &#123;&#125;\", &#123; total &#125;) next 是 Iterator 实现者被要求定义的唯一方法 123let v1 = vec![1, 2, 3];let mut v1_iter = v1.iter();assert_eq!(v1_iter.next(), Some(&amp;1)); 调用 map 方法创建一个新迭代器，接着调用 collect 方法消费新迭代器并创建一个 vector 1234567//next 一次返回迭代器中的一个项，封装在 Some 中，当迭代器结束时，它返回 Nonefn main() &#123; let v1: Vec&lt;i32&gt; = vec![1, 2, 3]; let mut newiter = v1.iter().map(|x| x + 1); let newVector: Vec&lt;_&gt; = newiter.collect(); assert_eq!(newVector, vec![2, 3, 4]);&#125; 迭代器 iter()、iter_mut()、into_iter()区别： iter()返回的是值的不可变引用. 即&amp;T iter_mut() 返回的是值的可变引用. 即&amp;mut T into_iter() 返回的是T类型的值 12345678910111213141516171819use core::num;fn main() &#123; // iter() 返回的是值的不可变引用，即&amp;T.(此处map里闭包x本身无法改变) let vec = vec![1, 2, 3, 4]; let new_vec: Vec&lt;_&gt; = vec.iter().map(|x| x + 1).collect(); println!(\"&#123;:?&#125;\", vec); println!(\"&#123;:?&#125;\", new_vec); //iter_mut() 返回的是值的可变引用，即&amp;mut T.(此处map里闭包x本身+1) let mut vec = vec![1, 2, 3, 4]; vec.iter_mut().for_each(|x| *x += 1); println!(\"&#123;:?&#125;\", vec); //into_iter() 返回的是T类型的值 (因为所有权 vec是不能再使用) let vec = vec![1, 2, 3, 4]; let new_vec: Vec&lt;_&gt; = vec.into_iter().filter(|x| *x == 2).collect(); // println!(\"&#123;:?&#125;\", vec); // 无法编译 println!(\"&#123;:?&#125;\", new_vec);&#125; 实现Iterator trait 来创建自定义迭代器: 1234567891011121314151617181920212223struct Counter &#123; count: u32,&#125;impl Counter &#123; fn new() -&gt; Counter &#123; Counter &#123; count: 0 &#125; &#125;&#125;//Counter 类型实现 Iterator trait，通过定义 next 方法来指定使用迭代器时的行为impl Iterator for Counter &#123; type Item = u32; //将迭代器的关联类型 Item 设置为 u32，意味着迭代器会返回 u32 值集合 fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; &#123; if self.count &lt; 5 &#123; self.count += 1; Some(self.count) &#125; else &#123; None &#125; &#125;&#125; Rust里iterator的定义： 12345pub trait Iterator &#123; type Item; fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt;;&#125;","path":"posts/6b1809c0.html","date":"10-03","excerpt":"","tags":[{"name":"Rust","slug":"Rust","permalink":"https://zhulg.github.io/tags/Rust/"}]},{"title":"Rust学习精简笔记总结(一)","text":"Rust精简笔记 适用对Rust感兴趣，想快速学习上手（多学几轮）、Rust知识点速查、回顾。 精简总结使用，深入扩展需继续对应官网，真知实践。 参考The Rust Programming Language &amp; Rust in Action 一.变量： 变量声明使用let, 默认为不可变（即只读），声明可变变量 mut （可读写） 123let x = 5; //类型可以由编译器自动推断出来let y: i32 = 6; //或者是在创建变量时，声明类型let z = 7i32; //数字类型，可以在数字字面量中加入类型注解 二.基本数据类型：数字类型: 分为有符号和无符号整数，浮点数类型、特定平台的整数 每一个有符号的变体可以储存包含从 -2n-1 到2n-1-1 在内的数字，这里 n 是变体使用的位数。如：i8 范围（-128-127） 无符号的范围为0到 2n-1，如: u8 范围（0-255）(00000000 - 11111111) 类型 长度 描述 i8, i16, i32, i64, i128 8,16,32,64,64,128 (bit) 有符号整数 u8, u16, u32, u64, u128 8,16,32,64,64,128 (bit) 无符号整数 f32, f64 32,64(位) f32 是单精度浮点数，f64 是双精度浮点数 isize, usize 32或64 32 位架构上它们是 32 位的，64 位架构上它们是 64 位的 Rust中的整型字面值: 数字字面值 描述 Decimal (十进制) 1_100 （使用 _ 做为分隔符以方便读数） Hex (十六进制) 0xff（0x开头） Octal (八进制) 0o77 （0o开头） Binary (二进制) 0b1111_0000（0b开头） Byte (单字节字符)(仅限于u8) b’A’（b开头） 布尔类型 bool：1234fn main() &#123; let t = true; let f: bool = false; // with explicit type annotation&#125; 复合类型： 元组（tuple）和数组（array） Tuple: 将多个其他类型的值组合进一个复合类型，声明后长度固定，索引下标从0开始. 123let tup: (i32, f64, u8) = (500, 8.4, 2); //声明类型let score = (&quot;Team A&quot;, 12); //自推断let five_hundred = tup.0; //取出元组里的500，下标0 array: 数组里数据类型必现一致，长度固定 123let a = [1, 2, 3, 4, 5]; // 自推断let b: [i32; 5] = [1, 2, 3, 4, 5]; // 在方括号中包含每个元素的类型，后跟分号，再后跟数组元素的数量。let c = [3; 5]; //变量名为c的数组将包含 5 个元素,数值都为3，等价与let a = [3, 3, 3, 3, 3] 三. 流程控制if &amp; if let：123456789101112 let number = 3; if number &lt; 5 &#123; println!(\"condition was true\"); &#125; else &#123; println!(\"condition was false\"); &#125; // match pattern and assign variable if let Some(i) = num &#123; println!(\"number is: &#123;&#125;\", i); &#125; // if let 语法让我们以一种不那么冗长的方式结合 if 和 let，来处理只匹配一个模式的值而忽略其他模式的情况 loop:12345678let mut count = 0;loop &#123; count += 1; if count == 4 &#123; println!(\"break\"); break; &#125;&#125; Nested loops &amp; labels (循环标签): 如果存在嵌套循环在一个循环上指定一个 循环标签（loop label) 标识为’名字 123456'outer: loop &#123; 'inner: loop &#123; break; // This breaks the inner loop break 'outer; // // This breaks the outer loop &#125;&#125; while &amp; while let:1234567while n &lt; 101 &#123; n += 1;&#125;let mut optional = Some(0);while let Some(i) = optional &#123; print!(\"&#123;&#125;\", i);&#125; for 遍历集合:1234567891011let a = [10, 20, 30, 40, 50];for element in a &#123; println!(\"the value is: &#123;element&#125;\");&#125;//使用iter()let array = [(1, 2), (2, 3)];for (x, y) in array.iter() &#123; // x, y accessible in loop body only println!(\"x=&#123;&#125;,y=&#123;&#125;\", x, y);&#125; match:12345let optional = Some(0);match optional &#123; Some(i) =&gt; println!(\"&#123;&#125;\", i), None =&gt; println!(\"No value.\"),&#125; 四.所有权&amp;引用&amp;借用所有权规则:123Rust 中的每一个值都有一个 所有者（owner）值在任一时刻有且只有一个所有者当所有者（变量）离开作用域，这个值将被丢弃 借用规则：(引用的行为)12同一作用域内，一个资源要么有一个可变引用，要么存在多个不可变引用引用总是有效的 String引用：12345let s1 = String::from(\"hello world!\");let s1_ref = s1; // immutable referencelet mut s2 = String::from(\"hello\");let s2_ref = &amp;mut s2; // mutable references2_ref.push_str(\" world!\"); 函数里使用值，但不获取所有权, 使用&amp;，获取变量引用 ，仅读权限 123456789fn main() &#123; let s1 = String::from(\"hello\"); let len = calculate_length(&amp;s1); println!(\"The length of '&#123;&#125;' is &#123;&#125;.\", s1, len);&#125;fn calculate_length(s: &amp;String) -&gt; usize &#123; s.len()&#125; 函数里参数可变引用, 使用&amp;mut ，获取变量可变操作 123456789fn main() &#123; let mut s = String::from(\"hello\"); change(&amp;mut s);&#125;// 对参数声明&amp;mut ，操作写字符fn change(some_string: &amp;mut String) &#123; some_string.push_str(\", world\"); println!(\"&#123;&#125;\", some_string);&#125; 操作符对应的权限：123x 不可变的值（所有权）&amp;x x不可变的引用 （只读）&amp;mut x x的可变引用（读写） 字符串 slice: slice 允许你引用集合中一段连续的元素序列，而不用引用整个集合。slice 是一类引用，它没有所有权 123456fn main() &#123; let s = String::from(\"hello world\"); let hello = &amp;s[0..5]; let world = &amp;s[6..11];&#125; 五. struct 普通结构体： struct+一个名字，在大括号中每一部分可以是不同类型，定义每一部分数据的名字和类型，称之为结构体字段 123456struct User &#123; active: bool, username: String, email: String, sign_in_count: u64,&#125; 创建一个实例需要以结构体的名字开头，接着在大括号中使用 key: value 键-值对的形式提供字段 123456let userinfo = User &#123; email: String::from(\"someone@example.com\"), username: String::from(\"someusername123\"), active: true, sign_in_count: 1,&#125;; 元组结构体（tuple structs): 元组结构体有着结构体名称提供的含义，但没有具体的字段名，只有字段的类型 1234567struct Color(i32, i32, i32);struct Point(i32, i32, i32);fn main() &#123; let black = Color(0, 0, 0); let origin = Point(0, 0, 0);&#125; 类单元结构体（unit-like structs）: 没有任何字段的结构体 1234struct AlwaysEqual;fn main() &#123; let subject = AlwaysEqual;&#125; impl为结构体添加方法：12345678910struct Rectangle &#123; width: u32, height: u32,&#125;impl Rectangle &#123; fn area(&amp;self) -&gt; u32 &#123; self.width * self.height &#125;&#125; &amp;self 实际上是 self: &amp;Self 的缩写。在一个 impl 块中，Self 类型是 impl 块的类型的别名。方法的第一个参数必须有一个名为 self 的Self 类型的参数 impl里的关联函数：12345678impl Rectangle &#123; fn square(size: u32) -&gt; Self &#123; Self &#123; width: size, height: size, &#125; &#125;&#125; 所有在 impl 块中定义的函数被称为 关联函数（associated functions），因为它们与 impl 后面命名的类型相关。我们可以定义不以 self 为第一参数的关联函数（因此不是方法），因为它们并不作用于一个结构体的实例 多个 impl 块： 每个结构体都允许拥有多个 impl 块, 但一个方法只能属于一个impl块。 六.Enum 结构体给予将字段和数据聚合在一起的方法，像 Rectangle 结构体有 width 和 height 两个字段。而枚举给予你将一个值成为一个集合之一的方法。 1234567891011121314151617enum IpAddrKind &#123; V4, V6,&#125;enum IpAddrKind &#123; V4, V6,&#125;fn main() &#123; let four = IpAddrKind::V4; let six = IpAddrKind::V6; route(IpAddrKind::V4); route(IpAddrKind::V6);&#125;fn route(ip_kind: IpAddrKind) &#123;&#125; 枚举可以包含不同的类型:123456enum Message &#123; Quit, // 没有关联任何数据 Move &#123; x: i32, y: i32 &#125;, //类似结构体包含命名字段 Write(String), //包含单独一个 String ChangeColor(i32, i32, i32), //包含三个 i32&#125; 结构体和枚举还有另一个相似点：就像可以使用 impl 来为结构体定义方法那样，也可以在枚举上定义方法。这是一个定义于我们 Message 枚举上的叫做 call 的方法： 1234567891011121314151617fn main() &#123; enum Message &#123; Quit, Move &#123; x: i32, y: i32 &#125;, Write(String), ChangeColor(i32, i32, i32), &#125; impl Message &#123; fn call(&amp;self) &#123; // 在这里定义方法体 &#125; &#125; let m = Message::Write(String::from(\"hello\")); m.call();&#125; 标准库中实用的枚举：Option1234enum Option&lt;T&gt; &#123; None, Some(T), &#125; 1234enum Result&lt;T, E&gt; &#123; OK(T), Err(E),&#125; 七.match控制流结构 前面流程控制简单说明了match使用，结合enum来看看match的更多使用场景总结 基础匹配语法： 123456let number = 2;match number &#123; 1 | 2 =&gt; println!(\"1 or 2\"), // 匹配到某一个 3..=5 =&gt; println!(\"3到5\"), // 通过 ..= 匹配值的范围 _ =&gt; println!(\"invalid\"), //未匹配到 _&#125; match 解构结构体:123456789101112struct Point &#123; x: i32, y: i32,&#125;fn main() &#123; let p = Point &#123; x: 0, y: 7 &#125;; let Point &#123; x: a, y: b &#125; = p; assert_eq!(0, a); assert_eq!(7, b);&#125; 解构枚举：12345678910111213141516171819202122232425262728enum Message &#123; Quit, Move &#123; x: i32, y: i32 &#125;, Write(String), ChangeColor(i32, i32, i32),&#125;fn main() &#123; let msg = Message::ChangeColor(0, 160, 255); match msg &#123; Message::Quit =&gt; &#123; println!(\"The Quit variant has no data to destructure.\") &#125; Message::Move &#123; x, y &#125; =&gt; &#123; println!( \"Move in the x direction &#123;&#125; and in the y direction &#123;&#125;\", x, y ); &#125; Message::Write(text) =&gt; println!(\"Text message: &#123;&#125;\", text), Message::ChangeColor(r, g, b) =&gt; println!( \"Change the color to red &#123;&#125;, green &#123;&#125;, and blue &#123;&#125;\", r, g, b ), &#125;&#125;//打印结果到change the color.... 解构嵌套的结构体和枚举:123456789101112131415161718192021222324252627enum Color &#123; Rgb(i32, i32, i32), Hsv(i32, i32, i32),&#125;enum Message &#123; Quit, Move &#123; x: i32, y: i32 &#125;, Write(String), ChangeColor(Color),&#125;fn main() &#123; let msg = Message::ChangeColor(Color::Hsv(0, 160, 255)); match msg &#123; Message::ChangeColor(Color::Rgb(r, g, b)) =&gt; println!( \"Change the color to red &#123;&#125;, green &#123;&#125;, and blue &#123;&#125;\", r, g, b ), Message::ChangeColor(Color::Hsv(h, s, v)) =&gt; println!( \"Change the color to hue &#123;&#125;, saturation &#123;&#125;, and value &#123;&#125;\", h, s, v ), _ =&gt; (), &#125;&#125; 用 .. 忽略剩余值:1234567891011121314//通过使用 .. 来忽略 Point 中除 x 以外的字段fn main() &#123; struct Point &#123; x: i32, y: i32, z: i32, &#125; let origin = Point &#123; x: 0, y: 0, z: 0 &#125;; match origin &#123; Point &#123; x, .. &#125; =&gt; println!(\"x is &#123;&#125;\", x), &#125;&#125; Match guards: 匹配守卫（match guard）是一个指定于 match 分支模式之后的额外 if 条件，它也必须被满足才能选择此分支 12345678fn main() &#123; let num = Some(4); match num &#123; Some(x) if x &lt; 5 =&gt; println!(\"less than five: &#123;&#125;\", x), Some(x) =&gt; println!(\"&#123;&#125;\", x), None =&gt; (), &#125;&#125; @绑定: 运算符@，允许我们在创建一个存放值的变量的同时，测试其值是否匹配模式。即@ 可以在一个模式中同时测试和保存变量值。 123456789101112131415fn main() &#123; enum Message &#123; Hello &#123; id: i32 &#125;, &#125; let msg = Message::Hello &#123; id: 5 &#125;; match msg &#123; Message::Hello &#123; id: id_variable @ 3..=7, //使用id_variable变量配合@，以便此分支相关联的代码可以使用它 &#125; =&gt; println!(\"Found an id in range: &#123;&#125;\", id_variable), Message::Hello &#123; id: 10..=12 &#125; =&gt; &#123; println!(\"Found an id in another range\") &#125; Message::Hello &#123; id &#125; =&gt; println!(\"Found some other id: &#123;&#125;\", id), &#125;&#125;","path":"posts/658f0ea2.html","date":"09-24","excerpt":"","tags":[{"name":"Rust","slug":"Rust","permalink":"https://zhulg.github.io/tags/Rust/"}]},{"title":"Flutter Widget生命周期总结","text":"Flutter Widget生命周期分为2种，一种有状态的组件StatefulWidget的生命周期，和无状态的StatelessWidget 组件的生命周期。 一.StatefulWidget的生命周期 先看一张statefulwidget生命周期图 （若文中图片无法显示，请科学上网查看：推荐工具） 继承StatefulWidget的组件会先进行构造方法，在进行对应的Widget的CreateState, 在State里 1.createState： 创建新的StatefulWidget的时候，就会立即执行createState方法，返回一个state的实例与当前widget建立关系。 123456class MyHomePage extends StatefulWidget &#123; const MyHomePage(&#123;Key? key, required this.title&#125;) : super(key: key); final String title; @override State&lt;MyHomePage&gt; createState() =&gt; _MyHomePageState();&#125; 2. initState： initState 是 StatefulWidget 创建完后，在State里调用的第一个方法, 只执行一次（iOS 的 viewDidLoad()、Android 的 onCreate）, StatefulWidget 已经被加载到渲染树里了但还没开始渲染，这里常做一些初始化变量工作。 1234@overridevoid initState()&#123; super.initState();&#125; 3. didChangeDependencies: 在initState回调函数执行之后立即调用，之后当 StatefulWidget 刷新的时候，就不会调用了, 当State对象的依赖发生变化时会被再次调用（层级变化&amp;共享依赖变化）。官网文档举例，如果之前build构建里依赖的 InheritedWidget 发生变化之后，那么他的 didChangeDependencies 会被再次调用。（InheritedWidget是 Flutter 中非常重要的一个功能型组件，它提供了一种在 widget 树中从上到下共享数据的方式，应用的根 widget 中通过InheritedWidget共享了一个数据，可以在任意子widget 中来获取该共享的数据）（场景：主题颜色、地区语言或者其他通用变量等） 12@overridevoid didChangeDependencies() &#123; &#125; 4. build： build方法在didChangeDependencies之后会立即调用，之后每次当setState方法被调用后，都会进行重新build，并返回要渲染的widiget 1234@overrideWidget build(BuildContext context) &#123; return Scaffold()&#125; 5. didUpdateWidget： 比较严谨官方描述: If the parent widget changes its properties or configurations, and the parent wants to rebuild the child widget, with the same Runtime Type, then didUpdateWidget is triggered. This unsubscribes to the old widget and subscribes to the configuration changes of the new widget! 12345@override void didUpdateWidget(covariant CurrentClass oldWidget) &#123; // TODO: implement didUpdateWidget super.didUpdateWidget(oldWidget); &#125; 6. deactivate： 当要将 State 对象从渲染树中移除的时候，就会调用 deactivate 生命周期，这标志着 StatefulWidget 将要销毁，但是有时候 State 不会被销毁，而是重新插入到渲染树种(例如；当使用Navigator.push 移动到下一个屏幕) 1234@override void deactivate() &#123; super.deactivate(); &#125; 7. dispose 当 View 不需要再显示，从渲染树中移除的时候，State 就会永久的从渲染树中移除，就会调用 dispose 生命周期，(在 dispose 里做一些取消监听、动画的操作，和 initState 是相反) 1234@override void dispose() &#123; super.dispose(); &#125; 二. StatelessWidget的生命周期 StatelessWidget的生命周期比较简单，通过构造方法，build方法来进行渲染需要的widget，由于是无状态的也就执行一次。 深入理解 Flutter 的生命周期是写出高质量、高性能应用的基础。同样地，在日常开发和内容创作中，善用自动化工具也是提升个人效率的关键。如果你对如何将 AI 与自动化工具结合，打造一套属于自己的高效工作流感兴趣，可以阅读我的另一篇实战文章：《N8N教程：搭建公众号自动化写作工作流完整指南》。","path":"posts/f4ca6a79.html","date":"05-27","excerpt":"","tags":[{"name":"flutter","slug":"flutter","permalink":"https://zhulg.github.io/tags/flutter/"}]},{"title":"Flutter架构构成和渲染原理","text":"一.Flutter架构构成 Flutter的架构是一个可扩展的分层系统设计，上层组件各自依赖下层组件，层级不可越级访问，各个层级模块可替换 Flutter从分层构成看主要分为3个层级： 123Dart FrameworkC++ EnginePlatform Embedder 从官网的架构图片层级分析：（科学上网可见图片） 1. Platform Embedder：(平台嵌入层) 平台层潜入层作用:是把 Flutter 代码打包嵌入到具体的实现平台, 来呈现所有 Flutter 内容的原生系统应用, 它充当着宿主操作系统（android/ios/macOS/..）和 Flutter 之间的粘合剂的角色。 提供flutter的运行入口，初始化 Flutter 引擎，管理flutter应用生命周期 并对上层提供最基础的能力(渲染画布、插件系统、交互管理、消息循环等) 2. C/C++ Engine: 它的主要职责是光栅化合成上屏幕用于显示绘制内容（当需要绘制新一帧的内容时，将负责对需要合成的场景进行栅格化） 提供了 Flutter 核心 API 的底层实现，包括图形（通过 Skia）、文本布局、文件及网络 IO、辅助功能支持、插件架构和 Dart 运行环境及编译环境的工具链。 引擎将底层 C++ 代码包装成 Dart 代码，通过 dart:ui 暴露给 Flutter 框架层，而dart:ui 包是 Flutter App 的构建基础 3. Dart Framework: 提供了以 Dart 语言编写的现代响应式框架，对渲染逻辑做了统一封装，屏蔽了底层实现，对底层 C++ Engine 提供双向通信能力 开发者只需要通过该层使用widget控件构建 App 视图即可 Dart Framework 包括丰富的平台，布局和基础库。从上层到下层，依次有： 1234Material 和 Cupertino 分别实现了 android Material 和 iOS 设计规范。widget 层是一种组合的抽象,widgets 层让可以自由组合你需要复用的各种控件类渲染层 用于提供操作布局的抽象，负责控件布局摆放及更新基础的 foundational 类及一些基层之上的构建块服务， animation、 painting 和 gestures，它们可以提供上层常用的抽象。 Flutter核心组件1.Widget (应用开发者直接使用) Widget是Flutter的核心部分, Flutter的口号 Everything’s a widget,是构建应用的基础块 Widgets 通过布局组合形成一种层次结构关系。每个 Widget 都嵌套在其父级的内部，并可以通过父级接收上下文 Widget 不只表示UI 控件，还表示一些功能性的组件Navigator、GestureDetector 组件 2. Element （实例化的 Widget 对象） 在构建的阶段，Flutter 会将代码中描述的 widgets 转换成对应的 Element 树，每一个 Widget 都有一个对应的 Element。每一个 Element 代表了树状层级结构中特定位置的 widget 实例。 目前有两种 Element 的基本类型： 12ComponentElement : Element 的宿主 RenderObjectElement :参与布局或绘制阶段的 Element。 在代码阶段的widget层级在生成绘制后会多一些层级（源码和官网演示看查看到），这里面多一些的层级往往就是参与布局和绘制RenderObjectElement 注：ColoredBox 、RawImage、RichText 为绘制时产生的新增widget层级（科学上网可见图片） 3.RenderObject（树形） 用于应用界面的布局和绘制，保存了元素的大小，布局等信息 在构建阶段，Flutter 会为 Element 树中的每个 RenderObjectElement 创建或更新其对应的一个从 RenderObject 继承的对象。 当应用运行时 Flutter 使用 RenderObject 的数据绘制应用界面，最终形成一个 Render Tree。(图片需要科学上网) 大部分的 Flutter widget 是由一个继承了 RenderBox 的子类的对象渲染的，真正负责干活（layout、paint） 所有 RenderObject 的根节点是 RenderView，代表了渲染树的总体输出。当平台需要渲染新的一帧内容时（例如一个 vsync 信号或者一个纹理的更新完成），会调用一次 compositeFrame() 方法，它是 RenderView 的一部分。该方法会创建一个 SceneBuilder 来触发当前画面的更新。当画面更新完毕，RenderView 会将合成的画面传递给 dart:ui 中的 Window.render() 方法，控制 GPU 进行渲染。 三者直接关系：123Widget 是应用界面的声明的控件，为开发者直接使用的控件Element 链接 Widget 和 RenderObject，管理界面的更新和修改。RenderObject 保存具体的布局信息，负责绘制 UI, 为实际渲染 Widget重新创建，Element 树和 RenderObject 树并不会完全重新创建，如果 newWidget 与oldWidget 的 runtimeType 和 key 相等时，更新已经存在的 Element 对象，不然就选择重新创建新的 Element。 二.Flutter渲染原理 从Flutter的核心控件大概已经初步了解到了渲染的相关流程，核心控件到绘制的情况。 一般计算机绘图原理：屏幕显示器一般以60Hz的固定频率刷新，每一帧图像绘制完成后，会继续绘制下一帧，这时显示器就会发出一个Vsync信号，按60Hz计算，屏幕每秒会发出60次这样的信号。CPU计算好显示内容提交给GPU，GPU渲染好传递给显示器显示。flutter 渲染原理相同。渲染过程会使用上边介绍的核心流程控件。 Flutter 的渲染流水线也包括两个线程，UI 线程和 GPU 线程，UI 线程主要负责的是根据 UI 界面的描述生成 UI 界面的绘制指令，建立过程中生成 Render，往下布局、绘制大小等工作，完成以后会生成一个 Layer Tree，到了 GPU 线程之后会调用 Skia 做渲染","path":"posts/c8a78489.html","date":"05-13","excerpt":"","tags":[{"name":"flutter","slug":"flutter","permalink":"https://zhulg.github.io/tags/flutter/"}]},{"title":"NFT是什么有哪些应用场景","text":"NFT是什么 NFT的全称为 Non-fungible Tokens（非同质化代币 ) ，用以代表独特物品所有权的代币 非同质化是一个经济术语，用它来描述家具、歌曲、字画、电脑等物品，这些东西不能与其他物品互换，因为它们具有独特属性。 NFT的主要功能是作为可验证的所有权证明，并显示资产所有权随时间推移的转移记录 NFT起源于2017年的加密猫游戏，用于表示每只猫拥有的不同花色、基因、代际等信息。 目前最热的在数字艺术品、收藏品只是使用 NFT 的一种方式，NFT可以代表任何独特资产的所有权。 （若文中图片无法显示，请科学上网查看：推荐工具） NFT的工作原理 NFT通过工作量证明（PoW）区块链运作，PoW是一个过程，其中一方向其他方证明已经为一个目标付出了一定量的努力 NFT 一次只能有一个所有者。 通过唯一的 ID 和其他代币无法复制的元数据管理所有权。 NFT 通过智能合约铸造，智能合约分配 NFT 的所有权并管理它们的可转让性。 有人创建或铸造 NFT 时，他们会执行存储在符合不同标准的智能合约中的代码(如 ERC-721。 此信息会添加到正在管理 NFT 的区块链中) 铸造过程具有以下步骤： 123新建区块验证信息将信息录入区块链 NFT与去中心化 NFT的核心是内容和所有权验证，由于区块链不适合存储大量数据，因此一般将NFT的元数据（metadata）存储在去中心化存储网络上（一般是IPFS），将NFT的发行、流通记录存储在区块链上 NFT 有什么用 加速数字化，数字化后更便于流通、存证、防伪、溯源，复制实体物品的属性，稀缺性、独特性和所有权证明形成NFT 解决了当前互联网上存在的一些问题。 NFT互联网 目前互联网 NFT 在数字世界里是独一无二的，没有两个相同的 NFT 文件副本（如.mp3 或 .jpg）与原始文件并无二致 每个 NFT 必须有一个所有者，而且是一条公开记录，任何人都可以轻松核实。 数字物品的所有权记录存储在由机构控制的服务器上 - 您必须相信他们的话 NFT 与使用以太坊构建的任何内容都兼容交换 拥有数字产品的公司必须构建自己的基础设施。 例如，一个售卖活动数字门票的应用程序必须建立自己的门票交易所。 内容创建人可以在任何地方出售他们的作品，并可以进入全球市场。 创建人依靠所用平台的基础设施和分布。 这些通常受到使用条款和地理限制的制约。 创建人可以保留对自己作品的所有权，并直接要求收取转售版税。 音乐媒体服务等平台扣留了大部分销售利润 如何创建NFT NFT交易平台均可创建，如：OpenSea、Rarible、SuperRare、MakersPlace、KnowOrigin、Mintbase、Foundation、AsyncArt等。 其本质为数字资产token化，数字资产分两类：原生数字资产（如：纯数字载体艺术品）、数字化后的物理资产（如：实体油画的扫描电子版、嵌入NFC芯片的实体雕塑等） NFT的应用场景和未来 NFT有可能带来盗版保护、知识产权安全、数字身份验证系统、内容创作者收入系统、游戏、许可、证书、美术的全新世界，甚至允许拥有巨大价值的房地产的部分所有权。 数字艺术品：艺术家可以将其数字艺术品变现、游戏中创建可验证的游戏物品、游戏中创建可验证的游戏物品 123456789GIF收藏品音乐视频车内饰品真实世界活动的门票代币化发票法律文档签名","path":"posts/64ceaf0c.html","date":"05-06","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"},{"name":"元宇宙","slug":"元宇宙","permalink":"https://zhulg.github.io/tags/元宇宙/"}]},{"title":"元宇宙是什么有哪些应用场景","text":"一,元宇宙是什么： 元宇宙本质上是对现实世界的虚拟化、数字化的一些列技术 通过多种技术构成的一种虚拟世界和现实的映射，这些技术最主要的构成包括： 12345678人机交互设备网络传输芯片算力人工智能区块链云服务游戏技术.... 目前更多对元宇宙的探索多停留在虚拟空间和世界，但元宇宙远远不至此，更多的技术结合还在探索和落地。 在元宇宙世界里，人们可以自由穿梭于物理世界和数字世界，在虚拟空间和时间节点所构成的元宇宙中学习、工作、交友、购物、旅游等等 二,元宇宙包含哪些技术： （若文中图片无法显示，请科学上网查看：推荐工具） 人机交互设备： 这个大家很容易想到AR、VR、MR等，特别是 XR，持续迭代升级，虚拟沉浸现实体验的基础 网络传输： 未来需要更强的网络传输能力包括6G等，零延迟，满足高分辨率图像和视频传输能力 芯片算力： 需要更多对算力满足对数据技术等软硬件能力，包括GPU 服务器、CPU、量子计算等 人工智能： 这个包括机器学习、视觉处理、自然语言、知识图谱等满足人类更多智能推断和判定需求 区块链技术： 区块链技术满足了虚拟世界中去中心化，数字货币，智能合约等天然技术基础 云服务： 大量的数据需要云技术、云存储、边缘计算满足终端设备数据显示和存储需求 游戏技术 新的业务场景需要游戏引擎、3D、unity技术结合构建图形化技术和沉浸式画面体验 三,元宇宙未来发展阶段： 个人认为目前的元宇宙更多在概念阶段，也包括一些通过元宇宙来概念和骗局，大家需要理清技术原理慎重投资 1.已落地场景：123AR/VR 虚拟游戏链游3D网购 2.进展中场景：12345智能头盔虚拟场景会议沉浸式社交、游戏沉浸式娱乐、体育、健康模拟等应用形成人类虚拟式，面对面体验 3.未来场景1234在已有场景中包含有工作资产的交易元宇宙中角色职位真实世界互通、形成元宇宙社会形态 四,元宇宙构成和应用场景 通过一张图来概括元宇宙从底层技术到应用场景的构成，来更好理解元宇宙的生态和落地场景。 从技术视角也许没有创造性的技术产出，但是随着元宇宙快速发展和巨头的投入，未来一定会有创新的落地和业务，为用户提供更多的体验和便利场景。 五,元宇宙的投资： 目前投资大多在链游、AR\\VR应用和硬件、技术投资参考大公司风向标，关注新技术。 以元宇宙&amp;区块链的炒作、技术类用户慎重投资","path":"posts/263.html","date":"04-28","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"},{"name":"元宇宙","slug":"元宇宙","permalink":"https://zhulg.github.io/tags/元宇宙/"}]},{"title":" Web3是什么与区块链关系","text":"web3是什么1.先从维基百科看Web3的解释: Web 3.0是关于万维网发展的一个概念，主要与基于区块链的去中心化、加密货币以及非同质化代币有关。 区块链有关的web3概念是由以太坊联合创始人Gavin Wood于2014年提出，并于2021年受到加密货币爱好者、大型科技公司, 风险投资公司的关注Web3 2. 对比web1.0和web2.0来理解： Web 1.0 is like a one-way system. 用户只能被动地浏览文本、图片以及简单的视频内容，网站提供什么，用户查看什么。几乎没有互动可言。 In Web 2.0 of the internet. 互联网开始与人互动,论坛、语音、朋友圈 In Web 3.0, data will be connected in a decentralized way. 数据已去中心用户生活在互联网中 3.从时代规则来进行对比：（若文中图片无法显示，请科学上网查看：推荐工具） Web 1.0 时代规则：平台进行创造、所有、控制、并自身受益。（早期信息网站） Web 2.0时代规则：用户来创造、平台所有和控制、平台分配。（近期比较火的自媒体、抖音短视频等） Web 3.0时代规则：用户来创造、用户所有和控制、协议分配。（归属明确，协议不可篡改，去中心化） 4.对比目前Web2.0的应用来看web3.0: web3与区块链的关系1231.区块链是一个去中心化计算协议，区块链技术确保了数据不可篡改，明确了相关归属，具备天然的分布式数据储存2.在协议方面区块链有智能合约概念，通过合约，用户权利与价值的分配协议可以无需借助可信第三方。3.区块链技术满足了web3定义的相关规则，是一种重要的技术实现手段。","path":"posts/55503.html","date":"04-23","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"},{"name":"web3","slug":"web3","permalink":"https://zhulg.github.io/tags/web3/"}]},{"title":"MVC/MVP/MVVM/MVI架构模式","text":"1.MVC: View 层接受输入，并送到指令到 Controller层 Controller 处理业务逻辑后，对 Model 改变状态，有时也直接更新View Model 更新数据发送到 View，View层更新界面 2.MVP: View 与 Model 不再进行通信 View 与 Model 通过Presenter层通信降低耦合 View层负责界面展示，Presenter层处理逻辑业务代码会变厚 3.MVVM： View 与 Model 保持不直接通信，与MVP思想大致相同 通过绑定思想建立View层和ViewModel映射，实现界面和数据自动同步 ViewModel层多包含处理的业务逻辑，并与Model层通信 4.MVI: MVI 是 Model-View-Intent 的缩写，它也是一种响应式 + 流式处理思想的架构（数据模型驱动界面）。 把用户操作，形成以Intent的形式，通知Model里对应的状态方法 Model基于Intent更新State，保证状态逻辑的一致性 View接收到State变化刷新界面层 Android架构中MVI与MVVM分层变动： MVVM 代码分层的 View 和 ViewModel 在 MVI 中统一称为 UI Layer，而 Model 层在 MVI 中变成了 Data Layer。 MVI 概念中的 Model 作为状态模型，在 UI Layer 的 ViewModel 和 Data Layer 的 Repository 中分别体现为 UI State 和 Data Flow MVI优点: 通过数据模型驱动界面，应用会更便于测试、更稳定可靠 强调数据单向流动，容易对状态变化进行跟踪和回溯 MVI缺点: 所有的操作都会转换成State，所以当复杂页面的State容易膨胀","path":"posts/9541.html","date":"02-13","excerpt":"","tags":[{"name":"App","slug":"App","permalink":"https://zhulg.github.io/tags/App/"},{"name":"架构","slug":"架构","permalink":"https://zhulg.github.io/tags/架构/"}]},{"title":"iOS设备型号和名称对照","text":"方便线上日志根据获取到的设备标示，去查找对应具体设备名称 iPad设备标示和设备名称对应表： iPad设备型号 设备名称 iPad1,1 iPad iPad1,2 iPad 3G iPad2,1 iPad 2 iPad2,2 iPad 2 iPad2,3 iPad 2 iPad2,4 iPad 2 iPad2,5 iPad Mini iPad2,6 iPad Mini iPad2,7 iPad Mini iPad3,1 iPad 3 iPad3,2 iPad 3 iPad3,3 iPad 3 iPad3,4 iPad 4 iPad3,5 iPad 4 iPad3,6 iPad 4 iPad4,1 iPad Air iPad4,2 iPad Air iPad4,3 iPad Air iPad4,4 iPad Mini 2 iPad4,5 iPad Mini 2 iPad4,6 iPad Mini 2 iPad4,7 iPad Mini 3 iPad4,8 iPad Mini 3 iPad4,9 iPad Mini 3 iPad5,1 iPad Mini 4 iPad5,2 iPad Mini 4 iPad5,3 iPad Air 2 iPad5,4 iPad Air 2 iPad6,3 iPad Pro 9.7 iPad6,4 iPad Pro 9.7 iPad6,7 iPad Pro 12.9 iPad6,8 iPad Pro 12.9 iPad6,11 iPad 5 iPad6,12 iPad 5 iPad7,1 iPad Pro 12.9 inch 2nd gen iPad7,2 iPad Pro 12.9 inch 2nd gen iPad7,3 iPad Pro 10.5 inch iPad7,4 iPad Pro 10.5 inch iPad7,5 iPad 6 iPad7,6 iPad 6 iPad7,11 iPad 7 iPad7,12 iPad 7 iPad8,1 ~ 8,4 iPad Pro 11-inch iPad8,5 ~ 8,8 iPad Pro 12.9-inch 3rd gen iPad8,9 ~ 8,10 iPad Pro 11-inch 2nd gen iPad8,11 ~ 8,12 iPad Pro 12.9-inch 4th gen iPad11,1 iPad Mini 5 iPad11,2 iPad Mini 5 iPad11,3 iPad Air 3 iPad11,4 iPad Air 3 iPad11,6 iPad 8 iPad11,7 iPad 8 iPad13,1 iPad Air 4 iPad13,2 iPad Air 4 iPad12,1 iPad 9 iPad12,2 iPad 9 iPad14,1 iPad Mini 6 iPad14,2 iPad Mini 6 iPad13,4 ~ 13,7 iPad Pro 11-inch 3nd gen iPad13,8 ~ 13,11 iPad Pro 12.9-inch 5th gen 手机型号对应表： iphone对应型号 名称 iPhone3,1 iPhone 4 iPhone3,2 iPhone 4 iPhone3,3 iPhone 4 iPhone4,1 iPhone 4S iPhone5,1 iPhone 5 iPhone5,2 iPhone 5 iPhone5,3 iPhone 5c iPhone5,4 iPhone 5c iPhone6,1 iPhone 5s iPhone6,2 iPhone 5s iPhone7,1 iPhone 6 Plus iPhone7,2 iPhone 6 iPhone8,1 iPhone 6s iPhone8,2 iPhone 6s Plus iPhone8,4 iPhone SE iPhone9,1 iPhone 7 iPhone9,2 iPhone 7 Plus iPhone9,3 iPhone 7 iPhone9,4 iPhone 7 Plus iPhone10,1 iPhone 8 iPhone10,2 iPhone 8 Plus iPhone10,4 iPhone 8 iPhone10,5 iPhone 8 Plus iPhone10,3 iPhone X iPhone10,6 iPhone X iPhone11,2 iPhone XS iPhone11,4 iPhone XS Max iPhone11,6 iPhone XS Max iPhone11,8 iPhone XR iPhone12,1 iPhone 11 iPhone12,3 iPhone 11 Pro iPhone12,5 iPhone 11 Pro Max iPhone12,8 iPhone SE 2 iPhone13,1 iPhone 12 mini iPhone13,2 iPhone 12 iPhone13,3 iPhone 12 Pro iPhone13,4 iPhone 12 Pro Max iPhone14,4 iPhone 13 mini iPhone14,5 iPhone 13 iPhone14,2 iPhone 13 Pro iPhone14,3 iPhone 13 Pro Max","path":"posts/14423.html","date":"01-11","excerpt":"","tags":[{"name":"ios","slug":"ios","permalink":"https://zhulg.github.io/tags/ios/"}]},{"title":"技术开发流程","text":"技术开发流程 产品研发过程中，涉及到技术实现环节的相关流程梳理的梳理是非常重要的，在多年的技术管理过程中一直实践并不断总结和完善开发流程、管理方法论。 相关的方法论也是经过验证在产品交付、项目把控、人员能力提升等环节都有非常好的使用价值。 技术管理和技术开发流程没有一成不变，只有最适合自己团队发展现状的管理方法。 1.图解流程 2.核心阶段： 第一阶段，研发需要对业务进行深度体验，吃透业务场景，分析里面使用技术，形成基于业务场景的技术选型和架构。 第二阶段，在产品人员进行业务设计阶段，研发需要开始着手搭建，不基于产品层面的所有底层基础技术。 第三阶段，在产品评审完成研发任务后，进入开发阶段，研发需要提供排期和项目里程碑点，预留技术buffer时间和备选方案，里程碑验收。 3.版本迭代规范： 版本迭代基本规范，遵循大小版本，大功能点提前准备，隔版本上线，小版本当前版本上线。 版本迭代中，除产品需求外，默认包括线上问题bugfix ,性能优化，代码完善，研发排期需要预留时间。 隔代版本技术预研，要在版本迭代中研发提前安排进入预言阶段，确保隔代版本能进入下版本上线。 4.研发核心遵守： 预研先行，提前储备 技术实现，遵循产品需求，业务评审文档 代码编写，遵循通用及各端语言规范，入库review流程 需求变动，知会到负责人（产品&amp;技术），并要明确确认和风险 技术文档，记录研发过程技术实现相关设计，时序图等，达到第2人能交接标准 跟踪文档，记录每个版本产品需求、技术、优化改动的，提测前知会QA，协助验收。","path":"posts/26749.html","date":"09-12","excerpt":"","tags":[{"name":"管理杂烩","slug":"管理杂烩","permalink":"https://zhulg.github.io/tags/管理杂烩/"}]},{"title":"Linux系统安装rvm管理rbuy版本","text":"ruby使用 ruby是个面向对象的脚本语言，相对比较小众使用，随着python的兴起。但是对应工具类的使用还是占有一席之地，使用也比较广泛很多创业公司也在只用。 rvm是管理ruby的版本 rvm类似node的nvm，方便管理对版本的管理和使用切换。由于ruby是不经常使用，现用现学，快速解决问题，ruby也更简洁符合人类思维。最近工具类使用了下对后续使用快速搭建环境做个简单的记录，后续能快速恢复知识和使用。 安装rvm 1.可能会失败、按指示进行或者重复几次，依赖网络和翻墙情况 1curl -L get.rvm.io | bash -s stable 2 . 查看rvm安装情况, 并生效配置其中的配置项 source /usr/local/rvm/scripts/rvm 1find / -name rvm 查看版本情况（可能你需要特定的版本安装） 1rvm list known 安装版本ruby（从上边选择你期望的版本） 1rvm install xxx 使用版本ruby 1rvm use xxx 其他操作","path":"posts/17705.html","date":"09-12","excerpt":"","tags":[{"name":"Ruby","slug":"Ruby","permalink":"https://zhulg.github.io/tags/Ruby/"}]},{"title":"WebView跨域问题","text":"WebView的资源跨域 从出现的问题来讲： 移动端使用webView去加载本地H5离线包（file://），在离线的H5里有http相关的请求，这样会出现file协议和http造成的不同源问题 1from origin &apos;null&apos; has been blocked by CORS policy: No &apos;Access-Control-Allow-Origin&apos; header is present on the requested resource. If an opaque response serves your needs, set the request&apos;s mode to &apos;no-cors&apos; to fetch the resource with CORS disabled. 或者类似出现： 1cross origin requests are only supported for protocol schemes: http, data, chrome, https. 出现原因： 同源策略造成，大众叫法一般称为跨域了 同源要满足：协议相同、域名相同、端口相同 http://www.example.com:80/ 同源政策的目的，是为了保证用户信息的安全，防止恶意的网站窃取数据 CORS是什么： 是一种基于HTTP 头的机制，该机制通过允许服务器标示除了它自己以外的其它 origin（域，协议和端口），这样浏览器可以访问加载这些资源。 跨源资源共享还通过一种机制来检查服务器是否会允许要发送的真实请求，该机制通过浏览器发起一个到服务器托管的跨源资源的”预检”请求。 在预检中，浏览器发送的头中标示有HTTP方法和真实请求中会用到的头。 跨源域资源共享（ CORS ）机制允许 Web 应用服务器进行跨源访问控制，从而使跨源数据传输得以安全进行。 原理解决：​ 出现不同源情况下，使用cors的方式来进行解决，如上日志描述 对请求的资源服务器设置允许跨源请求 使用WebView的设置允许使用file文件来进行访问，但是APP安全性来说是致命 使用同源的方式来进行请求和加载 推荐方案： Android上以前解决该类问题方案设置 setAllowFileAccessFromFileURLs 来允许其他协议访问加载的file开头的页面，这个已经被披露严重漏洞 官方推荐： WebViewAssetLoader androidx.webkit.WebViewAssetLoader 1Helper class to load local files including application&apos;s static assets and resources using http(s): // URLs inside a WebView class. Loading local files using web-like URLs instead of &quot;file://&quot; is desirable as it is compatible with the Same-Origin policy. AssetsPathHandler ​为该PathHandler的实现类 提供 AssetsPathHandler, ResourcesPathHandler 、InternalStoragePathHandler 满足各个场景需要 DEFAULT_DOMAIN默认appassets.androidplatform.net 字符串常量可替换 AssetsPathHandler的用法： 1234567891011121314151617181920212223242526272829303132333435final WebViewAssetLoader assetLoader = new WebViewAssetLoader . Builder ( ) . addPathHandler ( &quot;/assets/&quot; , new AssetsPathHandler ( this ) ) . build ( ) ; webView. setWebViewClient ( new WebViewClient ( ) &#123; @Override @RequiresApi ( 21 ) public WebResourceResponse shouldInterceptRequest ( WebView view, WebResourceRequest request) &#123; return assetLoader. shouldInterceptRequest (request. getUrl ( ) ) ; &#125; @Override @SuppressWarnings ( &quot;deprecation&quot; ) // for API &lt; 21 public WebResourceResponse shouldInterceptRequest ( WebView view, WebResourceRequest request) &#123; return assetLoader. shouldInterceptRequest ( Uri . parse (request) ) ; &#125;&#125; ) ; WebSettings webViewSettings = webView. getSettings ( ) ;// Setting this off for security. Off by default for SDK versions &gt;= 16.webViewSettings. setAllowFileAccessFromFileURLs ( false ) ;// Off by default, deprecated for SDK versions &gt;= 30.webViewSettings. setAllowUniversalAccessFromFileURLs ( false ) ;// Keeping these off is less critical but still a good idea, especially if your app is not// using file:// or content:// URLs.webViewSettings. setAllowFileAccess ( false ) ;webViewSettings. setAllowContentAccess ( false ) ; // Assets are hosted under http(s)://appassets.androidplatform.net/assets/... .// If the application&apos;s assets are in the &quot;main/assets&quot; folder this will read the file// from &quot;main/assets/www/index.html&quot; and load it as if it were hosted on:// https://appassets.androidplatform.net/assets/www/index.htmlwebview. loadUrl ( &quot;https://appassets.androidplatform.net/assets/www/index.html&quot; ) ; 这样在loadurl是就可以使用 https://appassets.androidplatform.net/assets/www/index.html 主要domain的部分和后边assets是需要对应的，这样通过https来加载，而实际好找的对应的本地资源通过流的方式进行的读取，避免了非同源问题的出现。","path":"posts/52150.html","date":"08-13","excerpt":"","tags":[{"name":"App","slug":"App","permalink":"https://zhulg.github.io/tags/App/"}]},{"title":"Nrm管理源","text":"关于npm源 在国内使用这个源是不稳定的，一般用淘宝npm源: https://registry.npm.taobao.org/在终端输入: 1npm config set registry https://registry.npm.taobao.org/ 查看 1npm config list 为方便管理和切换这些源 ，可以按照nrm nrm 是一个 npm 源管理器, 可以管理并快速地在切换NPM源 nrm安装: 1npm install -g nrm 使用nrm 查看： nrm ls 1234567 npm -------- https://registry.npmjs.org/ yarn ------- https://registry.yarnpkg.com/ cnpm ------- http://r.cnpmjs.org/* taobao ----- https://registry.npm.taobao.org/ nj --------- https://registry.nodejitsu.com/ npmMirror -- https://skimdb.npmjs.com/registry/ edunpm ----- http://registry.enpmjs.org/ 切换 1nrm use taobao //切换到taobao 添加新源 1nrm add &lt;registry&gt; &lt;url&gt; [home] 删除源 1nrm del &lt;registry&gt;","path":"posts/26211.html","date":"03-04","excerpt":"","tags":[{"name":"npm","slug":"npm","permalink":"https://zhulg.github.io/tags/npm/"},{"name":"JS","slug":"JS","permalink":"https://zhulg.github.io/tags/JS/"}]},{"title":"Scratch Android安装","text":"Scratch APK Scratch由于官网被墙，正常的话也无法从googlePlay进行安装。而官方的APK安装包可以进行参考对二次开发的话需要安装。 Scratch APK的下载可以从googleplay上下载国内被墙也基本上无法用，需要下载最新的APK包进行安装。 下载APK包 下载APK包可以从apkpure上进行下载，前提是需要科学上网，下载完成后可以对其安装 由于Scratch的包是XAPK的，需要进行XAPK的安装器进行安装 下载安装Xapk install xapk install 的下载也可以https://www.xapk.pro/ 进行下载并安装 Scratch push SDCARD 将下载好的 Scratch APK push 到SD卡上进行扫描安装，如果小米手机关闭miui优化，进行安装。 最新安装包 目前最新安装包已下载，如有童鞋需要可以邮件我","path":"posts/1971.html","date":"01-05","excerpt":"","tags":[{"name":"Scratch","slug":"Scratch","permalink":"https://zhulg.github.io/tags/Scratch/"}]},{"title":"App WebView白屏检测及解决总结","text":"App上WebView白屏 在移动端上场景的H5页面白屏问题，根据平台分为Android和ios端上H5白屏问题（相关解决和优化基于移动端侧） Android的的白屏问题表现现对比较多些，按问题类型大致可以概括为： 123456机型兼容造成JS语法兼容造成网络加载获取数据造成软件系统版本兼容造成内存或者渲染进程造成android上疑难杂症 IOS的问题造成白屏的原因现对较少，因为WKWebView来说通过系统组件来保障，相对Android系统webview碎片化要好的多： 1234网络加载获取数据造成系统软件版本造成JS语言兼容造成内存不足造成 （若文中图片无法显示，请科学上网查看：推荐工具） Android端白屏问题（APP侧解决方案） 常见的语法造成白屏相关 12使用了es6的语法对低版本未做兼容引入了三方外部插件，外部插件语法存在兼容性问题语法错误造成页面无法渲染 webview加载H5界面时,H5中的一些控件标签可能使用后android中不支持设置如下方式 12// 解决对某些标签的不支持出现白屏webSettings.setDomStorageEnabled(true); 一些机型硬件加速相关问题 12webView.setBackgroundColor(ContextCompat.getColor(this,android.R.color.transparent));webView.setBackgroundResource(R.color.black);//根据需求修改 网络资源获取造成的白屏12这种情况与获取的资源有关系，可以通过loading状态和箭听webviewClient方法进行处理（这次主要调研基于业务的本地化内存造成的白屏） 内存相关造成白屏 内存导致的白屏或者其他异常问题，有时白屏显示，有时界面渲染失败等奇怪现象，但是内存白屏是最不好处理，又需要给用户友好体验的问题。 webview自身内存问题：本身webview自身比较重，切存在activity或fragment里就牵涉到声明周期和创建的问题，和声明周期里回收问题，一般解决方法在声明周期销毁时先destory在设置null 。先加载null内容的过程需要实际代码验证。 1234567if (mWebView != null) &#123; mWebView.loadDataWithBaseURL(null, &quot;&quot;, &quot;text/html&quot;, &quot;utf-8&quot;, null); mWebView.clearHistory(); mLayout.removeView(mWebView); mWebView.destroy(); mWebView = null; &#125; 独立进程的方式，一般不采用涉及跨进程数据通信，加大维护难度 加载内容内存问题造成的白屏：可以从以下几个思路进行解决 123监控webview的渲染进程状态监测H5页面白屏页面监测webview里的内存 1. 监控WebView渲染进程（适合项目应用） webView的内存从4.4变为基于Google的Chromium的实现 Chromium的架构可以看到（Android 8.0默认打开多进程），Render Process 是单独的进程通过IPC来交互数据，GPU Process仍然为Browser Process的一个线程 12We use separate processes for browser tabs to protect the overall application from bugs and glitches in the rendering engine. We also restrict access from each rendering engine process to others and to the rest of the system. In some ways, this brings to web browsing the benefits that memory protection and access control brought to operating systems.We refer to the main process that runs the UI and manages tab and plugin processes as the &quot;browser process&quot; or &quot;browser.&quot; Likewise, the tab-specific processes are called &quot;render processes&quot; or &quot;renderers.&quot; The renderers use the Blink open-source layout engine for interpreting and laying out HTML. 官网架构里解释了相关多进程的目的，browser是单独的进程，确保渲染在出现故障的时候可以不影响browser的进程显示。 我们相关的白屏的出现除了之前的因素和语法问题之前，就是渲染进程出现了问题。因为我们白屏主要出现在渲染进程，那就可以通过渲染进程查找出问题时相关的状态信息，问题就转化为我们如何知道Render Process的相关状态和监控 关于Render进程可以在文档里查到关于webview的Termination Handling ，通过该方法检测到渲染进程, 通过实现client里的onRenderProcessGone方法。 原理和实现： 12345当检测到渲染进程被页面大内存消耗导致被杀或者异常终止时，移除当前webview实例并消耗，否则新渲染进程会失效通过新的实例加载出新的执行逻辑，可以reload页面或者其他业务逻辑, （而browser进程不死用户无感知）防止当前reload页面如有大内存死循环，可能直接会被系统kill（要考虑到系统版本限制问题，并适用于X5WebView） 代码demo可以联系我,目前暂时未放gitlab上 2. 监控WebView页面白屏（适合数据采集） 内存问题是造成白屏的重要一部分，还有就是其他莫名奇妙问题造成的页面白屏（这种白屏可能不是内存，js语法、网络加载等造成白屏） 如果能够在APP端检测到白屏页面出现，采取相应的提示或者reload ,也是很好解决疑难杂症的白屏方案 技术点实现：123对WebView在调用完成后进行截图遍历截图的像素点的颜色值设定白色像素点比例确认是否白屏 3. 监测webview里的内存 目前关于如何监测webView里的内存占用情况，在原生端上还没有更好的思路去处理，需要进一步调研 在项目里的实现，可以优先使用前2中方案。 Ios端WKWebView白屏 相对Android上的白屏，ios白屏的出现在app端上大部分为内存占用产生，其他网络、资源、js语言兼容、中文字样ulr等同样也会发生白屏，这类问题需要针对分析。关于内存原因造成的白屏问题可以从下边思路着手解决。 内存白屏产生的原因：WKWebView 是运行在一个独立进程中的组件，当 WKWebView 上占用内存过大时，WKWebView 所在的 WebContent Process 会被系统 kill 掉，反映在用户体验上就是发生了白屏。 1. ios系统方案 （原理同Android上的RendProcess） WKNavigationDelegate的回调方法webViewWebContentProcessDidTerminate 里直接进行reload 检测 webView.title 是否为空 12 尝试在每次请求kWebview前清理缓存 webview reload 2.白屏像素检测（非内存引起的，适合数据采集或必要reload） 原理：类似于android的白屏检测，通过截图检测像素点，来判断是否白屏 123通过获取截图截图进行缩放像素点进行遍历色值判断比例 检测时机 : 在loadurl之后 接收到didcommit 或 didfinish回调中进行判断, 另外需在业务项目里核算性能开销 3.疑难问题白屏 渲染异常: 这种白屏问题可以通过检查层级定位相关问题 https://github.com/Flipboard/FLEX，使用flex查看白屏层级，查看异常时view层级（ APP测） 资源遇错: H5里进行监测的方式，当出现加载H5资源错误的时候，wkwebview的渲染异常，就根据加载出错重新reload (H5内部监控) Reload处理白屏 在APP端上除去相关页面元素，加载错误、兼容性，语法错误造成白屏，以上相关方案可以启到检测并尝试重试刷新页面，达到用户无感知，避免白屏的出现和出现白屏瞬间进行切换或者刷新。 reload可以做到解决一部分问题，但同时需要关注reload带来的异常问题和解决内存泄露的根本问题 1234页面上大内存出现后，短时间内存回收不及时，造成reload后问题依然存在。reload前需要释放必要的内存资源，否则可能持续内存占用reload不能解决问题。设置reload的最大重试次数，防止页面意外进入死循环调试解决耗内存的原因，从根源上进行优化处理","path":"posts/40855.html","date":"12-30","excerpt":"","tags":[{"name":"App","slug":"App","permalink":"https://zhulg.github.io/tags/App/"}]},{"title":"Medium文章免费阅读方法","text":"medium上一些不错的技术文章会长付费阅读，技术文章在未商业化前应该是平等获取及阅读的。 1Not every story on Medium is free, like this one. Become a member to get unlimited access and support the voices you want to hear more from. 网上看到有个国外小哥破解教程，记录下. 里面包括教程，已验证目前完全可用。 1https://sugoidesune.github.io/readium/","path":"posts/43467.html","date":"12-17","excerpt":"","tags":[{"name":"Tools","slug":"Tools","permalink":"https://zhulg.github.io/tags/Tools/"}]},{"title":"ScratchJr源代码编译记录","text":"ScratchJr编译 源码下载后可以根据相应的模块进行编译，由于源代码里包含google相关的统计服务，在国内环境下一版不会使用，国内有自己的统计和上报服务。 代码下载：https://github.com/LLK/scratchjr.git 环境搭建 1.需要安装相应的python svg&amp; librsvg&amp; imagemagick， 需要有brew相关环境 123Run sudo easy_install pysvg to install python svg librariesRun brew install librsvg to install commandline rsvg-convertRun brew install imagemagick to install commandline magick 2.由于项目依赖nodejs ，需要安装相应的nodejs并在工程下载后进行 npm install 安装相应模块. 在项目跟目录 1npm install 依赖完成后会存在 node_modules 目录下，（ 如果不进行初始化依赖。后边工程将无法运行 scratchjr/node_modules/webpack/bin/webpack.js’） ios源码编译 进入源码的工程打开ios代码所在的目录, 查看相关Podfile , 由于原工程使用Firebase 需要google相关服务，可以直接拿掉。然后代码里去掉相关代码即可。 1234567platform :ios, &apos;8.0&apos;# add the Firebase pod for Google Analytics#pod &apos;Firebase/Analytics&apos;target &apos;ScratchJr Free&apos; doendtarget &apos;ScratchJrTests&apos; doend 去掉代码里相关的使用的相关地方: 运行相关的工程，在运行务必进行npm install 初始化项目依赖，否则运行可能出现依赖错误导致界面异常。 Android源码编译 进入android的目录打开studio进行编译，相同的直接去掉相关依赖 在build.gradle工程和Module的gradle文件里去掉相关依赖 12classpath &apos;com.google.gms:google-servicesapply plugin: &apos;com.google.gms.google-services&apos; 注释去掉 12processFreeDebugGoogleServices.dependsOn switchToFreeGAprocessFreeReleaseGoogleServices.dependsOn switchToFreeGA 工程出现错误 bundle-compile.sh finished with non-zero exit value 1 (这个是执行文件里所依赖的nodejs没有找到执行路径，需要软引用进行下处理) 1sudo ln -s &quot;$(which node)&quot; /usr/local/bin/node","path":"posts/32936.html","date":"12-14","excerpt":"","tags":[{"name":"Scratch","slug":"Scratch","permalink":"https://zhulg.github.io/tags/Scratch/"}]},{"title":"Scratch项目和原理","text":"项目构成 Scratch-gui项目是其官方的开源scratch 3.0的编程网站代码，在上次记录里已经进行了初步编译构建，从其中的配置信息里可以看到相关的依赖库。 12345678910111213141516&quot;redux&quot;: &quot;3.7.2&quot;,&quot;redux-throttle&quot;: &quot;0.1.1&quot;,&quot;scratch-audio&quot;: &quot;0.1.0-prerelease.20200528195344&quot;,&quot;scratch-blocks&quot;: &quot;0.1.0-prerelease.20201205050032&quot;,&quot;scratch-l10n&quot;: &quot;3.10.20201206031447&quot;,&quot;scratch-storage&quot;: &quot;1.3.3&quot;,&quot;scratch-vm&quot;: &quot;0.2.0-prerelease.20201125065300&quot;,&quot;scratch-paint&quot;: &quot;0.2.0-prerelease.20201020103914&quot;,&quot;scratch-render&quot;: &quot;0.1.0-prerelease.20201113223804&quot;,&quot;scratch-svg-renderer&quot;: &quot;0.2.0-prerelease.20201019174008&quot;,&quot;startaudiocontext&quot;: &quot;1.2.1&quot;,&quot;style-loader&quot;: &quot;^0.23.0&quot;,&quot;text-encoding&quot;: &quot;0.7.0&quot;,&quot;to-style&quot;: &quot;1.3.3&quot;,&quot;wav-encoder&quot;: &quot;1.3.0&quot;,&quot;xhr&quot;: &quot;2.5.0&quot; 主要依赖库介绍 这些模块也都在Scratch的项目组代码里 12345678scratch-vm：虚拟机，管理状态并执行业务逻辑scratch-blocks：代码积木块模块scratch-l10n：国际化scratch-paint：绘图拓展scratch-render：舞台渲染，在舞台区域出现的基于WebGL的处理器scratch-storage：作品存储加载scratch-svg-renderer：svg的处理scratch-audio：使用的声音拓展 运行原理 用scratch-blocks生成语句块—&gt; 用scratch-vm 虚拟机抽象成底层语法—-&gt;调用scratch-render 和scratch-paint渲染到界面 ####运行模块的介绍： Scratch-blocks: Scratch Blocks是Google Blockly项目的一个分支，该项目提供了用于构建创意计算接口的设计规范和代码库。此代码库与Scratch虚拟机（VM）一起，可以快速设计和开发可视化编程接口。与Blockly不同，Scratch Blocks不使用代码生成器，而是利用Scratch虚拟机创建高度动态的交互式编程环境(官方翻译) 123scratch-blocks是scratch-gui依赖的一个基本模块。它的作用是生成gui界面上的blocks。blocks的作用是通过拖曳的方法组成blocks堆块scratch-gui的blocks的生成文件在scratch-blocks\\blocks_vertical里一个块的定义，对应这背后的js函数 比如一个右转多少度的块的定义: 12345678910111213141516171819202122232425Blockly.Blocks[&apos;motion_turnright&apos;] = &#123; /** * Block to turn right. * @this Blockly.Block */ init: function() &#123; this.jsonInit(&#123; &quot;message0&quot;: “右转 %1 %2 度”, &quot;args0&quot;: [ &#123; &quot;type&quot;: &quot;field_image&quot;, &quot;src&quot;: Blockly.mainWorkspace.options.pathToMedia + &quot;rotate-right.svg&quot;, &quot;width&quot;: 24, &quot;height&quot;: 24 &#125;, &#123; &quot;type&quot;: &quot;input_value&quot;, &quot;name&quot;: &quot;DEGREES&quot; &#125; ], &quot;category&quot;: Blockly.Categories.motion,//块归属的类，这里是运动类。 &quot;extensions&quot;: [&quot;colours_motion&quot;, &quot;shape_statement&quot;] &#125;); &#125;&#125;; scratch-vm: 12虚拟机屏蔽底层硬件差异和dom渲染差异 , 使得程序可以跨端移植react本质上也是虚拟机,虚拟dom屏蔽设备渲染差异( dom只有pc浏览器能识别 , 但虚拟dom是js对象 , 因而在手机上能解析成viewPort),native屏蔽底层硬件差异 ,使得程序可以在Android和ios都可以运行 编译和启动: 123git clone https://github.com/LLK/scratch-vm.gitcd scratch-vmnpm install npm start后访问 http://localhost:8073/playground/ sb2/sb3文件: 1Scratch VM能解析的文件类型，sb2为Scratch2.0项目文件，sb3为Scratch3.0项目文件 参考 https://github.com/LLK/scratch-gui/wiki/Getting-Started","path":"posts/36765.html","date":"12-09","excerpt":"","tags":[{"name":"Scratch","slug":"Scratch","permalink":"https://zhulg.github.io/tags/Scratch/"}]},{"title":"Scratch源码及相关介绍","text":"国内图形化编程的应用，大部分都是基于scratch源码来实现的二次开发，主要介绍scratch的源码和模块 关于Scratch Scratch是麻省理工学院的“终身幼儿园团队”（Lifelong Kindergarten Group）开发的图形化编程工具，主要面对青少年开放。 目前已有原始版本（1.4版本）、2.0版本（增加克隆积木，Lego和Makey makey拓展积木）、3.0版本（增加音乐、画笔、视频侦测、文字朗读、翻译等选择性下载扩展积木，并增加micro：bit和Lego mindstorms EV3拓展积木）所有人可以在任意版本中创作自己的程序 Scratch相关源码 全项目分组: https://github.com/LLK Scratch-www : https://github.com/LLK/scratch-www Scratch-www是Scratch社区的独立Web客户端，使用React和Redux构建。 ScratchJr: ScratchJr是一种入门编程语言，可让幼儿（5-7岁）创建自己的互动故事和游戏。 1https://github.com/LLK/scratchjr scratch-gui: 用于创建和运行Scratch 3.0项目的图形用户界面。 Scratch Blocks: Scratch Blocks是下一代图形编程模块的新开发项目，基于Google与麻省理工学院Scratch团队的合作 - 以Google的Blockly技术为基础，并以Scratch团队为年轻人开发创意学习工具的专业知识为基础。 Scratch Blocks将提供一个框架，用于构建垂直（基于文本）和水平（基于图标）格式的编程块。 scratch-render: 用于Scratch 3.0的基于WebGL的渲染引擎。 环境搭建Scratch-gui项目搭建： 目前基于Scratch 3 ，通过H5的方式来来实现的，所以编程拖拽部分的模块是通过H5来实现的，目前scratch包括了PC,和移动端相关的实现，移动端上通过ScratchJr的作为平台，国内头部的这块也用jr来实现了自己相关的APP 先搭建PC端的scratch-gui项目： 1https://github.com/LLK/scratch-gui.git 到项目目录下进行 npm install （前提相关的node环境已经安装） （若文中图片无法显示，请科学上网查看：推荐工具） 运行项目：npm start 可以看到运行起来项目： scratchjr项目编译： 下载scratchjr 源代码 项目架构介绍 需要相关的环境依赖：需要安装出来SVG相关依赖库和图片合成编辑的命令行工具 12345Ensure you have node and npm installed.Run sudo easy_install pysvg to install python svg librariesRun brew install librsvg to install commandline rsvg-convertRun brew install imagemagick to install commandline magickIn the top level of the scratchjr repo directory, install npm dependencies for bundling the JavaScript: npm install 环境依赖安装成功后，就可以进行源码进行相关编译项目，这过程可能会有相关环境安装失败情况出现（自行查找解决） 根据边的架构可以看到相关代码模块的构成部分，可能运行不起来，需要把google相关的google-services进行移除下。 ios方式打开 打开的方式和依赖于Android相同，需要相关的依赖环境与Android依赖相同，之后通过xcode打开ios/ScratchJr.xcworkspace即可","path":"posts/60112.html","date":"12-07","excerpt":"","tags":[{"name":"Scratch","slug":"Scratch","permalink":"https://zhulg.github.io/tags/Scratch/"}]},{"title":"Android进程间通信总结","text":"Android进程间通用常见方式: 123456 Bundle：四大组件间通信, 通过intent放入Bundle数据 intent.putExtras(bundle)，但是只能单向的而且是常用基本数据。 File：文件共享 ，但是涉及多线程读写问题ContentProvider：应用间数据共享（基于 Binder）AIDL：Binder机制（基于 Binder）Messager：基于AIDL、Handler实现 （基于 Binder）Socket：建立C/S通信模型 这里面有个类Binder， 他是AIDL、Messager的基础，是实现跨进程通信的核心 Binder常见的使用地方 binder用在绑定服务的地方，从官网的文档里可以看到，常用的3个方式。https://developer.android.com/guide/components/bound-services#Binder 本应用内与service交互获取数据：过扩展 Binder 类并从 onBind() 返回该类的实例来创建接口。收到 Binder 后，客户端可利用其直接访问 Binder 实现或 Service 中可用的公共方法。 跨进程的交互使用Messenger（底层只是对Binder的简单包装），使用 Messenger 为服务提供接口。借助此方法，您无需使用 AIDL 便可执行进程间通信 (IPC)，封装的单线程AIDL。 跨进程AIDL：Messenger 会在单个线程中创建包含所有客户端请求的队列，以便服务一次接收一个请求。不过，如果想让服务同时处理多个请求，则可直接使用 AIDL 同一进程内与service使用 ，且无需跨进程工作 Binder使用 则您可以实现自有 Binder 类，让客户端通过该类直接访问服务中的公共方法。 service里，实现onBind方法，通过IBinder，提供客户端进行访问的实例，客户端通过IBinder ,拿到service的实例，即能拿到service的相关方法访问 1234567891011121314151617public class MyService extends Service &#123; private final Binder mBinder = new MyBinder(); private final Random mGenerator = new Random(); @Nullable @Override public IBinder onBind(Intent intent) &#123; return mBinder; &#125; public class MyBinder extends Binder &#123; public MyService getService() &#123; return MyService.this; &#125; &#125; public int getNextNumber() &#123; return mGenerator.nextInt(100); &#125;&#125; 使用者的代码： 通过bindService后在connection里获取到 IBinder ，通过Binder那到services，继而访问对应的方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class MainActivity extends AppCompatActivity &#123; private MyService mService; private boolean binded = false; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); &#125; @Override protected void onStart() &#123; super.onStart(); Intent intent = new Intent(this, MyService.class); bindService(intent, connection, Context.BIND_AUTO_CREATE); &#125; ServiceConnection connection = new ServiceConnection() &#123; @Override public void onServiceConnected(ComponentName name, IBinder service) &#123; MyService.MyBinder binder = (MyService.MyBinder) service; mService = binder.getService(); binded = true; &#125; @Override public void onServiceDisconnected(ComponentName name) &#123; binded = false; &#125; &#125;; @Override protected void onStop() &#123; super.onStop(); unbindService(connection); &#125; public void myButton(View view) &#123; if (binded) &#123; int data = mService.getNextNumber(); Toast.makeText(this, data+&quot;&quot;, Toast.LENGTH_SHORT).show(); &#125; &#125;&#125; AIDL的使用（底层使用Binder）跨进程通信方式 创建AIDL文件，使用studio在src目录创建后，rebuild工程后，会在gen目录下生产IBinder 接口文件，生成文件的名称与 .aidl 文件的名称保持一致，区别在于其使用 .java 扩展名（IRemoteService.aidl 生成的文件名是 IRemoteService.java） 12345678interface IRemoteService &#123; /** * Demonstrates some basic types that you can use as parameters * and return values in AIDL. */ void basicTypes(int anInt, long aLong, boolean aBoolean, float aFloat, double aDouble, String aString);&#125; Android SDK 工具会生成以 .aidl 文件命名的 .java 接口文件。生成的接口包含一个名为 Stub 的子类（例如，YourInterface.Stub），该子类是其父接口的抽象实现，并且会声明 .aidl 文件中的所有方法。 暴露在使用的services里进行实现 IRemoteService.Stub()，供客户端进行使用 12345678910111213141516171819202122public class RemoteService extends Service &#123; @Override public void onCreate() &#123; super.onCreate(); &#125; @Override public IBinder onBind(Intent intent) &#123; // Return the interface return binder; &#125; private final IRemoteService.Stub binder = new IRemoteService.Stub() &#123; public int getPid()&#123; return Process.myPid(); &#125; public void basicTypes(int anInt, long aLong, boolean aBoolean, float aFloat, double aDouble, String aString) &#123; // Does nothing &#125; &#125;;&#125; 当客户端（如 Activity）调用 bindService() 以连接此服务时，客户端的 onServiceConnected() 回调会接收服务的 onBind() 方法所返回的 binder 实例。 当客户端在 onServiceConnected() 回调中收到 IBinder 时，它必须调用 YourServiceInterface.Stub.asInterface(service)，以将返回的参数转换成 YourServiceInterface 类型。 123456789101112131415IRemoteService iRemoteService;private ServiceConnection mConnection = new ServiceConnection() &#123; // Called when the connection with the service is established public void onServiceConnected(ComponentName className, IBinder service) &#123; // Following the example above for an AIDL interface, // this gets an instance of the IRemoteInterface, which we can use to call on the service iRemoteService = IRemoteService.Stub.asInterface(service); &#125; // Called when the connection with the service disconnects unexpectedly public void onServiceDisconnected(ComponentName className) &#123; Log.e(TAG, &quot;Service has unexpectedly disconnected&quot;); iRemoteService = null; &#125;&#125;; AIDL传递对象时需要注意，跨进程通过bundle传递对象时，如果bundle中存放了parcelable对象需要手动设置setClassLoader，因为默认情况下bundle传输使用的ClassLoader是BootClassLoader，而BootClassLoader只能加载系统类，我们本工程的class需要使用PathClassLoader进行加载，因此需要额外的调用bundle的setClassLoader方法设置类加载器 1234567private final IRectInsideBundle.Stub binder = new IRectInsideBundle.Stub() &#123; public void saveRect(Bundle bundle)&#123; bundle.setClassLoader(getClass().getClassLoader()); Rect rect = bundle.getParcelable(&quot;rect&quot;); process(rect); // Do more with the parcelable. &#125;&#125;; 如要调用通过 AIDL 定义的远程接口，调用类必须执行以下步骤： 12345671. 在项目的 src/ 目录中加入 .aidl 文件。2. 声明一个 IBinder 接口实例（基于 AIDL 生成)，一般在RemoteService里实现3. 实现 ServiceConnection。4. 调用 Context.bindService()，从而传入您的 ServiceConnection 实现。（客户端使用）5. 在 onServiceConnected() 实现中，您将收到一个 IBinder 实例（名为 service）。调用 YourInterfaceName.Stub.asInterface((IBinder)service)，以将返回的参数转换为 YourInterface 类型。6. 调用您在接口上定义的方法。您应始终捕获 DeadObjectException 异常，系统会在连接中断时抛出此异常。您还应捕获 SecurityException 异常，当 IPC 方法调用中两个进程的 AIDL 定义发生冲突时，系统会抛出此异常。7. 如要断开连接，请使用您的接口实例调用 Context.unbindService()。 使用 Messenger 让服务与远程进程通信，则可使用 Messenger 为您的服务提供接口。借助此方法，您无需使用 AIDL 便可执行进程间通信 (IPC)。（官方摘录） 对于大多数应用，服务无需执行多线程处理，因此使用 Messenger 即可让服务一次处理一个调用。如果您的服务必须执行多线程处理，请使用 AIDL 来定义接口。 相对AIDL来说，Messenger的使用是很简单了，省去中间很多繁琐的操作，对AIDL进行了封装，也就是对 Binder 的封装 使用步骤： 123456服务实现一个 Handler，由该类为每个客户端调用接收回调。服务使用 Handler 来创建 Messenger 对象（对 Handler 的引用）。Messenger 创建一个 IBinder，服务通过 onBind() 使其返回客户端。客户端使用 IBinder 将 Messenger（其引用服务的 Handler）实例化，然后使用后者将 Message 对象发送给服务。服务在其 Handler 中（具体地讲，是在 handleMessage() 方法中）接收每个 Message。这样，客户端便没有方法来调用服务。相反，客户端会传递服务在其 Handler 中接收的消息（Message 对象）。 例子 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class MessengerService extends Service &#123; /** * Command to the service to display a message */ static final int MSG_SAY_HELLO = 1; /** * Handler of incoming messages from clients. */ static class IncomingHandler extends Handler &#123; private Context applicationContext; IncomingHandler(Context context) &#123; applicationContext = context.getApplicationContext(); &#125; @Override public void handleMessage(Message msg) &#123; switch (msg.what) &#123; case MSG_SAY_HELLO: Toast.makeText(applicationContext, &quot;hello!&quot;, Toast.LENGTH_SHORT).show(); break; default: super.handleMessage(msg); &#125; &#125; &#125; /** * Target we publish for clients to send messages to IncomingHandler. */ Messenger mMessenger; /** * When binding to the service, we return an interface to our messenger * for sending messages to the service. */ @Override public IBinder onBind(Intent intent) &#123; Toast.makeText(getApplicationContext(), &quot;binding&quot;, Toast.LENGTH_SHORT).show(); mMessenger = new Messenger(new IncomingHandler(this)); return mMessenger.getBinder(); &#125;&#125; 客户端只需根据服务返回的 IBinder 创建 Messenger，然后利用 send() 发送消息。例如，以下简单 Activity 展示如何绑定到服务并向服务传递 MSG_SAY_HELLO 消息： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class ActivityMessenger extends Activity &#123; /** Messenger for communicating with the service. */ Messenger mService = null; /** Flag indicating whether we have called bind on the service. */ boolean bound; /** * Class for interacting with the main interface of the service. */ private ServiceConnection mConnection = new ServiceConnection() &#123; public void onServiceConnected(ComponentName className, IBinder service) &#123; // This is called when the connection with the service has been // established, giving us the object we can use to // interact with the service. We are communicating with the // service using a Messenger, so here we get a client-side // representation of that from the raw IBinder object. mService = new Messenger(service); bound = true; &#125; public void onServiceDisconnected(ComponentName className) &#123; // This is called when the connection with the service has been // unexpectedly disconnected -- that is, its process crashed. mService = null; bound = false; &#125; &#125;; public void sayHello(View v) &#123; if (!bound) return; // Create and send a message to the service, using a supported &apos;what&apos; value Message msg = Message.obtain(null, MessengerService.MSG_SAY_HELLO, 0, 0); try &#123; mService.send(msg); &#125; catch (RemoteException e) &#123; e.printStackTrace(); &#125; &#125; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.main); &#125; @Override protected void onStart() &#123; super.onStart(); // Bind to the service bindService(new Intent(this, MessengerService.class), mConnection, Context.BIND_AUTO_CREATE); &#125; @Override protected void onStop() &#123; super.onStop(); // Unbind from the service if (bound) &#123; unbindService(mConnection); bound = false; &#125; &#125;&#125; 服务端如果需要通过接收到消息，在给客户端恢复，可利用message里的 replyTo 引用，保存Messenger对象，通过改对象的send到达回复消息。 Messenger的源码可以看到，通过构造时传入的Handler , 通过target.getIMessenger() ，可以看到MessengerImpl的接口定义是AIDL的实现，底层也是AIDL，而AIDL的底层又是通过Binder 123public Messenger(Handler target) &#123; mTarget = target.getIMessenger();&#125; 1234567891011121314151617@UnsupportedAppUsagefinal IMessenger getIMessenger() &#123; synchronized (mQueue) &#123; if (mMessenger != null) &#123; return mMessenger; &#125; mMessenger = new MessengerImpl(); return mMessenger; &#125;&#125;private final class MessengerImpl extends IMessenger.Stub &#123; public void send(Message msg) &#123; msg.sendingUid = Binder.getCallingUid(); Handler.this.sendMessage(msg); &#125;&#125; Binder Binder 是一种进程间通信机制，基于开源的 OpenBinder实现 Binder是Android提供的一套进程间通信框架。系统服务ActivityManagerService,LocationManagerService，等都是在单独进程中的，使用binder和应用进行通信。 因为整个Android系统分成三层。最上层是application应用层，第二层是Framework层，第三层是native层。 12Android中的应用层和系统服务层不在同一个进程，系统服务在单独的进程中。Android中不同应用属于不同的进程中。 Android应用和系统services运行在不同进程中是为了安全，稳定，以及内存管理的原因，但是应用和系统服务需要通信和分享数据。这里面靠的就是Binder机制。一个进程是不能直接直接操作另一个进程的，比如说读取另一个进程的数据，或者往另一个进程的内存空间写数据，进程之间的通信要通过内核进程才可以。 IPC全名为inter-Process Communication，含义为进程间通信, Binder是android实现的进程间通信的一种方式。 Linux和Binder的各自的IPC通信原理 几个主要概念： 1，内核空间和用户空间： 1User space（用户空间）和 Kernel space（内核空间）。内核空间是Linux内核的运行空间，用户空间是用户程序的运行空间。为了保护用户进程不能直接操作内核，保证内核的安全，操作系统从逻辑上将虚拟空间划分为用户空间和内核空间。Linux 操作系统将最高的1GB字节供内核使用，称为内核空间，较低的3GB 字节供各进程使用，称为用户空间。（32位操作系统） 2的32次方, 除以3个1024得到4G，（https://www.pianshen.com/article/19121897068/），一个地址就是内存中最小存储单位一个字节，估为4G。 2，系统调用: 12345用户空间需要访问内核空间，就需要借助系统调用来实现。系统调用是用户空间访问内核空间的唯一方式，保证了所有的资源访问都是在内核的控制下进行的，避免了用户程序对系统资源的越权访问，提升了系统安全性和稳定性。 进程A和进程B的用户空间可以通过如下系统函数和内核空间进行交互。copy_from_user：将用户空间的数据拷贝到内核空间。copy_to_user：将内核空间的数据拷贝到用户空间。 3，内存映射: 123 由于应用程序不能直接操作设备硬件地址，所以操作系统提供了一种机制：内存映射，把设备地址映射到进程虚拟内存区。 举个例子，如果用户空间需要读取磁盘的文件，如果不采用内存映射，那么就需要在内核空间建立一个页缓存，页缓存去拷贝磁盘上的文件，然后用户空间拷贝页缓存的文件，这就需要两次拷贝。由于新建了虚拟内存区域，那么磁盘文件和虚拟内存区域就可以直接映射，少了一次拷贝。内存映射全名为Memory Map，在Linux中通过系统调用函数mmap来实现内存映射。将用户空间的一块内存区域映射到内核空间。映射关系建立后，用户对这块内存区域的修改可以直接反应到内核空间，反之亦然。内存映射能减少数据拷贝次数，实现用户空间和内核空间的高效互动 Linux的IPC通信原理 内核程序在内核空间分配内存并开辟一块内核缓存区，发送进程通过copy_from_user函数将数据拷贝到到内核空间的缓冲区中。同样的，接收进程在接收数据时在自己的用户空间开辟一块内存缓存区，然后内核程序调用 copy_to_user() 函数将数据从内核缓存区拷贝到接收进程。这样数据发送进程和数据接收进程完成了一次数据传输，也就是一次进程间通信。 Linux的IPC通信原理有两个问题： 12一次数据传递需要经历：用户空间 --&gt; 内核缓存区 --&gt; 用户空间，需要2次数据拷贝，这样效率不高。接收数据的缓存区由数据接收进程提供，但是接收进程并不知道需要多大的空间来存放将要传递过来的数据，因此只能开辟尽可能大的内存空间或者先调用API接收消息头来获取消息体的大小，浪费了空间或者时间。 2.2 Binder的通信原理 Binder是基于内存映射来实现的,Binder通信的步骤如下: 1234Binder驱动在内核空间创建一个数据接收缓存区。在内核空间开辟一块内核缓存区，建立内核缓存区和数据接收缓存区之间的映射关系，以及数据接收缓存区和接收进程用户空间地址的映射关系。发送方进程通过copy_from_user()函数将数据拷贝 到内核中的内核缓存区，由于内核缓存区和接收进程的用户空间存在内存映射，因此也就相当于把数据发送到了接收进程的用户空间，这样便完成了一次进程间的通信。 整个过程只使用了1次拷贝，不会因为不知道数据的大小而浪费空间或者时间，效率更高。 一次完整的 Binder IPC 通信过程通常是这样：（如上图） 123首先 Binder 驱动在内核空间创建一个数据接收缓存区；接着在内核空间开辟一块内核缓存区，建立内核缓存区和内核中数据接收缓存区之间的映射关系，以及内核中数据接收缓存区和接收进程用户空间地址的映射关系；发送方进程通过系统调用 copyfromuser() 将数据 copy 到内核中的内核缓存区，由于内核缓存区和接收进程的用户空间存在内存映射，因此也就相当于把数据发送到了接收进程的用户空间，这样便完成了一次进程间的通信。 Binder机制优点：1231、只需要进行一次数据拷贝，性能上仅次于共享内存2、基于C/S架构，职责明确，架构清晰，稳定性较好3、为每个App分配UID，UID是鉴别进程身份的标志，安全性较好","path":"posts/44524.html","date":"11-12","excerpt":"","tags":[{"name":"Android","slug":"Android","permalink":"https://zhulg.github.io/tags/Android/"}]},{"title":"Android消息机制总结","text":"本文来总结下Android消息机制涉及相关的知识点，handler 、ThreadLocal 、looper、 MessageQueue、Message、对象池使用，掌握消息机制相关知识。 消息机制相关知识点 Android消息机制涉及相关的知识点，handler 、ThreadLocal 、looper、 MessageQueue、Message、对象池使用Handler handler在Android里常用在子线程的数据抛给主线程使用，常见操作更新UI。但是它也能实现任意两个线程的数据传递。 在子线程上创建Handler时需要Looper.prepare()和Looper.loop() , UI线程也是需要的可以从ActivityThread的main里看到，所以默认系统为主线程已经调用过 12345678910111213class MyThread extends Thread &#123; public Handler mHandler; public void run() &#123; Looper.prepare(); mHandler = new Handler() &#123; public void handleMessage(Message msg) &#123; // process incoming messages here &#125; &#125;; Looper.loop(); &#125; 创建Handler为什么需要 Looper.prepare()和Looper.loop() Handle 实例创建的源码 123456789101112public Handler(@Nullable Callback callback, boolean async) &#123; // 核心代码块 mLooper = Looper.myLooper(); if (mLooper == null) &#123; throw new RuntimeException( &quot;Can&apos;t create handler inside thread &quot; + Thread.currentThread() + &quot; that has not called Looper.prepare()&quot;); &#125; mQueue = mLooper.mQueue; mCallback = callback; mAsynchronous = async; &#125; 从代码里看到获取mLooper时会当未空，需要先进行 Looper.prepare() , 查看Looper里的方法 12345678910public static void prepare() &#123; prepare(true);&#125;private static void prepare(boolean quitAllowed) &#123; if (sThreadLocal.get() != null) &#123; throw new RuntimeException(&quot;Only one Looper may be created per thread&quot;); &#125; sThreadLocal.set(new Looper(quitAllowed));&#125; 可以看到prepare的过程会在 Looper里的sThreadLocal创建出来Looper的实例，并进行保存。 1234private Looper(boolean quitAllowed) &#123; mQueue = new MessageQueue(quitAllowed); mThread = Thread.currentThread(); &#125; 创建Looper的时候可以看到引入了MessageQueue， 并在Looper实例里创建了MessageQueue的实例，用于存储Message Looper prepare() 是为了创建出来Looper，并存放在ThreadLocal里，在构建Looper实例时候，也创建出来消息队列MessageQueue。而Looper.loop()则从消息队列里取出来消息，进行执行。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120/** * Run the message queue in this thread. Be sure to call * &#123;@link #quit()&#125; to end the loop. */public static void loop() &#123; final Looper me = myLooper(); if (me == null) &#123; throw new RuntimeException(&quot;No Looper; Looper.prepare() wasn&apos;t called on this thread.&quot;); &#125; final MessageQueue queue = me.mQueue; // Make sure the identity of this thread is that of the local process, // and keep track of what that identity token actually is. Binder.clearCallingIdentity(); final long ident = Binder.clearCallingIdentity(); // Allow overriding a threshold with a system prop. e.g. // adb shell &apos;setprop log.looper.1000.main.slow 1 &amp;&amp; stop &amp;&amp; start&apos; final int thresholdOverride = SystemProperties.getInt(&quot;log.looper.&quot; + Process.myUid() + &quot;.&quot; + Thread.currentThread().getName() + &quot;.slow&quot;, 0); boolean slowDeliveryDetected = false; for (;;) &#123; Message msg = queue.next(); // might block if (msg == null) &#123; // No message indicates that the message queue is quitting. return; &#125; // This must be in a local variable, in case a UI event sets the logger final Printer logging = me.mLogging; if (logging != null) &#123; logging.println(&quot;&gt;&gt;&gt;&gt;&gt; Dispatching to &quot; + msg.target + &quot; &quot; + msg.callback + &quot;: &quot; + msg.what); &#125; // Make sure the observer won&apos;t change while processing a transaction. final Observer observer = sObserver; final long traceTag = me.mTraceTag; long slowDispatchThresholdMs = me.mSlowDispatchThresholdMs; long slowDeliveryThresholdMs = me.mSlowDeliveryThresholdMs; if (thresholdOverride &gt; 0) &#123; slowDispatchThresholdMs = thresholdOverride; slowDeliveryThresholdMs = thresholdOverride; &#125; final boolean logSlowDelivery = (slowDeliveryThresholdMs &gt; 0) &amp;&amp; (msg.when &gt; 0); final boolean logSlowDispatch = (slowDispatchThresholdMs &gt; 0); final boolean needStartTime = logSlowDelivery || logSlowDispatch; final boolean needEndTime = logSlowDispatch; if (traceTag != 0 &amp;&amp; Trace.isTagEnabled(traceTag)) &#123; Trace.traceBegin(traceTag, msg.target.getTraceName(msg)); &#125; final long dispatchStart = needStartTime ? SystemClock.uptimeMillis() : 0; final long dispatchEnd; Object token = null; if (observer != null) &#123; token = observer.messageDispatchStarting(); &#125; long origWorkSource = ThreadLocalWorkSource.setUid(msg.workSourceUid); try &#123; msg.target.dispatchMessage(msg); if (observer != null) &#123; observer.messageDispatched(token, msg); &#125; dispatchEnd = needEndTime ? SystemClock.uptimeMillis() : 0; &#125; catch (Exception exception) &#123; if (observer != null) &#123; observer.dispatchingThrewException(token, msg, exception); &#125; throw exception; &#125; finally &#123; ThreadLocalWorkSource.restore(origWorkSource); if (traceTag != 0) &#123; Trace.traceEnd(traceTag); &#125; &#125; if (logSlowDelivery) &#123; if (slowDeliveryDetected) &#123; if ((dispatchStart - msg.when) &lt;= 10) &#123; Slog.w(TAG, &quot;Drained&quot;); slowDeliveryDetected = false; &#125; &#125; else &#123; if (showSlowLog(slowDeliveryThresholdMs, msg.when, dispatchStart, &quot;delivery&quot;, msg)) &#123; // Once we write a slow delivery log, suppress until the queue drains. slowDeliveryDetected = true; &#125; &#125; &#125; if (logSlowDispatch) &#123; showSlowLog(slowDispatchThresholdMs, dispatchStart, dispatchEnd, &quot;dispatch&quot;, msg); &#125; if (logging != null) &#123; logging.println(&quot;&lt;&lt;&lt;&lt;&lt; Finished to &quot; + msg.target + &quot; &quot; + msg.callback); &#125; // Make sure that during the course of dispatching the // identity of the thread wasn&apos;t corrupted. final long newIdent = Binder.clearCallingIdentity(); if (ident != newIdent) &#123; Log.wtf(TAG, &quot;Thread identity changed from 0x&quot; + Long.toHexString(ident) + &quot; to 0x&quot; + Long.toHexString(newIdent) + &quot; while dispatching to &quot; + msg.target.getClass().getName() + &quot; &quot; + msg.callback + &quot; what=&quot; + msg.what); &#125; msg.recycleUnchecked(); &#125;&#125; Message在MessageQueue的存储是通过Message.next 来存放的，类似单链表的存储结构。在取出的时候通过 MessageQueue.next()方法取出某个message, message之间也是通过next属性，形成链表存储在MessageQueue里。 消息机制总结 Handler可以在主线程创建也可以在子线程创建，主线程创建时已在系统启动时（ActivityThread的main方法里），调用过Looper.prepare和Loop，所以创建完直接使用。但是子线程创建Handler需要先prepare()，创建出来Looper对象，以及消息队列，之后进行Loop()运行起来，从消息队列死循环取消息出来，并进行分发出去进行执行，即到handler里进行dispatchMessage 一个线程可以有多个handler，但是只能有一个Looper和一个MessageQueue， 每个线程对应一个Looper，每个线程的Looper通过ThreadLocal来存储保证，Looper对象的内部又维护有唯一的一个MessageQueue Handler提供创建消息的方法obtainMessage和 sendMessage的方法，通过Handler持有的mQueue（消息队列引用），放入消息到队列（MessageQueue）。 mQueue = mLooper.mQueue; Handler的消息发生 Handler的obtainMessage方法通过对象复用方式，减少对象的创建, 1234567891011121314151617/** * Return a new Message instance from the global pool. Allows us to * avoid allocating new objects in many cases. */public static Message obtain() &#123; synchronized (sPoolSync) &#123; if (sPool != null) &#123; Message m = sPool; sPool = m.next; m.next = null; m.flags = 0; // clear in-use flag sPoolSize--; return m; &#125; &#125; return new Message();&#125; 在Message中有一个static Message变量sPool，这个变量是用于缓存Message对象的, 当sPool不为空就取出, 相应个数减一，并通过next 设定下一个对象，重新赋值到sPool sPool中缓存的Message是哪里来回收来的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * Return a Message instance to the global pool. * &lt;p&gt; * You MUST NOT touch the Message after calling this function because it has * effectively been freed. It is an error to recycle a message that is currently * enqueued or that is in the process of being delivered to a Handler. * &lt;/p&gt; */ public void recycle() &#123; if (isInUse()) &#123; if (gCheckRecycle) &#123; throw new IllegalStateException(&quot;This message cannot be recycled because it &quot; + &quot;is still in use.&quot;); &#125; return; &#125; recycleUnchecked(); &#125; /** * Recycles a Message that may be in-use. * Used internally by the MessageQueue and Looper when disposing of queued Messages. */ @UnsupportedAppUsage void recycleUnchecked() &#123; // Mark the message as in use while it remains in the recycled object pool. // Clear out all other details. flags = FLAG_IN_USE; what = 0; arg1 = 0; arg2 = 0; obj = null; replyTo = null; sendingUid = UID_NONE; workSourceUid = UID_NONE; when = 0; target = null; callback = null; data = null; synchronized (sPoolSync) &#123; if (sPoolSize &lt; MAX_POOL_SIZE) &#123; next = sPool; sPool = this; sPoolSize++; &#125; &#125; &#125; 使用obtain获取Message对象是因为Message内部维护了一个数据缓存池，回收的Message不会被立马销毁，而是放入了缓存池，在获取Message时会先从缓存池中去获取，缓存池为null才会去创建新的Message。 HandlerThread Handler可以在主线程上创建也可以在子线程上创建，HandlerThread 继承自Thread ,本质是一个Thread , 在run方法里创建了Looper和MessageQueue对象，并开启了Looper轮询消息。 通过获取HandlerThread的looper对象传递给主线程的Handler对象（构造handler时传入），然后在handleMessage()方法中执行异步任务。Handler虽然是在住线程创建，但是它的handleMessage接收到消息是在HandlerThread线程，达到收到消息，执行异步任务的操作。与以往常用handleMessage里主线程操作不同，因为传入的looper是HandlerThread里构造的，是一个子线程。 HandlerThread相当于在子线程上创建的Handler，android做了层封装为提供了现成的使用。可以在handleMessage里处理异步任务 模板用法： 123456789101112131415161718//步骤1：创建HandlerThread的实例对象=已经创建了一个新线程//参数=线程名字，作用是标记该线程HandlerThread mHandlerThread = new HandlerThread(&quot;handlerThread&quot;);//步骤2：启动线程mHandlerThread.start();//步骤3：创建工作线程Handler，传入 handlerThread.getLooper() , 实现消息处理的操作，并与其他线程进行通信Handler mHandler = new Handler( handlerThread.getLooper() ) &#123; @Override public boolean handleMessage(Message msg) &#123; //运行HandlerThread子线程，用于实现自己的消息处理 return true; &#125; &#125;);//步骤4：结束线程，即停止线程的消息循环mHandlerThread.quit(); 使用场景： 存在多个耗时的任务需要放到开启子线程依次去处理（串行处理任务） HandlerThread是一个子线程，适合处理耗时的任务，其次，Handler分发消息是通过MessageQueue顶部的Message不断的通过Message的next依次取出Message，符合任务的按顺序串行处理的要求，所以使用HandlerThread就能完美的解决","path":"posts/4547.html","date":"11-09","excerpt":"","tags":[{"name":"Android","slug":"Android","permalink":"https://zhulg.github.io/tags/Android/"}]},{"title":"Android等保评测处理","text":"等保评测常见问题处理，处理等保类相关风险，加固是最好的选择，特别是付费专业版。但是有些付费还是比较贵。 从代码层面可通过TracerPid反调试实现防止代码动态调试 防止反调试原理 TracerPid反调试的原理就是检测这个字段是否为0，为0说明没有被调试，不为0说明正在被调试，检测调试器直接退出就可以达到反调试的效果 代码里的处理方式，只需要定时扫描这个文件，判断TracerPid的值就能做到反调试的情况，从而避免动态调试和注入的情况出现。 核心代码 1234567891011121314151617181920212223242526private fun isUnderTraced(): Boolean &#123; val processStatusFilePath = java.lang.String.format(Locale.US, &quot;/proc/%d/status&quot;, Process.myPid()) val procInfoFile = File(processStatusFilePath) try &#123; val b = BufferedReader(FileReader(procInfoFile)) var readLine: String? while (b.readLine().also &#123; readLine = it &#125; != null) &#123; if (readLine?.contains(&quot;TracerPid&quot;)!!) &#123; val arrays = readLine!!.split(&quot;:&quot;.toRegex()).toTypedArray() if (arrays.size == 2) &#123; val tracerPid = arrays[1].trim &#123; it &lt;= &apos; &apos; &#125;.toInt() if (tracerPid != 0) &#123; return true &#125; &#125; &#125; &#125; b.close() &#125; catch (e: Exception) &#123; e.printStackTrace() &#125; return false&#125; 相关so文件处理 有些so文件为系统的，打算等保需要加固，可以通过导出加固方式，也可以通过规避加入，像lib/armeabi-v7a/librsjni.so 文件：lib/armeabi-v7a/libRSSupport.so renderscript这些系统的的可以去除掉进行特殊处理。ß123456packagingOptions &#123; // for renderscript exclude &apos;lib/armeabi-v7a/libRSSupport.so&apos; exclude &apos;lib/armeabi-v7a/librsjni_androidx.so&apos; exclude &apos;lib/armeabi-v7a/librsjni.so&apos;&#125;","path":"posts/65331.html","date":"09-30","excerpt":"","tags":[{"name":"Android","slug":"Android","permalink":"https://zhulg.github.io/tags/Android/"}]},{"title":"JVM思维导图知识点回顾","text":"JVM运行原理图 JVM相关思维导图知识点 说明：思维导图部分来源网上整理，只做个人知识点回顾。","path":"posts/59677.html","date":"09-24","excerpt":"","tags":[{"name":"java","slug":"java","permalink":"https://zhulg.github.io/tags/java/"}]},{"title":"JVM内存分配与回收总结","text":"对象的内存分配主要在堆上分配，主要分配在新生代的 Eden 区上，少数情况下可能直接分配在老年代 堆内存结构通常将堆内存结构按新生代和老年代进行划分，在 JDK 8 之后取消了永久代。 新生代 内部包含 Eden 区域，作为对象初始分配的区域；两个 Survivor，也叫 from、to 区域，用来放置从 Minor GC 中生存下来的对象。 如果Eden内存空间不足，就会发生Minor GC 12Java 应用不断创建对象，优先分配在 Eden 区域，当空间占用达到一定阈值时，触发 Minor GC。没有被引用的对象被回收，仍然存活的对象被复制到 JVM 选择的 Survivor 区域。如下图，数字 1 表示对象的存活年龄计数在下一次 Minor GC 时，另外一个 Survivor 区域会成为 to 区域， Eden 区域存活的对象和 from 区域对象都会被复制到 to 区域，存活的年龄计会被加 1。上述过程会发生很多次，直到有对象年龄计数达到阈值，这些对象会被晋升到老年代。 其中对 Eden 区域再进行划分， Hotspot JVM 还有一个概念叫着 Thread Local Allocation（TLAB），这是 JVM 为每个线程分配的一个私有缓存区域。多线程同时分配内存时，为了避免操作同一地址，可能需要使用加锁机制，进而影响分配速度 老年代 大对象直接进入老年代 123大对象是指需要大量连续内存空间的 Java 对象，如很长的字符串或数据。一个大对象能够存入 Eden 区的概率比较小，发生分配担保的概率比较大，而分配担保需要涉及大量的复制，就会造成效率低下。虚拟机提供了一个 -XX:PretenureSizeThreshold 参数，令大于这个设置值的对象直接在老年代分配 长期存活的对象将进入老年代 12JVM 给每个对象定义了一个对象年龄计数器。当新生代发生一次 Minor GC 后，存活下来的对象年龄 +1，当年龄超过一定值时，就将超过该值的所有对象转移到老年代中去。使用 -XXMaxTenuringThreshold 设置新生代的最大年龄，只要超过该参数的新生代对象都会被转移到老年代中去。 动态对象年龄判定 1如果当前新生代的 Survivor 中，相同年龄所有对象大小的总和大于 Survivor 空间的一半，年龄 &gt;= 该年龄的对象就可以直接进入老年代，无须等到 MaxTenuringThreshold 中要求的年龄。 空间分配担保 1新生代中有大量的对象存活，survivor空间不够，当出现大量对象在MinorGC后仍然存活的情况（最极端的情况就是内存回收后新生代中所有对象都存活），就需要老年代进行分配担保，把Survivor无法容纳的对象直接进入老年代.只要老年代的连续空间大于新生代对象的总大小或者历次晋升的平均大小，就进行Minor GC，否则FullGC。","path":"posts/44013.html","date":"09-15","excerpt":"","tags":[{"name":"java","slug":"java","permalink":"https://zhulg.github.io/tags/java/"}]},{"title":"Java线程池总结","text":"一. 线程池主要解决什么问题12一是避免了处理任务时创建销毁线程开销的代价二是提供资源限制和管理手段，避免了线程数量膨胀导致的过分调度问题，保证了对内核的充分利用 二. ThreadPoolExecutor Java中的线程池核心实现类是ThreadPoolExecutor , 从类图中可以看到相关结构 ThreadPoolExecutor实现的顶层接口是Executor，顶层接口Executor提供了一种思想：将任务提交和任务执行进行解耦。用户无需关注如何创建线程，如何调度线程来执行任务，用户只需提供Runnable对象，将任务的运行逻辑提交到执行器(Executor)中，由Executor框架完成线程的调配和任务的执行部分。 ExecutorService接口增加了一些能力：（1）扩充执行任务的能力，补充可以为一个或一批异步任务生成Future的方法；（2）提供了管控线程池的方法，比如停止线程池的运行。 AbstractExecutorService则是上层的抽象类，将执行任务的流程串联了起来，保证下层的实现只需关注一个执行任务的方法即可。 最下层的实现类ThreadPoolExecutor实现最复杂的运行部分，ThreadPoolExecutor将会一方面维护自身的生命周期，另一方面同时管理线程和任务，使两者良好的结合从而执行并行任务。 2-1. ThreadPoolExecutor是如何运行，如何同时维护线程和执行任务 三 .Executors Executors 目前提供了 5 种不同的线程池创建配置：（待补充） 参考： https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html","path":"posts/8776.html","date":"09-14","excerpt":"","tags":[{"name":"java","slug":"java","permalink":"https://zhulg.github.io/tags/java/"}]},{"title":"Java垃圾收集总结","text":"一，垃圾收集的相关原理 垃圾回收的前提是清楚哪些内存可以被释放 跟进Java里JVM内存结构可以知道，对象的实例都存放在堆上，还有就是方法区的元数据，这2部分内存的分配和回收都是动态的，垃圾收集器所关注的正是这部分内存。 1. 判断对象是否存活可回收 对对象实例的收集主要是两种基本算法 12引用计数法可达性分析法 引用计数法：在对象头维护着一个 counter 计数器，对象被引用一次则计数器 +1；若引用失效则计数器 -1。当计数器为 0 时，就认为该对象无效了。 12引用计数算法的实现简单，判定效率也很高，在大部分情况下它都是一个不错的算法。但是主流的 Java 虚拟机里没有选用引用计数算法来管理内存，主要是因为它很难解决对象之间循环引用的问题。例如：对象 objA 和 objB 都有字段 instance，令 objA.instance = objB 并且 objB.instance = objA，由于它们互相引用着对方，导致它们的引用计数都不为 0，于是引用计数算法无法通知 GC 收集器回收它们 可达性分析法： 所有和 GC Roots 直接或间接关联的对象都是有效对象，和 GC Roots 没有关联的对象就是无效对象。 GC Roots 指虚拟机栈和本地方法栈中正在引用的对象、静态属性引用的对象和常量。即方法运行时，方法中引用的对象；类的静态变量引用的对象；类中常量引用的对象，Native方法中引用的对象 2.回收方法区内存 方法区中存放生命周期较长的类信息、常量、静态变量，每次垃圾收集只有少量的垃圾被清除。方法区中主要清除两种垃圾： 12废弃常量无用的类 判定废弃常量: 只要常量池中的常量不被任何变量或对象引用，那么这些常量就会被清除掉。比如，一个字符串 “bingo” 进入了常量池，但是当前系统没有任何一个 String 对象引用常量池中的 “bingo” 常量，也没有其它地方引用这个字面量，必要的话，”bingo”常量会被清理出常量池。 判定无用的类 , 判定一个类是否是“无用的类”，条件较为苛刻。1234该类的所有对象都已经被清除加载该类的 ClassLoader 已经被回收该类的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。一个类被虚拟机加载进方法区，那么在堆中就会有一个代表该类的对象：java.lang.Class。这个对象在类被加载进方法区时创建，在方法区该类被删除时清除 垃圾收集算法 知道如何判定无效对象、无用类、废弃常量之后，剩余工作就是回收这些垃圾。常见的垃圾收集算法有以下几个： 1.标记清除算法： 算法分为标记和清除两个阶段，首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。 缺点在于，垃圾被回收以后造成了大量不连续的内存碎片。碎片太多可能会导致以后需要分配较大对象时，无法找到连续的足够内存从而频繁触发垃圾收集，降低系统效率。 2. 复制算法：为了解决“标记，清除”算法的问题一种被称为复制的算法出现了，它将内存平均分为两块，每次只使用其中一块，当这一块存满时触发垃圾收集，将还存活的对象复制到另一块内存，然后将这块内存清掉，这样就不会存在内存碎片的问题 缺点：内存缩小为原来的一半，浪费空间。 3.标记整理算法： 复制算法在存活对象较多的时候需要复制的操作也较多，最关键的是只能利用一半的内存，标记整理算法可以解决这个问题，标记整理算法中的标记和标记清除算法一样，要被回收的对象找出来以后让所有存活的对象向一端移动，然后将内存的剩余部分直接清理掉。 4. 分代收集算法： 分代收集算法将内存分为新生代和老年代，新生代又分为：较大的Eden区（占80%）和两块Survivor区(各占10%)，刚刚创建的对象存放在新生代的Eden区。 12新生代: 复制算法 。 (因为新生代对象生存时间比较短，80%都是要回收的对象，采用标记-清除算法则内存空间碎片化严重，采用复制算法可以灵活高效，且便与整理空间。)老年代 : 标记- 清除算法、标记-整理算法（因为老年代的空间比较大，不能采用复制算法，特别占用内存空间，）","path":"posts/80.html","date":"09-04","excerpt":"","tags":[{"name":"java","slug":"java","permalink":"https://zhulg.github.io/tags/java/"}]},{"title":"JVM内存区域划分总结","text":"JVM 内存区域分为下面几个方面,程序计数器、Java虚拟机栈（Java栈）、Java堆、方法区、运行时常量池、本地方法栈。 1.程序计数器 程序计数器会存储当前线程正在执行的Java方法的JVM指令地址（字节码指令地址）。在 JVM规范中，每个线程都有它自己的程序计数器，并且任何时间一个线程都只有一个方法在执行，也就是所谓的当前方法。 程序计数器的作用 12字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制。在多线程情况下，程序计数器记录的是当前线程执行的位置，从而当线程切换回来时，就知道上次线程执行到哪了。 程序计数器的特点 1234是一块较小的内存空间。线程私有，每条线程都有自己的程序计数器。生命周期：随着线程的创建而创建，随着线程的结束而销毁。是唯一一个不会出现OutOfMemoryError的内存区域。 2.Java 虚拟机栈（Java Virtual Machine Stack） Java 虚拟机栈是描述 Java 方法运行过程的内存模型。 早期也叫 Java 栈。每个线程在创建时都会创建一个虚拟机栈，其内部保存一个个的栈帧（Stack Frame），对应着一次次的 Java 方法调用。 栈帧中存储着局部变量表、操作数（operand）栈、动态链接、方法正常退出或者异常退出的定义等 Java 虚拟机栈的特点 123451. 局部变量表随着栈帧的创建而创建，它的大小在编译时确定，创建时只需分配事先规定的大小即可。在方法运行过程中，局部变量表的大小不会发生改变。2. Java 虚拟机栈会出现两种异常：StackOverFlowError 和 OutOfMemoryError。StackOverFlowError 若 Java 虚拟机栈的大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度时，抛出 StackOverFlowError 异常。OutOfMemoryError 若允许动态扩展，那么当线程请求栈时内存用完了，无法再动态扩展时，抛出 OutOfMemoryError 异常。3. Java 虚拟机栈也是线程私有，随着线程创建而创建，随着线程的结束而销毁。 3.本地方法栈 本地方法栈是为 JVM 运行 Native 方法准备的空间，由于很多 Native 方法都是用 C 语言实现的，所以它通常又叫 C 栈。 它与 Java 虚拟机栈实现的功能类似，只不过本地方法栈是描述本地方法运行过程的内存模型。 4.堆（Heap） 堆是用来存放对象的内存空间，几乎所有的对象都存储在堆中。 堆的特点 1234线程共享，整个 Java 虚拟机只有一个堆，所有的线程都访问同一个堆。而程序计数器、Java 虚拟机栈、本地方法栈都是一个线程对应一个。在虚拟机启动时创建。是垃圾回收的主要场所。进一步可分为：新生代、老年代 5.方法区（Method Area） Java 虚拟机规范中定义方法区是堆的一个逻辑部分,这也是所有线程共享的一块内存区域，用于存储所谓的元（Meta）数据，例如类结构信息，以及对应的运行时常量池、字段、方法代码等 6.运行时常量池 常量池是方法区里的一部分, 方法区中存放：类信息、常量、静态变量、即时编译器编译后的代码。常量就存放在运行时常量池中 内存结构图 产生OOM的地方：除了程序计数器之外，都会产生相关的OOM，最主要是在堆上。还有一种是直接内存，也是造成OOM的原因。 直接内存 内存对象分配在JVM中堆以外的内存称为直接内存，这些内存直接受操作系统管理（而不是JVM），这样做的好处是能够在一定程度上减少垃圾回收对应用程序造成的影响。一般我们使用Unsafe和NIO包下ByteBuffer来创建堆外内存 为什么使用堆外内存： 12341、减少了垃圾回收使用堆外内存的话，堆外内存是直接受操作系统管理( 而不是虚拟机 )。这样做的结果就是能保持一个较小的堆内内存，以减少垃圾收集对应用的影响。2、提升复制速度(io效率)堆内内存由JVM管理，属于“用户态”；而堆外内存由OS管理，属于“内核态”。如果从堆内向磁盘写数据时，数据会被先复制到堆外内存，即内核缓冲区，然后再由OS写入磁盘，使用堆外内存避免了这个操作 堆外内存申请(了解) DK的ByteBuffer类提供了一个接口allocateDirect(int capacity)进行堆外内存的申请，底层通过unsafe.allocateMemory(size)实现。Netty、Mina等框架提供的接口也是基于ByteBuffer封装的。 1234567import java.nio.ByteBuffer;public class DirectOom &#123; public static void main(String[] args) &#123; //直接分配128M的直接内存(100M) ByteBuffer bb = ByteBuffer.allocateDirect(128*1024*1204); &#125;&#125; 直接内存（direct memory）不属于JVM运行时数据区的一部分，属于堆外内存，会被频繁使用，因此在设置各个内存范围时要留出一部分物理内存，否则也容易抛出OutOfMemoryError","path":"posts/50924.html","date":"08-31","excerpt":"","tags":[{"name":"java","slug":"java","permalink":"https://zhulg.github.io/tags/java/"}]},{"title":"Java单例模式总结","text":"单例的创建常分为2种类型12懒汉式：使用的时候才创建饿汉式：类加载的视角就创建了实例 懒汉式 常见例子，线程不安全的懒汉式 12345678910public class Singleton &#123; private static Singleton instance; private Singleton ()&#123;&#125; public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 单线程的时候工作正常，但在多线程的情况下就有问题了。如果两个线程同时运行到判断instance是否为null的if语句，并且instance的确没有被创建时，那么两个线程都会创建一个实例 多线程的懒汉式: 通过synchronized方式来确保线程安全，但是因为是锁的方式，每次调用getInstance()方法时都被synchronized关键字锁住了，会引起线程阻塞，影响程序的性能123456public static synchronized Singleton1 getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; 饿汉式 无线程安全问题，不能延迟加载，影响系统性能。 1234567public class Singleton &#123; private static Singleton instance = new Singleton(); private Singleton ()&#123;&#125; public static Singleton getInstance() &#123; return instance; &#125; &#125; 如何解决线程安全，并能做到性能不受影响 好的单例方式 考虑到线程安全，性能问题，延迟初始化角度进行单例的创建和使用 1.双重检验锁:1234567891011121314public class Singleton &#123; private volatile static Singleton singleton; //1:volatile修饰 private Singleton ()&#123;&#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; //2:减少不必要要同步，优化性能 synchronized (Singleton.class) &#123; // 3：同步，线程安全 if (singleton == null) &#123; singleton = new Singleton(); //4：创建singleton 对象 &#125; &#125; &#125; return singleton; &#125; &#125; 为什么要双重检验: 12第一重判断在同步前通过判读singleton是否初始化，减少不必要的同步开销。第2重抢到锁之后再次判断是否为空, 多线程情况下如果第2个线程抢到锁后发现不为空了，就不在创建。volatile 作用是为了防止singleton = new Singleton() 指令重拍，造成返回对象是错误的。下边具体有介绍。 整体好处： 123延迟初始化。和懒汉模式一致，只有在初次调用静态方法getSingleton，才会初始化signleton实例。性能优化。同步会造成性能下降，同步前通过判读singleton是否初始化，减少不必要的同步开销线程安全。同步创建Singleton对象，同时注意到静态变量singleton使用volatile修饰。 volatile的作用是什么，volatile主要包含两个功能。 12保证可见性。使用 volatile 定义的变量，将会保证对所有线程的可见性。禁止指令重排序优化。 由于 volatile 禁止对象创建时指令之间重排序，所以其他线程不会访问到一个未初始化的对象，从而保证安全性。 上边代码为什么要使用volatile ？ 虽然已经使用synchronized进行同步，但在第4步创建对象时，会有下面的伪代码： 123memory=allocate(); //1：分配内存空间ctorInstance(); //2:初始化对象singleton=memory; //3:设置singleton指向刚排序的内存空间 复制代码当线程A在执行上面伪代码时，2和3可能会发生重排序，因为重排序并不影响运行结果，还可以提升性能，所以JVM是允许的。如果此时伪代码发生重排序，步骤变为1-&gt;3-&gt;2,线程A执行到第3步时，线程B调用getsingleton方法，在判断singleton==null时不为null，则返回singleton。但此时singleton并还没初始化完毕，线程B访问的将是个还没初始化完毕的对象。当声明对象的引用为volatile后，伪代码的2、3的重排序在多线程中将被禁止! 2.静态内部类模式: 静态内部类，线程安全，主动调用时才实例化，延迟加载效率高，推荐使用。 12345678910public class Singleton &#123; private Singleton()&#123; &#125; public static Singleton getSingleton()&#123; return Inner.instance; &#125; private static class Inner &#123; private static final Singleton instance = new Singleton(); &#125; &#125; 静态内部类方式的好处： 123外部类加载时并不需要立即加载内部类，内部类不被加载则不去初始化INSTANCE，故而不占内存实现代码简洁，延迟初始化。调用getSingleton才初始化Singleton对象。线程安全。JVM在执行类的初始化阶段，会获得一个可以同步多个线程对同一个类的初始化的锁。 静态内部类又是如何实现线程安全的？ 虚拟机会保证一个类的()方法在多线程环境中被正确地加锁、同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的()方法，其他线程都需要阻塞等待，直到活动线程执行()方法完毕 可以看出instance在创建过程中是线程安全的，所以说静态内部类形式的单例可保证线程安全，也能保证单例的唯一性，同时也延迟了单例的实例化 其他知识： init和clinit区别 init和clinit方法执行时机不同 1init是对象构造器方法，也就是说在程序执行 new 一个对象调用该对象类的 constructor 方法时才会执行init方法，而clinit是类构造器方法，也就是在jvm进行类加载—–验证—-解析—–初始化，中的初始化阶段jvm会调用clinit方法。 执行目的的不同 1init是instance实例构造器，对非静态变量解析初始化，而clinit是class类构造器对静态变量，静态代码块进行初始化 3.枚举单例模式 枚举类型，无线程安全问题，在涉及到反射和序列化的单例中，建议使用下文的枚举类型模式。避免反序列化创建新的实例, Effective Java 是推荐该方法的 枚举单例模式的线程安全, 同样利用静态内部类中的类初始化锁, 枚举单例模式能够在序列化和反射中保证实例的唯一性。 123456public enum Singleton &#123; INSTANCE; public void doSomething()&#123; //todo &#125;&#125; 为什么枚举单例是线程安全的 其实枚举在经过javac的编译之后，会被转换成形如public final class T extends Enum的定义，枚举中的各个枚举项同事通过static来定义的。 例如枚举： 123public enum T &#123; SPRING,SUMMER,AUTUMN,WINTER;&#125; 反编译之后 12345678910111213141516171819public final class T extends Enum&#123; //省略部分内容 public static final T SPRING; public static final T SUMMER; public static final T AUTUMN; public static final T WINTER; private static final T ENUM$VALUES[]; static &#123; SPRING = new T(&quot;SPRING&quot;, 0); SUMMER = new T(&quot;SUMMER&quot;, 1); AUTUMN = new T(&quot;AUTUMN&quot;, 2); WINTER = new T(&quot;WINTER&quot;, 3); ENUM$VALUES = (new T[] &#123; SPRING, SUMMER, AUTUMN, WINTER &#125;); &#125;&#125; 枚举类编译后默认为final class，可防止被子类修改。常量类可被继承修改、增加字段等，容易导致父类的不兼容。枚举类型是线程安全的，并且只会装载一次，充分的利用了枚举的这个特性来实现单例模式。 枚举实现的单例可以避免反射、序列化问题。序列化会通过反射调用无参数的构造方法创建一个新的对象， 枚举是无法进行反射的，所以也达到了防止反射和反序列化相关隐患 static类型的属性会在类被加载之后被初始化, 当一个Java类第一次被真正使用到的时候静态资源被初始化、Java类的加载和初始化过程都是线程安全的（因为虚拟机在加载枚举的类的时候，会使用ClassLoader的loadClass方法，而这个方法使用同步代码块保证了线程安全）。所以，创建一个enum类型是线程安全的 破坏单例模式的方法及预防措施 1、除枚举方式外，其他方法都会通过反射的方式破坏单例。反射是通过强行调用私有构造方法生成新的对象，所以如果我们想要阻止单例破坏，可以在构造方法中进行判断，若已有实例,，则阻止生成新的实例，解决办法如下: 12345private Singleton()&#123; if (instance != null)&#123; throw new RuntimeException(&quot;实例已经存在，请通过 getInstance()方法获取&quot;); &#125;&#125; 2、如果单例类实现了序列化接口Serializable, 就可以通过反序列化破坏单例。所以我们可以不实现序列化接口，如果非得实现序列化接口，可以重写反序列化方法readResolve()，反序列化时直接返回相关单例对象。 123public Object readResolve() throws ObjectStreamException &#123; return instance;&#125; 参考相关文章总结：https://blog.csdn.net/u011514810/article/details/76762176","path":"posts/28018.html","date":"08-28","excerpt":"","tags":[{"name":"java","slug":"java","permalink":"https://zhulg.github.io/tags/java/"}]},{"title":"Android动画相关总结","text":"Android的动画常用的种类，一般指视图动画、属性动画、以及过渡动画 常用的种类一般为4种，分别适用于不同的场景 12345Frame Animation：逐帧动画，即顺序播放事先做好的图像，跟电影类似 。Tween Animation：补间动画，通过对场景里的对象不断做图像变换 Property Animation：属性动画，补间动画增强版，支持对对象执行动画。Transition Animation：过渡动画，主要是实现Activity或View过渡动画效果 动画实现方式 一种方式定义在资源文件里方式xml形式，另一一种通过代码方式，视图动画常用xml定义方式。 视图动画 使用视图动画框架可以创建两种类型的动画： 12帧动画：通过使用 AnimationDrawable 按顺序显示一系列图片来创建动画, 即顺序播放事先做好的图像，跟电影类似 补间动画：通过使用 Animation 对单张图片执行一系列转换来创建动画 帧动画 在 XML 中定义的按顺序显示一系列图片的动画（如电影） 123animation-list：xml文件根节点的标签名，表示逐帧动画。item表示每一帧的资源内容。android:oneshot：该属性用来控制动画是否循环播放，true表示不会循环播放，false表示会循环播放。android:duration：该属性表示每一帧持续播放的时间 官网例子: 1234567&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;animation-list xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; android:oneshot=&quot;false&quot;&gt; &lt;item android:drawable=&quot;@drawable/rocket_thrust1&quot; android:duration=&quot;200&quot; /&gt; &lt;item android:drawable=&quot;@drawable/rocket_thrust2&quot; android:duration=&quot;200&quot; /&gt; &lt;item android:drawable=&quot;@drawable/rocket_thrust3&quot; android:duration=&quot;200&quot; /&gt;&lt;/animation-list&gt; 使用： 123456val rocketImage: ImageView = findViewById(R.id.rocket_image) rocketImage.setBackgroundResource(R.drawable.rocket_thrust) val rocketAnimation = rocketImage.background if (rocketAnimation is Animatable) &#123; rocketAnimation.start() &#125; 补间动画 在 XML中定义的动画，用于对图形执行旋转、淡出、移动和拉伸等转换，并指定动画变化的时间与方式等 ，主要有四种基本的效果：透明度、缩放、位移、旋转 在xml文件形式定义时，xml文件中标签名分别如下所示： 1234alph：渐变透明度动画效果scale： 渐变尺寸伸缩动画效果translate：画面转换位置移动动画效果rotate：画面转移旋转动画效果 在Java代码中，对应的类分别为AlphaAnimation，ScaleAnimation，TranslateAnimation，RotateAnimation 属性动画 通过使用 Animator 在设定的时间段内修改对象的属性值来创建动画 在 XML 中定义的动画的话，用于在设定的一段时间内修改目标对象的属性，例如背景颜色或 Alpha 值。 Animator是属性动画的基类，是一个抽象类。该抽象类有两个重要的具体实现类，分别是：ValueAnimator和ObjectAnimator类。另外还会使用到Evaluator，AnimatorSet等类 1234567891011121314151617181920212223242526&lt;set android:ordering=[&quot;together&quot; | &quot;sequentially&quot;]&gt; &lt;objectAnimator android:propertyName=&quot;string&quot; android:duration=&quot;int&quot; android:valueFrom=&quot;float | int | color&quot; android:valueTo=&quot;float | int | color&quot; android:startOffset=&quot;int&quot; android:repeatCount=&quot;int&quot; android:repeatMode=[&quot;repeat&quot; | &quot;reverse&quot;] android:valueType=[&quot;intType&quot; | &quot;floatType&quot;]/&gt; &lt;animator android:duration=&quot;int&quot; android:valueFrom=&quot;float | int | color&quot; android:valueTo=&quot;float | int | color&quot; android:startOffset=&quot;int&quot; android:repeatCount=&quot;int&quot; android:repeatMode=[&quot;repeat&quot; | &quot;reverse&quot;] android:valueType=[&quot;intType&quot; | &quot;floatType&quot;]/&gt; &lt;set&gt; ... &lt;/set&gt;&lt;/set&gt; 该文件必须具有一个根元素，可以是 、 或 。可以将动画元素（包括其他 元素）组合到 元素中。 使用： 12345val set: AnimatorSet = AnimatorInflater.loadAnimator(myContext, R.animator.property_animator) .apply &#123; setTarget(myObject) start() &#125; ObjectAnimator的原理是直接对对象的属性值进行改变操作，从而实现动画效果 过渡动画 一般通过使用 Android 的过渡框架，只需提供起始布局和结束布局，即可为界面中的各种运动添加动画效果。可以选择所需的动画类型（例如，淡入/淡出视图或更改视图尺寸），而过渡框架会确定如何为从起始布局到结束布局的运动添加动画效果。 过渡框架包含以下功能： 1234群组级动画：将一个或多个动画效果应用于视图层次结构中的所有视图。内置动画：对淡出或移动等常见效果使用预定义动画。资源文件支持：从布局资源文件加载视图层次结构和内置动画。生命周期回调：接收可控制动画和层次结构更改流程的回调 用户在多个 Activity 之间移动的切换过渡动画， activity.overridePendingTransition() 的过渡动画","path":"posts/42188.html","date":"08-25","excerpt":"","tags":[{"name":"Android","slug":"Android","permalink":"https://zhulg.github.io/tags/Android/"}]},{"title":"Git项目使用子模块","text":"当你在一个Git项目上工作时，你需要在其中使用另外一个Git项目做为子项目。一般做法你可以使用release的版本作为子项目不更新，也可以使用库。当一些场景，比如你要使用别人的样式库，可能会随着更新或做自己的调整，这个时候通过导入包不是很适合了，这个使用你需要使用git的子模块了。 git 添加子项目工submodules 来解决上述场景。 添加子模块: 在你主工程下依赖子git项目 1git submodule add https://github.com/xxx.git xxx目录下 查看子模块: 1git submodule 克隆带有含子模块的仓库 直接 进行克隆是无法拉取之模块的代码，可加上 –recursive 参数 1git clone --recursive https://github.com/zhulg/zhulg.github.io.git 提交子模块 1先到子模块里提交后，回到主模块里进行提交。主页在子模块里的分之提交时，要看当前分之，否则可能链接失败在github上通过主模块看不到子模块。","path":"posts/21930.html","date":"08-22","excerpt":"","tags":[{"name":"git","slug":"git","permalink":"https://zhulg.github.io/tags/git/"}]},{"title":"Java线程状态及关键方法","text":"先回顾Java里的几个方法 先了解下Java跟线程相关的几个方法是sleep、yield、wait、join，为什么会有这么些个方法，这些方法是要解决什么问题？ 直观区别： 123Object里的相关的方法：wait()和notify()、notifyAll() Thread类的静态方法： Thread.sleep(long) 和Thread.yield()join()：是由线程对象来调用。 Object.wait()和Thread. sleep()的关键的区别在于 1234wait()是用于线程间通信的，而sleep()是用于短时间暂停当前线程wait，释放cpu资源，也释放锁资源 ，sleep释放cpu资源，不释放锁资源wait用于锁机制， wait，notify,notifyall 都是Object对象的方法，是一起使用的，用于锁机制sleep是线程的方法, 这就是为啥sleep不释放锁，wait释放锁的原因 Thread.sleep(long) 和Thread.yield() 区别 12sleep()会让当前线程休眠进入阻塞状态并释放CPU。 方法会给其他线程运行的机会，而不考虑其他线程的优先级，因此会给较低线程一个运行的机会,如果有同步锁则sleep不会释放锁即其他线程无法获得同步锁 可通过调用interrupt()方法来唤醒休眠线程yield()让出CPU调度 。方法只会给相同优先级者更高优先级的线程一个运行的机会。调用yield方法只是一个建议，告诉线程调度器我的工作已经做的差不多了，可以让别的相同优先级的线程使用CPU了，没有任何机制保证采纳。 join：一种特殊的wait， thread.join()，用于保持线程的执行顺序。当前运行线程调用另一个线程的join方法，当前线程进入阻塞状态直到另一个线程运行结束等待该线程终止。 注意该方法也需要捕捉异常。 ##Java 线程声明周期 NEW : A thread that has not yet started is in this state. RUNNABLE: A thread executing in the Java virtual machine is in this state. BLOCKED: A thread that is blocked waiting for a monitor lock is in this state. WAITING: A thread that is waiting indefinitely for another thread to perform a particular action is in this state. 比如：ThreadA调用了Object.wait()方法，此时ThreadA状态为WAITING。ThreadA会等待其他的线程调用 Object.notify()或Object.notifyAll才会被唤醒，继续执行后面的逻辑 TIMED_WAITING: A thread that is waiting for another thread to perform an action for up to a specified waiting time is in this state. 线程正在等待其他线程的操作，直到超过指定的超时时间,线程在调用以下方法是会将状态改变为TIMED_WAITING状态: 12345Thread.sleepObject.wait with timeoutThread.join with timeoutLockSupport.parkNanosLockSupport.parkUntil TERMINATED: A thread that has exited is in this state.","path":"posts/23024.html","date":"08-18","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://zhulg.github.io/tags/Java/"}]},{"title":"Ios遗忘记录","text":"ios相关快捷键 12345678910111213141.运行:command + R 2.编译:command + B3.停止:command + .4.工程导航如图从左到右分别对应 command +1~8.5.快速查找打开类:command+ shift+ O6.command + shift + j 快速地在代码库定位文件，打开折叠的文件夹 command + 1 打开 工程导航器 command + shift + f 打开 搜索导航器 command + shift + 0 打开 文档和参考 command + shift + o 打开 跳转栏和快速打开搜索输入，快速打开文件 7,command+control+ &lt;-- 前进或者后退代码8，control+6 列出当前类的所有方法 网上快捷键 12345678910111213141516Cmd + shift + O 快速查找类，通过这个可以快速跳到指定类的源代码中。Ctrl + 6 列出当前文件中的所有方法，可以输入关键字过滤。Cmd + Ctrl + Up 在.h 和 .m之间切换Cmd + Shift + Y切换Console Vie的显示隐藏Cmd + Ctrl + Left/Right 到上/下一次编辑的位置Cmd + Opt + J 跳转到文件过滤区Cmd + Shift + F 在工程中查找Cmd + R 运行Cmd + B 编译工程Cmd + Shift + K 清空编译好的文件Cmd + . 结束本次调试Esc 调出代码补全Cmd + 单击 查看方法实现Opt + 单击 查看方法文档Cmd + T 新建Tab栏Cmd + Shift + [ 在Tab栏之间切换 Property 和Synthesize12345Property定义：@property 声明用于自动创建property属性变量的getter和setterSynthesize定义：@Synthesize声明实现了property属性变量的getter和setter。例子:在 interface：@property dataType variableName在 implementation: synthesiz variableName","path":"posts/16388.html","date":"10-01","excerpt":"","tags":[{"name":"ios","slug":"ios","permalink":"https://zhulg.github.io/tags/ios/"}]},{"title":"Ios启动分析","text":"1、OC调用 C++ 会为静态创建的对象生成初始化器，与静态语言不同，OC基于Runtime机制可以用类的名字来实例化一个类的对象。Runtime 维护了一张映射类名与类的全局表，当加载一个 dylib 时，其定义的所有的类都需要被注册到这个全局表中。ObjC 在加载时可以通过 fix-up 在动态类中改变实例变量的偏移量，利用这个技术可以在不改变dylib的情况下添加另一个 dylib 中类的方法，而非常见的通过定义类别（Category）的方式改变一个类的方法。 主执行文件和相关的 dylib的依赖关系构成了一张巨大的有向图，执行初始化器先加载叶子节点，然后逐步向上加载中间节点，直至最后加载根节点。这种加载顺序确保了安全性，加载某个 dylib 前，其所依赖的其余 dylib 文件肯定已经被预先加载。最后 dyld 会调用 main() 函数。main() 会调用 UIApplicationMain()，程序启动。 2、程序启动逻辑 使用Xcode打开一个项目，很容易会发现一个文件－－main.m文件，此处就是应用的入口了。程序启动时，先执行main函数，main函数是ios程序的入口点，内部会调用UIApplicationMain函数，UIApplicationMain里会创建一个UIApplication对象 ，然后创建UIApplication的delegate对象 —–（您的）AppDelegate ，开启一个消息循环（main runloop），每当监听到对应的系统事件时，就会通知AppDelegate。 123456789int main(int argc, char * argv[]) &#123;@autoreleasepool &#123;return UIApplicationMain(argc, argv, nil, NSStringFromClass([AppDelegate class]));&#125;&#125; UIApplication对象是应用程序的象征，每一个应用都有自己的UIApplication对象，而且是单例的。通过[UIApplication sharedApplication]可以获得这个单例对象，一个iOS程序启动后创建的第一个对象就是UIApplication对象， 利用UIApplication对象，能进行一些应用级别的操作。 3、UIApplicationMain函数实现如下：123456int UIApplicationMain&#123; int argc, char *argv[], NSString *principalClassName, NSString * delegateClassName&#125; 第一个参数表示参数的个数，第二个参数表示装载函数的数组，第三个参数，是UIApplication类名或其子类名，若是nil，则默认使用UIApplication类名。第四个参数是协议UIApplicationDelegate的实例化对象名，这个对象就是UIApplication对象监听到系统变化的时候通知其执行的相应方法。 启动完毕会调用 didFinishLaunching方法，并在这个方法中创建UIWindow，设置AppDelegate的window属性，并设置UIWindow的根控制器。如果有storyboard，会根据info.plist中找到应用程序的入口storyboard并加载箭头所指的控制器，显示窗口。storyboard和xib最大的不同在于storyboard是基于试图控制器的，而非视图或窗口。展示之前会将添加rootViewController的view到UIWindow上面（在这一步才会创建控制器的view）1 [window addSubview: window.rootViewControler.view]; 每个应用程序至少有一个UIWindow，这window负责管理和协调应用程序的屏幕显示，rootViewController的view将会作为UIWindow的首视图。未使用storyboard的启动 4、程序启动的完整过程如下： 1.main 函数 2.UIApplicationMain 1234567创建UIApplication对象创建UIApplication的delegate对象delegate对象开始处理(监听)系统事件(没有storyboard)程序启动完毕的时候, 就会调用代理的application:didFinishLaunchingWithOptions:方法在application:didFinishLaunchingWithOptions:中创建UIWindow创建和设置UIWindow的rootViewController显示窗口 3.根据Info.plist获得最主要storyboard的文件名,加载最主要的storyboard(有storyboard) 创建UIWindow 创建和设置UIWindow的rootViewController 显示窗口 5、AppDelegate的代理方法 app启动完毕后就会调用 1(BOOL)application:(UIApplication *)application didFinishLaunchingWithOptions:(NSDictionary *)launchOptions app程序失去焦点就会调用 1(void)applicationWillResignActive:(UIApplication *)application app进入后台的时候调用， 一般在这里保存应用的数据(游戏数据,比如暂停游戏) 1(void)applicationDidEnterBackground:(UIApplication *)application app程序程序从后台回到前台就会调用 1(void)applicationWillEnterForeground:(UIApplication *)application app程序获取焦点就会调用 1(void)applicationDidBecomeActive:(UIApplication *)application 内存警告，可能要终止程序，清除不需要再使用的内存(void)applicationDidReceiveMemoryWarning:(UIApplication *)application 程序即将退出调用(void)applicationWillTerminate:(UIApplication *)application AppDelegate加载顺序 1231.application:didFinishLaunchingWithOptions:2.applicationDidBecomeActive: ViewController中的加载顺序 12345678910111.loadView2.viewDidLoad3.viewWillAppear4.viewWillLayoutSubviews5.viewDidLayoutSubviews6.viewDidAppear View中的加载顺序 12345671.initWithCoder（如果没有storyboard就会调用initWithFrame，这里两种方法视为一种）2.awakeFromNib3.layoutSubviews4.drawRect 一些方法的使用时机 (void)load;应用程序启动就会调用的方法，在这个方法里写的代码最先调用。 (void)initialize;用到本类时才调用，这个方法里一般设置导航控制器的主题等，如果在后面的方法设置导航栏主题就太迟了！ (BOOL)application:(UIApplication )application didFinishLaunchingWithOptions:(NSDictionary)launchOptions;这个方法里面会创建UIWindow，设置根控制器并展现，比如某些应用程序要加载授权页面也是在这加，也可以设置观察者，监听到通知切换根控制器等。 (void)awakeFromNib; 在使用IB的时候才会涉及到此方法的使用，当.nib文件被加载的时候，会发送一个awakeFromNib的消息到.nib文件中的每个对象，每个对象都可以定义自己的awakeFromNib函数来响应这个消息，执行一些必要的操作。在这个方法里设置view的背景等一系列普通操作。 (void)loadView;创建视图的层次结构，在没有创建控制器的view的情况下不能直接写 self.view 因为self.view的底层是： 1 - (void)viewWillLayoutSubviews; 视图将要布局子视图，苹果建议的设置界面布局属性的方法，这个方法和viewWillAppear里，系统的底层都是没有写任何代码的，也就是说这里面不写super 也是可以的。 6、启动分析 应用启动时，会播放一个启动动画。iPhone上是400ms，iPad上是500ms。如果应用启动过慢，用户就会放弃使用，甚至永远都不再回来。为了防止一个应用占用过多的系统资源，开发iOS的苹果工程师门设计了一个“看门狗”的机制。在不同的场景下，“看门狗”会监测应用的性能。如果超出了该场景所规定的运行间，“看门狗”就会强制终结这个应用的进程。 iOS App启动时会链接并加载Framework和static lib，执行UIKit初始化，然后进入应用程序回调，执行Core Animation transaction等。每个Framework都会增加启动时间和占用的内存，不要链接不必要的Framework，必要的Framework不要标记为Optional。避免创建全局的C++对象。 初始化UIKit时字体、状态栏、user defaults、Main.storyboard会被初始化。User defaults本质上是一个plist文件，保存的数据是同时被反序列化的，不要在user defaults里面保存图片等大数据。 对于 OC 来说应尽量减少 Class,selector 和 category 这些元数据的数量。编码原则和设计模式之类的理论会鼓励大家多写精致短小的类和方法，并将每部分方法独立出一个类别，但这会增加启动时间。在调用的地方使用初始化器，不要使用\\atribute((constructor)) 将方法显式标记为初始化器，而是让初始化方法调用时才执行。比如使用 dispatch_once(),pthread_once() 或 std::once()。也就是在第一次使用时才初始化，推迟了一部分工作耗时。 建立网络连接前需要做域名解析，如果网关出现问题，dns解析不正常时，dns的超时时间是应用控制不了的。在程序设计时要考虑这些问题，如果程序启动时有网络连接，应尽快的结束启动过程，网络访问通过线程解决，而不阻塞主线程的运行。","path":"posts/12312.html","date":"09-26","excerpt":"","tags":[{"name":"ios","slug":"ios","permalink":"https://zhulg.github.io/tags/ios/"}]},{"title":"Mac Iterm2 Rz/sz上传下载文件","text":"问题描述： 使用 rz 进行上传时却报错了： 123rz waiting to receive.**B0100000023be50使用 sz 下载也是报错：**B00000000000000 解决方案： 安装 lrzsz :brew install lrzsz 配置 iTerm2 安装完成后我们需要在 iTerm2 中使用的话，还需要一些配置 进入到 /usr/local/bin 目录下，下载两个脚本文件 1234cd /usr/local/bin sudo wget https://gist.githubusercontent.com/sy-records/1b3010b566af42f57fa6fa38138dd22a/raw/2bfe590665d3b0e6c8223623922474361058920c/iterm2-send-zmodem.sh sudo wget https://gist.githubusercontent.com/sy-records/40f4ba22e3fbdeedf58463b067798962/raw/b32d2f7ac3fa54acca81be3664797cebb724690f/iterm2-recv-zmodem.shsudo chmod 777 /usr/local/bin/iterm2-* 下载好之后我们进行 iTerm2 的配置 点击 iTerm2 的设置界面 Perference -&gt; Profiles -&gt; Default -&gt; Advanced -&gt; Triggers 的 Edit 按钮 点击+号，添加对应的参数 123456789Regular expression: rz waiting to receive.\\*\\*B0100 Action: Run Silent Coprocess Parameters: /usr/local/bin/iterm2-send-zmodem.sh Instant: checkedRegular expression: \\*\\*B00000000000000 Action: Run Silent Coprocess Parameters: /usr/local/bin/iterm2-recv-zmodem.sh Instant: checked 添加配置","path":"posts/16281.html","date":"09-24","excerpt":"","tags":[{"name":"linux","slug":"linux","permalink":"https://zhulg.github.io/tags/linux/"}]},{"title":"Kotlin常混淆操作记录","text":"kotlin易混淆操作符 操作符？ 如果要允许为空，我们可以声明一个变量为可空字符串，写作 String? 123456var b: String? = &quot;abc&quot;b = null // okprint(b)var b: String? = &quot;abc&quot;b = null // okprint(b) 安全调用操作符 ? 1234val a = &quot;Kotlin&quot;val b: String? = nullprintln(b?.length)println(a?.length) // 无需安全调用 以上结果 123null6如果 b 非空，就返回 b.length，否则返回 null，这个表达式的类型是 Int?。 安全调用在链式调用中很有用。例如，如果一个员工 Bob 可能会（或者不会）分配给一个部门， 并且可能有另外一个员工是该部门的负责人，那么获取 Bob 所在部门负责人（如果有的话）的名字，我们写作： 12bob?.department?.head?.name如果任意一个属性（环节）为空，这个链式调用就会返回 null。 操作符!!第三种选择是为 NPE 爱好者准备的：非空断言运算符（!!）将任何值转换为非空类型，若该值为空则抛出异常。我们可以写 b!! ，这会返回一个非空的 b 值 （例如：在我们例子中的 String）或者如果 b 为空，就会抛出一个 NPE 异常： 12val l = b!!.length因此，如果你想要一个 NPE，你可以得到它，但是你必须显式要求它，否则它不会不期而至。 安全的类型转换 如果对象不是目标类型，那么常规类型转换可能会导致 ClassCastException。 另一个选择是使用安全的类型转换，如果尝试转换不成功则返回 null： 12val aInt: Int? = a as? Intval aInt: Int? = a as? Int 取值方法(Getter)与设值方法(Setter)123var &lt;propertyName&gt;[: &lt;PropertyType&gt;] [= &lt;property_initializer&gt;] [&lt;getter&gt;] [&lt;setter&gt;] 其中的初始化器(initializer), 取值方法(getter), 以及设值方法(setter)都是可选的. 如果属性类型可以通过初始化器自动推断得到, (或者可以通过取值方法的返回值类型推断得到, 详情见下文), 则属性类型的声明也可以省略. 如果我们定义一个自定义取值方法(Getter), 那么每次读取属性值时都会调用这个方法(因此我们可以用这种方式实现一个计算得到的属性). 下面是一个自定义取值方法的示例: 12val isEmpty: Boolean get() = this.size == 0 field的使用 幕后属性或幕后字段。在Kotlin语言中，如果在类中定义一个成员变量，Kotlin将自动生成默认setter/getter方法。而Kotlin提供了一种非常特殊的方式声明setter/getter方法： 123456var name: String? = null set(value) &#123; field = value name = value //如果这样写，则出现循环调用 &#125; get() = field field是当前属性的影子，就是当前的值this,setter/getter方法中使用。 kotlin in/out泛型中使用 父类泛型对象可以赋值给子类泛型对象，用 in,子类泛型对象可以赋值给父类泛型对象，用 out。 如果你的类是将泛型作为内部方法的返回，那么可以用 out： 1234interface Production&lt;out T&gt; &#123; fun produce(): T&#125;可以称其为 production class/interface，因为其主要是产生（produce）指定泛型对象。因此，可以这样来记：produce = output = out。 In(逆变) 123456如果你的类是将泛型对象作为函数的参数，那么可以用 in：interface Consumer&lt;in T&gt; &#123; fun consume(item: T)&#125;可以称其为 consumer class/interface，因为其主要是消费指定泛型对象。因此，可以这样来记：consume = input = in。 Invariant(不变) 如果既将泛型作为函数参数，又将泛型作为函数的输出，那就既不用 in 或 out。1234interface ProductionConsumer&lt;T&gt; &#123; fun produce(): T fun consume(item: T)&#125;","path":"posts/40178.html","date":"08-20","excerpt":"","tags":[{"name":"Android","slug":"Android","permalink":"https://zhulg.github.io/tags/Android/"},{"name":"kotlin","slug":"kotlin","permalink":"https://zhulg.github.io/tags/kotlin/"}]},{"title":"Android Q适配","text":"适配指南： 安卓Q | 用户画像等功能受影响，Device ID禁用适配指南 变更影响： 1、影响范围 所有通过READ_PHONE_STATE权限获取Device ID的应用以及将设备WiFi Mac地址作为设备唯一标志符的应用都将受影响，预计受影响的应用比例超过90%。 2、兼容性表现 对于TargetSdkVersion&lt;Q且没有申请READ_PHONE_STATE权限的应用和TargetSdkVersion&gt;=Q的全部应用，获取device id会抛异常SecurityException。 对于 TargetSdkVersion&lt;Q且申请了READ_PHONE_STATE权限的应用，通过getDeviceId接口读取的值为Null。 当设备连接到不同的 Wi-Fi 网络时，系统会随机生成不同的 MAC 地址，将无法作为用户唯一标志。 3、受影响的业务场景 所有依赖Device ID以及固定Mac地址数据的业务都会受到影响，如数据统计、推荐、用户历史数据记录、广告、用户画像等。 适配指导： 1、参照官方文档进行适配 唯一标识符最佳方案： 12345https://developer.android.google.cn/training/articles/user-data-idsDevice ID变更介绍文档：https://developer.android.google.cn/preview/privacy/data-identifiers 2、使用Android ID 代替Device ID 123456Android ID获取代码：Settings.System.getString(context.getContentResolver(), Settings.Secure.ANDROID_ID);Android ID和Device ID主要区别在于手机恢复出厂设置后，Android ID将被重置，而Device ID无法重置。","path":"posts/51024.html","date":"08-11","excerpt":"","tags":[{"name":"Android","slug":"Android","permalink":"https://zhulg.github.io/tags/Android/"}]},{"title":"Android唯一标示","text":"androrid 唯一标示 方案1：UUID + SD卡（存取） 123456APP首次使用时，创建UUID，并保存到SD卡中。以后再次使用时，直接从SD卡取出来即可；很多APP就是这么做的；优点：数据唯一、不随APP一起删除；缺点：需要SD卡读写权限；防不住用户手动删除SD卡的文件； 方案2：imei + android_id + serial + 硬件uuid（自生成） 12345678AndroidId : 如：df176fbb152ddce,无需权限,极个别设备获取不到数据或得到错误数据；serial：如：LKX7N18328000931,无需权限,极个别设备获取不到数据；IMEI : 如：23b12e30ec8a2f17，需要权限；Mac: 如：6e:a5:....需要权限，高版本手机获得数据均为 00:00.....（不可使用）Build.BOARD 如：BLA 主板名称,无需权限,同型号设备相同Build.BRAND 如：HUAWEI 厂商名称,无需权限,同型号设备相同Build.HARDWARE 如：kirin970 硬件名称,无需权限,同型号设备相同Build......更多硬件信息，略 imei和Build.SERIAL 在Q上也将会无法获取到 代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169import android.content.Context;import android.os.Build;import android.provider.Settings;import android.telephony.TelephonyManager;import java.security.MessageDigest;import java.util.Locale;import java.util.UUID;public class DeviceIdUtil &#123; /** * 获得设备硬件标识 * * @param context 上下文 * @return 设备硬件标识 */ public static String getDeviceId(Context context) &#123; StringBuilder sbDeviceId = new StringBuilder(); //获得设备默认IMEI（&gt;=6.0 需要ReadPhoneState权限） String imei = getIMEI(context); //获得AndroidId（无需权限） String androidid = getAndroidId(context); //获得设备序列号（无需权限） String serial = getSERIAL(); //获得硬件uuid（根据硬件相关属性，生成uuid）（无需权限） String uuid = getDeviceUUID().replace(&quot;-&quot;, &quot;&quot;); //追加imei if (imei != null &amp;&amp; imei.length() &gt; 0) &#123; sbDeviceId.append(imei); sbDeviceId.append(&quot;|&quot;); &#125; //追加androidid if (androidid != null &amp;&amp; androidid.length() &gt; 0) &#123; sbDeviceId.append(androidid); sbDeviceId.append(&quot;|&quot;); &#125; //追加serial if (serial != null &amp;&amp; serial.length() &gt; 0) &#123; sbDeviceId.append(serial); sbDeviceId.append(&quot;|&quot;); &#125; //追加硬件uuid if (uuid != null &amp;&amp; uuid.length() &gt; 0) &#123; sbDeviceId.append(uuid); &#125; //生成SHA1，统一DeviceId长度 if (sbDeviceId.length() &gt; 0) &#123; try &#123; byte[] hash = getHashByString(sbDeviceId.toString()); String sha1 = bytesToHex(hash); if (sha1 != null &amp;&amp; sha1.length() &gt; 0) &#123; //返回最终的DeviceId return sha1; &#125; &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; &#125; //如果以上硬件标识数据均无法获得， //则DeviceId默认使用系统随机数，这样保证DeviceId不为空 return UUID.randomUUID().toString().replace(&quot;-&quot;, &quot;&quot;); &#125; //需要获得READ_PHONE_STATE权限，&gt;=6.0，默认返回null private static String getIMEI(Context context) &#123; try &#123; TelephonyManager tm = (TelephonyManager) context.getSystemService(Context.TELEPHONY_SERVICE); return tm.getDeviceId(); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; return &quot;&quot;; &#125; /** * 获得设备的AndroidId * * @param context 上下文 * @return 设备的AndroidId */ private static String getAndroidId(Context context) &#123; try &#123; return Settings.Secure.getString(context.getContentResolver(), Settings.Secure.ANDROID_ID); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; return &quot;&quot;; &#125; /** * 获得设备序列号（如：WTK7N16923005607）, 个别设备无法获取 * * @return 设备序列号 */ private static String getSERIAL() &#123; try &#123; return Build.SERIAL; &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; return &quot;&quot;; &#125; /** * 获得设备硬件uuid * 使用硬件信息，计算出一个随机数 * * @return 设备硬件uuid */ private static String getDeviceUUID() &#123; try &#123; String dev = &quot;3883756&quot; + Build.BOARD.length() % 10 + Build.BRAND.length() % 10 + Build.DEVICE.length() % 10 + Build.HARDWARE.length() % 10 + Build.ID.length() % 10 + Build.MODEL.length() % 10 + Build.PRODUCT.length() % 10 + Build.SERIAL.length() % 10; return new UUID(dev.hashCode(), Build.SERIAL.hashCode()).toString(); &#125; catch (Exception ex) &#123; ex.printStackTrace(); return &quot;&quot;; &#125; &#125; /** * 取SHA1 * @param data 数据 * @return 对应的hash值 */ private static byte[] getHashByString(String data) &#123; try&#123; MessageDigest messageDigest = MessageDigest.getInstance(&quot;SHA1&quot;); messageDigest.reset(); messageDigest.update(data.getBytes(&quot;UTF-8&quot;)); return messageDigest.digest(); &#125; catch (Exception e)&#123; return &quot;&quot;.getBytes(); &#125; &#125; /** * 转16进制字符串 * @param data 数据 * @return 16进制字符串 */ private static String bytesToHex(byte[] data)&#123; StringBuilder sb = new StringBuilder(); String stmp; for (int n = 0; n &lt; data.length; n++)&#123; stmp = (Integer.toHexString(data[n] &amp; 0xFF)); if (stmp.length() == 1) sb.append(&quot;0&quot;); sb.append(stmp); &#125; return sb.toString().toUpperCase(Locale.CHINA); &#125;&#125;","path":"posts/32390.html","date":"08-11","excerpt":"","tags":[{"name":"android","slug":"android","permalink":"https://zhulg.github.io/tags/android/"}]},{"title":"Kotlin里范围函数let/run/with等使用","text":"run run函数是说明最简单的范围方法,mood 被完全封闭在run范围内 123456789fun test() &#123; var mood = &quot;I am sad&quot; run &#123; val mood = &quot;I am happy&quot; println(mood) // I am happy &#125; println(mood) // I am sad&#125;","path":"posts/48067.html","date":"08-02","excerpt":"","tags":[{"name":"kotlin","slug":"kotlin","permalink":"https://zhulg.github.io/tags/kotlin/"}]},{"title":"Android架构组件记录","text":"Android官方架构组件 官方实验室地址：https://codelabs.developers.google.com/codelabs/android-lifecycles/index.html?index=..%2F..%2Findex#0 官方例子：https://github.com/googlesamples/android-architecture-components LifeCycle 通俗理解：有一个具有生命周期的组件 A (例如 Activity 或 Fragment)，而另一个组件 B 需要响应 A 组件的生命周期，传统的方式是在组件 A 的生命周期依赖组件 B，但是这种方式导致代码健壮性较低，同时易导致一系列的错误。使用 Lifecycle 组件，您可以将组件 B 的代码从组件 A 的生命周期方法中移到组件本身 LiveData LiveData 是一个可观察的数据持有者。与常规可观察性不同，LiveData 具有生命周期感知能力，这意味着它尊从其他应用程序组件（例如 Activity, Fragment, Service）的生命周期。 这种设计确保 LiveData 只更新处于活动生命周期状态的应用程序组件观察者。如果观察者的生命周期处于 STARTED 或 RESUMED 状态，则 LiveData 会将观察者视为活动状态。LiveData 仅将更新通知给活跃的观察者，未注册和非活动的观察者不会收到有关更新的通知。 创建一个 LiveData,然后一个简单的方法调用，我们在监听数据变化时传入了两个参数，前者 owner 用于将 livedata 与生命周期绑定，后者监听数据的变化，这样你就能使用 LiveData 了 如果观察者的生命周期处于 STARTED 或 RESUMED 状态，则 LiveData 会将观察者视为活动状态。LiveData 仅将更新通知给活跃的观察者 12345- LiveData 是一个可以被观察的数据持有类，它可以感知 Activity、Fragment或Service 等组件的生命周期。简单来说，他主要有一下优点。- 它可以做到在组件处于激活状态的时候才会回调相应的方法，从而刷新相应的 UI。不用担心发生内存泄漏- 当 config 导致 activity 重新创建的时候，不需要手动取处理数据的储存和恢复。它已经帮我们封装好了。- 当 Actiivty 不是处于激活状态的时候，如果你想 livedata setValue 之后立即回调 obsever 的 onChange 方法，而不是等到 Activity 处于激活状态的时候才回调 obsever 的 onChange 方法，你可以使用 observeForever 方法，但是你必须在 onDestroy 的时候 removeObserver。- 在你的项目中，是不是经常会碰到这样的问题，当网络请求结果回来的时候，你经常需要判断 Activity 或者 Fragment 是否已经 Destroy， 如果不是 destroy，才更新 UI。而当你如果使用 Livedata 的话，因为它是在 Activity 处于 onStart 或者 onResume 的状态时，他才会进行相应的回调，因而可以很好得处理这个问题，不必谢一大堆的 activity.isDestroyed()。接下来，让我们一起来看一下 LiveData 的使用 LiveData 的子类 LiveData 是一个抽象类，我们不能直接使用。 MutableLiveData 是 LiveData 的一个最简单实现，它可以接收数据更新并通知观察者。 ViewModel ViewModel 目的在于以生命周期的形式存储和管理与 UI 相关的数据。 ViewModel 允许数据在配置变化（例如屏幕旋转）后仍然存活。 ViewModel 的使用很简单，创建一个类继承 ViewModel,如果你想在 ViewModel 中使用 Context，可以继承 AndroidViewModel,然后通过一行代码即可得到 ViewModel 对象 1val viewModel = ViewModelProviders.of(this).get(UserViewModel::class.java) ViewModel负责为View准备数据。它们将数据暴露给正在监听更改的任何视图。在Android中，使用ViewModel类时应该记住一些具体的事实：123456ViewModel可以在Activity配置更改中保留其状态。它保存的数据立即可用于下一个Activity实例，而不需要在onSaveInstanceState()中保存数据，并手动还原。ViewModel与特定的Activity或Fragment实例无关。ViewModel允许在Fragment之间轻松共享数据（意味着您不再需要通过ctivity来协调动作）。ViewModel将保持在内存中，直到Lifecycle的范围永远消失 - Activity调用finish; 在Fragment调用ditached。因为ViewModel独立于Activity或Fragment实例，它不直接引用其中的任何View或保持上下文的引用。真会导致内存泄漏。如果ViewModel需要应用的上下文(例如查找系统服务)，它可继承AndroidViewModel类，并有一个构造函数来接收Application实例。 最佳实践 尽可能保持您的 UI 控制器（activity 和 fragment）精简。他们不应该试图获取他们自己的数据;相反，使用 ViewModel 来做到这一点，并通过监听 LiveData 对象来更新视图。 尝试编写数据驱动的用户界面，其中您的 UI 控制器的职责是在数据更改时更新视图，或将用户操作通知给ViewModel。 把你的数据逻辑放在 ViewModel 类中。 ViewModel 应作为您的 UI 控制器和其他应用程序之间的连接器。 但要小心，ViewModel 不负责提取数据（例如，来自网络）。 相反，ViewModel 应调用相应的组件来获取数据，然后将结果提供给UI控制器 使用 Data Binding 在视图和 UI 控制器之间保持干净的界面。 这可以使您的视图更具说明性，并最大限度地减少需要在 activity 和 fragment 中编写的更新代码。 如果你喜欢用 java 编程语言来做到这一点，可以使用像 Butter Knife 这样的库来避免样板代码并且能够更好的抽象。 如果您的 UI 很复杂，请考虑创建一个 presenter 来处理 UI 修改。这可能是一项艰巨的任务，但它可以使您的 U I组件更易于测试。 避免在 ViewModel 中引用 View 或 Activity 上下文。如果 ViewModel 存活的时间比 Activity（在配置更改的情况下），将会造成 activity 的内存泄漏 ##Kotlin BugKotlinDocument 方法注释插件 findviewbyid 通过引入 kotlinx.android.synthetic.main.activity_main.* 直接用变量 LiveData 还支持简单的数据变换。目前在 Transformations 类中有 map 和 switchMap 两个变换函数，如果属性 RxJava 则对这两个函数应该不陌生： 12map 是把一个数据类型变换为另外一个数据类型。switchMap 是把一个数据变化为另外一个 LiveData 。","path":"posts/57116.html","date":"07-31","excerpt":"","tags":[{"name":"Android","slug":"Android","permalink":"https://zhulg.github.io/tags/Android/"}]},{"title":"使用Python快速搭建静态服务器","text":"python3 中使用 SimpleHTTPServer,由于在python3中，因为已经将BaseHTTPServer.py, SimpleHTTPServer.py, CGIHTTPServer.py 模块合并为了server模块，所以启动服务器的代码也有所改变 1python3 -m http.server 8000 python2之前都是 python -m SimpleHTTPServer 8000启动","path":"posts/25502.html","date":"01-11","excerpt":"","tags":[{"name":"python","slug":"python","permalink":"https://zhulg.github.io/tags/python/"}]},{"title":"Flutter中ScopedModel的使用","text":"Scoped_model是一个dart第三方库，提供将数据模型从父Widget传递到它的后代的功能,它还会在模型更新时重新渲染使用该模型的所有子项. 原理 Scoped model使用了观察者模式，将数据模型放在父代，后代通过找到父代的model进行数据渲染。 数据改变时将数据传回，父代再通知所有用到了该model的子代去更新状态。 Scoped的思想就是把这些共享状态提升到顶层。123需要共享的状态需要继承至Model类使用ScopedModel包在最外层外形成顶层状态子页面通过ScopedModelDescendant找到顶层装态","path":"posts/23620.html","date":"12-27","excerpt":"","tags":[{"name":"flutter","slug":"flutter","permalink":"https://zhulg.github.io/tags/flutter/"}]},{"title":"flutter和原生和RN架构不同点","text":"原生： RN flutter: RN通过js编译成个平台view Flutter自己实现了一台UI框架，然后直接系统更底层渲染系统上画UI。它采用的开发语言不是JS，而Dart。Dart语言可以编译成原生代码，直接跟原生通信。 系统的UI框架可以取代，但是系统提供的一些服务是无法取代的。Flutter在跟系统service通信方式，采用的是类似插件式的方式(有点像远程过程调用RPC方式) Flutter学习了RN的UI编程方式，引入了状态机，更新UI时只更新最小改变区域。","path":"posts/16190.html","date":"12-14","excerpt":"","tags":[{"name":"flutter","slug":"flutter","permalink":"https://zhulg.github.io/tags/flutter/"}]},{"title":"Go结合gorm格式化时间","text":"go使用gorm做数据库映射时，数据库里存储时间为UTC时间 格式化时间格式 Go中使用gorm时，通过加入gorm.Model到自己的struct来定义一个model,一般定义时间类型为time.Time。由于在go的time包中实现json.Marshaler接口时指定了使用RFC3339Nano这种格式，所以model序列化为JSON的时候默认调MarshalJSON方法把time.Time类型的字段都搞成这种格式 https://stackoverflow.com/questions/28800672/how-to-add-new-methods-to-an-existing-type-in-go 通过别名和内嵌方式进行重写json.Marshaler方法。 如果没有使用gorm则需要通过别名定义，重写arshalJSON方法即可。如果涉及到使用gorm方式则需要加上database/sql的Value和Scan方法才行（否则时间字段在数据库里没有生成） 参见： https://github.com/jinzhu/gorm/issues/1611#issuecomment-329654638。 使用方式123456789101112131415161718192021222324252627282930313233343536package utilsimport ( &quot;time&quot; //&quot;strconv&quot; &quot;fmt&quot; &quot;database/sql/driver&quot; &quot;strconv&quot;)type LocalTime struct &#123; time.Time&#125;func (t LocalTime) MarshalJSON() ([]byte, error) &#123; //格式化秒 seconds := t.Unix() return []byte(strconv.FormatInt(seconds, 10)), nil&#125;func (t LocalTime) Value() (driver.Value, error) &#123; var zeroTime time.Time if t.Time.UnixNano() == zeroTime.UnixNano() &#123; return nil, nil &#125; return t.Time, nil&#125;func (t *LocalTime) Scan(v interface&#123;&#125;) error &#123; value, ok := v.(time.Time) if ok &#123; *t = LocalTime&#123;Time: value&#125; return nil &#125; return fmt.Errorf(&quot;can not convert %v to timestamp&quot;, v)&#125; 使用时在model里时间字段，使用LocalTime类型","path":"posts/41039.html","date":"11-21","excerpt":"","tags":[{"name":"go","slug":"go","permalink":"https://zhulg.github.io/tags/go/"}]},{"title":"Go Cobra使用记录","text":"go cobra 地址 https://github.com/spf13/cobra.git ,是一个创建CLI 命令行的golang库。 使用cobra可以在cli下返回程序和交互，功能强大。 下载 go get -u github.com/spf13/cobra/cobra （下载时可能要科学上网） 下载玩后记得go install 使用 cli 下执行corba,可相关操作方法如下 12345678910111213141516171819Cobra is a CLI library for Go that empowers applications.This application is a tool to generate the needed filesto quickly create a Cobra application.Usage: cobra [command]Available Commands: add Add a command to a Cobra Application help Help about any command init Initialize a Cobra ApplicationFlags: -a, --author string author name for copyright attribution (default &quot;YOUR NAME&quot;) --config string config file (default is $HOME/.cobra.yaml) -h, --help help for cobra -l, --license string name of license for the project --viper use Viper for configuration (default true)Use &quot;cobra [command] --help&quot; for more information about a command. 创建项目 cobra init mydemo 1234567mydemo├── LICENSE├── cmd│ └── root.go└── main.go1 directory, 3 files corba add test （添加一个测试文件）查看目录 123456mydemo/├── LICENSE├── cmd│ ├── root.go│ └── test.go└── main.go *到项目下运行 go run main.go test * 12mydemo$go run main.go testtest called 一个基本cobra工程完成，使用go run main.go test ,查看test.go 文件可以看到相关的命令及test called所处位置 123456789101112131415161718192021222324252627282930313233343536package cmdimport ( &quot;fmt&quot; &quot;github.com/spf13/cobra&quot;)// testCmd represents the test commandvar testCmd = &amp;cobra.Command&#123; Use: &quot;test&quot;, Short: &quot;A brief description of your command&quot;, Long: `A longer description that spans multiple lines and likely contains examplesand usage of using your command. For example:Cobra is a CLI library for Go that empowers applications.This application is a tool to generate the needed filesto quickly create a Cobra application.`, Run: func(cmd *cobra.Command, args []string) &#123; fmt.Println(&quot;test called&quot;) &#125;,&#125;func init() &#123; rootCmd.AddCommand(testCmd) // Here you will define your flags and configuration settings. // Cobra supports Persistent Flags which will work for this command // and all subcommands, e.g.: // testCmd.PersistentFlags().String(&quot;foo&quot;, &quot;&quot;, &quot;A help for foo&quot;) // Cobra supports local flags which will only run when this command // is called directly, e.g.: // testCmd.Flags().BoolP(&quot;toggle&quot;, &quot;t&quot;, false, &quot;Help message for toggle&quot;)&#125; cobra子命令的使用 形如 go run main.go test testsecond 创建子命令这种方式，只需要把子命令添加到父命令里即可，父命令在root命令里即可。构建方式如下 使用cobra add testsecond 目录下创建了testsecond.go文件 1234567mydemo/├── LICENSE├── cmd│ ├── root.go│ ├── test.go│ └── testsecond.go└── main.go 进入到testsecond.go 文件，把init方法里，用父命令添加即可 1testCmd.AddCommand(testsecondCmd) 使用：go run main.go test testsecond 发现打印出 1testsecond called 添加参数 根据提示添加即可。","path":"posts/3161.html","date":"11-02","excerpt":"","tags":[{"name":"go","slug":"go","permalink":"https://zhulg.github.io/tags/go/"}]},{"title":"Go语言基础记录","text":"go最基础备忘录 Go的基本类型： 123456789101112131415布尔类型：bool字符串：string有符号整形：int int8 int16 int32 int64无符号整形：uint uint8 uint16 uint32 uint64 uintptr byte // uint8 的别名 rune // int32 的别名， 代表一个Unicode码点浮点数：float32 float64复数：complex64 complex128 for 是 Go 中的 “while” 此时你可以去掉分号，因为 C 的 while 在 Go 中叫做 for。 1234567func main() &#123; sum := 1 for sum &lt; 1000 &#123; sum += sum &#125; fmt.Println(sum)&#125; if Go 的 if 语句与 for 循环类似，表达式外无需小括号 ( ) ，而大括号 { } 则是必须的。 123456func sqrt(x float64) string &#123; if x &lt; 0 &#123; return sqrt(-x) + &quot;i&quot; &#125; return fmt.Sprint(math.Sqrt(x))&#125; defer defer 语句会将函数推迟到外层函数返回之后执行。 12345func main() &#123; defer fmt.Println(&quot;world&quot;) fmt.Println(&quot;hello&quot;)&#125; Go数组、切片 声明一个包含 5 个元素的整型数组 1var array [5]int 声明一个包含 5 个元素的整型数组,用具体值初始化每个元素 1array := [5]int&#123;10, 20, 30, 40, 50&#125; 容量由初始化值的数量决定 1array := [...]int&#123;10, 20, 30, 40, 50&#125; 声明包含 3 个元素的指向字符串的指针数组 1234var array2 [3]*string使用字符串指针初始化这个数组array2 := [3]*string&#123;new(string), new(string), new(string)&#125;使用颜色为每个元素赋值 *array2[0] = &quot;Red&quot; *array2[1] = &quot;Blue&quot; *array2[2] = &quot;Green&quot; 切片 切片是围绕动态数组的概念 构建的，可以按需自动增长和缩小。切片的动态增长是通过内置函数 append 来实现的,这个函 数可以快速且高效地增长切片。还可以通过对切片再次切片来缩小一个切片的大小 切片是一个很小的对象，对底层数组进行了抽象，并提供相关的操作方法。切片有 3 个字段 的数据结构，这些数据结构包含 Go 语言需要操作底层数组的元数据。这 3 个字段分别是指向底层数组的指针、切片访问的元素的个数(即长度)和切片允许增长 到的元素个数(即容量) 创建切片的方法第一种：使用内置的 make 函数。当使用 make 时，需要传入一个参数，指定切片的长度 1234创建一个字符串切片,其长度和容量都是 5 个元素 slice := make([]string, 5)创建一个整型切片,其长度为 3 个元素，容量为 5 个元素 slice := make([]int, 3, 5) 另一种常用的创建切片的方法： 是使用切片字面量，这种方法和创建数组类似，只是不需要指定[]运算符里的值。初始的长度和容量会基于初始化时提供的元素的 个数确定。 12345678910111213通过切片字面量来声明切片创建字符串切片,其长度和容量都是 5 个元素slice := []string&#123;&quot;Red&quot;, &quot;Blue&quot;, &quot;Green&quot;, &quot;Yellow&quot;, &quot;Pink&quot;&#125;创建一个整型切片,其长度和容量都是 3 个元素 slice := []int&#123;10, 20, 30&#125;使用索引声明切片创建字符串切片使用空字符串初始化第 100 个元素 slice := []string&#123;99: &quot;&quot;&#125; 记住，如果在[]运算符里指定了一个值，那么创建的就是数组而不是切片。只有不指定值的时候，才会创建切片，声明数组和声明切片的不同,创建有 3 个元素的整型数组:array := [3]int&#123;10, 20, 30&#125;创建长度和容量都是 3 的整型切片:slice := []int&#123;10, 20, 30&#125; nil 和空切片 有时，程序可能需要声明一个值为 nil 的切片(也称 nil 切片)。只要在声明时不做任何初始化，就会创建一个 nil 切片.在需要描述一个不存在的切片时，nil 切片会很好用。例如，函数要求返回一个切片但是 发生异常的时候. 12345678 创建 nil 整型切片 var slice []int 声明空切片使用 make 创建空的整型切片 slice := make([]int, 0)使用切片字面量创建空的整型切片 slice := []int&#123;&#125; 使用切片 使用切片字面量来声明切片 1234创建一个整型切片,其容量和长度都是 5 个元素slice := []int&#123;10, 20, 30, 40, 50&#125;改变索引为 1 的元素的值 slice[1] = 25切片之所以被称为切片，是因为创建一个新的切片就是把底层数组切出一部分 使用切片创建切片 1234创建一个整型切片,其长度和容量都是 5 个元素slice := []int&#123;10, 20, 30, 40, 50&#125;创建一个新切片, 其长度为 2 个元素，容量为 4 个元素 newSlice := slice[1:3] 如何计算长度和容量 12345678对底层数组容量是 k 的切片 slice[i:j]来说 长度: j - i容量: k - i对 newSlice 应用这个公式就能得到代码清单 4-27 所示的数字。计算新的长度和容量 对底层数组容量是 5 的切片 slice[1:3]来说长度: 3 - 1 = 2 容量: 5 - 1 = 4可以用另一种方法来描述这几个值。第一个值表示新切片开始的元素的索引位置，这个例子 中是 1。第二个值表示开始的索引位置(1)，加上希望包含的元素的个数(2)，1+2 的结果是 3， 所以第二个值就是 3。容量是该与切片相关联的所有元素的数量 切片增加元素,要使用 append，需要一个被操作的切片和一个要追加的值。当 append 调用返回时，会返回一个包含修改结果的新切片。函数 append 总是会增加新切片的长 度，而容量有可能会改变，也可能不会改变，这取决于被操作的切片的可用容量 123456创建一个整型切片// 其长度和容量都是 5 个元素slice := []int&#123;10, 20, 30, 40, 50&#125;// 创建一个新切片,其长度为 2 个元素，容量为 4 个元素 newSlice := slice[1:3]// 使用原有的容量来分配一个新元素, 将新元素赋值为 60newSlice = append(newSlice, 60) 使用append 同时增加切片的长度和容量,如果切片的底层数组没有足够的可用容量，append 函数会创建一个新的底层数组，将被引 用的现有的值复制到新数组里，再追加新的值 123456789// 创建一个整型切片// 其长度和容量都是 4 个元素slice := []int&#123;10, 20, 30, 40&#125; // 向切片追加一个新元素// 将新元素赋值为 50newSlice := append(slice, 50)//当这个 append 操作完成后，newSlice 拥有一个全新的底层数组，这个数组的容量是原来 的两倍 在函数间传递切片:由于与切片关联的数据包含在底层数组里，不属于切片本身，所以将切片 复制到任意函数的时候，对底层数组大小都不会有影响。复制时只会复制切片本身，不会涉及底 层数组 映射（map） 创建和初始化,使用make 1234567使用 make 声明映射创建一个映射，键的类型是 string，值的类型是 intdict := make(map[string]int)创建一个映射，键和值的类型都是 string使用两个键值对初始化映射dict := map[string]string&#123;&quot;Red&quot;: &quot;#da1337&quot;, &quot;Orange&quot;: &quot;#e95a22&quot;&#125;创建映射时，更常用的方法是使用映射字面量。映射的初始长度会根据初始化时指定的键值 对的数量来确定 使用映射字面量声明空映射 123创建一个映射，使用字符串切片作为映射的键 dict := map[[]string]int&#123;&#125;Compiler Exception:invalid map key type []string 没有任何理由阻止用户使用切片作为映射的值，这个在使用一个映射 键对应一组数据时，会非常有用 声明一个存储字符串切片的映射 12创建一个映射，使用字符串切片作为值dict := map[int][]string&#123;&#125; go指针 Go 拥有指针。指针保存了值的内存地址。 一个指针变量指向了一个值的内存地址 在指针类型前面加上 * 号（前缀）来获取指针所指向的内容 123456789101112var a int= 20 /* 声明实际变量 */var ip *int /* 声明指针变量 */ip = &amp;a /* 指针变量的存储地址 */fmt.Printf(&quot;a 变量的地址是: %x\\n&quot;, &amp;a )// a 变量的地址是: 20818a220/* 指针变量的存储地址 */fmt.Printf(&quot;ip 变量储存的指针地址: %x\\n&quot;, ip )//ip 变量储存的指针地址: 20818a220/* 使用指针访问值 */fmt.Printf(&quot;*ip 变量的值: %d\\n&quot;, *ip ) //20 12345678类型 *T 是指向 T 类型值的指针。其零值为 nil。var p *int&amp; 操作符会生成一个指向其操作数的指针。i := 42p = &amp;i* 操作符表示指针指向的底层值。 指针常用场景 在go的方法定义里，作为接收者操作值 指针接收者的方法可以修改接收者指向的值（就像 Scale 在这做的）。由于方法经常需要修改它的接收者，指针接收者比值接收者更常用。结果是55. 若使用值接收者（移除第 16 行 Scale 函数声明中的 * ，则结果是5），那么 Scale 方法会对原始 Vertex 值的副本进行操作。 1234567891011121314151617181920212223242526package mainimport ( &quot;fmt&quot; &quot;math&quot;)type Vertex struct &#123; X, Y float64&#125;func (v Vertex) Abs() float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125;// 该方法接收着为 指针类型 *Vertexfunc (v *Vertex) Scale(f float64) &#123; v.X = v.X * f v.Y = v.Y * f&#125;func main() &#123; v := Vertex&#123;3, 4&#125; v.Scale(10) fmt.Println(v.Abs()) //输出50&#125; 结构体 一个结构体（struct）就是一个字段的集合,结构体字段使用点号来访问。 12345678910type A struct &#123; X int Y int&#125;func main() &#123; v := A&#123;1, 2&#125; v.X = 4 fmt.Println(v.X)&#125; 数据结构 数组，类型 [n]T 表示拥有 n 个 T 类型的值的数组。 切片,每个数组的大小都是固定的。而切片则为数组元素提供动态大小的、灵活的视角。在实践中，切片比数组更常用。类型 []T 表示一个元素类型为 T 的切片。 123primes := [6]int&#123;2, 3, 5, 7, 11, 13&#125;var s []int = primes[1:4]fmt.Println(s) //3,5,7 切片通过两个下标来界定，即一个上界和一个下界，二者以冒号分隔： a[low : high] 切片就像数组的引用,切片并不存储任何数据，它只是描述了底层数组中的一段。更改切片的元素会修改其底层数组中对应的元素。与它共享底层数组的切片都会观测到这些修改。 切片文法 类似于没有长度的数组文法。 123456这是一个数组文法：[3]bool&#123;true, true, false&#125;下面这样则会创建一个和上面相同的数组，然后构建一个引用了它的切片：[]bool&#123;true, true, false&#125; 切片的长度与容量,切片拥有 长度 和 容量 切片的长度就是它所包含的元素个数。切片的容量是从它的第一个元素开始数，到其底层数组元素末尾的个数。切片 s 的长度和容量可通过表达式 len(s) 和 cap(s) 来获取。Go 数组的长度不可改变，在特定场景中这样的集合就不太适用，Go中提供了一种灵活，功能强悍的内置类型切片(“动态数组”),与数组相比切片的长度是不固定的，可以追加元素，在追加时可能使切片的容量增大 append() 和 copy() 函数 如果想增加切片的容量，我们必须创建一个新的更大的切片并把原分片的内容都拷贝过来。 Range for 循环的 range 形式可遍历切片或映射,当使用 for 循环遍历切片时，每次迭代都会返回两个值。第一个值为当前元素的下标，第二个值为该下标所对应元素的一份副本。 delete() 函数用于删除集合的元素, 参数为 map 和其对应的 key。实例如下： 函数值 函数也是值。它们可以像其它值一样传递 函数值可以用作函数的参数或返回值。 12345678910111213func compute(fn func(float64, float64) float64) float64 &#123; return fn(3, 4)&#125;func main() &#123; hypot := func(x, y float64) float64 &#123; return math.Sqrt(x*x + y*y) &#125; fmt.Println(hypot(5, 12)) fmt.Println(compute(hypot)) fmt.Println(compute(math.Pow))&#125; Go 函数可以是一个闭包。闭包是一个函数值，它引用了其函数体之外的变量。该函数可以访问并赋予其引用的变量的值，换句话说，该函数被“绑定”在了这些变量上。 例如，函数 adder 返回一个闭包。每个闭包都被绑定在其各自的 sum 变量上。 1234567891011121314151617181920212223242526272829func adder() func(int) int &#123; sum := 0 return func(x int) int &#123; sum += x return sum &#125;&#125;func main() &#123; pos, neg := adder(), adder() for i := 0; i &lt; 10; i++ &#123; fmt.Println( pos(i), neg(-2*i), ) &#125;&#125;//值为：0 01 -23 -66 -1210 -2015 -3021 -4228 -5636 -7245 -90 函数和方法 Go 没有类。不过你可以为结构体类型定义方法。方法就是一类带特殊的 接收者 参数的函数。 方法，就是一类带特殊的 接收者 参数的函数。方法接收者在它自己的参数列表内，位于 func 关键字和方法名之间。 函数是指不属于任何结构体、类型的方法,也就是说，函数是没有接收者的；而方法是有接收者的 (v Vertex) 是方法的接收着。 123func (v Vertex) Abs() float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125; 方法的声明和函数类似，他们的区别是：方法在定义的时候，会在func和方法名之间增加一个参数，这个参数就是接收者，这样我们定义的这个方法就和接收者绑定在了一起，称之为这个接收者的方法。 Go语言里有两种类型的接收者：值接收者和指针接收者 使用值类型接收者定义的方法，在调用的时候，使用的其实是值接收者的一个副本，所以对该值的任何操作，不会影响原来的类型变量。 类型转换和类型断言 类型断言是将接口类型的值x，转换成类型T。 12345格式为：x.(T)v := x.(T)v, ok := x.(T)类型断言的必要条件是x是接口类型,非接口类型的x不能做类型断言 接口 接口类型 是由一组方法签名定义的集合，interface 是一种类型 *在Golang中只要实现了接口定义的所有方法，就是（JAVA implement）实现了该interface * 空接口 所有类型都实现了空接口，空接口可保存任何类型的值。（因为每个类型都至少实现了零个方法。）空接口被用来处理未知类型的值。例如，fmt.Print 可接受类型为 interface{} 的任意数量的参数 一个函数把interface{}作为参数，那么他可以接受任意类型的值作为参数，如果一个函数返回interface{},那么也就可以返回任意类型的值 空接口代码示例： 12345678910111213141516171819package mainimport ( &quot;fmt&quot;)//空接口使用，可以传入任何类型func describe(i interface&#123;&#125;) &#123; fmt.Printf(&quot;Type = %T, value = %v\\n&quot;, i, i)&#125;func main() &#123; s := &quot;Hello World&quot; i := 10 strt := struct&#123; name string &#125;&#123;name: &quot;jason&quot;&#125; describe(s) describe(i) describe(strt)&#125; 接口可以用于类型断言，用于提取接口的基础值，语法：i.(T) 1234567891011121314151617类型断言用于提取接口的基础值，语法：i.(T)package mainimport(&quot;fmt&quot;)func assert(i interface&#123;&#125;)&#123; s:= i.(int) fmt.Println(s)&#125;func main()&#123; var s interface&#123;&#125; = 55 assert(s)&#125; 以上程序打印的是int值， 但是如果我们给s 变量赋值的是string类型，程序就会panic。 接口可以拥有类型判断,类型type应该由类型转换的关键字type替换 i.(type) 123456789101112131415161718192021package mainimport ( &quot;fmt&quot;)func findType(i interface&#123;&#125;) &#123; switch i.(type) &#123; case string: fmt.Printf(&quot;String: %s\\n&quot;, i.(string)) case int: fmt.Printf(&quot;Int: %d\\n&quot;, i.(int)) default: fmt.Printf(&quot;Unknown type\\n&quot;) &#125;&#125;func main() &#123; findType(&quot;Naveen&quot;) findType(77) findType(89.98)&#125;","path":"posts/35121.html","date":"10-12","excerpt":"","tags":[{"name":"go","slug":"go","permalink":"https://zhulg.github.io/tags/go/"}]},{"title":"Mac终端代理解决dep Ensure","text":"使用Stellar go sdk,同步sdk里的依赖dep ensure -v 发现错误，需要挂上代理了。 dep ensure -v 出现类似错误。 12The following errors occurred while deducing packages: &quot;golang.org/x/net/http2&quot;: unable to deduce repository and source type for &quot;golang.org/x/net/http2&quot;: unable to read metadata: unable to fetch raw metadata: failed HTTP request to URL &quot;http://golang.org/x/net/http2?go-get=1&quot;: Get http://golang.org/x/net/http2?go-get=1: dial tcp xx.xx.xx.xx:80: i/o timeout 在当前端口设置,使端口也使用代理。设置前通过curl ip.cn 查看当前ip，设置后在查看，可以看到使用的是Shadowsocks代理的ip。(可在gwlist.js里需要确认系Shadowsocks的端口是否是1080) 新版本的ShadowSocks-NG 可以在设置里直接能查看到相关的端口。 123export http_proxy=socks5://127.0.0.1:1080 export https_proxy=socks5://127.0.0.1:1080 export all_proxy=socks5://127.0.0.1:1080 以上设置有时还是还是会失败，同步不下来。如果不行在通过http进行尝试，通过http方式可以来取下拉（需要查看ss的http端口是否是1087） 123export http_proxy=http://127.0.0.1:1087export https_proxy=https://127.0.0.1:1087 export all_proxy=https://127.0.0.1:1087 -","path":"posts/11588.html","date":"10-08","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"},{"name":"go","slug":"go","permalink":"https://zhulg.github.io/tags/go/"},{"name":"stellar","slug":"stellar","permalink":"https://zhulg.github.io/tags/stellar/"}]},{"title":"如何绑定两个Github帐号","text":"一般情况下，一台电脑上有自己的一个github账号，有时你可能会要跟公司和个人的账号分开来进行使用。此时，需要在一台电脑上操作2个github账号进行项目管理。你不能有多个账号添加了同一个公钥，否则你可能会遇到这样类似错误“ERROR: Permission to XXX.git denied to user”。要解决github账号分别对应公钥，需要在创建一个。（假设你已经在用一个自己的github账号绑定了自己的ssh公钥） 操作 进入到.ssh目录下查看已有的秘钥 12$ cd ~/.ssh $ ls 如果已经存在id_rsa ,id_rsa.pub等，你需要为你新的github账号创建新的ssh公钥。 生成新的key,需要注意的his，之前你创建可能还是一路回车，此刻需要你输入新的名字，比如id_rsa_second,让后回车。否则会自动覆盖你之前的sshkey.创建完后需要把你新的sshkey 拷贝到新的github账号下。 123$ssh-keygen -t rsa -C &quot;your_email@example.com&quot;Generating public/private rsa key pair.Enter file in which to save the key (/Users/zhulianggang/.ssh/id_rsa): 配置config,没有的话需要创建个,在.ssh路径下 123456789#default githubHost github.comHostName github.comIdentityFile ~/.ssh/id_rsa#新的账号，注意github_second,测试使用hostHost github_second.github.comHostName github.comIdentityFile ~/.ssh/id_rsa_second 取消全局用名配置，如果之前你有设置全局github用名,为你使用的工程里重新设置对应的用名名 123456取消globalgit config --global --unset user.namegit config --global --unset user.email每一个工程设置用户名git config user.email &quot;xxxx@xx.com&quot;git config user.name “xxxx” 新的github账号使用别名pull/push 1git clone git@github_second:username/reponame 检测后使用1234567$ssh -T git@github.comHi xxxx! You&apos;ve successfully authenticated, but GitHub does not provide shell access.ssh -T git@github_second.github.comHi xxx! You&apos;ve successfully authenticated, but GitHub does not provide shell access.说明已经可以成功使用，注意新账号使用别名（github_second）即可。","path":"posts/59372.html","date":"09-26","excerpt":"","tags":[{"name":"git","slug":"git","permalink":"https://zhulg.github.io/tags/git/"}]},{"title":"Stellar区块链记录","text":"一，关于Stellar网络相关概述 Stellar 是一个基于区块链的分布式开源网络，专为即时支付转账而设计。Stellar 由 Ripple 的联合创始人 Jed McCaleb 创立，旨在以极低的成本提供金融服务， 特别是为那些不属于传统银行业服务范围的人提供服务 Stellar相关特点 像比特币一样，Stellar的网络是去中心化、分布式账本。 比特币是比特币网络的本币，而lumens则是Stellar网络的本币。 Stellar网络中没有挖矿; 你可以运行Stellar核心验证节点，但验证交易不会被奖励新产生的lumens。 比特币使用POW作为其共识模型，而Stellar使用的是Stellar共识协议（SCP）的共识模式。SCP实施的是联邦拜占庭协议（FBA）共识模式。SCP不需要太多算力，理论上每秒交易吞吐量达到1000笔。 Stellar网络交易确认时间的中值为5秒。虽然lumens是Stellar网络的原生资产，但其网络支持许多不同类型的资产，每个人都可以发行新资产。外部货币（法币或外部区块链）支持的资产由Stellar网络锚系统提供支持。 Stellar网络内置了去中心化交易市场。 锚点作为法定货币进入Stellar网络的进入和退出点，为用户维护法币账户和Stellar钱包。如果用户将资金存入他们的法定货币账户，锚点将向用户的Stellar钱包存入等量的相应Stellar网络资产，反之亦然。大多数锚点是银行和支付公司等金融机构 Stellar lumens每年的固定名义通胀率为1％。还有一个收费池，用于发送网络交易的lumens费用。每个星期，由通货膨胀产生的新lumens和从收费池流出的lumens都会分配到Stellar钱包。每个钱包接收的lumens量基于投票系统。每个钱包都可以投票选择另一个钱包来接收lumens; 钱包中的每个lumens都被视为一票。 Stellar运行方式 和其他基于区块链的平台一样，Stellar 平台运行在一系列分布式服务器上。它由一个分布式分类账组成，记录网络上发生的每一笔交易。分类账每两到五秒更新一次，也就是网络上交易所需的平均时间。 Stellar 平台通过 Anchor（锚点）为任何想通过网络发送或接收付款的人发放信用额度。例如，如果你想向某人发送 100 美元， 需要先将钱存入 Anchor。收到这笔钱后，Anchor 会将金额记到你的 Stellar 账户。然后，你帐户里的资金可以发送给任何拥有 Stellar 帐户的人。收款人可以随时兑现 Stellar 账户里的资金 Stellar的共识协议（SCP） Stellar公开的白皮书（DavidMazières教授撰写）里详细介绍了Stellar共识协议（SCP）的工作原理。该白皮书在谷歌学术上列出，并在撰写此博客文章时被引用了39次。该论文长32页，技术性极强，包含关于联邦拜占庭协议（FBA）共识模型正确性的详细数学证明， SCP是建立在联邦拜占庭协议（Federated Byzantine Agreement）之上的成果，是一种新的共识方法Stellar白皮书对FBA的简要介绍： 在FBA中，每个参与者都知道其认为重要的其它人。在认定交易完成之前，它等待绝大多数其他人就此交易达成一致。反过来，那些重要的参与者不同意交易，直到他们认为重要的参与者同意为止，等等。最终，足够的网络接受一项交易，让攻击者无法将其回滚。只有这样参与者才认为交易已经结束。FBA共识可以确保金融网络的完整性。其去中心化控制可以刺激有机增长。 SCP有两个关键属性，使得Stellar网络成为强大的资产转移系统。首先，它对算力的要求极低，特别是与比特币的POW相比。其次，它具有超高的交易吞吐量，理论上可以达到每秒1000次交易。 lumens意义 如果Stellar网络的关键功能是自定义资产的传输和交换，为什么需要本地货币（lumens） 首先，lumens在网络中起到反垃圾攻击的作用。每笔交易都有lumens费用，这使网络垃圾攻击非常昂贵。此外，其网络中的所有账户要求余额不低于20lumens。其次，lumens为Stellar的内置的去中心化交易平台增加了流动性，为低成交量货币交易对提供交易桥梁。 为什么要选择Stellar Stellar有可以运行的产品 Stellar在SCP上有着令人印象非常深刻的白皮书。如上所述，该论文在谷歌学术上列出，在撰写本文时已经被引用了39次。这一技术实力也体现在该团队的产品——Stellar网络中。该网络功能齐全，所有核心组件都可以正常运行并记录在案。 Stellar Core是充当网络骨干的软件。Stellar Core节点通过SCP验证交易来保持网络运行。节点还允许所有者在网络中发布新资产或向网络提交交易。任何人都可以下载Stellar Core并开始运行节点。Horizon是连接到Stellar Core节点的服务器应用程序，允许应用程序通过RESTful HTTP API接口与Stellar网络进行交互，这对任何有能力的Web开发人员来说都应该是熟悉的。任何人都可以下载并运行Horizon服务器。 网络的锚点（记住锚点是Stellar网络的法币网关）也得到充分开发并有据可查。网桥服务器能够发送和接收符合规定的支付。每次发送或接收付款时，服务器都会通过合规服务器实现合规性，即桥服务器使用Stellar合规协议进行通信。Stellar网络也有自己的类似DNS的系统，通过可读地址映射到账户ID。该映射存储在联合服务器中。为了让网桥服务器根据人类可读地址确定账户ID，它必须通过Stellar联盟协议与联合服务器通信。 二，Stellar网络组件 整个网络其实由两个组件构成,一个用于与Stellar网络交互的API服务Horizon;另一个是网络的骨干,也就是Stellar Core. 网络中的所有的Horizon服务都会链接到Stellar core 上,由它通过共识算法负责交易的验证和处理工作,当我们谈到Stellar网络时,往往说的都是Stellar Core的集合,我们可以将Stellar core 理解为Bitcoin 中的节点,网络中相互连接的全部节点构成整个网络,而Horizon 就是用于与节点对话的HTTP服务了. Horizon实例是Stellar网络的开放接口访问平台，对外部应用提供访问Stellar网络的各种API，同时，当前对外提供提供JS、Go、Java、Ruby、Python和C#等版本的SDK，方便各类应用的快速接入 Stellar网络中的节点种类和功能,有全节点，同步节点，归档节点，建议采用三种节点的模式进行StellarCore实例的部署，当然，也可以将三种功能进行灵活配置，形成其他的部署模式。 账号模型和生成 Stellar采用账户（Account）模型组织链上信息，所有信息都关联到账户。 每个Stellar帐户都有一个公钥和一个秘密种子。 Stellar使用公钥加密来确保每个事务都是安全的。公钥通常可以安全共享 - 其他人需要它来识别您的帐户并验证您是否授权了交易。但是，种子是私人信息，证明您拥有自己的帐户。你永远不应该与任何人分享种子。 秘钥种子实际上是用于为您的帐户生成公钥和私钥的单个秘密数据。为方便起见，Stellar的工具使用种子而不是私钥：要完全访问帐户，您只需提供种子而不是公钥和私钥。 go语言生成公钥和种子秘钥。 12345678910111213141516171819package mainimport ( &quot;log&quot; &quot;github.com/stellar/go/keypair&quot;)func main() &#123; pair, err := keypair.Random() if err != nil &#123; log.Fatal(err) &#125; log.Println(pair.Seed()) // SAV76USXIJOBMEQXPANUOQM6F5LIOTLPDIDVRJBFFE2MDJXG24TAPUU7 （种子秘钥） log.Println(pair.Address()) // GCFXHS4GXL6BVUCXBWXGTITROWLVYXQKQLF4YH5O5JT3YZXCYPAFBJZB （公钥）&#125; 现在您已拥有种子和公钥，您可以创建一个帐户。为了防止人们制造大量不必要的账户，每个账户的最小余额必须为1 lumens（lumens是Stellar网络的内置货币）。但是，由于您还没有任何lumens，因此您无法支付帐户费用。在现实世界中，您通常会支付销售流明的交易所以创建新帐户。然而，在Stellar的测试网络中，您可以向我们友好的机器人Friendbot请求，为您创建一个帐户。要创建测试帐户，请向Friendbot发送您创建的公钥。它将使用该公钥作为帐户ID创建和资助新帐户 12345678910111213141516171819202122232425package mainimport ( &quot;net/http&quot; &quot;io/ioutil&quot; &quot;log&quot; &quot;fmt&quot;)func main() &#123; // pair is the pair that was generated from previous example, or create a pair based on // existing keys. address := pair.Address() resp, err := http.Get(&quot;https://friendbot.stellar.org/?addr=&quot; + address) if err != nil &#123; log.Fatal(err) &#125; defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) if err != nil &#123; log.Fatal(err) &#125; fmt.Println(string(body))&#125; 获取帐户的详细信息并检查其余额。账户可以带有多个余额 - 每种类型的货币对应一种余额,go语言代码。 123456789101112131415161718192021package mainimport ( &quot;fmt&quot; &quot;log&quot; &quot;github.com/stellar/go/clients/horizon&quot;)func main() &#123; account, err := horizon.DefaultTestNetClient.LoadAccount(pair.Address()) if err != nil &#123; log.Fatal(err) &#125; fmt.Println(&quot;Balances for account:&quot;, pair.Address()) for _, balance := range account.Balances &#123; log.Println(balance) &#125;&#125; 发送和接受 发送资产功能是给某个地址发送资产，接收功能是知道那个账号发送了资产。（代码表示参考文档发送和接收部分，暂不整理记录） 锚点（接入Stellar网络的银行） 锚点是人们信任持有存款并向Stellar网络发放信用额度的实体。 Stellar网络中的所有货币交易（lumens除外）均以锚点发行的信用形式出现，因此锚点充当现有货币与Stellar网络之间的桥梁。大多数人都是银行，储蓄机构，农民合作社，中央银行和汇款公司等组织。 作为Anchor,一般需要维护最少两个账户: 12- 1，An issuing account：仅用于发行和销毁资产的发行帐户。- 2，A base account：用于与其他Stellar帐户进行交易的基本帐户。它持有发行账户发行的资产余额 Customer Accounts(客户账户) 一般有2种方法对应用户的账号 一种是给锚点（接入的中央银行）里每个用户建立一个恒星账户。 另外一种是一个锚点只有一个账号，通过 federation(联合地址) 和 memo 来定位到具体的银行内部的用户。（一般采用这种方法） 建立锚点，基础架构需要满足1234付款。收到付款后，监控Stellar帐户并更新客户帐户。查找并响应联合地址请求。遵守反洗钱（AML）规定。 Stellar提供预构建的联合服务器（ federation server）和法规遵从性服务器（regulatory compliance server ），专为您安装和集成现有基础架构而设计。桥接服务器（ bridge server ）协调它们并简化与Stellar网络的交互。本指南演示了如何将它们与您的基础架构集成，但您也可以编写自己的自定义版本。 付款 1234567客户使用Anchor提供的客户端或者网页发出一笔付款;Anchor的内部服务通过桥接服务(Bridge)发出一笔付款;桥接服务决定是否需要进行合规检查并将交易的相关信息发给合规服务;合规服务通过查找联合抵制决定收款的账户ID;合规服务调用Anchor 的接口获取客户的相关信息并发送给付款组织的合规服务;如果通过了相关组织的合规验证,那么桥接服务就会创建并签发一笔交易,发送到Stellar 网络中;当交易被网络确认时,桥接服务收到消息最终更新客户的账户余额; 收款 12345678910发送者通过查找Stellar 账户ID根据客户的联合抵制发送一笔付款;发送者将付款信息与付款方的账户信息发送给收款方的合规服务;合规服务联系三个不同的服务;1.一个用于判断发送者是否允许的支付客户的制裁回调(Sanction Callback);2.如果发送者想要得到客户的信息,需要由回调来决定是否提供当前的客户信息;3.如果决定提供客户信息,通过回调的方式进行提供;发送方将交易发送到Stellar网络中;桥接服务监控Stellar网络中的这笔交易并确认是否是3.1中已经同意的付款;桥接服务通知我们的服务当前交易已经确定,可更新用户的账户余额. 三，恒星里主要概念账户 账户是Stellar中的核心数据结构,它是被存储在账本中的公钥标记的,账户中其他的数据结构都是属于某一个账户的,我们其中最熟悉的交易Transaction也是由账户创建的,每一笔交易都需要由当前账户的私钥签名 账户的构成结构 1234567891011struct AccountEntry &#123; AccountID accountID;//是当前账户的唯一标识符,在默认情况下都是账户对应的私钥; int64 balance; //当前账户持有的XLM余额 SequenceNumber seqNum;//最新交易的序列号 uint32 numSubEntries; //当前账户包含的条目数,例如:信任线,订单,数据等; AccountID* inflationDest; //标识当前账户接受通货膨胀的目标地址 uint32 flags; //标示 string32 homeDomain; Thresholds thresholds; Signer signers&lt;20&gt;; //签名&#125;; 每一个 Stellar 账户还都对应着唯一的 AccountEntry 以及多个 TrustLineEntry、OfferEntry 和 DataEntry TrustLineEntry 为例，信任线（TrustLine）其实就是 Stellar 中的某个账户接受另一个账户发行的资产，可以理解为一个关系表，其中存储着信任的 asset 以及资产的余额。 1234567struct TrustLineEntry &#123; AccountID accountID; Asset asset; int64 balance; int64 limit; uint32 flags;&#125;; Stellar 中的 DataEntry 可以保存一些与账户相关的数据 交易 交易实体的结构 12345678struct Transaction &#123; AccountID sourceAccount;//也就是发出交易的源地址，该交易必须被发出交易的源地址签名 uint32 fee; SequenceNumber seqNum; TimeBounds* timeBounds; Memo memo; Operation operations&lt;100&gt;;//就是一个操作的数组，其中包含了这一次交易需要执行的全部操作&#125;; 每一个 Transaction 都是由一组 Operation 构成的，可用的 Operation 包括 CreateAccount、Payment、PathPayment、ManageOffer 等等，以发出付款为例，我们可以向指定的账户发送特定数量的某资产。 这些 Operation 组成的交易就类似一个数据库中的事务，所有的操作要么执行成功，要么执行失败，Stellar 会保证一个交易的原子性 资产 除原生的资产 Lumens外，所有的资产都由发行人和资产类型组成。 持有 Stellar 中的资产时，其实是持有特定发行人的信誉，我们相信资产的发行人能够将 Stellar 中的资产兑换成货币、昂贵金属以及其他在网络中不存在的资源。但是当我们想要持有某一个发行人的发行的资产时，需要创建一个信任线（TrustLine），这些数据会存储在 Stellar 的账本中，也就是上面提到的 TrustLineEntry 1234567struct TrustLineEntry &#123; AccountID accountID; Asset asset; int64 balance; int64 limit; uint32 flags;&#125;; 当用户想要持有或者交易某一种资产时，它会创建一个等待发行人审批的信任线，发行人授权该信任线之后，用户才可以接受或者发出资产； 当发行人想要冻结用户访问资产的权限时，也可以随时取消用户的授权，在这之后用户就无法再发送或者接受该资产了 Stellar相关操作 https://www.stellar.org/laboratory 恒星实验室，学习恒星操作账号创建转账等 https://www.youtube.com/watch?v=OLBf6YVAjuE 使用laboratory进行发币流程 https://www.stellar.org/blog/tokens-on-stellar/（官方）","path":"posts/42221.html","date":"09-25","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Hyperledger-Fabric-Peer分析记录","text":"Fabric Peer分析 peer节点负责fabric中的交易背书和提交，每个peer里包含一个账本 peer节点之间通过Grpc进行通信，peer的常用角色类型为： 12- Endorser（背书者）：负责对来自客户端的交易提案进行检查和背书。- Committer（提交者）：负责检查交易请求，执行交易并维护区块链和账本结构。 peer代码目录 123456789101112peer├── chaincode ├── channel├── clilogging //peer clilogging命令及子命令实现├── common├── gossip //gossip最终一致性算法相关代码├── main.go //peer命令入口├── main_test.go├── mocks├── node├── testdata└── version Peer启动分析 待完成","path":"posts/46484.html","date":"08-31","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Docker日志管理记录","text":"docker日志清理 容器日志一般存放在/var/lib/docker/containers/container_id/下面 查看产生日志大小 12345678910#!/bin/shecho &quot;======== docker containers logs file size ========&quot; logs=$(find /app/install/docker/lib/docker/containers/ -name *-json.log) for log in $logs do ls -lh $log done 清理日志脚本 12345678910111213#!/bin/shecho &quot;==================== start clean docker containers logs ==========================&quot; logs=$(find /app/install/docker/lib/docker/containers/ -name *-json.log) for log in $logs do echo &quot;clean logs : $log&quot; cat /dev/null &gt; $log done echo &quot;==================== end clean docker containers logs ==========================&quot; 通过设置容器的日志大小解决 在/etc/docker/daemon.json, 增加配置项** 12&quot;log-driver&quot;:&quot;json-file&quot;, &quot;log-opts&quot;: &#123;&quot;max-size&quot;:&quot;500m&quot;, &quot;max-file&quot;:&quot;3&quot;&#125; max-size=500m，意味着一个容器日志大小上限是500M， max-file=3，意味着一个容器有三个日志，分别是id+.json、id+1.json、id+2.json。","path":"posts/43715.html","date":"08-30","excerpt":"","tags":[{"name":"docker","slug":"docker","permalink":"https://zhulg.github.io/tags/docker/"}]},{"title":"Hyperledger-Fabric-MSP分析记录","text":"fabric MSP功能及源码分析 MSP是Membership Service Provider的缩写，直译为成员关系服务提供者。 MSP作用就是负责区块链网络中对身份的管理和验证，在区块链网络中实现权限管理，包括下发、吊销及验证功能。 MSP是一个提供抽象化成员操作框架的组件,CA是MSP的具体实现。 msp常见结构 以下是一个MSP结构中常见的组成部分： 12345· 一组信任的根证书，是整个组织证书信任的基础，根证书可以签发中间层证书；· MSP的管理员的身份证书，管理员可以对MSP中证书进行管理；· 组织单元（Organizational Unit）列表（可选）；· 一组信任的中间证书，中间证书由根证书签发（可选）； · 证书撤销列表，代表被吊销的证书名单（可选）。 图片来自官网 123456789101112131415161718192021222324252627282930313233Root CAs | 根证书列表此文件夹包含，由此MSP代表的组织信任的Root CA，自签名X.509证书列表。此MSP文件夹中必须至少有一个Root CA X.509证书。这是最重要的文件夹，因为它标识了所有其它证书。Intermediate CAs | 中间证书列表此文件夹包含此组织信任的Intermediate CA的X.509证书列表。每个证书都必须由MSP中的一个Root CA签署，或者由 Intermediate CA 签署。Intermediate CA可以表示组织的不同细分或组织本身（例如，如果商业CA用于组织的身份管理）。在前一种情况下，可以使用CA层次结构中，较低的其他Intermediate CA来表示组织细分。请注意，可能有一个没有任何中间CA的功能网络，在这种情况下，此文件夹将为空。与Root CA文件夹一样，此文件夹定义了中间证书。只有拥有了这些证书，才能被系统视为组织成员的CA。Organizational Units (OUs) | 组织单元列表可选的Administrators | 管理员身份证书该文件夹包含一个身份列表，用于定义具有该组织管理员角色的参与者。对于标准MSP类型，此列表中应该有一个或多个X.509证书。Revoked Certificates | 撤销证书列表可选的KeyStore for Private Key | 私钥库该文件夹为peer 或 orderer节点（或客户端的local MSP）的local MSP定义，并包含节点的signing key（签名密钥）。 此密钥用于签署数据，作为认可阶段的一部分。该文件夹对Local MSP是必须的，并且必须包含一个私钥。 很明显，访问这个文件夹，只能由，对此peer有管理权限的用户。Channel MSP的配置不包括此部分，因为Channel MSP旨在提供纯粹的身份验证功能，而不是签署能力。TLS Root CA | TLS根证书列表此文件夹包含，此组织为TLS通信所信任的Root CA的自签名X.509证书列表。 TLS通信的一个例子是，peer需要连接到orderer以便它可以接收ledger更新。MSP TLS信息涉及网络内的节点，即对peers 和 the orderers，此文件夹中必须至少有一个TLS Root CA X.509证书。TLS Intermediate CA | TLS中间证书此文件夹包含由此MSP代表的，组织信任的用于TLS通信的Intermediate CA证书列表。当商业CA用于组织的TLS证书时，此文件夹特别有用。 它是可选的。Fabric中MSP相关实现代码都在msp目录下，目前采用了bccspmsp结构来代表一个成员身份结构，并且采用了MSPConfig（主要是其成员FabricMSPConfig）结构来代表跟该实体相关的证书信息。MSP中各实体资源的证书必须被证书信任树上的叶子节点签名。中间层签名的证书会被认为是非法实体证书。 MSP实践操作 MSP在Fabric中的作用是对用户进行管理，实践的基本步骤： 123第一，生成MSP相关的证书和签名。第二，在Peer，Orderer,Channel等组件的配置文件设置关于msp的相关信息（即：通过crypto-config.yaml，然后配置到configtx.yaml，配置到相关peer,order） 实际操作中 12345671. 编写crypto-config.yaml配置文件指定网络的拓扑结构和组织结构。2. cryptogen-生成秘钥和证书文件。快速地根据配置自动批量生成所需要的密钥和证书文件。3. 编写依赖配置文件configtx.yaml。该文件包含网络的定义，并给出了网络组件的每个网络实体的加密材料的存储位置。4. configtxgen-生成通道配置。在这个过程中，会生成系统channel的创世纪块。该创世纪块（genesis block）中包含所有MSP的验证元素。MSP验证元素有MSP身份标识（MSP identifier），root CAs，intermediate CAs，admin CAs，OU List，CRLs。 用cryptogen工具来生成的MSP需要用到的证书和相关文件。 主要包括各种证书和相关的签名。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980org1.example.com/├── ca # 存放组织Org1的根证书和对应的私钥文件，默认采用EC算法，证书为自签名。组织内的实体将基于该根证书作为证书根。│ ├── ca.org1.example.com-cert.pem│ └── dfb841b77804d726eea25231ae5e89a31901ca0538688a6d764731148f0bdc5b_sk├── msp # 存放代表该组织的身份信息。│ ├── admincerts # 组织管理员的身份验证证书，被根证书签名。│ │ └── Admin@org1.example.com-cert.pem│ ├── cacerts # 组织的根证书，同ca目录下文件。│ │ └── ca.org1.example.com-cert.pem│ └── tlscacerts # 用于TLS的CA证书，自签名。│ └── tlsca.org1.example.com-cert.pem├── peers # 存放属于该组织的所有Peer节点│ ├── peer0.org1.example.com # 第一个peer的信息，包括其msp证书和tls证书两类。│ │ ├── msp # msp相关证书 │ │ │ ├── admincerts # 组织管理员的身份验证证书。Peer将基于这些证书来认证交易签署者是否为管理员身份。│ │ │ │ └── Admin@org1.example.com-cert.pem│ │ │ ├── cacerts # 存放组织的根证书│ │ │ │ └── ca.org1.example.com-cert.pem│ │ │ ├── keystore # 本节点的身份私钥，用来签名│ │ │ │ └── 59be216646c0fb18c015c58d27bf40c3845907849b1f0671562041b8fd6e0da2_sk│ │ │ ├── signcerts # 验证本节点签名的证书，被组织根证书签名 │ │ │ │ └── peer0.org1.example.com-cert.pem│ │ │ └── tlscacerts # TLS连接用到身份证书，即组织TLS证书│ │ │ └── tlsca.org1.example.com-cert.pem│ │ └── tls # tls相关证书│ │ ├── ca.crt # 组织的根证书│ │ ├── server.crt # 验证本节点签名的证书，被组织根证书签名│ │ └── server.key # 本节点的身份私钥，用来签名│ └── peer1.org1.example.com # 第二个peer的信息，结构类似。（此处省略。）│ ├── msp│ │ ├── admincerts│ │ │ └── Admin@org1.example.com-cert.pem│ │ ├── cacerts│ │ │ └── ca.org1.example.com-cert.pem│ │ ├── keystore│ │ │ └── 82aa3f8f9178b0a83a14fdb1a4e1f944e63b72de8df1baeea36dddf1fe110800_sk│ │ ├── signcerts│ │ │ └── peer1.org1.example.com-cert.pem│ │ └── tlscacerts│ │ └── tlsca.org1.example.com-cert.pem│ └── tls│ ├── ca.crt│ ├── server.crt│ └── server.key├── tlsca # 存放tls相关的证书和私钥。│ ├── 00e4666e5f56804274aadb07e2192db2f005a05f2f8fcfd8a1433bdb8ee6e3cf_sk│ └── tlsca.org1.example.com-cert.pem└── users # 存放属于该组织的用户的实体 ├── Admin@org1.example.com # 管理员用户的信息，其中包括msp证书和tls证书两类。 │ ├── msp # msp相关证书 │ │ ├── admincerts # 组织根证书作为管理员身份验证证书 │ │ │ └── Admin@org1.example.com-cert.pem │ │ ├── cacerts # 存放组织的根证书 │ │ │ └── ca.org1.example.com-cert.pem │ │ ├── keystore # 本用户的身份私钥，用来签名 │ │ │ └── fa719a7d19e7b04baebbe4fa3c659a91961a084f5e7b1020670be6adc6713aa7_sk │ │ ├── signcerts # 管理员用户的身份验证证书，被组织根证书签名。要被某个Peer认可，则必须放到该Peer的msp/admincerts目录下 │ │ │ └── Admin@org1.example.com-cert.pem │ │ └── tlscacerts # TLS连接用的身份证书，即组织TLS证书 │ │ └── tlsca.org1.example.com-cert.pem │ └── tls # 存放tls相关的证书和私钥。 │ ├── ca.crt # 组织的根证书 │ ├── server.crt # 管理员的用户身份验证证书，被组织根证书签名 │ └── server.key # 管理员用户的身份私钥，被组织根证书签名。 └── User1@org1.example.com # 第一个用户的信息，包括msp证书和tls证书两类 ├── msp # msp证书相关信息 │ ├── admincerts # 组织根证书作为管理者身份验证证书。 │ │ └── User1@org1.example.com-cert.pem │ ├── cacerts # 存放组织的根证书 │ │ └── ca.org1.example.com-cert.pem │ ├── keystore # 本用户的身份私钥，用来签名 │ │ └── 97f2b74ee080b9bf417a4060bfb737ce08bf33d0287cb3eef9b5be9707e3c3ed_sk │ ├── signcerts # 验证本用户签名的身份证书，被组织根证书签名 │ │ └── User1@org1.example.com-cert.pem │ └── tlscacerts # TLS连接用的身份证书，被组织根证书签名。 │ └── tlsca.org1.example.com-cert.pem └── tls # 组织的根证书 ├── ca.crt # 组织的根证书 ├── server.crt # 验证用户签名的身份证书，被根组织证书签名 └── server.key # 用户的身份私钥用来签名。 msp的作用域分类 MSP出现在区块链网络中的两个地方：Channel配置（Channel MSP），以及本地（local MSP）。因此，MSP可以分为：local 和 channel MSPs localMSPlocalMSP，是为节点（peer 或 orderer）和用户（使用CLI或使用SDK的客户端应用程序的管理员）定义的。每个节点和用户都必须定义一个localMSP，以便在加入区块链的时候，进行权限验证。 channelMSP（globalMSP)channel MSP在channel层面定义管理和参与权。参与Channel的每个组织，都必须为其定义MSP。Channel上的Peers 和 orderers将在Channel MSP上共享数据，并且此后将能够正确认证Channel参与者。这意味着如果一个组织希望加入该Channel，那么需要在Channel配置中，加入一个包含该组织成员的信任链的MSP。否则来自该组织身份的交易将被拒绝。 MSP功能分类 Network MSP通过定义参与者组织MSPs，来定义网络中的成员。同时定义这些成员中哪些成员，有权执行管理任务（例如，创建Channel） Channel MSPChannel提供了一组特定的组织之间的私人通信，这些组织又对其进行管理控制。在该Channel的MSP上下文中的Channel policies定义谁能够参与Channel上的某些操作，例如添加组织或实例化chaincodes。 Peer MSP此Local MSP在每个peer的文件系统上定义，并且每个peer都有一个MSP实例。从概念上讲，它执行的功能与Channel MSP完全相同，限制条件是它仅用于定义它的peer上。 Orderer MSP与peer MSP一样，orderer local MSP也在节点的文件系统上定义，并且仅用于该节点。与peer 节点相似，orderer也由单个组织拥有，因此只有一个MSP来列出其信任的参与者或节点。 msp与组织的对应关系1，组织与MSP之间建立映射关系 建议实际的组织和MSP之间建立一一对应关系。当然也可以选择其他类型的映射关系 一个组织对应多个MSP的情况这种情况是一个组织有多个部门，从方便管理的角度或者隐私保护的角度而言，每个部门都要设置不同的MSP。每个Peer节点只设置一个MSP，同一组织内不同MSP的Peer节点之间不能互相认证，这样相同组织的不同部门之间不会同步数据，数据不能共享。 多个组织对应一个MSP这种情况是同一个联盟的不同组织之间采用相同的成员管理架构，数据会在不同组织之间同步。在Peer节点之间的Gossip通信中，数据是在相同通道配置了相同MSP的Peer节点之间同步的。如果多个组织对应一个MSP，则数据就不会限制在组织内部，会跨组织进行同步。这种情况我觉得很有应用场景。比如，C9联盟可以在同一个MSP管理下，既能够确保信任的基础，又能够实现数据的共享。其实这是由MSP定义的粒度问题，一个MSP可以和一个组织对应，也可以和多个组织对应，还可以和一个组织内部的多个部门对应，根据MSP配置好Peer节点后，数据同步就限制在了MSP定义的范围内。 2，一个组织内部实现不同的权限控制 给组织内的所有部门定义一个MSP给Peer节点配置MSP的时候，包含相同的可信根CA证书列表、中间CA证书、管理员证书，不同的Peer节点设置不同的所属部门。节点所属的部门是利用证书和部门之间映射的OrganizationalUnitIdentifiers定义的，它包含在MSP目录下配置文件“config.yaml”中。按照基于部门验证的方法来定义交易背书策略和通道管理策略，这样就可以实现不同的权限控制了。这种方法会有一个问题数据实际还是会在不同的Peer节点之间同步。因为Peer节点在识别组织身份类型OrgIdentityType的时候获取的是MSP标识，它会认为通道内相同MSP的节点都是可以分发数据的。 给组织内的每个部门单独定义MSP给Peer节点配置MSP的时候，不同部门配置的可信中间CA证书、管理员证书可以是不同的，不同部门成员的证书路径也是不同的。这种方式解决了所有部门定义在一个MSP中的问题，但是会带来管理上的复杂度。 MSP相关核心源码 MSP源码部分位于fabric下的msp目录 123456789101112131415161718192021222324252627282930313233343536msp├── cache│ ├── cache.go│ └── cache_test.go├── cert.go //证书相关结构体及方法。├── cert_test.go├── configbuilder.go//提供读取证书文件并将其组装成MSP等接口所需的数据结构，以及转换配置结构体（FactoryOpts-&gt;MSPConfig）等工具函数├── configbuilder_test.go├── factory.go├── factory_test.go├── idemixmsp.go├── idemixmsp_test.go├── identities.go//实现Identity、SigningIdentity接口├── mgmt│ ├── deserializer.go//MSPPrincipalGetter接口及其实现│ ├── deserializer_test.go│ ├── mgmt.go//msp相关管理方法实现│ ├── mgmt_test.go│ ├── peermsp_test.go│ ├── principal.go│ ├── principal_test.go│ └── testtools├── mocks│ └── mocks.go├── msp.go //定义接口MSP、MSPManager、Identity、SigningIdentity等├── msp_test.go├── mspimpl.go├── mspimplsetup.go├── mspimplvalidate.go├── mspmgrimpl.go //实现MSP接口，即bccspmsp├── mspwithintermediatecas_test.go├── nodeous_test.go├── ouconfig_test.go├── revocation_test.go├── testdata//省略└── tls_test.go 分析 有时间在总结","path":"posts/7421.html","date":"08-30","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Hyperledger Fabric Orderer分析记录","text":"Fabric Orderer主要作用Orderer，为排序节点，对所有发往网络中的交易进行排序，将排序后的交易进行出块，之后提交给Committer进行提交处理。 Orderer代码在orderer目录,基于1.2代码 123456789101112131415161718192021222324orderer├── README.md├── common│ ├── blockcutter //切块代码│ ├── bootstrap //初始区块的提供方式│ ├── broadcast //广播代码│ ├── localconfig //本地配置相关实现│ ├── metadata //通过metadata.go实现获取版本信息。│ ├── msgprocessor //消息处理│ ├── multichannel│ ├── performance│ └── server├── consensus //共识代码│ ├── consensus.go│ ├── kafka│ └── solo├── main.go //main入口├── mocks│ ├── common│ └── util└── sample_clients ├── broadcast_config ├── broadcast_msg └── deliver_stdout Orderer核心启动代码 通过 orderer 包下的 main() 方法实现，会进一步调用到 orderer/common/server 包中的 Main() 方法。 123456789101112131415161718192021func Main() &#123; //解析命令行参数 fullCmd := kingpin.MustParse(app.Parse(os.Args[1:])) // \"version\" command if fullCmd == version.FullCommand() &#123; fmt.Println(metadata.GetVersionInfo()) return &#125; //加载本地配置 conf, err := localconfig.Load() if err != nil &#123; logger.Error(\"failed to parse config: \", err) os.Exit(1) &#125; initializeLoggingLevel(conf) initializeLocalMsp(conf) prettyPrintStruct(conf) Start(fullCmd, conf)&#125; localconfig.Load（）：从本地配置文件和环境变量中读取配置信息，构建配置树结构。 initializeLoggingLevel(conf)：配置日志级别。 initializeLocalMsp(conf)：配置 MSP 结构。 prettyPrintStruct(conf)： 打印相关 Start(fullCmd, conf)：完成启动后的核心工作。 1、加载命令行工具并解析命令行参数orderer的命令行工具，基于gopkg.in/alecthomas/kingpin.v2实现，地址：http://gopkg.in/alecthomas/kingpin.v2。相关代码如下 123456789var ( app = kingpin.New(\"orderer\", \"Hyperledger Fabric orderer node\") //创建子命令start和version start = app.Command(\"start\", \"Start the orderer node\").Default() version = app.Command(\"version\", \"Show version information\") benchmark = app.Command(\"benchmark\", \"Run orderer in benchmark mode\"))//代码在orderer/main.go metadata.GetVersionInfo()代码如下： 12345678910111213func GetVersionInfo() string &#123; Version = common.Version if Version == \"\" &#123; Version = \"development build\" &#125; return fmt.Sprintf(\"%s:\\n Version: %s\\n Commit SHA: %s\\n\"+ \" Go version: %s\\n OS/Arch: %s\\n\"+ \" Experimental features: %s\\n\", ProgramName, Version, common.CommitSHA, runtime.Version(), fmt.Sprintf(\"%s/%s\", runtime.GOOS, runtime.GOARCH), common.Experimental)&#125;//代码在orderer/metadata/metadata.go 2、加载配置文件配置文件的加载，基于viper实现，即https://github.com/spf13/viper。 12conf, err := localconfig.Load()//代码在orderer/main.go localconfig.Load()代码如下： 1234567891011121314151617181920212223func Load() (*TopLevel, error) &#123; config := viper.New() //cf.InitViper作用为加载配置文件路径及设置配置文件名称 coreconfig.InitViper(config, \"orderer\") config.SetEnvPrefix(Prefix) config.AutomaticEnv() replacer := strings.NewReplacer(\".\", \"_\") config.SetEnvKeyReplacer(replacer) if err := config.ReadInConfig(); err != nil &#123; return nil, fmt.Errorf(\"Error reading configuration: %s\", err) &#125; var uconf TopLevel if err := viperutil.EnhancedExactUnmarshal(config, &amp;uconf); err != nil &#123; return nil, fmt.Errorf(\"Error unmarshaling config into struct: %s\", err) &#125; uconf.completeInitialization(filepath.Dir(config.ConfigFileUsed())) return &amp;uconf, nil&#125;//代码在orderer/localconfig/config.go 3、初始化日志系统（日志输出、日志格式、日志级别等）12initializeLoggingLevel(conf)//代码在orderer/main.go initializeLoggingLevel(conf)代码如下： 12345678func initializeLoggingLevel(conf *localconfig.TopLevel) &#123; //初始化日志输出对象及输出格式 flogging.InitBackend(flogging.SetFormat(conf.General.LogFormat), os.Stderr) //按初始化日志级别 flogging.InitFromSpec(conf.General.LogLevel)&#125;//代码在orderer/main.go 4、初始化本地MSP1initializeLocalMsp(conf) initializeLocalMsp(conf)代码如下： 12345678func initializeLocalMsp(conf *localconfig.TopLevel) &#123; // Load local MSP err := mspmgmt.LoadLocalMsp(conf.General.LocalMSPDir, conf.General.BCCSP, conf.General.LocalMSPID) if err != nil &#123; // Handle errors reading the config file logger.Fatal(\"Failed to initialize local MSP:\", err) &#125;&#125;//代码在orderer/main.go 5,启动Start方法1234567891011121314151617181920212223242526272829303132333435func Start(cmd string, conf *localconfig.TopLevel) &#123; signer := localmsp.NewSigner() // 初始化签名结构 serverConfig := initializeServerConfig(conf) grpcServer := initializeGrpcServer(conf, serverConfig) caSupport := &amp;comm.CASupport&#123; AppRootCAsByChain: make(map[string][][]byte), OrdererRootCAsByChain: make(map[string][][]byte), ClientRootCAs: serverConfig.SecOpts.ClientRootCAs, &#125; tlsCallback := func(bundle *channelconfig.Bundle) &#123; // only need to do this if mutual TLS is required if grpcServer.MutualTLSRequired() &#123; logger.Debug(\"Executing callback to update root CAs\") updateTrustedRoots(grpcServer, caSupport, bundle) &#125; &#125; manager := initializeMultichannelRegistrar(conf, signer, tlsCallback) mutualTLS := serverConfig.SecOpts.UseTLS &amp;&amp; serverConfig.SecOpts.RequireClientCert server := NewServer(manager, signer, &amp;conf.Debug, conf.General.Authentication.TimeWindow, mutualTLS) switch cmd &#123; case start.FullCommand(): // \"start\" command logger.Infof(\"Starting %s\", metadata.GetVersionInfo()) initializeProfilingService(conf) ab.RegisterAtomicBroadcastServer(grpcServer.Server(), server) logger.Info(\"Beginning to serve requests\") grpcServer.Start() case benchmark.FullCommand(): // \"benchmark\" command logger.Info(\"Starting orderer in benchmark mode\") benchmarkServer := performance.GetBenchmarkServer() benchmarkServer.RegisterService(server) benchmarkServer.Start() &#125;&#125; 5-1 start方法里 经过initializeServerConfig(conf) initializeGrpcServer(conf, serverConfig)启动Grpc服务 初始化initializeMultiChainManager（启动共识插件，接收和处理消息） 1manager := initializeMultiChainManager(conf, signer) initializeMultiChainManager(conf, signer)代码如下： 1234567891011121314151617181920func initializeMultichannelRegistrar(conf *localconfig.TopLevel, signer crypto.LocalSigner, callbacks ...func(bundle *channelconfig.Bundle)) *multichannel.Registrar &#123; // 创建操作账本的工厂结构 lf, _ := createLedgerFactory(conf) // Are we bootstrapping? 如果是首次启动情况，默认先创建系统通道的本地账本结构 if len(lf.ChainIDs()) == 0 &#123; initializeBootstrapChannel(conf, lf)//初始化引导通道（获取初始区块、创建链、添加初始区块） &#125; else &#123; logger.Info(\"Not bootstrapping because of existing chains\") &#125; //初始化共识插件，共识插件负责跟后台的队列打交道 consenters := make(map[string]consensus.Consenter) consenters[\"solo\"] = solo.New() consenters[\"kafka\"] = kafka.New(conf.Kafka) // 创建各个账本的管理器（Registrar）结构，并启动共识过程 return multichannel.NewRegistrar(lf, consenters, signer, callbacks...) //LedgerFactory、Consenter、签名&#125; 5-1-1: initializeMultiChainManager方法总结1234创建账本操作的工厂结构；如果是新启动情况，利用给定的系统初始区块文件初始化系统通道的相关结构；完成共识插件（包括 solo 和 kafka 两种）的初始化；multichannel.NewRegistrar(lf, consenters, signer) 方法会扫描本地账本数据（此时至少已存在系统通道），创建 Registrar 结构，并为每个账本都启动共识（如 Kafka 排序）过程。 5-1-2: multichannel.NewRegistrar方法 核心相关代码 1234567891011121314existingChains := ledgerFactory.ChainIDs()for _, chainID := range existingChains &#123; // 启动本地所有的账本结构的共识过程 if _, ok := ledgerResources.ConsortiumsConfig(); ok &#123; // 如果是系统账本（默认在首次启动时会自动创建） chain := newChainSupport(r, ledgerResources, consenters, signer) chain.Processor = msgprocessor.NewSystemChannel(chain, r.templator, msgprocessor.CreateSystemChannelFilters(r, chain)) r.chains[chainID] = chain r.systemChannelID = chainID r.systemChannel = chain defer chain.start() // 启动共识过程 else // 如果是应用账本 chain := newChainSupport(r, ledgerResources, consenters, signer) r.chains[chainID] = chain chain.start() // 启动共识过程,以 Kafka 共识插件为例，最终以协程方式调用到 orderer.consensus.kafka 包中的 startThread() 方法，将在后台持续运行 &#125; 5-2, 根据输入命令选择启动方式 (“start”下)123456//启动Go profiling服务（Go语言分析工具）initializeProfilingService(conf)//绑定 gRPC 服务并启动ab.RegisterAtomicBroadcastServer(grpcServer.Server(), server)logger.Info(\"Beginning to serve requests\")grpcServer.Start()","path":"posts/43591.html","date":"08-29","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Fabric工作机制及核心组件总结","text":"本文总结fabric工作机制及底层数据存储和上链过程的认识，帮助加深对fabric的理解和认识。 一, fabric1.0之后的运行架构 登记证书（0 Enroll): 使用fabric SDK向CA获取用户的证书（图上membership 服务，就是上图中的注册登记、身份认证，CA是MSP的实现） 发送提案(1 Endrose proposal)： 拿到正式根据背书策略发送提案到背书节点（背书策略在chaincode实例化时已经指定），到背书节点后会进行证书验证，并模拟计算chaincode里相关代码。 返回背书内容（图上没表示出来): 背书节点会把背书内容返回给客户端,客户端会收集到相关背书节点的背书内容，验证背书节点有效性（有几个背书节点要收到几个节点背书内容） 提交交易到order(2 Submit Transaction/ 3 Relay Submit tX): 提交事务到order里，图上显示是先到peer上，在转播到order,实际是直接到order上,order对交易进行排序，根据出块策略进行出块。 传递区块(4 Deliver batch)将排序后的区块Deliver到leader peer上, 底层通过gossip协议进行同步到各节点，节点再次验证计算结果，与之前计算一致，就写人到Ledger，写完账本通过event通知到客户端。 二，fabric交易流程 交易流程基本上也展示了fabric在运行时的架构，在官网的这个图上可以比较详细看到交易涉及的流程 参考另一篇笔记 三，fabric数据存储方式及数据结构 fabric的数据是一个个数据块组成链式结构，第一个区块为创世区块，后边区块链接上一个区块的hash头部区块 每一个区块有区块头和区块体组成，区块体里存储交易的数据。 1,区块构成 区块头部分:有当前number,上一个区块hash，当前区块体数据hash。 区块数据:包含多条交易数据 区块元数据:包含4种元数据，SIGNATURES、 LAST_CONFIG、ORDERER和TRANSACTIONS_FILTER，前三个是Order service添加进去的，最后一个是Committer添加的。 参考更多介绍 2,Fabric账本结构 fabric的账本存在与每一个peer里，数据存储分为文件存储和数据库（leveldb,couchdb）,文件存储部分用来存储区块数据，写入到BlockFile_xx中 先通过一个图看下账本基本结构，进入peer容器里，到/var/hyperledger/production/ledgersData下。(这个使用了couchdb所以下边没有stateLeveldb) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647root@1658e694975d:/var/hyperledger/production# tree ledgersData/ledgersData/|-- chains| |-- chains| | `-- gomevisionchannel| | |-- blockfile_000000| | |-- blockfile_000001| | |-- blockfile_000002| | |-- blockfile_000003| | |-- blockfile_000004| | |-- blockfile_000005| | |-- blockfile_000006| | |-- blockfile_000007| | |-- blockfile_000008| | `-- blockfile_000009| `-- index| |-- 000168.ldb| |-- 000237.ldb| |-- 000238.ldb| |-- 000239.ldb| |-- 000240.ldb| |-- 000241.ldb| |-- 000242.ldb| |-- 000243.ldb| |-- 000244.ldb| |-- 000245.ldb| |-- 000246.ldb| |-- 000247.ldb| |-- 000248.ldb| |-- CURRENT| |-- LOCK| |-- LOG| `-- MANIFEST-000263|-- historyLeveldb| |-- 000010.log| |-- 000012.ldb| |-- CURRENT| |-- LOCK| |-- LOG| `-- MANIFEST-000011`-- ledgerProvider |-- 000002.ldb |-- 000005.log |-- CURRENT |-- LOCK |-- LOG `-- MANIFEST-000006 chains：chains/chains下包含的mychannel是对应的channel的名称，因为Fabric是有多channel的机制，而channel之间的账本是隔离的，每个channel都有自己的账本空间。 chains/index下面包含的是levelDB数据库文件，DB中存储的是区块索引部分。（从indexDB中读取Block的位置信息（blockfile的编号、位置偏移量，打开对应的blockfile，位移到指定位置，读取Block数据） stateLeveldb：存储的是链码 putstate写入的数据(我这个用的couchdb所以没有出现) ledgerProvider：数据库内存储的是当前节点所包含channel的信息。主要是为了Fabric的多channel机制服务的; historyLeveldb：数据库内存储的链码写入的key的历史记录的索引地址。 四，Fabric数据交易结构 数据交易的结构在源码 protos/common/common.pb.go，交易的封装即Envelope结构体 Envelope直译为信封，封装Payload和Signature。Payload为有效负荷，又包括Header和Data,其中Header又包括ChannelHeader，SignatureHeader 1234567// Envelope wraps a Payload with a signature so that the message may be authenticatedtype Envelope struct &#123; // A marshaled Payload Payload []byte `protobuf:\"bytes,1,opt,name=payload,proto3\" json:\"payload,omitempty\"` // A signature by the creator specified in the Payload header Signature []byte `protobuf:\"bytes,2,opt,name=signature,proto3\" json:\"signature,omitempty\"`&#125; Payload结构体： 1234type Payload struct &#123; Header *Header //Header Data []byte //Transaction序列化&#125; Payload里Header结构： 1234type Header struct &#123; ChannelHeader []byte `protobuf:\"bytes,1,opt,name=channel_header,json=channelHeader,proto3\" json:\"channel_header,omitempty\"` SignatureHeader []byte `protobuf:\"bytes,2,opt,name=signature_header,json=signatureHeader,proto3\" json:\"signature_header,omitempty\"`&#125; 网上一张比较直观交易结构图，交易的数据结构进行了划分。 Transaction相关结构体 1234type Transaction struct &#123; Actions []*TransactionAction //Payload.Data是个TransactionAction数组，容纳每个交易&#125;//代码在protos/peer/transaction.pb.go sTransactionAction结构体： 12345type TransactionAction struct &#123; Header []byte Payload []byte&#125;//代码在protos/peer/transaction.pb.go ChaincodeActionPayload相关结构体 12345type ChaincodeActionPayload struct &#123; ChaincodeProposalPayload []byte Action *ChaincodeEndorsedAction&#125;//代码在protos/peer/transaction.pb.go ChaincodeEndorsedAction结构体： 12345type ChaincodeEndorsedAction struct &#123; ProposalResponsePayload []byte //ProposalResponsePayload序列化 Endorsements []*Endorsement&#125;//代码在protos/peer/transaction.pb.go ProposalResponsePayload结构体： 12345type ProposalResponsePayload struct &#123; ProposalHash []byte Extension []byte //ChaincodeAction序列化&#125;//代码在protos/peer/proposal_response.pb.go ChaincodeAction结构体： 1234567type ChaincodeAction struct &#123; Results []byte //TxRwSet序列化 Events []byte Response *Response ChaincodeId *ChaincodeID&#125;//代码在protos/peer/proposal.pb.go 五，Fabric的智能合约chaincode Fabric项目中提供了用户链码和系统链码 用户chaincode运行在单独的容器中，提供对上层应用的支持，系统chaincode则嵌入在系统内，提供对系统进行配置、管理的支持。 开发过程中通过调用chaincode达到对账本的操作。 系统chaincode则维护整改交易过程中的各个环节操作。 参考网上一张图用于说明 chaincode有对应的生命周期，install, instantiate,invoke,query,upgrade等操作，声明周期有系统链码LSCC进行管理 chaincode初始化会把chaincode放到各个peer内部。 用户chaincode生成容器方式与peer交互 书写用户链码2个重要的方法 12Init：当链码收到实例化（instantiate）或者升级（update）类型的交易时，Init被调用。 Invoke：当链码收到调用（invoke）或者查询（query）类型的交易时，invoke方法被调用。 用户链码容器通过Grpc与peer进行通信，链码容器启动后，会向Peer节点进行注册，gRPC地址为/protos.ChaincodeSupport/Register，消息为ChaincodeMessage结构 12345678910111213type ChaincodeMessage struct &#123; Type ChaincodeMessage_Type `protobuf:\"varint,1,opt,name=type,enum=protos.ChaincodeMessage_Type\" json:\"type,omitempty\"` Timestamp *google_protobuf1.Timestamp `protobuf:\"bytes,2,opt,name=timestamp\" json:\"timestamp,omitempty\"` Payload []byte `protobuf:\"bytes,3,opt,name=payload,proto3\" json:\"payload,omitempty\"` Txid string `protobuf:\"bytes,4,opt,name=txid\" json:\"txid,omitempty\"` Proposal *SignedProposal `protobuf:\"bytes,5,opt,name=proposal\" json:\"proposal,omitempty\"` // event emitted by chaincode. Used only with Init or Invoke. // This event is then stored (currently) // with Block.NonHashData.TransactionResult ChaincodeEvent *ChaincodeEvent `protobuf:\"bytes,6,opt,name=chaincode_event,json=chaincodeEvent\" json:\"chaincode_event,omitempty\"` // channel id ChannelId string `protobuf:\"bytes,7,opt,name=channel_id,json=channelId\" json:\"channel_id,omitempty\"`&#125; Order组件 待完成 MSP 待完成","path":"posts/23433.html","date":"08-22","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"关于区块链账户模型记录","text":"在区块链的账号数据模型里，一种方法称为UTXO（未使用交易输出）模型，另一种是账户/余额模型。 UTXO模型由比特币使用，而以太坊，fabric使用账户/余额模型. UTXO模型 UTXO的英文全称为Unspent Transaction Output,（未消费的交易输出）。 UTXO理解为交易过程中的一个数据结构,包含交易数据和执行脚本(Pubkey scripts),是某地址已经收到的但是尚未花费出去的加密数字货币 UTXO模型中，交易处理的基本单位是一个交易记录，任何一个交易的输入都是某一个交易的输出。 某一个账户中的余额并不是由一个数字表示的，而是由当前区块链网络中所有跟当前账户有关的 UTXO 组成的，多个未消掉的UXTO why UTXO 比特币是去中心化的设计，所以没有一个或者几个中心机构来对账、清洁算,它需要有自己的一套清洁算系统。而这套系统就是UTXO支付模型 整个交易、结算的过程都是由UTXO来完成的，其完全不借助第三方，也几乎不会发生算错的情况。 UTXO特点 每个UTXO都是独一无二的，就好像带有编码的钞票一样（对应现实生活人民币找零） 相比钞票来说，UTXO更灵活，并没有固定面额的限制，任意数额都可以 UTXO是不能分割的，只能被消耗掉 在交易前后，UTXO的数量可能增多，也可能减少 每笔交易的输入和输出都是有关系的，可以通过UTXO不停往前追溯，直到挖矿 账户余额模型 目前各大银行使用的，支付宝使用的，一个中心话结算，A转账给B，A减多少，B加多少，在一个事务里完成。 ####二者对比 UTXO模型的好处是： 12可扩展性 - 由于可以同时处理多个UTXO，因此可以实现并行事务并鼓励可伸缩性创新。隐私 - 甚至比特币也不是一个完全匿名的系统，但只要用户为每笔交易使用新地址，UTXO就可以提供更高级别的隐私。 如果需要增强隐私性，可以考虑更复杂的方案，例如环签名。 账户/余额模型的好处是：12简单性 - 以太坊选择了一种更直观的模式，以便为复杂智能合约的开发人员带来益处，尤其是那些需要国家信息或涉及多方的开发人员。 一个例子是一个智能合约，跟踪各国根据它们执行不同的任务。 UTXO的无状态模型会迫使交易包含状态信息，这不必要地使合约的设计复杂化。效率 - 除了简单之外，账户/余额模型更加高效，因为每笔交易只需要验证发送账户是否有足够的余额来支付交易。","path":"posts/41894.html","date":"08-21","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Android Gradle依赖下载巨慢问题记录","text":"有段时间没写Android项目了，最近android9也发布了。当年也是从1.5开始的android之路。。。时间飞快。 今天构建一个项目，从头搭，发现android依赖库居然很长时间都没拉下了。。。已经科学上网。 想起各种代理，准备找找阿里云仓库解决下 在repositories里使用阿里仓库 12345678910 repositories &#123;// google()// jcenter() maven &#123; url &apos;https://plugins.gradle.org/m2/&apos; &#125; maven &#123; url &apos;http://maven.aliyun.com/nexus/content/repositories/google&apos; &#125; maven &#123; url &apos;http://maven.aliyun.com/nexus/content/groups/public/&apos; &#125; maven &#123; url &apos;http://maven.aliyun.com/nexus/content/repositories/jcenter&apos;&#125; &#125; 在allprojects里 123456789101112131415allprojects &#123; repositories &#123;// jcenter()// maven &#123;// url &quot;https://maven.google.com&quot;// &#125; maven &#123; url &apos;https://plugins.gradle.org/m2/&apos; &#125; maven &#123; url &apos;http://maven.aliyun.com/nexus/content/repositories/google&apos; &#125; maven &#123; url &apos;http://maven.aliyun.com/nexus/content/groups/public/&apos; &#125; maven &#123; url &apos;http://maven.aliyun.com/nexus/content/repositories/jcenter&apos;&#125; &#125;&#125; 再次进行同步，依赖很快同步下来。","path":"posts/4988.html","date":"08-09","excerpt":"","tags":[{"name":"android","slug":"android","permalink":"https://zhulg.github.io/tags/android/"},{"name":"gradle","slug":"gradle","permalink":"https://zhulg.github.io/tags/gradle/"}]},{"title":"fabric1.2多机部署e2e_cli例子","text":"fabric1.2版本多机器部署e2e_cli 在实际的生产环境fabric的多个peer节点跟着组织接入网络，这些机器分布在各个地方，各个机器上。 而例子是在一台机器部署演示，故进行生产环境拆分部署验证。（后续进行k8s验证使用） 目前准备拆分1.2版本e2e_cli例子，有4个kafka,3个zookeeper,1个order,4个peer,1个cli. 个人笔记记录，如需交流邮件（lg.json@gmail.com） 一，机器准备： 为验证分布式多机器部署，拆分思路：拆分4个peer到(41,42,37,38机器上)，cli与pee0共在41机器上。 zookeeper有3个，拆分到32，33，34机器上 kafka有4个，（暂不拆分，与拆分zookeeper同理），orderer和kafka保留在40机器上。 1234567891010.112.178.40 （order,kafka）10.112.178.41 (peer0-org1,cli)10.112.178.42 (peer1-org1)10.112.178.37 (peer0-org2)10.112.178.38 (peer1-org2)10.112.178.32 (zookeeper0)10.112.178.33 (zookeeper1)10.112.178.34 (zookeeper2) 1，机器环境准备： 安装crul sudo yum install curl 出现错误执行curl更新： 12curl: (35) Peer reports incompatible or unsupported protocol version.使用该命令更新： sudo yum update -y nss curl libcurl docker卸载 1234567891011sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine \\ docker-ce 使用这个脚本快速安装docker 1234567891011121314151617181920#!/bin/shsudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine \\ docker-cesudo yum install -y yum-utils device-mapper-persistent-data lvm2sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.reposudo yum makecache fastsudo yum -y install docker-ceecho &quot;====================begin start docker ==========================&quot;sudo service docker startecho &quot;==================== end ==========================&quot; 安装docker composer 12345sudo curl -L https://github.com/docker/compose/releases/download/1.22.0/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-composesudo chmod +x /usr/local/bin/docker-composedocker-compose --version 安装go https://studygolang.com/dl 从golang中文网下载需要的包，1.10.3 123curl -O https://dl.google.com/go/go1.10.3.linux-amd64.tar.gz //下载sudo tar -C /usr/local -xzf go1.10.3.linux-amd64.tar.gz //解压 go环境变量 sudo vim /etc/profile 添加如下，第一个是系统go的地址。后两个是你相关的go的工作目录，和你go的工程生成的bin。 123export PATH=$PATH:/usr/local/go/binexport GOPATH=$HOME/goexport PATH=$PATH:$GOPATH/bin 下载fabric1.2镜像和官方例子(一般是下载不了的，通过访问地址，保存成sh在执行就搞定) 1curl -sSL http://bit.ly/2ysbOFE | bash -s 1.2.0 跑个例子验证下环境 cd fabric-samples/first-network 1./byfn.sh up 2， 安装其他机器环境 把下载fabric镜像直接考过去，直接下太慢。 12docker save $(docker images -q) -o images1.2 （这种方式导入时还需要重新建tag）docker save $(docker images |grep hyperledger | awk &#123;&apos;print $1&apos;&#125; ) -o myimages1.2 //这种可以直接导入不需重建tag scp到其他机器上，进行docker导入 1docker load - i myimages1.2 其他环境也同上安装下，使各个机器环境一致，特别是docker。 二， 进行peer拆分 进入40机器上e2e_cli例子下 ./network_setup.sh up 正常了 ./network_setup.sh down 仅验证环境 执行./generateArtifacts.sh mychannel 系统会创建channel-artifacts文件夹，里面包含了mychannel这个通道相关的文件，另外还有一个crypto-config文件夹，里面包含了各个节点的公私钥和证书的信息。 在其他机器上源码例子里，先删掉e2e_cli,在使用40机器上e2e_cli(确保40上执行了./generateArtifacts.sh mychannel后)，确保各个机器使用相同的私钥正式。 12xx替换成41,42,37,38，都用40上的e2e_cliscp -r e2e_cli/ zhulianggang@10.112.178.XX:/home/zhulianggang/go/src/github.com/hyperledger/fabric/examples/ 1，41机器上peer0.org1.example.com 41机器上e2e_cli下创建docker-compose-peer.yaml,内容如下： 41上运行pee0,和cli，注意 extra_hosts: 使用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#version: &apos;2&apos;services: peer0.org1.example.com: container_name: peer0.org1.example.com extends: file: base/docker-compose-base.yaml service: peer0.org1.example.com extra_hosts: - &quot;orderer.example.com:10.112.178.40&quot; cli: container_name: cli image: hyperledger/fabric-tools tty: true environment: - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_LOGGING_LEVEL=DEBUG - CORE_PEER_ID=cli - CORE_PEER_ADDRESS=peer0.org1.example.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_PEER_LOCALMSPTYPE=bccsp - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer # command: /bin/bash -c &apos;./scripts/script.sh $&#123;CHANNEL_NAME&#125;; sleep $TIMEOUT&apos; volumes: - /var/run/:/host/var/run/ - ../chaincode/go/:/opt/gopath/src/github.com/hyperledger/fabric/examples/chaincode/go - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ - ./scripts:/opt/gopath/src/github.com/hyperledger/fabric/peer/scripts/ - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts depends_on: # - orderer.example.com - peer0.org1.example.com # - peer1.org1.example.com # - peer0.org2.example.com # - peer1.org2.example.com extra_hosts: - &quot;orderer.example.com:10.112.178.40&quot; - &quot;peer0.org1.example.com:10.112.178.41&quot; - &quot;peer1.org1.example.com:10.112.178.42&quot; - &quot;peer0.org2.example.com:10.112.178.37&quot; - &quot;peer1.org2.example.com:10.112.178.38&quot; 2，42机器上peer1.org1.example.com 42机器上创建docker-compose-peer.yaml 12345678910version: &apos;2&apos;services: peer1.org1.example.com: container_name: peer1.org1.example.com extends: file: base/docker-compose-base.yaml service: peer1.org1.example.com extra_hosts: - &quot;orderer.example.com:10.112.178.40&quot; 3，37机器上peer1.org1.example.com 37机器上创建docker-compose-peer.yaml 12345678910version: &apos;2&apos;services: peer0.org2.example.com: container_name: peer0.org2.example.com extends: file: base/docker-compose-base.yaml service: peer0.org2.example.com extra_hosts: - &quot;orderer.example.com:10.112.178.40&quot; 4，38机器上peer1.org1.example.com 38机器上创建docker-compose-peer.yaml 12345678910version: &apos;2&apos;services: peer1.org2.example.com: container_name: peer1.org2.example.com extends: file: base/docker-compose-base.yaml service: peer1.org2.example.com extra_hosts: - &quot;orderer.example.com:10.112.178.40&quot; 三， 进行zookeeper拆分 分别在32，33，34上创建zookeeper_0.yaml,zookeeper_1.yaml,zookeeper_2,yaml ZOO_SERVERS本机的需要修改0.0.0.0，如果写为ip，则2888:3888只为本机开放，外面机器无法访问。 zookeeper_0.yaml内容 12345678910version: &apos;2&apos;services: zookeeper0: container_name: zookeeper0 extends: file: base/docker-compose-base.yaml service: zookeeper environment: - ZOO_MY_ID=1 - ZOO_SERVERS=server.1=0.0.0.0:2888:3888 server.2=10.112.178.33:2888:3888 server.3=10.112.178.34:2888:3888 zookeeper_1.yaml内容 可以使用 extra_hosts对应，也可以直接使用ip如上边zookeeper_0那样使用,但本机器必须0.0.0.0，否则zookepper无法使用 123456789101112131415version: &apos;2&apos;services: zookeeper1: container_name: zookeeper1 extends: file: base/docker-compose-base.yaml service: zookeeper environment: - ZOO_MY_ID=2 - ZOO_SERVERS=server.1=zookeeper0:2888:3888 server.2=0.0.0.0:2888:3888 server.3=zookeeper2:2888:3888 extra_hosts: - &quot;zookeeper0:10.112.178.32&quot; - &quot;zookeeper1:10.112.178.33&quot; - &quot;zookeeper2:10.112.178.34&quot; zookeeper_2.yaml内容 123456789101112131415version: &apos;2&apos;services: zookeeper2: container_name: zookeeper2 extends: file: base/docker-compose-base.yaml service: zookeeper environment: - ZOO_MY_ID=3 - ZOO_SERVERS=server.1=zookeeper0:2888:3888 server.2=zookeeper1:2888:3888 server.3=0.0.0.0:2888:3888 extra_hosts: - &quot;zookeeper0:10.112.178.32&quot; - &quot;zookeeper1:10.112.178.33&quot; - &quot;zookeeper2:10.112.178.34&quot; 四，对40上docker-peer-cli继续修改 这里面去掉了cli,去掉了zookeeper，去掉了zookeeper的依赖。 kafka上KAFKA_ZOOKEEPER_CONNECT部分可以使用zookeeper，需要进行extra_hosts一块用。也可以直接用ip使用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#version: &apos;2&apos;services:# zookeeper0:# container_name: zookeeper0# extends:# file: base/docker-compose-base.yaml# service: zookeeper# environment:# - ZOO_MY_ID=1# - ZOO_SERVERS=server.1=zookeeper0:2888:3888 server.2=zookeeper1:2888:3888 server.3=zookeeper2:2888:388# zookeeper1:# container_name: zookeeper1# extends:# file: base/docker-compose-base.yaml# service: zookeeper# environment:# - ZOO_MY_ID=2# - ZOO_SERVERS=server.1=zookeeper0:2888:3888 server.2=zookeeper1:2888:3888 server.3=zookeeper2:2888:388# # zookeeper2:# container_name: zookeeper2# extends:# file: base/docker-compose-base.yaml# service: zookeeper# environment:# - ZOO_MY_ID=3# - ZOO_SERVERS=server.1=zookeeper0:2888:3888 server.2=zookeeper1:2888:3888 server.3=zookeeper2:2888:388# kafka0: container_name: kafka0 extends: file: base/docker-compose-base.yaml service: kafka environment: - KAFKA_BROKER_ID=0 - KAFKA_MIN_INSYNC_REPLICAS=2 - KAFKA_DEFAULT_REPLICATION_FACTOR=3 - KAFKA_ZOOKEEPER_CONNECT=zookeeper0:2181,zookeeper1:2181,zookeeper2:2181# depends_on:# - zookeeper0# - zookeeper1# - zookeeper2 extra_hosts: - &quot;zookeeper0:10.112.178.32&quot; - &quot;zookeeper1:10.112.178.33&quot; - &quot;zookeeper2:10.112.178.34&quot; kafka1: container_name: kafka1 extends: file: base/docker-compose-base.yaml service: kafka environment: - KAFKA_BROKER_ID=1 - KAFKA_MIN_INSYNC_REPLICAS=2 - KAFKA_DEFAULT_REPLICATION_FACTOR=3 - KAFKA_ZOOKEEPER_CONNECT=10.112.178.32:2181,10.112.178.33:2181,10.112.178.34:2181# depends_on:# - zookeeper0# - zookeeper1# - zookeeper2 extra_hosts: - &quot;zookeeper0:10.112.178.32&quot; - &quot;zookeeper1:10.112.178.33&quot; - &quot;zookeeper2:10.112.178.34&quot; kafka2: container_name: kafka2 extends: file: base/docker-compose-base.yaml service: kafka environment: - KAFKA_BROKER_ID=2 - KAFKA_MIN_INSYNC_REPLICAS=2 - KAFKA_DEFAULT_REPLICATION_FACTOR=3 - KAFKA_ZOOKEEPER_CONNECT=zookeeper0:2181,zookeeper1:2181,zookeeper2:2181# depends_on:# - zookeeper0# - zookeeper1# - zookeeper2 extra_hosts: - &quot;zookeeper0:10.112.178.32&quot; - &quot;zookeeper1:10.112.178.33&quot; - &quot;zookeeper2:10.112.178.34&quot; kafka3: container_name: kafka3 extends: file: base/docker-compose-base.yaml service: kafka environment: - KAFKA_BROKER_ID=3 - KAFKA_MIN_INSYNC_REPLICAS=2 - KAFKA_DEFAULT_REPLICATION_FACTOR=3 - KAFKA_ZOOKEEPER_CONNECT=zookeeper0:2181,zookeeper1:2181,zookeeper2:2181# depends_on:# - zookeeper0# - zookeeper1# - zookeeper2 extra_hosts: - &quot;zookeeper0:10.112.178.32&quot; - &quot;zookeeper1:10.112.178.33&quot; - &quot;zookeeper2:10.112.178.34&quot; orderer.example.com: extends: file: base/docker-compose-base.yaml service: orderer.example.com container_name: orderer.example.com depends_on:# - zookeeper0# - zookeeper1# - zookeeper2 - kafka0 - kafka1 - kafka2 - kafka3 extra_hosts: - &quot;zookeeper0:10.112.178.32&quot; - &quot;zookeeper1:10.112.178.33&quot; - &quot;zookeeper2:10.112.178.34&quot; # peer0.org1.example.com: # container_name: peer0.org1.example.com # extends: # file: base/docker-compose-base.yaml # service: peer0.org1.example.com # peer1.org1.example.com: # container_name: peer1.org1.example.com # extends: # file: base/docker-compose-base.yaml # service: peer1.org1.example.com # peer0.org2.example.com: # container_name: peer0.org2.example.com # extends: # file: base/docker-compose-base.yaml # service: peer0.org2.example.com # peer1.org2.example.com: # container_name: peer1.org2.example.com # extends: # file: base/docker-compose-base.yaml # service: peer1.org2.example.com # cli: # container_name: cli # image: hyperledger/fabric-tools # tty: true # environment: # - GOPATH=/opt/gopath # - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock # - CORE_LOGGING_LEVEL=DEBUG # - CORE_PEER_ID=cli # - CORE_PEER_ADDRESS=peer0.org1.example.com:7051 # - CORE_PEER_LOCALMSPID=Org1MSP # - CORE_PEER_LOCALMSPTYPE=bccsp # - CORE_PEER_TLS_ENABLED=true # - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.crt # - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.key # - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt # - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp # working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer # command: /bin/bash -c &apos;./scripts/script.sh $&#123;CHANNEL_NAME&#125;; sleep $TIMEOUT&apos; # volumes: # - /var/run/:/host/var/run/ # - ../chaincode/go/:/opt/gopath/src/github.com/hyperledger/fabric/examples/chaincode/go # - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ # - ./scripts:/opt/gopath/src/github.com/hyperledger/fabric/peer/scripts/ # - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts # depends_on: # - orderer.example.com # - peer0.org1.example.com # - peer1.org1.example.com # - peer0.org2.example.com # - peer1.org2.example.com 五，进行启动验证 1,启动zookeeper,分别到32-34机器上启动,x为机器上对应的文件（0，1，2） 1docker-compose -f zookeeper_x.yaml up -d 2, 40上启动kafka和order, ./network_setup.sh up 123456CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESbea33ba03d0b hyperledger/fabric-orderer &quot;orderer&quot; 15 hours ago Up 15 hours 0.0.0.0:7050-&gt;7050/tcp orderer.example.com0bbaf8c2476d hyperledger/fabric-kafka &quot;/docker-entrypoint.…&quot; 15 hours ago Up 15 hours 9093/tcp, 0.0.0.0:33426-&gt;9092/tcp kafka0820c93d0b0dc hyperledger/fabric-kafka &quot;/docker-entrypoint.…&quot; 15 hours ago Up 15 hours 9093/tcp, 0.0.0.0:33425-&gt;9092/tcp kafka344a90d05f3df hyperledger/fabric-kafka &quot;/docker-entrypoint.…&quot; 15 hours ago Up 15 hours 9093/tcp, 0.0.0.0:33424-&gt;9092/tcp kafka1ae73e577f5d3 hyperledger/fabric-kafka &quot;/docker-entrypoint.…&quot; 15 hours ago Up 15 hours 9093/tcp, 0.0.0.0:33423-&gt;9092/tcp kafka2 3,到41，42，37，38上，运行peer 1docker-compose -f docker-compose-peer.yaml up -d 4,到41机器上通过进入cli docker exec -it cli bash后，验证。 1./scripts/script.sh mychannel 常见错误12Error: got unexpected status: BAD_REQUEST -- error authorizing update: error validating ReadSet: readset expected key [Group] /Channel/Application at version 0, but got version 1!!!!!!!!!!!!!!! Channel creation failed !!!!!!!!!!!!!!!! 这个错误是执行过,导致script.sh里执行版本不一致 docker rm -f $(docker ps -aq)确保各平台容器一致。 ，另一个常见问题秘钥和证书不一致，如果重新执行了生成了crypto-config，需要各个机器上一致。","path":"posts/61570.html","date":"08-09","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"fabric1.2下e2e_cli问题记录","text":"目前升级了fabric 1.2版本，是当前最新release版本。 从fabric1.1开始，这个经典的例子改为kafka共识，做为学习。 升级后常规验证 运行e2e_cli后发现日志有如下错误：Failed evaluating policy on signed data during check policy on channel 123456789101112Error: error endorsing query: rpc error: code = Unknown desc = Failed evaluating policy on signed data during check policy on channel [mychannel] with policy [/Channel/Application/Writers]: [Failed to reach implicit threshold of 1 sub-policies, required 1 remaining] - proposal response: &lt;nil&gt;===================== Query successful on peer1.org3 on channel &apos;mychannel&apos; ===================== ===================== All GOOD, End-2-End execution completed ===================== _____ _ _ ____ _____ ____ _____ | ____| | \\ | | | _ \\ | ____| |___ \\ | ____|| _| | \\| | | | | | _____ | _| __) | | _| | |___ | |\\ | | |_| | |_____| | |___ / __/ | |___ |_____| |_| \\_| |____/ |_____| |_____| |_____| 看起来运行成功了,查找了下发现是个bug. 这个bug地址是 https://jira.hyperledger.org/browse/FAB-11196 可以根据这个修改，在运行就OK了。 修改 e2e_cli下的configtx.yaml，在Org3处进行添加Org3MSP.member，如下。 12345678910Policies:Readers:Type: SignatureRule: &quot;OR(&apos;Org3MSP.admin&apos;, &apos;Org3MSP.peer&apos;, &apos;Org3MSP.client&apos;, &apos;Org3MSP.member&apos;)&quot;Writers:Type: SignatureRule: &quot;OR(&apos;Org3MSP.admin&apos;, &apos;Org3MSP.client&apos;, &apos;Org3MSP.member&apos;)&quot;Admins:Type: SignatureRule: &quot;OR(&apos;Org3MSP.admin&apos;)&quot; 新的代码作者已经提交了，可以用以上暂规避处理。","path":"posts/5070.html","date":"08-02","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Linux当前用户加入docker组","text":"docker的运行在root下，需要sudo方式进行查看 sudo docker ps 可以通过将当前普通用户加入到docker组里，不需要在sudo 通过ls -alh /var/run/docker.sock 查看到执行需要root权限。 把自己加入到docker group里 1sudo gpasswd -a $&#123;USER&#125; docker 重启docker 1sudo service docker restart 切换当前会话到新 group 或者重启 X 会话 必须执行 1newgrp - docker","path":"posts/55312.html","date":"08-01","excerpt":"","tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhulg.github.io/tags/Linux/"}]},{"title":"总结下Fabric从入门到崩溃路线","text":"fabric的学习路线总结回顾一下，也作为归纳和知识回顾。 技术点基本储备 了解区块链工作原理，各种概念算法，区块链的分布式，密码学，去中心，CAP，Basic Paxos, Multi-Paxos, Raft,Pow, PoS, DPoS,pbft fabric的源码基于go编写的，要学习源码go语言必须会,java基础，nodejs也会点。 docker的使用，grpc知道是什么怎么用，p2p网络了解不，kafka你的懂，数据库couchdb,leveldb你也得会些。 学习Fabric 环境构建，入门一般按照文档例子，本地能搭建起fabric网络，这里面docker，sh什么的需要熟悉，go环境等。网络搭建起来为止。 fabric基本例子，参考源码里的例子，自己运行这个过程可能比较让人放弃 模仿里面的例子进行改造，跑起自己区块链网络，这里面有常用的部署方式solo,kafka 通过fabric sdk连接自己构建的区块链网络，尝试区块链项目。有java,python,node，go 版本sdk. 学习composer,使用composer开发区块链项目。 接下来学习 以上学习fabric中的每一步，其实都是很大的一块东西，未必能学明白。是个多次反复都不一定明白的过程（目前资料还是有限） 学习fabric的源码，从源码里明白些东西，再回来折腾环境。要不环境可能就已经让你崩溃 学习过程中可能有很多新知识点不断出现,composer里的node各种框架，建模语言，各种查询方式，都要学下。 尝试个项目可能感觉还是力不从心，落地时候问题太多。fabric给的参考项目可能也会让你崩溃，但还是要参考下。 目前结合落地还是有很多不切实际的地方，能研究明白源码，进行改造贡献代码。 坚持总结，同行多交流，有些弯路是躲不了，就为给你涨经验。","path":"posts/19130.html","date":"07-26","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Node里express框架知识点记录","text":"Express是基于nodejs的web开发框架,使用vscode开发node 使用node调用hyperledger composer提供的模块接口,实现自己的composer接口服务。 vscode安装express123456- vs code 安装node express - 先安装express插件,vs商店里搜索- 在进行安装 npm install express-generator -g- 创建一个应用express myapp- vs打开这个应用，进入这个工程命令行npm install- npm start启动应用，访问http://127.0.0.1:3000/ 生成模板工程的结构 12345678myapp├── app.js├── bin├── node_modules├── package.json├── public├── routes└── views express主要包含三个核心概念：路由、中间件、模板引擎123中间件：在express应用中，一切皆中间件,各种应用逻辑，如cookie解析、会话处理、日志记录、权限校验等，都是通过中间件来完成的。路由：负责寻址的。模板引擎：负责视图动态渲染。 express工作机制 next：回调方法，当next()被调用时，就进入下一个中间件 常用中间件1234function login(req, res, next)&#123; doSomeBusinessLogic(); // 业务逻辑处理，比如权限校验、数据库操作、设置cookie等 next(); // 如果需要进入下一个中间件进行处理，则调用next();&#125; 常用中间件 123456body-parsercompressionserve-staticsessioncookie-parsermorgan 模板引擎,主要视图渲染模板 官网介绍","path":"posts/32797.html","date":"07-05","excerpt":"","tags":[{"name":"node","slug":"node","permalink":"https://zhulg.github.io/tags/node/"},{"name":"composer","slug":"composer","permalink":"https://zhulg.github.io/tags/composer/"},{"name":"vscode","slug":"vscode","permalink":"https://zhulg.github.io/tags/vscode/"}]},{"title":"使用Composer部署chaincode中超时问题记录","text":"使用composer进行部署chaincode，构建chaincode镜像时出现超时问题。 错误日志 Response from attempted peer comms was an error: Error: REQUEST_TIMEOUT 之前遇到过按照网上说法，设置yaml里peer上chaincode的超时时间有300改为1200，有时能解决，最近发现问题根源和有更简单处理方式。 一般执行composer network start xxx时出现 1234Starting business network definition. This may take a minute...Error: Error trying to start business network. Error: No valid responses from any peers.Response from attempted peer comms was an error: Error: REQUEST_TIMEOUTCommand failed 最新解决方案 之前解决过该问题，多设置超时，这个方案不靠谱。从出错的日志看，其实是npm要下载模块，进行构建image。但是npm这个东西国内。。。 所以需要设置npm代理源，看到官网上有给出设置的方法参见设置npm代理 步骤： 121，创建文件npmConfig，内容添加 registry=https://registry.npm.taobao.org2，在文件目录下重新执行 composer network install --card PeerAdmin@hlfv1 --archiveFile my-network@0.1.6.bna -o npmrcFile=npmConfig 执行完，在进行composer network start就非常快完成创建chaincode镜像和容器启动工作了。（fabric之前记得重启）","path":"posts/58142.html","date":"07-05","excerpt":"","tags":[{"name":"composer","slug":"composer","permalink":"https://zhulg.github.io/tags/composer/"},{"name":"fabric","slug":"fabric","permalink":"https://zhulg.github.io/tags/fabric/"}]},{"title":"Hyperledger Composer下docker重启后chaincode无法启动记录","text":"背景是磁盘空间因为docker容器日志满，环境是使用composer的区块链网络。 正确清理姿势（比如我这个） 12到 /app/install/docker/lib/docker/containers/ 下面的那个容器文件夹内执行 cat /dev/null &gt; *-json.log lsof |grep deleted 查看删除文件是否存在引用（如果直接删的日志，是不会减少空间的，需要删除引用） 由于一开始没有正确清理，直接删除了。空间没有恢复。果断重启了docker。。。发现之前的停止的chaincode则无法重启了，其他fabric组件都起来了，只有chaincode容器失败，日志。 123456&gt; gome-sellers-network@0.0.3-deploy.18 start /usr/local/src&gt; start-network &quot;--peer.address&quot; &quot;peer0.org2.example.com:7052&quot;running start.jsE0702 04:24:00.911674693 16 ssl_transport_security.cc:1063] Handshake failed with fatal error SSL_ERROR_SSL: error:0D0C5006:asn1 encoding routines:ASN1_item_verify:EVP lib.[2018-07-02T04:24:00.913] [ERROR] lib/handler.js - Chat stream with peer - on error: &quot;Error: 14 UNAVAILABLE: Connect Failed\\n at Object.exports.createStatusError (/usr/local/src/node_modules/grpc/src/common.js:87:15)\\n at ClientDuplexStream._emitStatusIfDone (/usr/local/src/node_modules/grpc/src/client.js:235:26)\\n at ClientDuplexStream._readsDone (/usr/local/src/node_modules/grpc/src/client.js:201:8)\\n at /usr/local/src/node_modules/grpc/src/client_interceptors.js:679:15&quot; 又进行了删除操作，把chaincode容器删掉,尝试重新部署chaincode,之前已经有card和管理员并进行初始化了，所以直接用composer的相关命令启动不了网络发现还是失败，重新install chaincode报已经初始化。下边无法进行了，只有启动了chaincode才能操作。 12345678910111213 composer network start -c PeerAdmin@byfn-network-org1 -n gome-sellers-network -V 0.0.3-deploy.18 -o endorsementPolicyFile=/tmp/composer/endorsement-policy.json -A gomeadmin -C gomeadmin/admin-pub.pem -A geliadmin -C geliadmin/admin-pub.pemStarting business network gome-sellers-network at version 0.0.3-deploy.18Processing these Network Admins: userName: gomeadmin userName: geliadmin✖ Starting business network definition. This may take a minute...Error: Error trying to start business network. Error: No valid responses from any peers.Response from attempted peer comms was an error: Error: 2 UNKNOWN: chaincode error (status: 500, message: chaincode exists gome-sellers-network)Response from attempted peer comms was an error: Error: 2 UNKNOWN: chaincode error (status: 500, message: chaincode exists gome-sellers-network)Response from attempted peer comms was an error: Error: 2 UNKNOWN: chaincode error (status: 500, message: chaincode exists gome-sellers-network)Response from attempted peer comms was an error: Error: 2 UNKNOWN: chaincode error (status: 500, message: chaincode exists gome-sellers-network)Command failed 在尝试不重新操作已有card和容器，发现都不行，只能重新启动fabric网络，重新生成card导入才行。 问题 docker重启，chaincode容器就无法再次回到之前状态（其他peer和order,ca都没问题） 遇到这情况需要重新部署chaincode才行，使用composer的话还有点麻烦。","path":"posts/42109.html","date":"07-02","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Mac上django安装","text":"django安装失败问题记录 Django是一个开放源代码的Web应用框架，由Python写成。采用了MTV的框架模式，即模型M，模板T和视图V。 使用django快速开发后端业务。 pip3 install django时直接安装会失败，一般原因是网络超时导致，原因… https://pypi.doubanio.com/simple/django/ 从这个目录地址可以看到django的版本 使用命令行进行安装（pip3目前使用）指定版本时diango==xxxx 1pip3 install -i https://pypi.douban.com/simple django==1.10.8 默认最新版本时 1pip3 install -i https://pypi.douban.com/simple django","path":"posts/34049.html","date":"06-26","excerpt":"","tags":[{"name":"python","slug":"python","permalink":"https://zhulg.github.io/tags/python/"},{"name":"django","slug":"django","permalink":"https://zhulg.github.io/tags/django/"}]},{"title":"Go版本管理工具gvm使用","text":"gvm 用于管理go版本 官网下安装 1bash &lt; &lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer) Installing Go (go1.5以上版本依赖1.4) 12gvm install go1.4gvm use go1.4 [--default] gvm下的配置地址需要修改下用github上地址 123vim ~/.gvm/scripts/install修改GO_SOURCE_URL=https://github.com/golang/go gvm list 查看安装 gvm use xxx –default切换go版本 go env 查看环境 有时需要对gopath环境需要自己设置，可以在.bashrc里进行设置自己要的地址即可 12export GOPATH=$HOME/goexport PATH=$PATH:$GOPATH/bin go env","path":"posts/63736.html","date":"06-21","excerpt":"","tags":[{"name":"go","slug":"go","permalink":"https://zhulg.github.io/tags/go/"}]},{"title":"Nginx代理部署vue工程","text":"docker pull nginx 拉取镜像 启动 123456docker container run \\ -d \\ -p 80:80 \\ --rm \\ --name mynginx \\ nginx 参数说明 1234-d：在后台运行-p ：容器的80端口映射到80--rm：容器停止运行后，自动删除容器文件--name：容器的名字为mynginx docker ps 可以看到。启动查看 挂载自己目录 12345678docker container run \\-d \\-p 80:80 \\--rm \\--name mynginx \\--volume &quot;$PWD/html&quot;:/usr/share/nginx/html \\--volume /mnt/install/docker/project/nginx/conf/nginx.conf:/etc/nginx/nginx.conf:rw \\nginx 存在的话用-v,不存在创建使用–volume 修改配置文件","path":"posts/30090.html","date":"06-12","excerpt":"","tags":[{"name":"nginx","slug":"nginx","permalink":"https://zhulg.github.io/tags/nginx/"}]},{"title":"Mac搭建以太坊私链","text":"搭建以太坊私链，需要安装geth 创建自己的私链存储目录，并创建个datadir目录。 1，添加传世区块配置文件 cd 到自己私链目录下，vim genesis.json ，与datadir同级位置 1234567891011121314151617&#123; &quot;config&quot;: &#123; &quot;chainId&quot;: 1000, &quot;homesteadBlock&quot;: 0, &quot;eip155Block&quot;: 0, &quot;eip158Block&quot;: 0 &#125;, &quot;nonce&quot;: &quot;0x0000000000000061&quot;, &quot;timestamp&quot;: &quot;0x0&quot;, &quot;parentHash&quot;: &quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;, &quot;gasLimit&quot;: &quot;0x8000000&quot;, &quot;difficulty&quot;: &quot;0x100&quot;, &quot;mixhash&quot;: &quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;, &quot;coinbase&quot;: &quot;0x3333333333333333333333333333333333333333&quot;, &quot;extraData&quot;: &quot;0x00000000&quot;, &quot;alloc&quot;: &#123;&#125;&#125; 相关参数说明（网上搜索，注意extraData格式不对会报错） 12345678910chainId: 以太坊主网chainId为0，私链自己修改为一个任意Id。mixhash: 与nonce配合用于挖矿，由上一个区块的一部分生成的hash。注意和nonce的设置需要满足以太坊的黄皮书, 4.3.4. Block Header Validity, (44)章节所描述的条件。nonce: nonce就是一个64位随机数，用于挖矿，注意他和mixhash的设置需要满足以太坊的黄皮书,4.3.4. Block Header Validity, (44)章节所描述的条件。difficulty: 设置当前区块的难度，如果难度过大，cpu挖矿就很难，这里设置较小难度alloc: 用来预置账号以及账号的以太币数量，因为私有链挖矿比较容易，所以我们不需要预置有币的账号，需要的时候自己创建即可以。coinbase: 矿工的账号，随便填timestamp: 设置创世块的时间戳parentHash: 上一个区块的hash值，因为是创世块，所以这个值是0extraData: 附加信息，随便填，可以填你的个性信息(需要二进制)gasLimit: 值设置对GAS的消耗总量限制，用来限制区块能包含的交易信息总和，因为我们是私有链，所以填最大 2，初始化以太坊节点1$ geth --datadir datadir init genesis.json 3，启动私链的以太坊节点1$ geth --datadir datadir --networkid 1000 console 4，进入后主要操作，可以尝试以下命令观察输出1234adminethpersonalminer 查看和添加账户 123456&gt; eth.accounts[]&gt; personal.newAccount(&quot;12345678&quot;)&quot;0x23f740f09cbafa5376bc985f055f356d629cf2ad&quot;&gt; eth.accounts[&quot;0x23f740f09cbafa5376bc985f055f356d629cf2ad&quot;] 5，退出 exit6，查看刚才目录下生成的文件1234567891011121314151617181920212223242526272829private_net/├── datadir│ ├── geth│ │ ├── LOCK│ │ ├── chaindata│ │ │ ├── 000002.ldb│ │ │ ├── 000003.log│ │ │ ├── CURRENT│ │ │ ├── LOCK│ │ │ ├── LOG│ │ │ └── MANIFEST-000004│ │ ├── lightchaindata│ │ │ ├── 000001.log│ │ │ ├── CURRENT│ │ │ ├── LOCK│ │ │ ├── LOG│ │ │ └── MANIFEST-000000│ │ ├── nodekey│ │ ├── nodes│ │ │ ├── 000001.log│ │ │ ├── CURRENT│ │ │ ├── LOCK│ │ │ ├── LOG│ │ │ └── MANIFEST-000000│ │ └── transactions.rlp│ ├── history│ └── keystore│ └── UTC--2018-06-11T14-17-50.790843570Z--23f740f09cbafa5376bc985f055f356d629cf2ad└── genesis.json","path":"posts/9685.html","date":"06-11","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"以太坊Geth及mac安装","text":"geth 全称go-ethereum，是以太坊的 go 语言命令行客户端，目前比较流行的一种。 The Go implementation is called Geth. Geth has been audited for security and will be the future basis for the enduser-facing Mist Browser, so if you have experience with web development and are interested in building frontends for dapps, you should experiment with Geth. 通过Geth，可以实现以太坊的各种功能,如账户的新建编辑删除，开启挖矿，ether币的转移，智能合约的部署和执行等 mac上安装 (go环境什么的都已经ok) 12brew tap ethereum/ethereumbrew install ethereum geth version 查看版本","path":"posts/52667.html","date":"06-08","excerpt":"","tags":[{"name":"区块链，以太坊","slug":"区块链，以太坊","permalink":"https://zhulg.github.io/tags/区块链，以太坊/"}]},{"title":"使用Hyperledger Composer落地项目","text":"composer构建和部署 关于composer的介绍和使用可参见官方文档。 以下关于composer的使用时结合项目，关键步骤记录。是在配置好连接，生成bna文件后的步骤。之前步骤可移步文档学习。 以下东西为自己笔记形式，不够详细。如需帮助指导请邮件我（lg.json@gmail.com） 开发基本步骤 生成bna文件之后的步骤 部署基于2个组织4个节点（文档里多节点部署） 1, 开始前对docker进行了重启（目的是清除之前docker里的数据，在没有对数据持久进行挂载的时候，重启不会生成新的秘钥使用之前配好的）12/byfn.sh -m restart -s couchdb -arm -fr $HOME/.composer 2, 初始化业务网络,申请身份12345composer network install --card PeerAdmin@byfn-network-org1 --archiveFile gome-sellers-network_0.0.12.bnacomposer network install --card PeerAdmin@byfn-network-org2 --archiveFile gome-sellers-network_0.0.12.bnacomposer identity request -c PeerAdmin@byfn-network-org1 -u admin -s adminpw -d gomeadmincomposer identity request -c PeerAdmin@byfn-network-org2 -u admin -s adminpw -d geliadmin 3, 启动网络1composer network start -c PeerAdmin@byfn-network-org1 -n gome-sellers-network -V 0.0.3-deploy.12 -o endorsementPolicyFile=/tmp/composer/endorsement-policy.json -A gomeadmin -C gomeadmin/admin-pub.pem -A geliadmin -C geliadmin/admin-pub.pem 4, 添加管理员card(组织1和组织2)12345678composer card create -p /tmp/composer/org1/byfn-network-org1.json -u gomeadmin -n gome-sellers-network -c gomeadmin/admin-pub.pem -k gomeadmin/admin-priv.pemcomposer card import -f gomeadmin@gome-sellers-network.cardcomposer card create -p /tmp/composer/org2/byfn-network-org2.json -u geliadmin -n gome-sellers-network -c geliadmin/admin-pub.pem -k geliadmin/admin-priv.pemcomposer card import -f geliadmin@gome-sellers-network.card 5,启动API1composer-rest-server -c gomeadmin@gome-sellers-network -n never -w true 6, 更新bna（测试开发阶段需要修改bna文件情况使用更新。执行一个组织上，在进行数据添加时发现会同步到其他pee容器）12345678composer network install --card PeerAdmin@byfn-network-org1 --archiveFile gome-sellers-network_0.0.12.bnacomposer network upgrade -c PeerAdmin@byfn-network-org1 -n gome-sellers-network -V 0.0.3-deploy.12composer network install --card PeerAdmin@byfn-network-org2 --archiveFile gome-sellers-network_0.0.12.bnacomposer network upgrade -c PeerAdmin@byfn-network-org2 -n gome-sellers-network -V 0.0.3-deploy.12 7, 添加seller1用户并申请身份信息12345composer participant add -c gomeadmin@gome-sellers-network -d &apos;&#123;&quot;$class&quot;:&quot;com.gomesellers.network.Seller&quot;,&quot;Id&quot;:&quot;1&quot;, &quot;Name&quot;:&quot;zhulianggang&quot;,&quot;orgId&quot;:&quot;001&quot;,&quot;orgName&quot;:&quot;格力&quot;&#125;&apos;composer identity issue -c gomeadmin@gome-sellers-network -f seller1.card -u seller1 -a &quot;resource:com.gomesellers.network.Seller#1&quot;composer card import -f seller1.card 8, 使用sell1 提交数据上链1composer transaction submit --card seller1@gome-sellers-network -d &apos;&#123;&quot;$class&quot;: &quot;org.hyperledger.composer.system.AddAsset&quot;,&quot;registryType&quot;: &quot;Asset&quot;,&quot;registryId&quot;: &quot;com.gomesellers.network.Order&quot;, &quot;targetRegistry&quot; : &quot;resource:org.hyperledger.composer.system.AssetRegistry#com.gomesellers.network.Order&quot;, &quot;resources&quot;: [&#123;&quot;$class&quot;: &quot;com.gomesellers.network.Order&quot;,&quot;orderId&quot;:&quot;1&quot;, &quot;itemDesc&quot;:&quot;MAC&quot;,&quot;channel&quot;:&quot;gome&quot;, &quot;itemNum&quot;:&quot;10&quot;,&quot;createTime&quot;:&quot;2018-5-30&quot;,&quot;sellerId&quot;:&quot;1&quot;,&quot;sellerName&quot;:&quot;zhulianggang&quot;,&quot;sellerOrgId&quot;:&quot;001&quot;,&quot;sellerOrgName&quot;:&quot;格力&quot;,&quot;sum&quot;:&quot;888&quot;,&quot;orginOrderId&quot;:&quot;1001&quot;&#125;]&#125;&apos; 9,添加seller2用户并申请身份12345composer participant add -c gomeadmin@gome-sellers-network -d &apos;&#123;&quot;$class&quot;:&quot;com.gomesellers.network.Seller&quot;,&quot;Id&quot;:&quot;2&quot;, &quot;Name&quot;:&quot;zhulg&quot;,&quot;orgId&quot;:&quot;001&quot;,&quot;orgName&quot;:&quot;格力&quot;&#125;&apos;composer identity issue -c gomeadmin@gome-sellers-network -f seller2.card -u seller2 -a &quot;resource:com.gomesellers.network.Seller#2&quot;composer card import -f seller2.card 10, 使用sell2 提交数据上链1composer transaction submit --card seller2@gome-sellers-network -d &apos;&#123;&quot;$class&quot;: &quot;org.hyperledger.composer.system.AddAsset&quot;,&quot;registryType&quot;: &quot;Asset&quot;,&quot;registryId&quot;: &quot;com.gomesellers.network.Order&quot;, &quot;targetRegistry&quot; : &quot;resource:org.hyperledger.composer.system.AssetRegistry#com.gomesellers.network.Order&quot;, &quot;resources&quot;: [&#123;&quot;$class&quot;: &quot;com.gomesellers.network.Order&quot;,&quot;orderId&quot;:&quot;2&quot;, &quot;itemDesc&quot;:&quot;MAC&quot;,&quot;channel&quot;:&quot;gome&quot;, &quot;itemNum&quot;:&quot;10&quot;,&quot;createTime&quot;:&quot;2018-5-30&quot;,&quot;sellerId&quot;:&quot;2&quot;,&quot;sellerName&quot;:&quot;zhulg&quot;,&quot;sellerOrgId&quot;:&quot;001&quot;,&quot;sellerOrgName&quot;:&quot;格力&quot;,&quot;sum&quot;:&quot;999&quot;,&quot;orginOrderId&quot;:&quot;1002&quot;&#125;]&#125;&apos; 不同身份提交数据上链，权限控制 本地启动composer playground，可查看不同card composer network list -c seller2@gome-sellers-network 业务网络下数据 启动的reset api 可以执行同样操作。唯一不同的是reset api 对应身份切换好像没有。只能再生成reset api时命令行指定身份,这样的话对应提交上链就只能用命令行方式 –card 身份提交了。（需要进一步研究下这块） 11,多用户模式解决以上问题 最近涉及到多用户模式业务开发，composer里的多用户模式可以完全解决用户身份问题。等空了做个总结记录。","path":"posts/59496.html","date":"05-30","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"},{"name":"composer","slug":"composer","permalink":"https://zhulg.github.io/tags/composer/"},{"name":"hyperledger composer","slug":"hyperledger-composer","permalink":"https://zhulg.github.io/tags/hyperledger-composer/"}]},{"title":"开搞以太坊","text":"关于区块链技术，fabric完成第一阶段目标 目前关于区块链技术的主流实现，hyperledger fabric基本上可以从原理到流程上，在到环境构建，到基于fabric开搞项目,环境上也是折磨的死去活来，还好都搞定了。算是可入手项目开发学习阶段了。 fabric还有很多细节和需要深入学习的地方，继续深入学习和高级应用作为第二阶段学习目标。 为什么学习以太坊 目的是更好理解区块链原理技术及应用 理解以太坊和fabric的差异，更好理解业务场景和区块链结合落地 一，以太坊是什么 以太坊是一个去中心化的，可以执行智能合约的平台（15年6月发行） 比特币的定义是一种数字货币，而以太坊则是执行智能合约的平台。而以太币(ether)则是执行智能合约所需要的消耗品。可以把以太坊想象成一个平台，而在上边运行汽车(智能合约),就需要汽油(ether) 现在我们接触的比较多的是app，而在区块链上搭建的app就叫dapp(decentralized application)。试想一下，如果一个合同的执行，不需要公证，不存在违约，过程公开透明，可追溯，永久存在，费用低廉。。太好。 以太坊历史 在2016年6月，The DAO事件成为以太坊发展的关键点。在2016年6月，The DAO事件成为以太坊发展的关键点 以太坊基金会最终的决定是执行硬分叉，于是也就有了ETC(以太坊经典)和ETH(以太坊) 以太坊共分为4个阶段: 即Frontier(前沿)、 Homestead(家园)、 Metropolis(大都会)、 Serenity(宁静)。目前已经进行到了Metropolis阶段。前三个阶段采用工作量证明机制(POW)，第四阶段会逐渐切换到权益证明机制(POS)。当切换至权益证明机制的时候，每一年以太坊的产量将降低，维持在0~200万左右。 以太坊术语 以太币（Ether）以太币是以太坊中货币的名称。以太币是用来支付交易和以太坊交易的计算费用。 ether也认为是以太币的单位，另一个常用的单位是wei。 1ether=1e18wei (1,000,000,000,000,000,000wei) 智能合约一套以数字形式定义的承诺（promises），包括合约参与方可以在上面执行这些承诺的协议。 以太坊虚拟机 EVM是以太坊中智能合约的运行环境。 Solidity是以太坊中用于开发智能合约的编程语言，目前开发智能合约用的最多的是Solidity。开发智能合约入门可参考智能合约开发环境搭建及Hello World合约。 Serpent一门智能合约的编程语言，语法类似Python，不再建议使用，建议转换到Viper。 Viper一门智能合约的编程语言，Vitalik最推崇的语言。取代Solidity的地位也是有可能的。 官方文档 Transaction 交易包含一系列价值的转移，从一个地址转到另一个。 消息合约能够向其他合约发送“消息”。消息是虚拟的，不能序列化，存在于以太坊执行环境中。可以被理解为函数调用。 以太坊客户端也称钱包，提供账户管理、挖矿、转账、智能合约的部署和执行等等功能，以太坊节点利用以太坊客户端接入到以太坊网络。 现在以太坊客户端主要有：Wallent/Mist ， Geth， Parity， Harmony，pyethapp等 Geth开发中使用最广泛的客户端，使用Go语言实现。 了解geth命令用法 Parity另一个较为常用的客户端，用Rust实现。 web3.jsweb3.js是一个实现与以太坊节点JSON-RPC通信的JavaScript库。类似还有Java库web3j。 geth提供的JavaScript控制台中，就包含的web3.js库事例web3。 Gas以太坊上用Gas机制来计费，Gas也可以认为是一个工作量单位，智能合约越复杂（计算步骤的数量和类型，占用的内存等），用来完成运行就需要越多Gas。 etherbase在你的节点上的主账户默认名字，如果你在挖矿，那么挖矿的回报会被放到这个账户中。 coinbase 是一个和etherbase类似的概念，但是对于众多的加密货币平台而言coinbase是一个更通用的术语。 balance 账户余额 GHOST协议Greedy Heaviest Observed Subtree, GHOST协议就是让我们必须选择一个在其上完成计算最多的路径。一个方法确定路径就是使用最近一个区块（叶子区块）的区块号，区块号代表着当前路径上总的区块数（不包含创世纪区块）。区块号越大，路径就会越长，就说明越多的挖矿算力被消耗在此路径上以达到叶子区块。使用这种推理就可以允许我们赞同当前状态的权威版本。 梅克尔帕特里夏树（MPT：Merkle Patricia Tree）一种数据结构，它会存储每个账户的状态（存储键值对关系）。这个树的建立是通过从每个节点开始，然后将节点分成多达16个组，然后散列每个组，然后对散列结果继续散列，直到整个树有一个最后的“根散列”。 Frontier（前沿）以太坊（路线图）的第一阶段，在2015年7月30日发布。 Homestead（家园）以太坊（路线图）的第二阶段，在2016年3月14日发布。 Metropolis（大都会）以太坊（路线图）的第三阶段，引入四大特性：zk-Snarks（基于”零知识证明”），PoS（Proof of Stake,即权益证明）早期实施，智能合约跟灵活和稳定， 抽象账户。 大都会又拆分为两个阶段实施（两个硬分叉）：拜占庭（Byzantium）及君士坦丁堡（Constantinople） 拜占庭拜占庭硬分叉在第437万个区块高度发生，时间是2017年10月16日，引入了zk-Snarks 及 抽象账户等。 君士坦丁堡预计在2018年实施， 主要的特性就是平滑处理掉所有由于”拜占庭”所引发的问题，并引入 PoW 和 PoS 的混合链模式。 Serenity（宁静）以太坊（路线图）的第四阶段， 零知识证明指的是证明者能够在不向验证者提供任何有用的信息的情况下，使验证者相信某个论断是正确的。 “零知识证明”实质上是一种涉及两方或更多方的协议，即两方或更多方完成一项任务所需采取的一系列步骤。证明者向验证者证明并使其相信自己知道或拥有某一消息，但证明过程不能向验证者泄漏任何关于被证明消息的信息。 PoS一种共识协议：作为验证节点，首先你必须拥有一定数量的以太币，根据以太币的数量和时间会产生用于下注验证区块的权益。只有拥有权益的节点才能有效验证区块，当你验证的区块被打包进链，你将获得和你权益成正比的区块奖励。如果你验证恶意或错误的区块，那么你所下注的权益将被扣除。 Casper 的共识算法以太坊中PoS协议的实现， 刚开始每100个区块将有一个采用PoS协议挖出 抽象账户在的以太坊有两类账户：即外部账户和合约账户，以太坊正在试图模糊二者的界限，即你可以同时拥有合约账户和外部账户，这种做法本质上就是让用户按照合约账户的格式来定义外部账户。 难度炸弹为了确保以太坊的矿工能加入到新链条中来，开发团队引入了”难度炸弹”机制。它会使难度系数呈指数增加以至于让挖矿变得几乎不可能的。 以太坊硬分叉硬分叉是对以太坊底层协议的改变，创建新的规则，提高整个系统。协议改变在某个特定区块上被激活。所有的以太坊客户端都需要升级，否则将停留在遵循旧规则的老链上。 ERC-20代币合约标准，一系列通过以太坊智能合约发布的代币制定了代币发放的通用规则。该标准是目前通过ICO发行代币的基础准则。 该标准能够确保基于以太坊的代币在整个生态系统中以一种可预测的方式进行，使去中心化应用程序和智能合约可以在整个平台上彼此协作，所有代币都遵循一个固定的安全标准。 EIPsEthereum Improvement Proposals - 以太坊改进协议 Ommer是一个区块的父区块与当前区块父区块的父区块是相同的。 由于以太坊区块生产时间（大概15秒左右）比比特币（大概10分钟左右）要快很多。更短的区块生产时间的一个缺点就是：更多的竞争区块会被矿工发现。 这些竞争区块同样也被称为“孤区块”（也就是被挖出来但是不会被添加到主链上的区块） Ommers的目的就是为了帮助奖励矿工纳入这些孤区块，Ommer区块会收到比全区块少一点的奖励。 预言机通过向智能合约提供数据，它现实世界和区块链之间的桥梁。 测试网络以太坊用来测试功能的网络，比如拜占庭分叉之前先在测试网络（Ropsten）上运行一段时间，稳定后再发布到公有链（正式网络）。 以太坊测试网络有： 1234567Olympic测试网络 - 早期的一个（预发布版本）测试网络，已不再使用Morden测试网络 - 以太坊第一个测试网络，已不再使用Ropsten测试网络 - 使用Pow，和当前的公有链环境一致，2016/11发布。Kovan测试网络 - 仅parity钱包支持，使用PoA共识Rinkeby测试网络 - 仅geth钱包支持，使用PoA共识 不同网络的特点可进一步查看这个问答DAO(decentralized autonomous organization)去中心自治组织DAO是建立在区块链之上的合约（或一系列合约），旨在制定规则、强制执行或使组织工作自动化，包括治理、筹资、运营、支出和扩张。","path":"posts/46989.html","date":"05-17","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Hyperledger Composer创建card区别记录","text":"启动网络并创建了networkadmin.card(默认的connection.json?)composer network start –networkName tutorial-network –networkVersion 0.0.1 –networkAdmin admin –networkAdminEnrollSecret adminpw –card PeerAdmin@hlfv1 –file networkadmin.card 创建PeerAdmin@fabric-network.cardcomposer card create -p connection.json -u PeerAdmin -c Admin@org1.example.com-cert.pem -k 114aab0e76bf0c78308f89efc4b8c9423e31568da0c340ca187a9b17aa9a4457_sk -r PeerAdmin -r ChannelAdmin","path":"posts/29329.html","date":"05-17","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"目前主流区块链技术","text":"区块链目前主流技术linux基金和IBM搞的hyperledger (目前主要搞这个) 这5个技术框架分别是： 12345- Hyperledger Sawtooth(物联网、生产、金融以及企业的区块链框架,可公链可私）- Hyperledger Iroha(轻量级的分布式账本， 侧重于移动)- **Hyperledger Fabric 联盟链目前比较流行**- Hyperledger Burrow- Hyperledger Indy 3个工具包分别是： 1234- Hyperledger Cello- Hyperledger Composer- Hyperledger Explorer- Hyperledger Quilt 以太坊 ethereum 主要以太坊技术、以太币。基于以太坊改造各种… R3 Corda 一个为金融服务设计的分布式账本系统 Corda 是一套分布式账本系统，用来记录、管理和同步传统金融机构间的「金融合约」。它很大程度上受启发于「区块链」系统，但是排除了一些不适合银行业应用场景的设计思路。 主要技术特性 123456789Corda 没有采用全局共享数据：即只有在合约范围内的合法参与主体才可见；Corda 没有中心控制节点来干预参与主体之间的流程；Corda 能就主体之间的单笔交易（这样的粒度）取得共识，而非系统级别；Corda 可以引入监管和监督节点；Corda 交易的确认由交易参与方完成，而不是由其它很多非相关的验证者确认；Corda 支持多种「共识机制」Corda 会明确记录「人类语言的法律文件」与「机器智能合约代码」之间的关联；Corda 由工业级别的工具打造；Corda 没有原生的「加密数字货币」 其他厂商自己实现区块链技术","path":"posts/29162.html","date":"05-16","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Fabric部署阿里云错误记录","text":"Fabric部署在阿里云上错误解决 正常执行docker-compose相关yaml，启动fabric容器时出现错误。 相关错误信息: runtime stack: runtime.throw(0xf11259, 0x2a) /opt/go/src/runtime/panic.go:605 +0x95 123456789101112131415161718192021222324atal error: unexpected signal during runtime execution[signal SIGSEGV: segmentation violation code=0x1 addr=0x63 pc=0x7fb147df1259]runtime stack:runtime.throw(0xf11259, 0x2a) /opt/go/src/runtime/panic.go:605 +0x95runtime.sigpanic() /opt/go/src/runtime/signal_unix.go:351 +0x2b8goroutine 38 [syscall, locked to thread]:runtime.cgocall(0xbf3800, 0xc4203fb5e8, 0xf0fa21) /opt/go/src/runtime/cgocall.go:132 +0xe4 fp=0xc4203fb5a8 sp=0xc4203fb568 pc=0x4023b4net._C2func_getaddrinfo(0x2f0ca00, 0x0, 0xc4203ff050, 0xc42000e298, 0x0, 0x0, 0x0) net/_obj/_cgo_gotypes.go:86 +0x5f fp=0xc4203fb5e8 sp=0xc4203fb5a8 pc=0x5f893fnet.cgoLookupIPCNAME.func2(0x2f0ca00, 0x0, 0xc4203ff050, 0xc42000e298, 0xc420423b60, 0x7ffeed519a83, 0x13) /opt/go/src/net/cgo_unix.go:151 +0x13f fp=0xc4203fb640 sp=0xc4203fb5e8 pc=0x5ffedfnet.cgoLookupIPCNAME(0x7ffeed519a83, 0x13, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0) /opt/go/src/net/cgo_unix.go:151 +0x175 fp=0xc4203fb738 sp=0xc4203fb640 pc=0x5fa195net.cgoIPLookup(0xc420423c20, 0x7ffeed519a83, 0x13) /opt/go/src/net/cgo_unix.go:203 +0x4d fp=0xc4203fb7c8 sp=0xc4203fb738 pc=0x5fa8ddruntime.goexit() /opt/go/src/runtime/asm_amd64.s:2337 +0x1 fp=0xc4203fb7d0 sp=0xc4203fb7c8 pc=0x45e391created by net.cgoLookupIP /opt/go/src/net/cgo_unix.go:213 +0xaf 问题原因是：DNS解析出了问题是阿里云主机的DNS部分配置GO语言的DNS解析不支持. 问题具体原因 可以查看cd到etc/resolv.conf文件查看 ure Go Resolver不支持的options single-request-reopen导致失败导致走了 CGO Resolver的方式 问题修改 需要在使用的docker-compose.yaml里添加环境 GODEBUG=netdns=go，重新启动fabric网络 12environment: - GODEBUG=netdns=go","path":"posts/64470.html","date":"05-14","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"使用Hyperledger Composer问题记录","text":"使用hyperledger composer 进行构建区块链项目 该问题在最后使用 Angular连接rest api时，出现 Invalid Host header 12yo hyperledger-composer:angular进入生成的工程里，执行npm start 问题解决参见 issues 或者修改以下文件 123你生成angular项目下面的 node_modules/webpack-dev-server/lib/Server.js (line 425)修改为: return true; 重新启动 错误不在出现，页面构建成功正常显示","path":"posts/24749.html","date":"05-14","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Fabric集成开启tls后出现错误记录","text":"目前在不开启tls时，通过fabric javasdk链接到fabric网络，数据到链一切正常。 开启tls后，通过配置修改，并在java代码上进行处理后，目前错误出现\\ Reason: UNAVAILABLE: Channel closed while performing protocol negotiation 主要错误堆栈，在初始化通道时失败。 123456789org.hyperledger.fabric.sdk.exception.TransactionException: Channel gomevisionchannel sendDeliver failed on orderer orderer.gomevision.com. Reason: UNAVAILABLE: Channel closed while performing protocol negotiation at org.hyperledger.fabric.sdk.OrdererClient.sendDeliver(OrdererClient.java:295) ~[fabric-sdk-java-1.0.1.jar:na] at org.hyperledger.fabric.sdk.Orderer.sendDeliver(Orderer.java:172) [fabric-sdk-java-1.0.1.jar:na] at org.hyperledger.fabric.sdk.Channel.seekBlock(Channel.java:1198) [fabric-sdk-java-1.0.1.jar:na] at org.hyperledger.fabric.sdk.Channel.getLatestBlock(Channel.java:1274) [fabric-sdk-java-1.0.1.jar:na] at org.hyperledger.fabric.sdk.Channel.getLastConfigIndex(Channel.java:1097) [fabric-sdk-java-1.0.1.jar:na] at org.hyperledger.fabric.sdk.Channel.getConfigurationBlock(Channel.java:1028) [fabric-sdk-java-1.0.1.jar:na] at org.hyperledger.fabric.sdk.Channel.parseConfigBlock(Channel.java:949) [fabric-sdk-java-1.0.1.jar:na] at org.hyperledger.fabric.sdk.Channel.initialize(Channel.java:676) [fabric-sdk-java-1.0.1.jar:na] 目前CA添加tls注册用户登记是正常的,从CA登记的管理员相关秘钥已经返回。 错误出现在构建通道，相关的peer和order已经使用了Properties属性。。。 错误需要继续定位，先记录下来。 问题解决 根据昨天定位思路，查找在peer和order的Properties的属性里发现设置有问题，结合到官方测试例子的的写法 1ordererProperties.setProperty(&quot;hostnameOverride&quot;, 填写对应orderer或者peer的名字); 目前fabric的javasdk还不是很好使用，官方只有测试用例，需要从测试用例里梳理使用的代码流程结合到自己的业务里去，还没看到过像样的例子提供。报错信息提示也比较隐晦。。比较坑 hyperledger fabric技术交流群 到期或者失效，发邮件(lg.json@gmail.com)给我你微信，拉你进群。","path":"posts/37885.html","date":"05-01","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Fabric的chaincode编写及接口","text":"fabric里链码的编写是go语言，一般编写和调试可在开发环境进行快速测试和开发。上次笔记有介绍。 chaincode的编写比较简单,主要涉及2个接口，实现这2个接口，在接口里编写对应的业务即可。 1234567func (s *gomevisionchaincode) Init(apiSub shim.ChaincodeStubInterface) pb.Response &#123; return shim.Success(nil)&#125;func (s *gomevisionchaincode) Invoke(apiSub shim.ChaincodeStubInterface) pb.Response &#123; return shim.Success(nil)&#125; chaincode涉及的接口操作 对fabric的操作都包含在这些接口里,链码通过这些接口与区块链fabric进行通信，上边的2个接口里调用以下方法进行与fabric交互。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154type ChaincodeStubInterface interface &#123; // GetArgs returns the arguments intended for the chaincode Init and Invoke // as an array of byte arrays. GetArgs() [][]byte // GetStringArgs returns the arguments intended for the chaincode Init and // Invoke as a string array. Only use GetStringArgs if the client passes // arguments intended to be used as strings. GetStringArgs() []string // GetFunctionAndParameters returns the first argument as the function // name and the rest of the arguments as parameters in a string array. // Only use GetFunctionAndParameters if the client passes arguments intended // to be used as strings. GetFunctionAndParameters() (string, []string) // GetArgsSlice returns the arguments intended for the chaincode Init and // Invoke as a byte array GetArgsSlice() ([]byte, error) // GetTxID returns the tx_id of the transaction proposal (see ChannelHeader // in protos/common/common.proto) GetTxID() string // InvokeChaincode locally calls the specified chaincode `Invoke` using the // same transaction context; that is, chaincode calling chaincode doesn&apos;t // create a new transaction message. // If the called chaincode is on the same channel, it simply adds the called // chaincode read set and write set to the calling transaction. // If the called chaincode is on a different channel, // only the Response is returned to the calling chaincode; any PutState calls // from the called chaincode will not have any effect on the ledger; that is, // the called chaincode on a different channel will not have its read set // and write set applied to the transaction. Only the calling chaincode&apos;s // read set and write set will be applied to the transaction. Effectively // the called chaincode on a different channel is a `Query`, which does not // participate in state validation checks in subsequent commit phase. // If `channel` is empty, the caller&apos;s channel is assumed. InvokeChaincode(chaincodeName string, args [][]byte, channel string) pb.Response // GetState returns the value of the specified `key` from the // ledger. Note that GetState doesn&apos;t read data from the writeset, which // has not been committed to the ledger. In other words, GetState doesn&apos;t // consider data modified by PutState that has not been committed. // If the key does not exist in the state database, (nil, nil) is returned. GetState(key string) ([]byte, error) // PutState puts the specified `key` and `value` into the transaction&apos;s // writeset as a data-write proposal. PutState doesn&apos;t effect the ledger // until the transaction is validated and successfully committed. // Simple keys must not be an empty string and must not start with null // character (0x00), in order to avoid range query collisions with // composite keys, which internally get prefixed with 0x00 as composite // key namespace. PutState(key string, value []byte) error // DelState records the specified `key` to be deleted in the writeset of // the transaction proposal. The `key` and its value will be deleted from // the ledger when the transaction is validated and successfully committed. DelState(key string) error // GetStateByRange returns a range iterator over a set of keys in the // ledger. The iterator can be used to iterate over all keys // between the startKey (inclusive) and endKey (exclusive). // The keys are returned by the iterator in lexical order. Note // that startKey and endKey can be empty string, which implies unbounded range // query on start or end. // Call Close() on the returned StateQueryIteratorInterface object when done. // The query is re-executed during validation phase to ensure result set // has not changed since transaction endorsement (phantom reads detected). GetStateByRange(startKey, endKey string) (StateQueryIteratorInterface, error) // GetStateByPartialCompositeKey queries the state in the ledger based on // a given partial composite key. This function returns an iterator // which can be used to iterate over all composite keys whose prefix matches // the given partial composite key. The `objectType` and attributes are // expected to have only valid utf8 strings and should not contain // U+0000 (nil byte) and U+10FFFF (biggest and unallocated code point). // See related functions SplitCompositeKey and CreateCompositeKey. // Call Close() on the returned StateQueryIteratorInterface object when done. // The query is re-executed during validation phase to ensure result set // has not changed since transaction endorsement (phantom reads detected). GetStateByPartialCompositeKey(objectType string, keys []string) (StateQueryIteratorInterface, error) // CreateCompositeKey combines the given `attributes` to form a composite // key. The objectType and attributes are expected to have only valid utf8 // strings and should not contain U+0000 (nil byte) and U+10FFFF // (biggest and unallocated code point). // The resulting composite key can be used as the key in PutState(). CreateCompositeKey(objectType string, attributes []string) (string, error) // SplitCompositeKey splits the specified key into attributes on which the // composite key was formed. Composite keys found during range queries // or partial composite key queries can therefore be split into their // composite parts. SplitCompositeKey(compositeKey string) (string, []string, error) // GetQueryResult performs a &quot;rich&quot; query against a state database. It is // only supported for state databases that support rich query, // e.g.CouchDB. The query string is in the native syntax // of the underlying state database. An iterator is returned // which can be used to iterate (next) over the query result set. // The query is NOT re-executed during validation phase, phantom reads are // not detected. That is, other committed transactions may have added, // updated, or removed keys that impact the result set, and this would not // be detected at validation/commit time. Applications susceptible to this // should therefore not use GetQueryResult as part of transactions that update // ledger, and should limit use to read-only chaincode operations. GetQueryResult(query string) (StateQueryIteratorInterface, error) // GetHistoryForKey returns a history of key values across time. // For each historic key update, the historic value and associated // transaction id and timestamp are returned. The timestamp is the // timestamp provided by the client in the proposal header. // GetHistoryForKey requires peer configuration // core.ledger.history.enableHistoryDatabase to be true. // The query is NOT re-executed during validation phase, phantom reads are // not detected. That is, other committed transactions may have updated // the key concurrently, impacting the result set, and this would not be // detected at validation/commit time. Applications susceptible to this // should therefore not use GetHistoryForKey as part of transactions that // update ledger, and should limit use to read-only chaincode operations. GetHistoryForKey(key string) (HistoryQueryIteratorInterface, error) // GetCreator returns `SignatureHeader.Creator` (e.g. an identity) // of the `SignedProposal`. This is the identity of the agent (or user) // submitting the transaction. GetCreator() ([]byte, error) // GetTransient returns the `ChaincodeProposalPayload.Transient` field. // It is a map that contains data (e.g. cryptographic material) // that might be used to implement some form of application-level // confidentiality. The contents of this field, as prescribed by // `ChaincodeProposalPayload`, are supposed to always // be omitted from the transaction and excluded from the ledger. GetTransient() (map[string][]byte, error) // GetBinding returns the transaction binding GetBinding() ([]byte, error) // GetSignedProposal returns the SignedProposal object, which contains all // data elements part of a transaction proposal. GetSignedProposal() (*pb.SignedProposal, error) // GetTxTimestamp returns the timestamp when the transaction was created. This // is taken from the transaction ChannelHeader, therefore it will indicate the // client&apos;s timestamp, and will have the same value across all endorsers. GetTxTimestamp() (*timestamp.Timestamp, error) // SetEvent allows the chaincode to propose an event on the transaction // proposal. If the transaction is validated and successfully committed, // the event will be delivered to the current event listeners. SetEvent(name string, payload []byte) error&#125;","path":"posts/53606.html","date":"04-21","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Fabric与springboot整合问题记录","text":"目前在做基于fabric的区块链项目，在整合springboot时遇到坑记录 在fabric网络启动后，springboot工程去连接时出现错误。 Channel mychannel sendDeliver failed on orderer orderer.example.com. Reason: INTERNAL: Connection closed with unknown cause 1234567891011121314151617181920212223242526io.grpc.StatusRuntimeException: INTERNAL: Connection closed with unknown cause at io.grpc.Status.asRuntimeException(Status.java:526) at io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:380) at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:419) at io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:60) at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:493) at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$500(ClientCallImpl.java:422) at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:525) at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37) at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:102) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:748)ERROR OrdererClient - Channel mychannel sendDeliver failed on orderer orderer.example.com. Reason: INTERNAL: Connection closed with unknown causeorg.hyperledger.fabric.sdk.exception.TransactionException: Channel mychannel sendDeliver failed on orderer orderer.example.com. Reason: INTERNAL: Connection closed with unknown cause at org.hyperledger.fabric.sdk.OrdererClient.sendDeliver(OrdererClient.java:295) at org.hyperledger.fabric.sdk.Orderer.sendDeliver(Orderer.java:172) at org.hyperledger.fabric.sdk.Channel.seekBlock(Channel.java:1198) at org.hyperledger.fabric.sdk.Channel.getLatestBlock(Channel.java:1274) at org.hyperledger.fabric.sdk.Channel.getLastConfigIndex(Channel.java:1097) at org.hyperledger.fabric.sdk.Channel.getConfigurationBlock(Channel.java:1028) at org.hyperledger.fabric.sdk.Channel.parseConfigBlock(Channel.java:949) at org.hyperledger.fabric.sdk.Channel.initialize(Channel.java:676) at com.example.fabric.HFJavaSDKBasicExample.getChannel(HFJavaSDKBasicExample.java:196) at com.example.fabric.HFJavaSDKBasicExample.main(HFJavaSDKBasicExample.java:63)Caused by: io.grpc.StatusRuntimeException: INTERNAL: Connection closed with unknown cause 这个错误原因居然是springboot版本导致。。。。目前fabric使用1.0.6（最新为1.1） 解决方法把springboot下降到2.0.0以下版本，注意是以下，1.5.9都可以。使用2.0.0以上目前会造成fabric网络出现必现问题，链接未知原因被拒，底层java代码不兼容。 hyperledger fabric技术交流群 到期或者失效，发邮件(lg.json@gmail.com)给我你微信，拉你进群。","path":"posts/46195.html","date":"04-19","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Linux常用配置查看命令","text":"Linux操作系统主要分为两大类： RedHat系列：Redhat、Centos、Fedora等 Debian系列：Debian、Ubuntu等。 linux下个系统软件安装辅助工具 wget （名字是World Wide Web与get的结合）类似于迅雷，是一种下载工具，用于下载网站/批量文件，通过HTTP、HTTPS、FTP三个最常见的TCP/IP协议下载。 apt-get是ubuntu下的一个软件安装方式，它是基于debain的。 yum是redhat系列linux操作系统下的软件安装方式 查看Linux系统发行版本 lsb_release -a 12345LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarchDistributor ID: CentOSDescription: CentOS Linux release 7.3.1611 (Core) Release: 7.3.1611Codename: Core 如果没有该命令，使用yum install -y redhat-lsb 进行安装后使用。查看操作系统版本 cat /etc/redhat-release查看Linux内核版本 uname -a 内存相关信息 cat /proc/meminfo 全部相关信息 cat /proc/meminfo | grep MemTotal 只看内存 CPU相关信息 cat /proc/cpuinfo 全部相关信息 cat /proc/cpuinfo | grep “cpu cores” | uniq 查看cpu核数 查看磁盘空间分区大小 df -h 查看端口 lsof -i:端口号 查看系统架构类型 arch 命令主要用于显示操作系统架构类型 查看分组和用户所属组 cat /etc/group 查看系统架构(通用) echo $(echo “$(uname -s|tr ‘[:upper:]’ ‘[:lower:]’|sed ‘s/mingw64_nt.*/windows/‘)-$(uname -m | sed ‘s/x86_64/amd64/g’)” | awk ‘{print tolower($0)}’) 压缩，解压 .tar.gz 和 .tgz 12 解压：tar zxvf FileName.tar.gz 压缩：tar zcvf FileName.tar.gz DirName .zip 123解压：unzip FileName.zip压缩：zip FileName.zip DirName压缩一个目录使用 -r 参数，-r 递归。例： $ zip -r FileName.zip DirName .tar 123 解包：tar xvf FileName.tar 打包：tar cvf FileName.tar DirName（注：tar是打包，不是压缩！）","path":"posts/6996.html","date":"04-15","excerpt":"","tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhulg.github.io/tags/Linux/"}]},{"title":"Fabric分节点部署到不同线上机器","text":"分机器部署节点 fabric在真正的应用环境里是不同的节点是部署在不同的机器上的，peer,orderer在不同机器是，根据需要orderer可集群。 先尝试把peer,orderer部署到不同的机器上。 线上部署 先搭建基本环境，使用例子验证基本环境通过。(基于Linux 3.10.0-514 x86_64) 1，安装go 下载 (arch命令查看机子架构x86,amd,arm，下载对应的架构go包) 12wget https://storage.googleapis.com/golang/go1.10.linux-amd64.tar.gzsudo tar -xzf go1.10.linux-amd64.tar.gz -C /usr/local 配置 123456sudo vim /etc/profile 并添加下面的内容：export GOROOT=/usr/local/goexport GOBIN=$GOROOT/binexport PATH=$PATH:$GOBINexport GOPATH=$HOME/gopath (可选设置) 生效 source /etc/profile 2,安装docker1wget -qO- https://get.docker.com/ | sh 如上一步骤有报错 Error: Delta RPMs disabled because /usr/bin/applydeltarpm not installed….可以先通过如下命令查找该包的包名： 123yum provides &apos;*/applydeltarpm&apos;然后用如下命令安装即可解决：yum install deltarpm 最后还是没安装上 其他方式安装 123yum install docker启动Docker服务：service docker start 3,安装docker-compose 第一种，使用yum安装 1234567891011需要先安装企业版linux附加包（epel) yum -y install epel-release安装pipyum -y install python-pip更新pippip install --upgrade pip安装docker-composepip install docker-compose查看docker-compose版本信息docker-compose --version环境正常可以直接安装（pip install docker-compose） 或者使用下载包安装 123sudo curl -L https://github.com/docker/compose/releases/download/1.21.0/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-composesudo chmod +x /usr/local/bin/docker-composedocker-compose --version 下载fabric源码 go get github.com/hyperledger/fabric cd /root/gopath/src/github.com/hyperledger/fabric 目前使用1.0.6版本，刚发布1.1release.考虑稳定切换到1.0.6 branch里是没有1.0.6办的，使用指定tag的版本进行切换12git tag （可以发现1.0.6版本）git checkout -b 1.0.6 v1.0.6 （可拉取指定tag） 进入源码提供脚本拉取镜像 fabric/examples/e2e_cli目录下，使用bash download-dockerimages.sh 下载需要的网络镜像。 也可以使用本地已经下载好的镜像（原因是下载太特么慢了要几个小时，就用下载好的镜像了） 1234561,save本地镜像1.0.6的到imagesdocker save $(docker images | grep 1.0.6 | awk &#123;&apos;print $1&apos;&#125; ) -o images2,上传到目前不机器,用户的根目录scp images xxxx@10.xxx.xx.xxx:~3,导入imagedocker load -i images 运行源码下的例子 进入源码里/examples/e2e_cli 1./network_setup.sh up 一个坑记录（mac下没问题是被生存的docker网络刚好是要找的）– fabric源码里的例子example下的e2e_cli启动时定义要找的名字与生成的名字会不一致。e2e_cli_default而定义要找的是e2ecli_default 1Error: Error endorsing chaincode: rpc error: code = Unknown desc = Error starting container: API error (404): &#123;&quot;message&quot;:&quot;network chlnetwork not found&quot;&#125; 运行docker network ls命令，看一眼显示出来的网络里，有没有报错里那个网络，如果没有的话，将你的本地网络改为命令输出里的网络。 改动配置文件e2e_cli/base/peer-base.yaml，里面的参数ORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=e2e_cli_default **关于docker网络名字，默认使用项目跟目录的项目名字_default,所以 hyperledger fabric技术交流群 到期或者失效，发邮件(lg.json@gmail.com)给我你微信，拉你进群。","path":"posts/15189.html","date":"04-14","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"关于学习遗忘曲线","text":"学习新东西太多，更容易忘记太多。 一段时间过后，如果没能对新技术多次实践应用到项目，发现可以忘的一干二净。。。 如何快速找回，就是对原来研究的技术做笔记，记录概念，原理，应用场景，在操作遍实际例子。基本1个小时快速找回当初状态。 对应新技术研究学习一定要记录一个学习路线，从简单是什么，原理，应用场景，附带个简单demo，为遗忘路线准备快速回忆。","path":"posts/47508.html","date":"04-11","excerpt":"","tags":[{"name":"随笔记录","slug":"随笔记录","permalink":"https://zhulg.github.io/tags/随笔记录/"}]},{"title":"Fabric中数据存储","text":"fabric中默认存储库levelDb存储设计 要达到数据不可篡改首先从数据结构上来看是一个链式存储，也是区块链之所以称之为区块链的原因。 每个存储单元包含上一存储单元的hash值以及自身存储的交易数据块，可以从表象来看就像把所有数据块连接在一起，称之为“区块链”，形成链状可追述的交易记录。 这种链状结构的数据称之为账本数据，保存着所有交易的记录，有普通文件保存，还有一个“世界状态”，其实质为Key-Value数据库，维护着交易数据的最终状态，便于查询等操作运算，并且每个数据都有其对应的版本号。 存储实现 Hyperledger fabric(HLF)的存储系统和比特币一样，也是由普通的文件和 kv 的数据库 （levelDB/couchDB）组成 Hyperledger fabric中，每个 channel 对应一个账本目录，在账本目录中由 blockfile_000000、blockfile_000001 命名格式的文件名组成。为了快速检索区块数据每个文件的大小是64M。每个区块的数据（区块头和区块里的所有交易）都会序列成字节码的形式写入 blockfile 文件中。 进入peer节点内可以查看到 在序列化的过程中，程序以 append 方式打开 blockfile 文件，然后将区块大小和和区块数据写入至 blockfile 文件中。以下是区块数据写入的具体描述： 123451.写入区块头数据，依次写入的数据为区块高度、交易哈希和前一个区块哈希；2. 写入交易数据，依次写入的数据为区块包含交易总量和每笔交易详细数据；3. 写入区块的Metadata 数据，依次写入的数据为 Metadata 数据总量和每个 Metadata 项的数据详细信息。 在写入数据的过程中会以 kv 的形式保存区块和交易在 blockfile 文件中的索引信息，以方便 HLF 的快速查询。 HLF 区块索引信息格式在 kv 数据库中存储的最终的 LevelKey 值有前缀标志和区块 hash 组成，而 LevelValue 的值由区块高度，区块 hash，本地文件信息(文件名，文件偏移等信息)，每个交易在文件中的偏移列表和区块的 MetaData 组成， HLF 按照特定的编码方式将上述的信息拼接成 db 数据库中的 value 。 HLF交易索引信息格式在kv数据库中存储最终的LevelKey值由channel_name，chaincode_name和chaincode中的key值组合而成： 1LevelKey = channel_name+chaincode_name+key(具体规则有待考证) 而 LevelValue 的值由BlockNum 区块号，TxNum 交易在区块中的编号组成， HLF 通过将区块号和交易编号按照特定的方式编码，然后与 chaincode 中的 value 相互拼接最终生成 db 数据库中的 value 。 hyperledger fabric技术交流群 到期或者失效，发邮件(lg.json@gmail.com)给我你微信，拉你进群。","path":"posts/40568.html","date":"04-10","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Fabric交易流程概述","text":"目前基于fabric1.0.6版本学习Fabric的交易流程中，主要关键节点参与，Peer节点、Orderer节点、CA节点及client端。 Peer节点 :该节点是参与交易的主体，可以说是代表每个参与到链上的成员，他负责储存完整的账本数据即区块链数据，负责共识环节中的执行智能合约，其中所有的Peer节点都维护完整的账本数据称之为Committer，而根据具体的业务划分背书策略时决定哪些Peer.peer有以下角色 123背书节点(Endorse Peer): 背书节点和具体的chaincode绑定，每个chaincode在实例化时会设置背书策略，在chaincode调用时需满足背书策略从背书节点收集足够的签名背书时交易才有效主节点(Leader Peer)：Leader Peer负责和排序节点Orderer进行通信，Leader Peer可通过选举产生记账节点(普通的Peer)：只负责验证交易和记账 Orderer节点:该节点接受包含背书签名的交易请求进行排序并打包生产新的区块，主体功能便是对交易排序从而保证各Peer节点上的数据一致性，也包含了ACL进行访问控制。目前Hyperledger Fabric的多个Orderer节点连接到Kafka集群利用Kafka的共识功能完成交易的排序和打包。 CA节点:该节点负责对加入链内的所有节点进行授权认证，包括上层的client端，每一个节点都有其颁发的证书用于交易流程中的身份识别。 client: Fabric对于client端提供了SDK让开发人员可以更容易的对接到区块链内的交易环节，交易的发起便是通过SDK进行。 交易流程图 整个执行流程： 1,应用程序创建交易提案并提交给背书节点 2,背书节点模拟执行交易并完成背书签名 3,背书节点将背书签名和模拟交易结果返回给应用程序 4,应用程序需收集足够的交易背书，构建交易请求后发送给排序节点 5,排序节点对交易进行排序并生成区块 6,排序节点生成区块后会广播给通道上不同组织的主节点 7,记账节点从主节点同步区块，验证区块内容并写入区块(所有的Peer节点都是记账节点) 官方图解主要包含4大步骤 步骤1：由client发起一个交易请求，而上图中的背书策略要求Peer1、Peer2及Peer3参与交易，所以client将请求分别发给Pee1、Peer2和Peer3 步骤2：三个Peer接收到交易请求后执行对应的智能合约并对结果进行签名然后分别将输出结果返回给client 步骤3：client收到所有执行结果后打包一并发送到Orderer 步骤4：Orderer将接收到的该次交易在交易池里进行排序并组合打包生成一个新的区块，Orderer将新的区块发送给所有的Peer节点，每个Peer节点接收到新区块后，对其中的每一笔交易结果的签名进行验证是否符合背书策略，以及比对读写集合与本地的版本是否相同，如满足所有条件则将新的区块写入本地账本内完成交易。 应用程序如何掉到fabric 应用程序需要通过通道连接到某一个Peer节点上使用chaincode与Fabric的网路进行通信，向背书节点提交交易提案（fabric java/node/go sdk-&gt;chaincode）","path":"posts/6511.html","date":"04-04","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Fabric使用开发模式编写chaincode","text":"在开发者模式下编写调试chaincode 在fabric-examples下提供有开发者模式，编译快速对chaincode的编写。 进入chaincode-docker-devmode，基于docker方式快速构建一个开发模式的网络。 1docker-compose -f docker-compose-simple.yaml up 在这个yaml里可以看到关键信息，在peer容器里命令标志用于设置开发者模式 command: peer node start –peer-chaincodedev=true -o orderer:7050 网络启动后可以看到 12345CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3d089e92ccc5 hyperledger/fabric-ccenv &quot;/bin/bash -c &apos;sleep…&quot; 44 minutes ago Up 44 minutes chaincodec6e93a9603f9 hyperledger/fabric-tools &quot;/bin/bash -c ./scri…&quot; 44 minutes ago Up 44 minutes cli84a87f2f2ab2 hyperledger/fabric-peer &quot;peer node start --p…&quot; 44 minutes ago Up 44 minutes 0.0.0.0:7051-&gt;7051/tcp, 0.0.0.0:7053-&gt;7053/tcp peer2d4e748b5041 hyperledger/fabric-orderer &quot;orderer&quot; 44 minutes ago Up 44 minutes 0.0.0.0:7050-&gt;7050/tcp orderer 启动网络并运行链码 具体信息可以看ymal里的配置，可以看到创建了myc通道，和一个peer,order节点 进入chaincode容器 docker exec -it chaincode bash 编译（go build）并启动chaincode1CORE_PEER_ADDRESS=peer:7051 CORE_CHAINCODE_ID_NAME=mycc:0 ./chaincode_example02 实例化链码和查询12345docker exec -it cli bashpeer chaincode install -n mycc -v 0 -p chaincodedev/chaincode/chaincode_example02peer chaincode instantiate -n mycc -v 0 -c &apos;&#123;&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;,&quot;100&quot;,&quot;b&quot;,&quot;200&quot;]&#125;&apos; -o orderer:7050 -C mycpeer chaincode invoke -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;invoke&quot;,&quot;a&quot;,&quot;b&quot;,&quot;10&quot;]&#125;&apos; -o orderer:7050 -C mycpeer chaincode query -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]&#125;&apos; -o orderer -C myc","path":"posts/27962.html","date":"03-28","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"webstom编译Fabric Node-Sdk记录","text":"使用fabric-node-sdk 使用代码1.0.6 fabric版本 编译fabric-samples下的fabcar代码，目前由于fabcar的代码使用了es6,故导致编译失败。 解决方法：设置下即可","path":"posts/14437.html","date":"03-26","excerpt":"","tags":[{"name":"fabric","slug":"fabric","permalink":"https://zhulg.github.io/tags/fabric/"},{"name":"fabric-node-sdk","slug":"fabric-node-sdk","permalink":"https://zhulg.github.io/tags/fabric-node-sdk/"},{"name":"webstom","slug":"webstom","permalink":"https://zhulg.github.io/tags/webstom/"}]},{"title":"Fabric网络启动流程-多节点操作查询","text":"基于fabric-samples/first-network下手动网络启动相关文件生成和配置。 待上篇分析继续 在其他节点上进行操作 上篇分析中使用的是单个几点peer0.org1.example.com:7051上进行的操作。 在这个网络中有2个组织，4个节点，在cli的配置里可以看到如下默认的配置，对应peer0.org1.example.com:7051 12345peer.org1.example.com:7051CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspCORE_PEER_ADDRESS=peer0.org1.example.com:7051CORE_PEER_LOCALMSPID=Org1MSPCORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt 在创建完通道后，需要在其他几点上部署链码前，需要设置cli的环境，对应成新的节点。并把该peer添加到channel里 例如：添加 peer1.org1.example.com:7051 节点 1234CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspCORE_PEER_ADDRESS=peer1.org1.example.com:7051CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/ca.crt 需要设置上述环境在cli bash里，并添加peer到channel( peer channel join -b xxx.block) 在新节点初始化chaincode1peer chaincode install -n mycc -v 1.0 -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 在节点上实例化chaincode 链码实例化一次 1peer chaincode instantiate -o orderer.example.com:7050 --tls $CORE_PEER_TLS_ENABLED --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n mycc -v 1.0 -c &apos;&#123;&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;, &quot;100&quot;, &quot;b&quot;,&quot;200&quot;]&#125;&apos; -P &quot;OR (&apos;Org1MSP.member&apos;,&apos;Org2MSP.member&apos;)&quot; 切换节点进行查询和执行 在cli bash里操作调用和查询，发现数据在不同节点是一致的。","path":"posts/10283.html","date":"03-23","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Fabric Explorer部署记录","text":"Hyperledger Explorer is a simple, powerful, easy-to-use, highly maintainable, open source browser for viewing activity on the underlying blockchain network. 通过explorer可以看到fabric的peer,channel,block 等信息 官网下载 12git clone https://github.com/hyperledger/blockchain-explorer.gitcd blockchain-explorer 使用mysql导入表 1mysql -u&lt;username&gt; -p &lt; db/fabricexplorer.sql 启动网络在fabric-samples/first-network下，启动网络。 1./byfn.sh -m up -c mychannel cd blockchain-explorer下编辑config.json文件,修改密码对应的路径，修改mysql的密码。 npm install 在初始化时会失败的，原因在国内你懂得,设置代理，继续执行。 1npm config set registry=&quot;http://r.cnpmjs.org&quot; 安装完成后，执行./start.sh 访问http://localhost:8081/ 我在config.sh里端口改为8081，默认8080","path":"posts/30329.html","date":"03-22","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Chaincode编写go里错误注意记录","text":"go里的方法在使用json.Marshal()时需要，结构的定义需要按照大写的方式来定义。 12var people = People&#123;NAME: params[1], AGE: params[2]&#125;peoplebytes, err := json.Marshal(people) 使用时结构的定义需要大写如下边方式,否则导致json.Marshal()结构为空。 1234type People struct &#123; NAME string `json:&quot;name&quot;` AGE string `json:&quot;age&quot;`&#125;","path":"posts/35801.html","date":"03-21","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Fabric的背书策略记录","text":"在fabric中，共识过程意味着多个节点对于某一批交易的发生顺序、合法性以及它们对账本状态的更新结构达成一致的观点。满足共识则意味着多个节点可以始终保证相同的状态，对于以同样顺序到达的交易可以进行一致的处理。 fabric中的共识包括背书、排序和验证三个环节的保障。 什么是背书策略 chaincode在实例化的时候，需要指定背书策略。这里的背书策略就是需要什么节点背书交易才能生效。 发起交易的时候，发起端（一般是SDK），需要指定交易发给哪些节点进行背书验证（fabric不会自动发送），而是由sdk发送。发送后等待背书节点的返回，收集到足够的背书后将交易发送给orderer（排序节点或称共识节点）进行排序打包分发。最后，当每个Peer接受到block数据后，会对其中的交易进行验证，如果交易不符合背书策略，就不会在本地生效，所以真正验证背书是在这一步。 背书策略用于指示区块链节点交易验证的规则。作为交易验证流程的一部分，当背书节点收到一个交易请求的时候, 该节点会调用 VSCC (验证用途的系统合约程序) 并与执行交易的合约相关联。为了确定交易的有效性，一个交易应该包含来自尽可能多的背书节点的一个或多个背书。VSCC用于判定下面的内容： 123所有背书是有效的 (即它们是来自预期消息上的有效证书的有效签名)得到一定数量的背书背书来自预期的来源（指定背书节点 背书策略就是用来定义上边的第二和第三点。 背书策略设计 背书策略有两个主要组成部分： 12主体principal阀门threshold gate P 标识期望背书的区块链节点 T 有两个输入参数：整数t（背书数量）和n （背书节点列表），即满足t的条件，并得到n的背书。 例如: T(2, ‘A’, ‘B’, ‘C’) 请求来自’A’、’B’、’C’的任意2个背书节点的签名T(1, ‘A’, T(2, ‘B’, ‘C’)) 请求来自A或来自B和C中的一个签名 命令行下的背书策略语法 在Fabric CLI中，使用了一种简单的boolean表达式来解释Endorse节点的背书策略。 Fabric 1.0使用MSP（成员管理服务）来描述主体principal，该MSP用于验证签名者的身份以及签名者在该MSP内所具有的权限。目前，支持两种角色：成员和管理员。 主体Principals的通用表现形式是MSP.ROLE，其中MSP是指MSP 的ID，ROLE是 member 或admin。 一个有效主体的示例是“Org0.admin”（Org0 MSP的任意管理员）或“Org1.member”（Org1 MSP的任意成员）。命令行语法是这样的： 123EXPR(E[, E...])其中EXPR可以是AND或OR，代表两个boolean表达式，E是主体或对EXPR的另一个嵌套调用。 例如：1234AND(&apos;Org1.member&apos;, &apos;Org2.member&apos;, &apos;Org3.member&apos;) 请求三个背书节点的签名OR(&apos;Org1.member&apos;, &apos;Org2.member&apos;) 请求两个背书节点中的任意一个的签名OR(&apos;Org1.member&apos;, AND(&apos;Org2.member&apos;, &apos;Org3.member&apos;)) 请求来自Org1 MSP成员或来自Org2 MSP成员和来自Org3 MSP成员的任意一个签名指定智能合约的背书策略 部署合约的开发人员可以指定背书策略来验证执行的合约。 默认策略需要来自DEFAULT MSP成员的一个签名。如果未在CLI中指定策略，则默认使用此选项。 背书策略可以在部署合约时使用-P选项指定，后面跟策略内容。 例如：1peer chaincode deploy -C testchainid -n mycc -p http://github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -c &apos;&#123;&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;,&quot;100&quot;,&quot;b&quot;,&quot;200&quot;]&#125;&apos; -P &quot;AND(&apos;Org1.member&apos;, &apos;Org2.member&apos;)&quot; 执行这条命令将在testchainid这条链上使用背书策略AND(‘Org1.member’, ‘Org2.member’).部署智能合约mycc","path":"posts/60266.html","date":"03-20","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Fabric网络启动流程-分步分析","text":"farbic 网络启动过程 基于fabric-samples/first-network下手动网络启动相关文件生成和配置。 生成组织关系和身份证书 使用Cryptogen，消费一个包含网络拓扑的crypto-config.yaml，并允许我们为组织和属于这些组织的组件生成一组证书和密钥。 crypto-config.yaml文件内容如下， 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273OrdererOrgs: # --------------------------------------------------------------------------- # Orderer # --------------------------------------------------------------------------- - Name: Orderer Domain: example.com # --------------------------------------------------------------------------- # &quot;Specs&quot; - See PeerOrgs below for complete description # --------------------------------------------------------------------------- Specs: - Hostname: orderer# ---------------------------------------------------------------------------# &quot;PeerOrgs&quot; - Definition of organizations managing peer nodes# ---------------------------------------------------------------------------PeerOrgs: # --------------------------------------------------------------------------- # Org1 # --------------------------------------------------------------------------- - Name: Org1 Domain: org1.example.com # --------------------------------------------------------------------------- # &quot;Specs&quot; # --------------------------------------------------------------------------- # Uncomment this section to enable the explicit definition of hosts in your # configuration. Most users will want to use Template, below # # Specs is an array of Spec entries. Each Spec entry consists of two fields: # - Hostname: (Required) The desired hostname, sans the domain. # - CommonName: (Optional) Specifies the template or explicit override for # the CN. By default, this is the template: # # &quot;&#123;&#123;.Hostname&#125;&#125;.&#123;&#123;.Domain&#125;&#125;&quot; # # which obtains its values from the Spec.Hostname and # Org.Domain, respectively. # --------------------------------------------------------------------------- # Specs: # - Hostname: foo # implicitly &quot;foo.org1.example.com&quot; # CommonName: foo27.org5.example.com # overrides Hostname-based FQDN set above # - Hostname: bar # - Hostname: baz # --------------------------------------------------------------------------- # &quot;Template&quot; # --------------------------------------------------------------------------- # Allows for the definition of 1 or more hosts that are created sequentially # from a template. By default, this looks like &quot;peer%d&quot; from 0 to Count-1. # You may override the number of nodes (Count), the starting index (Start) # or the template used to construct the name (Hostname). # # Note: Template and Specs are not mutually exclusive. You may define both # sections and the aggregate nodes will be created for you. Take care with # name collisions # --------------------------------------------------------------------------- Template: Count: 2 # Start: 5 # Hostname: &#123;&#123;.Prefix&#125;&#125;&#123;&#123;.Index&#125;&#125; # default # --------------------------------------------------------------------------- # &quot;Users&quot; # --------------------------------------------------------------------------- # Count: The number of user accounts _in addition_ to Admin # --------------------------------------------------------------------------- Users: Count: 1 # --------------------------------------------------------------------------- # Org2: See &quot;Org1&quot; for full specification # --------------------------------------------------------------------------- - Name: Org2 Domain: org2.example.com Template: Count: 2 Users: Count: 1 在这个文件里有一个count变量。我们将使用它来指定每个组织中peer的数量;例子中，每个组织有两个peer 我们运行cryptogen工具，生成的证书和密钥将被保存到名为crypto-config的文件夹中。(cryptogen需要配置在环境变量才能这么用) 123cryptogen generate --config=./crypto-config.yamlorg1.example.comorg2.example.com 其中里面生成额对应的秘钥和证书文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051├── ordererOrganizations│ └── example.com│ ├── ca│ │ ├── ca.example.com-cert.pem│ │ └── feb74b240fa3568a7d6966b7021cd5a7f186a1d91bece747844e27a8540dc465_sk│ ├── msp│ │ ├── admincerts│ │ ├── cacerts│ │ └── tlscacerts│ ├── orderers│ │ └── orderer.example.com│ ├── tlsca│ │ ├── e5622d48e5fd8e3b982d6e7f6ebed20321f1de0d1478f9d0c1b4f63dc894ccbf_sk│ │ └── tlsca.example.com-cert.pem│ └── users│ └── Admin@example.com└── peerOrganizations ├── org1.example.com │ ├── ca │ │ ├── ca.org1.example.com-cert.pem │ │ └── f5c0954e487ff4e71f77478db2ad2e14c92ffd0b5d093a1c73b64ae233a2813f_sk │ ├── msp │ │ ├── admincerts │ │ ├── cacerts │ │ └── tlscacerts │ ├── peers │ │ ├── peer0.org1.example.com │ │ └── peer1.org1.example.com │ ├── tlsca │ │ ├── 8d07c6968bea26c1277c5cf3bba114bf7c683e97bafc8eadf412fd97d5034cad_sk │ │ └── tlsca.org1.example.com-cert.pem │ └── users │ ├── Admin@org1.example.com │ └── User1@org1.example.com └── org2.example.com ├── ca │ ├── ca.org2.example.com-cert.pem │ └── cffd49870ddd4088820ee7787c60f77ee07c42f2e05ac0e9fe94fac77c972fc1_sk ├── msp │ ├── admincerts │ ├── cacerts │ └── tlscacerts ├── peers │ ├── peer0.org2.example.com │ └── peer1.org2.example.com ├── tlsca │ ├── 5f3f535f85bd861c1f7770f058f05e4a899506b5396ebd357db223b4590b49ba_sk │ └── tlsca.org2.example.com-cert.pem └── users ├── Admin@org2.example.com └── User1@org2.example.com crypto-config目录下产生一个order组织目录，和peer组织目录 12 cd crypto-config$lsordererOrganizations peerOrganizations 进入后发现peerOrganizations下会有2个组织(org1.example.com ，org2.example.com)，4个节点(peer0.org1.example.com，peer1.org1.example.com, peer0.org2.example.com ，peer1.org2.example.com) ordering服务启动初始区块 orderer节点在启动时候，可以指定使用提前生成的初始化区块文件作为系统通道的初始配置，初始区块中包含了ordering服务配置信息和联盟信息。 初始区块使用configtxgen工具生成，依赖configtx.yaml文件，这个文件定义了整个网络中相关配置和拓扑结构信息。（first-network下的这个文件） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149# Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#---################################################################################## Profile## - Different configuration profiles may be encoded here to be specified# as parameters to the configtxgen tool#################################################################################Profiles: TwoOrgsOrdererGenesis: Orderer: &lt;&lt;: *OrdererDefaults Organizations: - *OrdererOrg Consortiums: SampleConsortium: Organizations: - *Org1 - *Org2 TwoOrgsChannel: Consortium: SampleConsortium Application: &lt;&lt;: *ApplicationDefaults Organizations: - *Org1 - *Org2################################################################################## Section: Organizations## - This section defines the different organizational identities which will# be referenced later in the configuration.#################################################################################Organizations: # SampleOrg defines an MSP using the sampleconfig. It should never be used # in production but may be used as a template for other definitions - &amp;OrdererOrg # DefaultOrg defines the organization which is used in the sampleconfig # of the fabric.git development environment Name: OrdererOrg # ID to load the MSP definition as ID: OrdererMSP # MSPDir is the filesystem path which contains the MSP configuration MSPDir: crypto-config/ordererOrganizations/example.com/msp - &amp;Org1 # DefaultOrg defines the organization which is used in the sampleconfig # of the fabric.git development environment Name: Org1MSP # ID to load the MSP definition as ID: Org1MSP MSPDir: crypto-config/peerOrganizations/org1.example.com/msp AnchorPeers: # AnchorPeers defines the location of peers which can be used # for cross org gossip communication. Note, this value is only # encoded in the genesis block in the Application section context - Host: peer0.org1.example.com Port: 7051 - &amp;Org2 # DefaultOrg defines the organization which is used in the sampleconfig # of the fabric.git development environment Name: Org2MSP # ID to load the MSP definition as ID: Org2MSP MSPDir: crypto-config/peerOrganizations/org2.example.com/msp AnchorPeers: # AnchorPeers defines the location of peers which can be used # for cross org gossip communication. Note, this value is only # encoded in the genesis block in the Application section context - Host: peer0.org2.example.com Port: 7051################################################################################## SECTION: Orderer## - This section defines the values to encode into a config transaction or# genesis block for orderer related parameters#################################################################################Orderer: &amp;OrdererDefaults # Orderer Type: The orderer implementation to start # Available types are &quot;solo&quot; and &quot;kafka&quot; OrdererType: solo Addresses: - orderer.example.com:7050 # Batch Timeout: The amount of time to wait before creating a batch BatchTimeout: 2s # Batch Size: Controls the number of messages batched into a block BatchSize: # Max Message Count: The maximum number of messages to permit in a batch MaxMessageCount: 10 # Absolute Max Bytes: The absolute maximum number of bytes allowed for # the serialized messages in a batch. AbsoluteMaxBytes: 99 MB # Preferred Max Bytes: The preferred maximum number of bytes allowed for # the serialized messages in a batch. A message larger than the preferred # max bytes will result in a batch larger than preferred max bytes. PreferredMaxBytes: 512 KB Kafka: # Brokers: A list of Kafka brokers to which the orderer connects # NOTE: Use IP:port notation Brokers: - 127.0.0.1:9092 # Organizations is the list of orgs which are defined as participants on # the orderer side of the network Organizations:################################################################################## SECTION: Application## - This section defines the values to encode into a config transaction or# genesis block for application related parameters#################################################################################Application: &amp;ApplicationDefaults # Organizations is the list of orgs which are defined as participants on # the application side of the network Organizations: 该模板定义了TwoOrgsOrdererGenesis 和TwoOrgsChannel , TwoOrgsOrdererGenesis用于生成ordering服务初始区块文件。 BatchTimeout是配置多久产生一个区块，默认是2秒。如果配置的时间过小就会产生很多空的区块，配置时间太长，则发现等待产生区块的时间太长。具体时间由交易频率和业务量决定。我们实际项目中，通常配置在30秒。 MaxMessageCount是配置在一个区块中允许的交易数的最大值。默认值是10。 交易数设置过小，导致区块过多，增加orderer的负担，因为要orderer要不断的打包区块，然后deliver给通道内的所有peer,这样还容易增加网络负载，引起网络拥堵。实际项目中通常配置500，不过具体还应该看业务情况，因为如果每个交易包含的数据的size如果太大，那么500个交易可能导致一个区块太大，因此需要根据实际业务需求权衡。 以上2个设置谁先满足要求，即执行。 我们需要设置一个环境变量来告诉configtxgen哪里去寻找configtx.yaml。然后，我们将调用configtxgen工具去创建orderer genesis block： 12345export FABRIC_CFG_PATH=$PWDconfigtxgen -profile TwoOrgsOrdererGenesis -outputBlock ./channel-artifacts/genesis.block2018-03-13 16:52:18.697 CST [common/configtx/tool] main -&gt; INFO 001 Loading configuration2018-03-13 16:52:18.736 CST [common/configtx/tool] doOutputBlock -&gt; INFO 002 Generating genesis block2018-03-13 16:52:18.739 CST [common/configtx/tool] doOutputBlock -&gt; INFO 003 Writing genesis block 在/channel-artifacts目录下看到生成的genesis.block 创建交易通道配置 我们需要创建channel transaction配置。请确保替换$CHANNEL_NAME或者将CHANNEL_NAME设置为整个说明中可以使用的环境变量： 123456export CHANNEL_NAME=mychannel# this file contains the definitions for our sample channelconfigtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel.tx -channelID $CHANNEL_NAME2018-03-13 17:32:39.744 CST [common/configtx/tool] main -&gt; INFO 001 Loading configuration2018-03-13 17:32:39.750 CST [common/configtx/tool] doOutputChannelCreateTx -&gt; INFO 002 Generating new channel configtx2018-03-13 17:32:39.751 CST [common/configtx/tool] doOutputChannelCreateTx -&gt; INFO 003 Writing new channel tx 在channel-artifacts目录下看到生成的channel.tx 生成锚节点配置更新文件（每个组织中第一个节点peer0作为锚节点与其他组织进行通信） 12345678configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.2018-03-13 17:44:26.627 CST [common/configtx/tool] main -&gt; INFO 001 Loading configuration2018-03-13 17:44:26.634 CST [common/configtx/tool] doOutputAnchorPeersUpdate -&gt; INFO 002 Generating anchor peer update2018-03-13 17:44:26.635 CST [common/configtx/tool] doOutputAnchorPeersUpdate -&gt; INFO 003 Writing anchor peer updatetx -channelID $CHANNEL_NAME -asOrg Org2MSPin/fabric-samples/first-network$configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org2MSPanchors.2018-03-13 17:44:35.236 CST [common/configtx/tool] main -&gt; INFO 001 Loading configuration2018-03-13 17:44:35.239 CST [common/configtx/tool] doOutputAnchorPeersUpdate -&gt; INFO 002 Generating anchor peer update2018-03-13 17:44:35.239 CST [common/configtx/tool] doOutputAnchorPeersUpdate -&gt; INFO 003 Writing anchor peer update channel-artifacts目录下生成了 1Org1MSPanchors.tx Org2MSPanchors.tx channel.tx genesis.block 启动网络 我们将利用docker-compose-cli.yaml脚本来启动我们的区块链网络。docker-compose-cli.yaml文件利用我们之前下载的镜像，并用以前生成的genesis.block来引导orderer。 1234working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer# command: /bin/bash -c &apos;./scripts/script.sh $&#123;CHANNEL_NAME&#125;; sleep $TIMEOUT&apos;volumes如果没有注释掉docker-compose-cli.yaml里这行，该脚本将在网络启动时执行所有命令 启动这个网络 12345678$CHANNEL_NAME=$CHANNEL_NAME TIMEOUT=1000 docker-compose -f docker-compose-cli.yaml up -dCreating peer0.org1.example.com ... doneCreating cli ... doneCreating peer0.org2.example.com ...Creating orderer.example.com ...Creating peer1.org2.example.com ...Creating peer0.org1.example.com ...Creating cli ... 创建并加入通道 确保容器已经起来后，执行 12345- docker exec -it cli bashroot@0d78bb69300d:/opt/gopath/src/github.com/hyperledger/fabric/peer#接下来执行：export CHANNEL_NAME=mychannelpeer channel create -o orderer.example.com:7050 -c $CHANNEL_NAME -f ./channel-artifacts/channel.tx --tls $CORE_PEER_TLS_ENABLED --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem 创建成功会生成 mychannel.block peer channel join -b mychannel.block 节点加入通道，这个节点是 CORE_PEER_ADDRESS=peer0.org1.example.com:7051 可以修改cli容器里的地址进行让其他节点加入进行了 安装和实例化链码 参见其他笔记 hyperledger fabric技术交流群 到期或者失效，发邮件(lg.json@gmail.com)给我你微信，拉你进群。","path":"posts/29630.html","date":"03-13","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Go代码结构及开发注意","text":"Go 代码必须保存在工作区中, 工作区就是一个特定的目录结构, 根目录下有如下3个目录 123src 目录: 存放 go 源码文件, 按 package 来组织 (一个 package 一个文件夹)pkg 目录: 存放 package 对象bin 目录: 存放可执行的命令command 注意配置go的开发环境，GOPATH,GOBIN,ROROOT,其中gopath是指的你的工作区目录,gobin是工作区生成bin目录，用于存放go install后生成的可执行文件,goroot:The root of the go tree go文件的包名可执行的为main,作为包使用的使用package xxx, 作为包使用的文件，其中的方法定义，需要第一个字母大写。 go build,和go install.当作为包使用时，go build不会生成任何文件。当对使用包的文件进行install，才会被加载对应使用包的文件到pkg相应的目录下（xxx.a形式）。 如果使用IDE则直接运行，命令行build,install可以看到以上过程。 命令行后查看产生的文件如图","path":"posts/23918.html","date":"03-09","excerpt":"","tags":[{"name":"go","slug":"go","permalink":"https://zhulg.github.io/tags/go/"}]},{"title":"Go语言glide包管理器使用","text":"glide 安装 1brew install glide glide包使用日志记录 日志记录错误地方可以重新执行查看 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148/Users/Meixin/Blockchain/LearnGo/src/github.com$glide init[INFO] Generating a YAML configuration file and guessing the dependencies[INFO] Attempting to import from other package managers (use --skip-import to skip)[INFO] Scanning code to look for dependencies[INFO] --&gt; Found reference to bogus/package[INFO] --&gt; Found reference to github.com/DATA-DOG/godog[INFO] --&gt; Adding sub-package gherkin to github.com/DATA-DOG/godog[INFO] --&gt; Found reference to github.com/Shopify/sarama[INFO] --&gt; Found reference to github.com/cloudflare/cfssl/api[INFO] --&gt; Adding sub-package csr to github.com/cloudflare/cfssl[INFO] --&gt; Adding sub-package log to github.com/cloudflare/cfssl[INFO] --&gt; Adding sub-package signer to github.com/cloudflare/cfssl[INFO] --&gt; Found reference to github.com/davecgh/go-spew/spew[INFO] --&gt; Found reference to github.com/fsouza/go-dockerclient[INFO] --&gt; Found reference to github.com/golang/groupcache/lru[INFO] --&gt; Found reference to github.com/golang/mock/gomock[INFO] --&gt; Found reference to github.com/golang/protobuf/jsonpb[INFO] --&gt; Adding sub-package proto to github.com/golang/protobuf[INFO] --&gt; Adding sub-package ptypes to github.com/golang/protobuf[INFO] --&gt; Adding sub-package ptypes/empty to github.com/golang/protobuf[INFO] --&gt; Adding sub-package ptypes/timestamp to github.com/golang/protobuf[INFO] --&gt; Found reference to github.com/gorilla/mux[INFO] --&gt; Found reference to github.com/hashicorp/go-version[INFO] --&gt; Found reference to github.com/looplab/fsm[INFO] --&gt; Found reference to github.com/miekg/pkcs11[INFO] --&gt; Found reference to github.com/mitchellh/mapstructure[INFO] --&gt; Found reference to github.com/op/go-logging[INFO] --&gt; Found reference to github.com/pkg/errors[INFO] --&gt; Found reference to github.com/spf13/cast[INFO] --&gt; Found reference to github.com/spf13/cobra[INFO] --&gt; Found reference to github.com/spf13/pflag[INFO] --&gt; Found reference to github.com/spf13/viper[INFO] --&gt; Found reference to github.com/stretchr/testify/assert[INFO] --&gt; Adding sub-package mock to github.com/stretchr/testify[INFO] --&gt; Found reference to github.com/syndtr/goleveldb/leveldb[INFO] --&gt; Adding sub-package leveldb/iterator to github.com/syndtr/goleveldb[INFO] --&gt; Adding sub-package leveldb/opt to github.com/syndtr/goleveldb[INFO] --&gt; Adding sub-package leveldb/util to github.com/syndtr/goleveldb[INFO] --&gt; Found reference to golang.org/x/crypto/ocsp[INFO] --&gt; Found reference to golang.org/x/crypto/sha3[INFO] --&gt; Found reference to golang.org/x/net/context[INFO] --&gt; Found reference to google.golang.org/grpc[INFO] --&gt; Adding sub-package codes to google.golang.org/grpc[INFO] --&gt; Adding sub-package connectivity to google.golang.org/grpc[INFO] --&gt; Adding sub-package credentials to google.golang.org/grpc[INFO] --&gt; Adding sub-package grpclog to google.golang.org/grpc[INFO] --&gt; Adding sub-package keepalive to google.golang.org/grpc[INFO] --&gt; Adding sub-package peer to google.golang.org/grpc[INFO] --&gt; Adding sub-package status to google.golang.org/grpc[INFO] --&gt; Found reference to gopkg.in/alecthomas/kingpin.v2[INFO] --&gt; Found reference to gopkg.in/yaml.v2[INFO] --&gt; Found reference to hyperledger/cci/appinit[INFO] --&gt; Found reference to hyperledger/cci/org/hyperledger/chaincode/example02[INFO] --&gt; Found reference to hyperledger/ccs[INFO] Writing configuration file (glide.yaml)[INFO] Would you like Glide to help you find ways to improve your glide.yaml configuration?[INFO] If you want to revisit this step you can use the config-wizard command at any time.[INFO] Yes (Y) or No (N)?y[INFO] Looking for dependencies to make suggestions on[INFO] --&gt; Scanning for dependencies not using version ranges[INFO] --&gt; Scanning for dependencies using commit ids[INFO] Gathering information on each dependency[INFO] --&gt; This may take a moment. Especially on a codebase with many dependencies[INFO] --&gt; Gathering release information for dependencies[INFO] --&gt; Looking for dependency imports where versions are commit ids[INFO] Here are some suggestions...[INFO] The package github.com/DATA-DOG/godog appears to have Semantic Version releases (http://semver.org).[INFO] The latest release is v0.7.5. You are currently not using a release. Would you like[INFO] to use this release? Yes (Y) or No (N)n[INFO] Would you like to remember the previous decision and apply it to future[INFO] dependencies? Yes (Y) or No (N)y[INFO] No proposed changes found. Have a nice day.[zhulianggang@bogon:/Users/Meixin/Blockchain/LearnGo/src/github.com$lsKnetic glide.yaml hyperledger nsf[zhulianggang@bogon:/Users/Meixin/Blockchain/LearnGo/src/github.com$glide install[INFO] Lock file (glide.lock) does not exist. Performing update.[INFO] Downloading dependencies. Please wait...[INFO] --&gt; Fetching github.com/davecgh/go-spew[INFO] --&gt; Fetching github.com/golang/protobuf[INFO] --&gt; Fetching github.com/miekg/pkcs11[INFO] --&gt; Fetching github.com/op/go-logging[INFO] --&gt; Fetching github.com/fsouza/go-dockerclient[INFO] --&gt; Fetching github.com/looplab/fsm[INFO] --&gt; Fetching github.com/cloudflare/cfssl[INFO] --&gt; Fetching github.com/spf13/cobra[INFO] --&gt; Fetching bogus/package[INFO] --&gt; Fetching github.com/spf13/viper[INFO] --&gt; Fetching github.com/hashicorp/go-version[INFO] --&gt; Fetching github.com/pkg/errors[INFO] --&gt; Fetching github.com/Shopify/sarama[INFO] --&gt; Fetching github.com/gorilla/mux[INFO] --&gt; Fetching github.com/spf13/cast[INFO] --&gt; Fetching github.com/golang/groupcache[INFO] --&gt; Fetching github.com/golang/mock[INFO] --&gt; Fetching github.com/mitchellh/mapstructure[INFO] --&gt; Fetching github.com/spf13/pflag[INFO] --&gt; Fetching github.com/DATA-DOG/godog[WARN] Unable to checkout bogus/package[ERROR] Update failed for bogus/package: Cannot detect VCS[INFO] --&gt; Fetching github.com/stretchr/testify[INFO] --&gt; Fetching github.com/syndtr/goleveldb[INFO] --&gt; Fetching golang.org/x/crypto/ocsp[INFO] --&gt; Fetching golang.org/x/crypto/sha3[INFO] --&gt; Fetching golang.org/x/net/context[INFO] --&gt; Fetching google.golang.org/grpc[INFO] --&gt; Fetching gopkg.in/alecthomas/kingpin.v2[INFO] --&gt; Fetching gopkg.in/yaml.v2[INFO] --&gt; Fetching hyperledger/cci/appinit[WARN] Unable to checkout hyperledger/cci/appinit[ERROR] Update failed for hyperledger/cci/appinit: Cannot detect VCS[INFO] --&gt; Fetching hyperledger/cci/org/hyperledger/chaincode/example02[WARN] Unable to checkout hyperledger/cci/org/hyperledger/chaincode/example02[ERROR] Update failed for hyperledger/cci/org/hyperledger/chaincode/example02: Cannot detect VCS[INFO] --&gt; Fetching hyperledger/ccs[WARN] Unable to checkout hyperledger/ccs[ERROR] Update failed for hyperledger/ccs: Cannot detect VCS[WARN] Unable to checkout golang.org/x/crypto/ocsp[ERROR] Update failed for golang.org/x/crypto/ocsp: Cannot detect VCS[WARN] Unable to checkout golang.org/x/crypto/sha3[ERROR] Update failed for golang.org/x/crypto/sha3: Cannot detect VCS[WARN] Unable to checkout golang.org/x/net/context[ERROR] Update failed for golang.org/x/net/context: Cannot detect VCS[WARN] Unable to checkout google.golang.org/grpc[ERROR] Update failed for google.golang.org/grpc: Cannot detect VCS[WARN] Unable to checkout github.com/fsouza/go-dockerclient[ERROR] Update failed for github.com/fsouza/go-dockerclient: Unable to get repository: Cloning into &apos;/Users/zhulianggang/.glide/cache/src/https-github.com-fsouza-go-dockerclient&apos;...error: RPC failed; curl 56 SSLRead() return error -9806fatal: The remote end hung up unexpectedlyfatal: early EOFfatal: index-pack failed: exit status 128[ERROR] Failed to do initial checkout of config: Cannot detect VCSCannot detect VCSCannot detect VCSCannot detect VCSCannot detect VCSCannot detect VCSCannot detect VCSCannot detect VCSUnable to get repository: Cloning into &apos;/Users/zhulianggang/.glide/cache/src/https-github.com-fsouza-go-dockerclient&apos;...error: RPC failed; curl 56 SSLRead() return error -9806fatal: The remote end hung up unexpectedlyfatal: early EOFfatal: index-pack failed: exit status 128","path":"posts/42315.html","date":"03-07","excerpt":"","tags":[{"name":"go","slug":"go","permalink":"https://zhulg.github.io/tags/go/"}]},{"title":"Fabric中的术语","text":"Auditability（审计性）：在一定权限和许可下，可以对链上的交易进行审计和检查。 Block（区块）：代表一批得到确认的交易信息的整体，准备被共识加入到区块链中。 Blockchain（区块链）：由多个区块链接而成的链表结构，除了初始区块，每个区块头部都包括前继区块内容的 hash 值。 Chaincode（链码）：区块链上的应用代码，扩展自“智能合约”概念，支持 golang、nodejs 等语言，多为图灵完备。 Channel（通道）：Fabric 网络上的私有隔离。通道中的 chaincode 和交易只有加入该通道的节点可见。同一个节点可以加入多个通道，并为每个通道内容维护一个账本。 Committer（提交节点）：1.0 架构中一种 peer 节点角色，负责对 orderer 排序后的交易进行检查，选择合法的交易执行并写入存储。 Commitment（提交）：提交节点完成对排序后交易的验证，将交易内容写到区块，并更新世界观的过程。 Confidentiality（保密）：只有交易相关方可以看到交易内容，其它人未经授权则无法看到。 Endorser（推荐节点或背书节点）：1.0 架构中一种 peer 节点角色，负责检验某个交易是否合法，是否愿意为之背书、签名。 Endorsement：背书过程。按照 chaincode 部署时候的 endorsement 策略，相关 peer 对交易提案进行模拟和检查，决策是否为之背书。如果交易提案获得了足够多的背书，则可以构造正式交易进行进一步的共识。 Invoke（调用）：一种交易类型，对 chaincode 中的某个方法进行调用，一般需要包括调用方法和调用参数。 Ledger（账本）：包括区块链结构（带有所有的交易信息）和当前的世界观（world state）。 Member（成员）：代表某个具体的实体身份，在网络中有用自己的根证书。节点和应用都必须属于某个成员身份。同一个成员可以在同一个通道中拥有多个 peer 节点，其中一个为 leader 节点，代表成员与排序节点进行交互，并分发排序后的区块给属于同一成员的其它节点。 MSP（Member Service Provider，成员服务提供者）：抽象的实现成员服务（身份验证，证书管理等）的组件，实现对不同类型的成员服务的可拔插支持。 Non-validating Peer（非验证节点）：不参与账本维护，仅作为交易代理响应客户端的 REST 请求，并对交易进行一些基本的有效性检查，之后转发给验证节点。 Orderer（排序节点）：1.0 架构中的共识服务角色，负责排序看到的交易，提供全局确认的顺序。 Permissioned Ledger（带权限的账本）：网络中所有节点必须是经过许可的，非许可过的节点则无法加入网络。 Privacy（隐私保护）：交易员可以隐藏交易的身份，其它成员在无特殊权限的情况下，只能对交易进行验证，而无法获知身份信息。 System Chain（系统链）：由对网络中配置进行变更的配置区块组成，一般可以用来作为组成网络成员们形成的联盟约定。 Transaction（交易）：执行账本上的某个函数调用或者部署 chaincode。调用的具体函数在 chaincode 中实现。 Transactor（交易者）：发起交易调用的客户端。 Validating Peer（验证节点）：维护账本的核心节点，参与一致性维护、对交易的验证和执行。 World State（世界状态）：即最新的全局账本状态。Fabric 用它来存储历史交易发生后产生的最新的状态，可以用键值或文档数据库实现。 Anchor（锚点）：一般指作为刚启动时候的初始联络元素或与其它结构的沟通元素。如刚加入一个 channel 的节点，需要通过某个锚点节点来快速获取 channel 内的情况（如其它节点的存在信息）。","path":"posts/50907.html","date":"03-05","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Hyperledger Fabric Chaincode汇总","text":"chaincode是什么 是一个类，这个类要实现fabric预先定义的一个接口。 它部署在fabric系统的结点上，Chaincode程序是依赖于fabric系统结点的。 Chaincode可通过应用提交的交易对账本状态初始化并进行管理，是生成Transaction的唯一来源，是外界与Fabric区块链交互的唯一渠道。 Fabric中，Chaincode就是开发者实现智能合约的方式。（智能合约就是用程序实现合约的内容，并且这个程序是事件驱动、有状态的）。 chaincode相关联的几个概念 Channel:通道，⼦链。同⼀peer可加⼊不同channel。Chaincode的操作基于channel进⾏。同⼀channel上的peer结点同步其上chaincode执⾏的结果。 Endorser:（模拟）执⾏Chaincode。分离计算任务，减轻consensus节点负担，增加吞吐量。⽀持endorsement policy，更加灵活。 Orderer: 对chaincode执⾏结果consensus。⽀持solo/ka|a/sBFT不同的ordering策略。 Committer:将chaincode执⾏结果写进ledger。 chaincode 编写 实现这个Fabric的接口 1234567891011type Chaincode interface &#123; // Init is called during Instantiate transaction after the chaincode container // has been established for the first time, allowing the chaincode to // initialize its internal data Init(stub ChaincodeStubInterface) pb.Response // Invoke is called to update or query the ledger in a proposal transaction. // Updated state variables are not committed to the ledger until the // transaction is committed. Invoke(stub ChaincodeStubInterface) pb.Response&#125; 例如 123456789101112131415package main import ( &quot;errors&quot; &quot;fmt&quot; &quot;github.com/hyperledger/fabric/core/chaincode/shim&quot; ) type SimpleChaincode struct &#123; &#125;func (t *SimpleChaincode) Init(stub shim.ChaincodeStubInterface,funcGon string, args []string)([]byte,error)func (t *SimpleChaincode) Invoke(stub shim.ChaincodeStubInterface,funcGon string,args[]string)([]byte,error)func main() &#123; err := shim.Start(new(SimpleChaincode)) if err != nil &#123; fmt.Prinn(&quot;Error starGng Simple chaincode: %s&quot;, err) &#125; &#125; chaincode 生命周期 chaincode生命周期的命令：package, install, instantiate,upgrade。在未来的版本中会添加stop和start交易的指令，以便能方便地停止与重启chaincode，而不用非要真正卸载它才行。在成功安装与实例化chaincode后，chaincode就处于运行状态，接着就可以用invoke交易指令来处理交易了。一段chaincode可以在安装后的任何时间被更新。 chaincode操作 进入开发者模式进行操作，确保已经下载过fabric-samples的例子代码（官网github上） cd chaincode-docker-devmode docker-compose-simple.yaml peer容器（ command: peer node start –peer-chaincodedev=true -o orderer:7050）有一个 –peer-chaincodedev标识，在构建peer node的时候传递这个标识，可以不使用Docker容器部署chaincode。 (启动网络) 1docker-compose -f docker-compose-simple.yaml up docker ps 可以看到需要的容器 12345CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES46c8bcf1c57a hyperledger/fabric-tools &quot;/bin/bash -c ./scri…&quot; 4 hours ago Up 4 hours clic1ade7741693 hyperledger/fabric-ccenv &quot;/bin/bash -c &apos;sleep…&quot; 4 hours ago Up 4 hours chaincode01cdf578d4bb hyperledger/fabric-peer &quot;peer node start --p…&quot; 4 hours ago Up 4 hours 0.0.0.0:7051-&gt;7051/tcp, 0.0.0.0:7053-&gt;7053/tcp peerc57803b7d3e9 hyperledger/fabric-orderer &quot;orderer&quot; 4 hours ago Up 4 hours 0.0.0.0:7050-&gt;7050/tcp orderer 进入chaincode docker 1234567docker exec -it chaincode bashroot@c1ade7741693:/opt/gopath/src/chaincode# lschaincode_example02 fabcar marbles02 saccroot@c1ade7741693:/opt/gopath/src/chaincode# cd saccroot@c1ade7741693:/opt/gopath/src/chaincode/sacc# lssacc sacc.goroot@c1ade7741693:/opt/gopath/src/chaincode/sacc# cd sacc 1go build 现在运行chaincode： 1CORE_PEER_ADDRESS=peer:7051 CORE_CHAINCODE_ID_NAME=mycc:0 ./sacc 另起一个终端 123docker exec -it cli bashpeer chaincode install -p chaincodedev/chaincode/sacc -n mycc -v 0peer chaincode instantiate -n mycc -v 0 -c &apos;&#123;&quot;Args&quot;:[&quot;a&quot;,&quot;10&quot;]&#125;&apos; -C myc 以上步骤，会把chaincode初始化到peer节点的文件系统中，位置在peer容器里的var/hyperledger/production/chaincodes下面，instantiate时从这个地方实例化 ‘-c‘参数指定的函数名和参数，-v 版本，-C 通道名称 -n 链码名称 现在我们执行一次将a的值设为20的调用： 1peer chaincode invoke -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;set&quot;, &quot;a&quot;, &quot;20&quot;]&#125;&apos; -C myc 最后查询a的值，我们会看到20。 1peer chaincode query -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]&#125;&apos; -C myc chaincode 更新 chaincode的更新过程目前验证是这样的 1231,需要重新启动下自己的chaincode代码，CORE_PEER_ADDRESS=peer:7051 CORE_CHAINCODE_ID_NAME=mycc:输入新版本号 ./sacc2,peer chaincode install -p chaincodedev/chaincode/sacc -n mycc -v 新版本号3,peer chaincode upgrade -n mycc -v 新版本号 -c &apos;&#123;&quot;Args&quot;:[&quot;a&quot;,&quot;10&quot;]&#125;&apos; -C myc 以上比较不理解的是需要从新启动下新版本对应的chaincode才行，否则在更新时会报找不到1Error: Error endorsing chaincode: rpc error: code = Unknown desc = Failed to init chaincode(handler not found for chaincode mycc:xxx)","path":"posts/7106.html","date":"03-01","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Goland破解使用","text":"Mac下 goland的使用 官网下载 地址 目前版本为2017.3.2 sudo cp /users/xxxx/Downloads/JetbrainsLicense.jar /Library/JetbrainsLicense/ 把下载到jar包放到固定位置，后续使用。 去应用程序/Applications中找到对应程序显示包,打开bin下面面的goland.vmoptions 追加 -javaagent:/Library/JetbrainsLicense/JetbrainsLicense.jar 打开goland 选择认证方式Activaction code，输入下面内容 1234567891011121314151617181920212223242526&#123;&quot;licenseId&quot;:&quot;1337&quot;,&quot;licenseeName&quot;:&quot;替换你的名字（随意）&quot;,&quot;assigneeName&quot;:&quot;&quot;,&quot;assigneeEmail&quot;:&quot;&quot;,&quot;licenseRestriction&quot;:&quot;Unlimited license till end of the century.&quot;,&quot;checkConcurrentUse&quot;:false,&quot;products&quot;:[&#123;&quot;code&quot;:&quot;II&quot;,&quot;paidUpTo&quot;:&quot;2099-12-31&quot;&#125;,&#123;&quot;code&quot;:&quot;DM&quot;,&quot;paidUpTo&quot;:&quot;2099-12-31&quot;&#125;,&#123;&quot;code&quot;:&quot;AC&quot;,&quot;paidUpTo&quot;:&quot;2099-12-31&quot;&#125;,&#123;&quot;code&quot;:&quot;RS0&quot;,&quot;paidUpTo&quot;:&quot;2099-12-31&quot;&#125;,&#123;&quot;code&quot;:&quot;WS&quot;,&quot;paidUpTo&quot;:&quot;2099-12-31&quot;&#125;,&#123;&quot;code&quot;:&quot;DPN&quot;,&quot;paidUpTo&quot;:&quot;2099-12-31&quot;&#125;,&#123;&quot;code&quot;:&quot;RC&quot;,&quot;paidUpTo&quot;:&quot;2099-12-31&quot;&#125;,&#123;&quot;code&quot;:&quot;PS&quot;,&quot;paidUpTo&quot;:&quot;2099-12-31&quot;&#125;,&#123;&quot;code&quot;:&quot;DC&quot;,&quot;paidUpTo&quot;:&quot;2099-12-31&quot;&#125;,&#123;&quot;code&quot;:&quot;RM&quot;,&quot;paidUpTo&quot;:&quot;2099-12-31&quot;&#125;,&#123;&quot;code&quot;:&quot;CL&quot;,&quot;paidUpTo&quot;:&quot;2099-12-31&quot;&#125;,&#123;&quot;code&quot;:&quot;PC&quot;,&quot;paidUpTo&quot;:&quot;2099-12-31&quot;&#125;,&#123;&quot;code&quot;:&quot;DB&quot;,&quot;paidUpTo&quot;:&quot;2099-12-31&quot;&#125;,&#123;&quot;code&quot;:&quot;GO&quot;,&quot;paidUpTo&quot;:&quot;2099-12-31&quot;&#125;,&#123;&quot;code&quot;:&quot;RD&quot;,&quot;paidUpTo&quot;:&quot;2099-12-31&quot;&#125;],&quot;hash&quot;:&quot;2911276/0&quot;,&quot;gracePeriodDays&quot;:7,&quot;autoProlongated&quot;:false&#125; 确认下，之后可以使用了。 附jar包下载:地址","path":"posts/50193.html","date":"02-28","excerpt":"","tags":[{"name":"Tools","slug":"Tools","permalink":"https://zhulg.github.io/tags/Tools/"}]},{"title":"Fabric部署例子错误日志","text":"部署Building Your First Network例子时，最后一步出现错误 日志为：Error: Error endorsing chaincode: rpc error: code = Unknown desc = Timeout expired while starting chaincode mycc:1.0(networkid:dev,peerid:peer0.org1.example.com,tx:936cdc1e9dd24b6eb0ae456ebd33b74706fdc682f5ce33c4c7bb479edc2e8353) 在mac环境下操作，可能与端口映射有关，暂时记录后续解决。 第二天进行上述问题解决 网上有相同错误出现也在最后一步，目前没有人回答解决方式。 把容器关掉，重启电脑，按照文档重新操作。 仍旧采用手动模式启动网络和构建环境，这次在最后一步没有出现上述错误。 对比之前步骤：是对代码进行重新拉取（之前操作过代码），重新参照文档进行执行步骤进行，问题解决。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293[zhulianggang@deMacBook-Pro:/Users/Meixin/Blockchain/fabric-samples/first-network$CHANNEL_NAME=$CHANNEL_NAME TIMEOUT=100 docker-compose -f docker-compose-cli.yaml up -dCreating peer0.org1.example.com ... doneCreating cli ... doneCreating peer1.org1.example.com ...Creating peer1.org2.example.com ...Creating peer0.org1.example.com ...Creating orderer.example.com ...Creating cli ...[zhulianggang@deMacBook-Pro:/Users/Meixin/Blockchain/fabric-samples/first-network$docker exec -it cli bashNNEL_NAME=mychannelopt/gopath/src/github.com/hyperledger/fabric/peer# export CHAroot@f3f2e62d56b9:/opt/gopath/src/github.com/hyperledger/fabric/peer#root@f3f2e62d56b9:/opt/gopath/src/github.com/hyperledger/fabric/peer#NNEL_NAME=mychannelopt/gopath/src/github.com/hyperledger/fabric/peer# export CHAroot@f3f2e62d56b9:/opt/gopath/src/github.com/hyperledger/fabric/peer#le.com/msp/tlscacerts/tlsca.example.com-cert.pemample.com/orderers/orderer.examp2018-02-26 03:12:56.001 UTC [msp] GetLocalMSP -&gt; DEBU 001 Returning existing local MSP2018-02-26 03:12:56.001 UTC [msp] GetDefaultSigningIdentity -&gt; DEBU 002 Obtaining default signing identity2018-02-26 03:12:56.013 UTC [channelCmd] InitCmdFactory -&gt; INFO 003 Endorser and orderer connections initialized2018-02-26 03:12:56.016 UTC [msp] GetLocalMSP -&gt; DEBU 004 Returning existing local MSP2018-02-26 03:12:56.016 UTC [msp] GetDefaultSigningIdentity -&gt; DEBU 005 Obtaining default signing identity2018-02-26 03:12:56.016 UTC [msp] GetLocalMSP -&gt; DEBU 006 Returning existing local MSP2018-02-26 03:12:56.016 UTC [msp] GetDefaultSigningIdentity -&gt; DEBU 007 Obtaining default signing identity2018-02-26 03:12:56.016 UTC [msp/identity] Sign -&gt; DEBU 008 Sign: plaintext: 0A8C060A074F7267314D53501280062D...53616D706C65436F6E736F727469756D2018-02-26 03:12:56.016 UTC [msp/identity] Sign -&gt; DEBU 009 Sign: digest: B5D898A654F2EABC35005D34CED73EE570B2610DD5EA613383174A3AA5C59B332018-02-26 03:12:56.016 UTC [msp] GetLocalMSP -&gt; DEBU 00a Returning existing local MSP2018-02-26 03:12:56.016 UTC [msp] GetDefaultSigningIdentity -&gt; DEBU 00b Obtaining default signing identity2018-02-26 03:12:56.017 UTC [msp] GetLocalMSP -&gt; DEBU 00c Returning existing local MSP2018-02-26 03:12:56.017 UTC [msp] GetDefaultSigningIdentity -&gt; DEBU 00d Obtaining default signing identity2018-02-26 03:12:56.017 UTC [msp/identity] Sign -&gt; DEBU 00e Sign: plaintext: 0AC3060A1508021A0608B8F6CDD40522...20AA143C54061DF7DAB091F959E8DE232018-02-26 03:12:56.017 UTC [msp/identity] Sign -&gt; DEBU 00f Sign: digest: AA79F2F70CBBEB5B34445F2AECA34700B0BF5C57E4532ED4032AE2560F8BD7652018-02-26 03:12:56.149 UTC [msp] GetLocalMSP -&gt; DEBU 010 Returning existing local MSP2018-02-26 03:12:56.150 UTC [msp] GetDefaultSigningIdentity -&gt; DEBU 011 Obtaining default signing identity2018-02-26 03:12:56.150 UTC [msp] GetLocalMSP -&gt; DEBU 012 Returning existing local MSP2018-02-26 03:12:56.150 UTC [msp] GetDefaultSigningIdentity -&gt; DEBU 013 Obtaining default signing identity2018-02-26 03:12:56.150 UTC [msp/identity] Sign -&gt; DEBU 014 Sign: plaintext: 0AC3060A1508021A0608B8F6CDD40522...B68EBE5D9DB612080A021A0012021A002018-02-26 03:12:56.150 UTC [msp/identity] Sign -&gt; DEBU 015 Sign: digest: 317192563E677B3B3F16EFAC2286A09EEFF929D636C7EEEC74CECB68956010412018-02-26 03:12:56.153 UTC [channelCmd] readBlock -&gt; DEBU 016 Got status: &amp;&#123;NOT_FOUND&#125;2018-02-26 03:12:56.154 UTC [msp] GetLocalMSP -&gt; DEBU 017 Returning existing local MSP2018-02-26 03:12:56.155 UTC [msp] GetDefaultSigningIdentity -&gt; DEBU 018 Obtaining default signing identity2018-02-26 03:12:56.170 UTC [channelCmd] InitCmdFactory -&gt; INFO 019 Endorser and orderer connections initialized2018-02-26 03:12:56.370 UTC [msp] GetLocalMSP -&gt; DEBU 01a Returning existing local MSP2018-02-26 03:12:56.371 UTC [msp] GetDefaultSigningIdentity -&gt; DEBU 01b Obtaining default signing identity2018-02-26 03:12:56.371 UTC [msp] GetLocalMSP -&gt; DEBU 01c Returning existing local MSP2018-02-26 03:12:56.371 UTC [msp] GetDefaultSigningIdentity -&gt; DEBU 01d Obtaining default signing identity2018-02-26 03:12:56.371 UTC [msp/identity] Sign -&gt; DEBU 01e Sign: plaintext: 0AC3060A1508021A0608B8F6CDD40522...EF996566D82D12080A021A0012021A002018-02-26 03:12:56.371 UTC [msp/identity] Sign -&gt; DEBU 01f Sign: digest: 10BC20CFB31CF56778E028F01EFF2E064ABCC753200CA906B9D13B998B4427F92018-02-26 03:12:56.377 UTC [channelCmd] readBlock -&gt; DEBU 020 Received block: 02018-02-26 03:12:56.378 UTC [main] main -&gt; INFO 021 Exiting.....root@f3f2e62d56b9:/opt/gopath/src/github.com/hyperledger/fabric/peer# lschannel-artifacts crypto mychannel.block scriptsel join -b mychannel.block th/src/github.com/hyperledger/fabric/peer# peer chann2018-02-26 03:13:12.733 UTC [msp] GetLocalMSP -&gt; DEBU 001 Returning existing local MSP2018-02-26 03:13:12.733 UTC [msp] GetDefaultSigningIdentity -&gt; DEBU 002 Obtaining default signing identity2018-02-26 03:13:12.741 UTC [channelCmd] InitCmdFactory -&gt; INFO 003 Endorser and orderer connections initialized2018-02-26 03:13:12.742 UTC [msp/identity] Sign -&gt; DEBU 004 Sign: plaintext: 0A8A070A5C08011A0C08C8F6CDD40510...929B4E708DB81A080A000A000A000A002018-02-26 03:13:12.742 UTC [msp/identity] Sign -&gt; DEBU 005 Sign: digest: 1A319B71E615CC7D4071E1587AEE41061CB4FF5E68680166310788D109AA52082018-02-26 03:13:12.808 UTC [channelCmd] executeJoin -&gt; INFO 006 Peer joined the channel!2018-02-26 03:13:12.808 UTC [main] main -&gt; INFO 007 Exiting.....go/chaincode_example02v 1.0 -p github.com/hyperledger/fabric/examples/chaincode/2018-02-26 03:13:20.735 UTC [msp] GetLocalMSP -&gt; DEBU 001 Returning existing local MSP2018-02-26 03:13:20.735 UTC [msp] GetDefaultSigningIdentity -&gt; DEBU 002 Obtaining default signing identity2018-02-26 03:13:20.736 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 003 Using default escc2018-02-26 03:13:20.736 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 004 Using default vscc2018-02-26 03:13:20.813 UTC [golang-platform] getCodeFromFS -&gt; DEBU 005 getCodeFromFS github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example022018-02-26 03:13:20.993 UTC [golang-platform] func1 -&gt; DEBU 006 Discarding GOROOT package fmt2018-02-26 03:13:20.993 UTC [golang-platform] func1 -&gt; DEBU 007 Discarding provided package github.com/hyperledger/fabric/core/chaincode/shim2018-02-26 03:13:20.993 UTC [golang-platform] func1 -&gt; DEBU 008 Discarding provided package github.com/hyperledger/fabric/protos/peer2018-02-26 03:13:20.994 UTC [golang-platform] func1 -&gt; DEBU 009 Discarding GOROOT package strconv2018-02-26 03:13:20.997 UTC [golang-platform] GetDeploymentPayload -&gt; DEBU 00a done2018-02-26 03:13:21.005 UTC [msp/identity] Sign -&gt; DEBU 00b Sign: plaintext: 0A89070A5B08031A0B08D1F6CDD40510...5F74FD270000FFFFDB02AC89002C00002018-02-26 03:13:21.005 UTC [msp/identity] Sign -&gt; DEBU 00c Sign: digest: 02E5237D20C2C3CBFE7B25142D6B768F4EA32874302BDA8FAF41094AAC54C9C52018-02-26 03:13:21.010 UTC [chaincodeCmd] install -&gt; DEBU 00d Installed remotely response:&lt;status:200 payload:&quot;OK&quot; &gt;2018-02-26 03:13:21.010 UTC [main] main -&gt; INFO 00e Exiting.....&apos; -P &quot;OR (&apos;Org1MSP.member&apos;,&apos;Org2MSP.member&apos;)&quot;gs&quot;:[&quot;init&quot;,&quot;a&quot;, &quot;100&quot;, &quot;b&quot;,&quot;200&quot;]&#125;2018-02-26 03:13:26.505 UTC [msp] GetLocalMSP -&gt; DEBU 001 Returning existing local MSP2018-02-26 03:13:26.505 UTC [msp] GetDefaultSigningIdentity -&gt; DEBU 002 Obtaining default signing identity2018-02-26 03:13:26.512 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 003 Using default escc2018-02-26 03:13:26.512 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 004 Using default vscc2018-02-26 03:13:26.513 UTC [msp/identity] Sign -&gt; DEBU 005 Sign: plaintext: 0A95070A6708031A0C08D6F6CDD40510...324D53500A04657363630A04767363632018-02-26 03:13:26.514 UTC [msp/identity] Sign -&gt; DEBU 006 Sign: digest: 4713950FB2016BDEE810A76DA80E1A73703740B5F7C8E6230E617E843605280C2018-02-26 03:13:39.871 UTC [msp/identity] Sign -&gt; DEBU 007 Sign: plaintext: 0A95070A6708031A0C08D6F6CDD40510...1974DA15342608566EF6D2AE756A4CBF2018-02-26 03:13:39.872 UTC [msp/identity] Sign -&gt; DEBU 008 Sign: digest: E32CF9439BF3964502AAA3D418094EF596F9C9E70DC3E40FFCF26F1095593FC42018-02-26 03:13:39.881 UTC [main] main -&gt; INFO 009 Exiting.....root@f3f2e62d56b9:/opt/gopath/src/github.com/hyperledger/fabric/peer# peer chaincode query -C $CHANNEL_NAME -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]&#125;&apos;2018-02-26 03:14:02.583 UTC [msp] GetLocalMSP -&gt; DEBU 001 Returning existing local MSP2018-02-26 03:14:02.583 UTC [msp] GetDefaultSigningIdentity -&gt; DEBU 002 Obtaining default signing identity2018-02-26 03:14:02.583 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 003 Using default escc2018-02-26 03:14:02.584 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 004 Using default vscc2018-02-26 03:14:02.584 UTC [msp/identity] Sign -&gt; DEBU 005 Sign: plaintext: 0A95070A6708031A0C08FAF6CDD40510...6D7963631A0A0A0571756572790A01612018-02-26 03:14:02.584 UTC [msp/identity] Sign -&gt; DEBU 006 Sign: digest: 681150DCAE15AFAD4F1F6755A38CEA9A1860E2900A2C06D77953F604BCBC32EFQuery Result: 1002018-02-26 03:14:02.601 UTC [main] main -&gt; INFO 007 Exiting.....root@f3f2e62d56b9:/opt/gopath/src/github.com/hyperledger/fabric/peer#","path":"posts/51437.html","date":"02-24","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"区块链基本概念","text":"区块链: 一种新型去中心化协议，能安全地存储比特币交易或其它数据，信息不可伪造和篡改，可以自动执行智能合约，无需任何中心化机构的审核。交易既可以是比特币这样的数字货币，也可以是债权、股权、版权等数字资产，区块链技术解决了拜占庭将军问题，大大降低了现实经济的信任成本与会计成本，重新定义了互联网时代的产权制度 比特币:（英语：Bitcoin[注 2]）是一种去中心化，非普遍可全球支付的电子加密货币[6]。比特币由中本聪（又译中本哲史）[注 3]（化名）于2009年1月3日，基于无国界的对等网络，用共识主动性开源软件发明创立。截至2018年1月14日，比特币是目前市场总值最高的加密货币[7]。任何人皆可参与比特币活动，可以通过称为挖矿[注 4]的电脑运算来发行。比特币协议数量上限为2100万个，以避免通货膨胀问题。使用比特币是通过私钥作为数字签名，允许个人直接支付给他人，不需经过如银行、清算中心、证券商等第三方机构，从而避免了高手续费、繁琐流程以及受监管性的问题[8]，任何用户只要拥有可连接互联网的数字设备皆可使用。2017年8月1日出现比特币现金(Bitcoin Cash, BCC, BCH)，是一个比特币的硬分叉。 钱包:：比特币钱包使用户可以检查、存储、花费其持有的比特币，其形式多种多样，功能可繁可简，它可以是遵守比特币协议运行的各种工具，如电脑客户端、手机客户端、网站服务、专用设备，也可以只是存储著比特币私密密钥的介质，如一张纸、一段暗号、一个U盘、一个文本文档，因为只要掌握比特币的私密密钥，就可以处置其对应地址中包含的比特币。比特币无法存入一般的银行账户，交易只能在比特币网络上进行，使用前需下载客户端或接入线上网络[32] 客户端: 比特币客户端有很多.比特币官方客户端为Bitcoin QT，由中本聪开发[32]。Bitcoin QT从0.4.0版本开始，支持钱包档加密存储。加密的钱包在每次付款的时候，都必须输入密码。但如果用加密之前备份的钱包文件（wallet.dat）替换回来，还是可以正常交易。考虑到比特币的原理可得出，掌握私密密钥即拥有对相应地址中比特币的处置权，不管对钱包文件（内容包括各个地址对应的私密密钥）是进行了加密还是删除，都不能否定它。 地址与私密密钥: 比特币在产生地址时，相对应的私密密钥也会一起产生， 彼此的关系犹如银行存款的账号和密码，有些在线钱包的私密密钥是存储在云的，用户只能通过该在线钱包的服务使用比特币 地址用于接收比特币，功能类似银行的存款账号，但不需要实名登记,比特币的地址是由用户的公开密钥经过 SHA-256 散列运算后，再通过 RIPEMD-160 散列运算而得，其长度固定为 160 个比特(bits)，通常会利用 Base-58 将之编码成一串由英文字母和数字所组成的字符串，以方便显示或散布，其特征是皆以“1”或者“3”开头，区分大小写[34]，但不包括“IlO0”等字符，“1”开头的地址长26~34位，“3”开头的地址长34位 私密密钥:比特币的私密密钥（私钥，private key），作用相当于金融卡提款或消费的密码，用于证明比特币的所有权。拥有者必须私密密钥可以给交易消息（最常见的，花费比特币的消息）签名，以证明消息的发布者是相应地址的所有者，没有私钥，就不能给消息签名，作为不记名货币，网络上无法认得所有权的证据，也就不能使用比特币，交易时以网络会以公钥确认，掌握私密密钥就等于掌握其对应地址中存放的比特币 挖矿: (比特币):比特币矿工是由遍布世界各地、任何人都有参与权的比特币网络的成员。为了获得新发行的比特币，成为一个遵循比特币协议的发行人，成员需要透过电脑设备解答数学难题，此过程犹如开采矿物，故称为“挖矿”，用于挖矿的中央处理器CPU、图形处理器GPU、特殊应用集成电路ASIC等电脑设备，称为“矿机”，使用矿机挖矿，并保障比特币区块链连续运作的人被称为“矿工”。矿工也用矿机验证交易，包括交易消息的数字签名，证明花费者所有权，并防止一币多付的发生，而赚取比特币手续费。 交易:比特币点对点网络将所有的交易历史都存储在区块链中，比特币交易就是在区块链账本上“记账”，通常它由比特币客户端协助完成。付款方需要以自己的私钥对交易进行数字签名，证明所有权并认可该次交易。比特币会被记录在收款方的地址上，交易无需收款方参与，收款方可以不在线，甚至不存在，交易的资金支付来源，也就是花费，称为“输入”，资金去向，也就是收入，称为“输出”。如有输入，输入必须大于等于输出，输入大于输出的部分即为交易手续费。矿工产出交易没有输入，只有输出，交易记录会显示新生成的比特币（Newly Generated Coins），除矿工产出交易外，一个输入必然是另一笔交易的一个输出，也就是一笔收入必然是其他人的支付。一个输入没有成为另一笔交易的输出时，它是“未花费的”，也就是“账户余额”。收录此交易的区块被广播后，此交易就有了“1个确认”。矿工们平均每10分钟产生一个区块，每一个新区块的诞生会使此交易的确认数加1。当确认数达到6时，通常这笔交易被认为比较安全、难以逆转。[47]。比特币交易为不可逆，每一笔交易都无法撤销，商家不必遭到诈骗式的拒付而遭受损失，唯一可以获得退款的方法，就是请对方再做一笔反向交易，但需要对方的配合. 比特币分布:作为匿名的比特币地址，原则上无法得知持有者，除非特别情况，通常也无法得知某人拥有的比特币地址，每个人都可以创建及拥有许多的比特币地址，不同地址可能由同一人持有，包括有些余额很少的地址，且不代表持有者的真实财富状况，而该地址的私钥若丢失，里面的比特币就不能使用，因此某些地址的比特币，特别是只进不出、或长期未花用的地址，可能是私钥已丢失、而任何人皆无法再使用的地址，而且有些地址是由交易所等机构持有，不属于特定个人。 安全性： 比特币结合P2P对等网络技术和密码学原理，来维持发行系统的安全可靠性。[57]与有中心服务器的中央网络系统不同，在P2P网络中无中心服务器，每个用户端既是一个节点，也有服务器的功能，任何一个节点都无法直接找到其他节点，必须依靠其户群进行信息交流。比特币使用以下3种机制，来解决初次运行时，查找其他节点的问题。在默认情况下，运行比特币的用户端加入一个IRC聊天通道，并可以获知加入该通道的其他用户端的IP地址和端口。该通道的名称和IRC聊天服务器的名称被写在了比特币软件中。一些“知名的”比特币节点也被编写在软件中，以防IRC聊天服务功能由于某种原因无法访问。可以手动添加运行比特币的其他用户端的IP地址。现在不需要运行上述3个机制，一旦连接到比特币的某个节点，在发送的信息中，就会包含对等网络P2P其他节点的地址，直接通过其匿名用户群来找到其他节点。节点遍布整个互联网的P2P技术和密码学原理相结合，确保了比特币发行系统无法被政府、组织、或黑客监控、隔离、或破坏，从而保障了系统的可靠性和匿名性。[58]。拒绝服务式（DDoS）以及其他攻击，其目标都是针对比特币交易中心，这和攻击或关闭传统货币交易所的网络，理论上不影响其货币发行和使用一样 匿名与隐私保护：匿名与隐私是比特币问世时主要的诉求，因为交易或创建比特币地址、钱包时，不需要提供任何个人信息，但交易信息是向全网广播的，因此所有交易记录细节都是公开的、而可以追踪。不同于采用实名制的传统金融机构，通过将交易信息与客户个资严格保密来保护客户隐私，但若国家机关基于特定原因，而向金融机构索要数据，这样仍然会使隐私消失，而使得特定交易信息与客户个资曝光[60]，比特币通过为每笔交易创建不同的地址来保护隐私，官方网站也建议每一个地址只做一次交易[61]。例如，甲方希望发送1.20 BTC给乙方，那么比特币网络上所有节点都能够查阅这笔1.20 BTC的交易细节。但除非甲方或者乙方公布自己拥有其中的一个地址，否则作为不记名的货币，其他人很难知道这笔交易是发生在甲方与乙方之间的。 公有链：是任何节点都是向任何人开放的，每个人都可以参与到这个区块链中参与计算，而且任何人都可以下载获得完整区块链数据（全部账本）。 联盟链：是指参与每个节点的权限都完全对等，大家在不需要完全互信的情况下就可以实现数据的可信交换，联盟链的各个节点通常有与之对应的实体机构组织，通过授权后才能加入与退出网络。通常是公司与公司、组织与组织之间达成的联盟模式。 私有链：有些区块链的应用场景下，并不希望这个系统任何人都可以参与，不对外公开，只有被许可的节点才可以参与并且查看所有数据。那么这种区块链结构我们称为私有链。一般适用于特定机构的内部数据管理与审计 共识机制： 顾名思义，就是在一个问题上达成共识的一套方法。在区块链中，共识机制也是区块链的底层技术，也是最为重要的技术。它的存在就是为了完成节点间信息同步，交易的确认，网络运行等重要任务。常见的共识机制有：POW、POS、DPOS、PBFT、SCP等。","path":"posts/455.html","date":"01-31","excerpt":"","tags":[{"name":"区块链","slug":"区块链","permalink":"https://zhulg.github.io/tags/区块链/"}]},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","path":"posts/16107.html","date":"01-26","excerpt":"","tags":[{"name":"hexo","slug":"hexo","permalink":"https://zhulg.github.io/tags/hexo/"}]},{"title":"协同过滤对比","text":"UserCF和ItemCF对比记录 性能 12UserCF: 适用于用户较少的场合，如果用户很多，计算用户 相似度矩阵代价很大ItemCF: 适用于物品数明显小于用户数的场合，如果物品很多,计算物品相似度矩阵代价很大 适用领域 12UserCF: 时效性较强，用户个性化兴趣不太明显的领域ItemCF:长尾物品丰富，用户个性化需求强烈的领域 实时性 12UserCF:用户有新行为，不一定造成推荐结果的立即变化ItemCF:用户有新行为，一定会导致推荐结果的实时变化 冷启动 123UserCF:在新用户对很少的物品产生行为后，不能立即对他 进行个性化推荐，因为用户相似度表是每隔一段时间离线计算的.新物品上线后一段时间，一旦有用户对物品产生行 为，就可以将新物品推荐给和对它产生行为的用户 兴趣相似的其他用户ItemCF:新用户只要对一个物品产生行为，就可以给他推荐和该物品相关的其他物品,但没有办法在不离线更新物品相似度表的情况 下将新物品推荐给用户 推荐理由 12UserCF:很难提供令用户信服的推荐解释ItemCF:利用用户的历史行为给用户做推荐解释，可以令 用户比较信服","path":"posts/46889.html","date":"01-26","excerpt":"","tags":[{"name":"推荐系统","slug":"推荐系统","permalink":"https://zhulg.github.io/tags/推荐系统/"}]},{"title":"推荐系统学习建议","text":"推荐系统学习路线 基础知识的储备，掌握相关的基本概念、推荐算法等理论知识，活学活用。如《集体智慧编程》、《推荐系统实践》、《推荐系统》。还有殿堂级大作《Recommender systems handbook》，里面不仅对推荐系统方方面面有详细介绍，还给出了引用的论文，值得投入更多的时间和精力不断钻研。 亲自动手实践才能深入体会推荐系统的各个环节，才能对各种推荐算法的优缺点有真切感受。一方面可以很熟练的完成简单的推荐算法，如content-based、item-based CF等。另一方面要掌握一些常见的推荐算法库，如SvdFeature、LibFM、Mahout、MLib等。 推荐系统的方方面面提现了很多很多学科的智慧，如信息检索、数据挖掘和机器学习等，掌握这些知识，对推荐效果提升、性能优化都有极大的帮助，也会不断的拓展推荐系统的业务场景。 阅读相关的paper是免不了的，Recsys、KDD、SIGIR等都有推荐系统方面的论文。","path":"posts/15795.html","date":"01-19","excerpt":"","tags":[{"name":"推荐系统","slug":"推荐系统","permalink":"https://zhulg.github.io/tags/推荐系统/"}]},{"title":"Kafka","text":"###kafka概述 关于快速学习方法领悟 学习不熟悉的领域和知识，要快速找出技术的原理，核心功能点，能做什么能，用于解决什么问题。 暂时忽略技术细节，找出技术主干，根据项目和日后学习循序渐进到细节部分。 一，kafka是什么 Apache kafka是消息中间件的一种，关于消息中间件摘录一段网上比较好的通俗理解。 举个例子，生产者消费者，生产者生产鸡蛋，消费者消费鸡蛋，生产者生产一个鸡蛋，消费者就消费一个鸡蛋，假设消费者消费鸡蛋的时候噎住了（系统宕机了），生产者还在生产鸡蛋，那新生产的鸡蛋就丢失了。再比如生产者很强劲（大交易量的情况），生产者1秒钟生产100个鸡蛋，消费者1秒钟只能吃50个鸡蛋，那要不了一会，消费者就吃不消了（消息堵塞，最终导致系统超时），消费者拒绝再吃了，”鸡蛋“又丢失了，这个时候我们放个篮子在它们中间，生产出来的鸡蛋都放到篮子里，消费者去篮子里拿鸡蛋，这样鸡蛋就不会丢失了，都在篮子里，而这个篮子就是”kafka“。鸡蛋其实就是“数据流”，系统之间的交互都是通过“数据流”来传输的（就是tcp、http什么的），也称为报文，也叫“消息”。消息队列满了，其实就是篮子满了，”鸡蛋“ 放不下了，那赶紧多放几个篮子，其实就是kafka的扩容。各位现在知道kafka是干什么的了吧，它就是那个”篮子” 二，kafka和核心功能 发布订阅:消息传递系统，发布和订阅记录流，类似消息队列和企业级的消息系统 处理: 高效实时处理，以流的形式处理记录 存储:数据流安全地在分布式集群中复制存储，以容错的方式存储记录流。 三，kafka相关术语 Topic：Kafka将消息种子(Feed)分门别类， 每一类的消息称之为话题(Topic). Producer：发布消息的对象称之为话题生产者(Kafka topic producer) Consumer：订阅消息并处理发布的消息的种子的对象称之为话题消费者(consumers) Broker：已发布的消息保存在一组服务器中，称之为Kafka集群。集群中的每一个服务器都是一个代理(Broker). 消费者可以订阅一个或多个话题，并从Broker拉数据，从而消费这些已发布的消息（有点上边篮子的意思） 四，Mac安装kafka brew install kafka 123456789101112131415Updating Homebrew...==&gt; Auto-updated Homebrew!Updated 1 tap (caskroom/cask).No changes to formulae.==&gt; Downloading https://homebrew.bintray.com/bottles/kafka-0.11.0.1.sierra.bottle.1.tar.gz######################################################################## 100.0%==&gt; Pouring kafka-0.11.0.1.sierra.bottle.1.tar.gz==&gt; CaveatsTo have launchd start kafka now and restart at login: brew services start kafkaOr, if you don&apos;t want/need a background service you can just run: zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties &amp; kafka-server-start /usr/local/etc/kafka/server.properties==&gt; Summary🍺 /usr/local/Cellar/kafka/0.11.0.1: 149 files, 35.5MB kafka启动依赖zookeeper，需要先启动zookepper 1234/usr/local/Cellar/zookeeper/3.4.10/bin$./zkServer startZooKeeper JMX enabled by defaultUsing config: /usr/local/etc/zookeeper/zoo.cfgStarting zookeeper ... STARTE 五，使用官方例子 到这个 /usr/local/Cellar/kafka/0.11.0.1$下 sudo ./bin/kafka-server-start ./libexec/config/server.properties 创建一个名为“test”的Topic，只有一个分区和一个备份：到/usr/local/Cellar/kafka/0.11.0.1$ 1bin/kafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test 启动生成者 1bin/kafka-console-producer --broker-list localhost:9092 --topic test 输入： 123This is a messageThis is another messagehello world 查看消费 1bin/kafka-console-consumer --bootstrap-server localhost:9092 --topic test --from-beginning 设置多个broker集群方式，参见官网","path":"posts/13749.html","date":"12-16","excerpt":"","tags":[{"name":"kafka","slug":"kafka","permalink":"https://zhulg.github.io/tags/kafka/"}]},{"title":"Flume概述","text":"概述 Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。 主要功能 1.日志收集Flume最早是Cloudera提供的日志收集系统，目前是Apache下的一个孵化项目，Flume支持在日志系统中定制各类数据发送方，用于收集数据。 2.数据处理Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力 Flume提供了从console（控制台）、RPC（Thrift-RPC）、text（文件）、tail（UNIX tail）、syslog（syslog日志系统，支持TCP和UDP等2种模式），exec（命令执行）等数据源上收集数据的能力。 安装 brew install flume 1234567891011121314$brew install flumeUpdating Homebrew...==&gt; Auto-updated Homebrew!Updated 2 taps (caskroom/cask, homebrew/core).==&gt; New Formulaelibidn2 mongodb@3.4==&gt; Updated Formulaemongodb ✔ advancemame gsoap libcdio oniguruma pygobject tinyxml2 youtube-dlack ffmpeg lgogdownloader mono optipng shpotify wireguard-tools==&gt; Downloading https://www.apache.org/dyn/closer.cgi?path=flume/1.6.0/apache-flume-1.6.0-bin.tar.gz==&gt; Best Mirror http://mirrors.hust.edu.cn/apache/flume/1.6.0/apache-flume-1.6.0-bin.tar.gz######################################################################## 100.0%🍺 /usr/local/Cellar/flume/1.6.0: 1,497 files, 77.8MB, built in 1 minute 55 seconds 核心原理和概念 Flume使用agent来收集日志，agent包括三个组成部分： source：收集数据 channel：存储数据 sink ：输出数据 Flume使用source接收日志，然后缓存到channel中，最后通过sink将数据输出到目的地。只有在sink将channel中的数据成功发送出去之后，channel才会将临时数据进行删除，这种机制保证了数据传输的可靠性与安全性。 Flume支持agent串联操作，也就是说可以将上一个agent的sink输出到作为下一个agent的source的输入。 source还支持接受多个输入，sink也可以将数据输出到多个目的地中 配置和例子使用 配置文件在 /usr/local/Cellar/flume/1.6.0/libexec/conf, flume可以接收很多不同的输入源, 也可以输出到不同地方, 首先如果配置文件下没有flume-env.sh, 那么需要 cp flume-env.sh.template flume-env.sh, 然后需要cp flume-conf.properties.template flume-conf.properties, 这个是创建一个flume启动的配置文件。（使用时需要在这个里面进行配置） 运行官方的例子：编辑example.conf 放在/usr/local/Cellar/flume/1.6.0目录下 1234567891011121314151617181920212223# example.conf: A single-node Flume configuration# Name the components on this agenta1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = netcata1.sources.r1.bind = localhosta1.sources.r1.port = 44444# Describe the sinka1.sinks.k1.type = logger# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 在这个配置文件里面仅定义了一个agent，它的名字叫a1，a1有一个source监听的是端口44444的数据，有一个channel是在内存中缓存event数据，还有一个sink将event数据打印到console控制台。在这个配置文件中配置了多个组件，然后描述了它们的type和配置参数。一个给定的配置文件可以指定多个不同名字的agent，当一个flume进程启动的时候，一个标志会被传进去告诉它启动哪一个agent /usr/local/Cellar/flume/1.6.0下启动： 1$bin/flume-ng agent --conf conf --conf-file example.conf --name a1 -Dflume.root.logger=INFO,console 另起客户端 telnet localhost 44444 查看输出","path":"posts/15079.html","date":"12-12","excerpt":"","tags":[{"name":"flume","slug":"flume","permalink":"https://zhulg.github.io/tags/flume/"}]},{"title":"openresty安装Mac环境","text":"openresty概述 OpenResty® 是一个基于 Nginx 与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。 OpenResty® 通过汇聚各种设计精良的 Nginx 模块（主要由 OpenResty 团队自主开发），从而将 Nginx 有效地变成一个强大的通用 Web 应用平台。这样，Web 开发人员和系统工程师可以使用 Lua 脚本语言调动 Nginx 支持的各种 C 以及 Lua 模块，快速构造出足以胜任 10K 乃至 1000K 以上单机并发连接的高性能 Web 应用系统。 mac环境安装 brew install openresty/brew/openresty 安装成功后把nginx配置到环境变量(如果之前安装过nginx,干脆给卸载了，用brew uninstall） 1export PATH=/usr/local/opt/openresty/nginx/sbin:$PATH 配置成功就可以任意环境使用（记得生效下） 启动nginx，使用sudo nginx 相对于启动了openresty. 访问localhost:80 看到openstry介绍 命令行 sudo nginx -V 查看相关文件位置 环境变量配置进去后就可以通过这些命令操作openresty 1234启动:nginx停止:nginx -s stop 停止nginx也停止了openresty重启:nginx -s reload检验nginx配置是否正确: nginx -t 使用例子 为了测试使用创建另一个目录，不使用openresty里的配置文件。启动时也启动的是该配置文件。 mkdir ~/openresty-test ~/openresty-test/logs/ ~/openresty-test/conf/ 在conf文件下创建nginx.conf文件 12345678910111213141516worker_processes 1;error_log logs/error.log;events &#123; worker_connections 1024;&#125;http &#123; server &#123; listen 8085; location / &#123; default_type text/html; content_by_lua &apos; ngx.say(&quot;&lt;p&gt;hello, world&lt;/p&gt;&quot;) &apos;; &#125; &#125;&#125; nginx -p pwd/ -c conf/nginx.conf (需要先停止之前启动的nginx,如果启动过。然后执行) 启动后访问 http://localhost:8085","path":"posts/89.html","date":"12-12","excerpt":"","tags":[{"name":"openresty","slug":"openresty","permalink":"https://zhulg.github.io/tags/openresty/"}]},{"title":"hadoop笔记（三）Intellij中开发","text":"在Intellij中运行hadoop程序 使用Intellij创建maven工程。 在pom.xml里创建hadoop相关依赖。 12345678910111213141516171819202122232425262728293031323334353637383940&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt; &lt;version&gt;2.8.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-hdfs&lt;/artifactId&gt; &lt;version&gt;2.8.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-mapreduce-client-core&lt;/artifactId&gt; &lt;version&gt;2.8.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-mapreduce-client-jobclient&lt;/artifactId&gt; &lt;version&gt;2.8.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 改造SDK源码下的wordCount例子代码 添加日志输出配置 1234log4j.appender.stdout = org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.Target = System.outlog4j.appender.stdout.layout = org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern = [%-5p] %d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; method:%l%n%m%n 运行结果 工程地址github地址","path":"posts/14959.html","date":"12-10","excerpt":"","tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://zhulg.github.io/tags/hadoop/"}]},{"title":"Jenkins本地使用命令记录","text":"mac上jenkins记录安装 brew install jenkins which jenkins 查看安装位置 jenkins 启动 jenkins -v 版本查看 url上的开关命令123http://localhost:8080/exit //退出Jenkinshttp://localhost:8080/restart //重启http://localhost:8080/reload //重新加载","path":"posts/55605.html","date":"12-08","excerpt":"","tags":[{"name":"jenkins","slug":"jenkins","permalink":"https://zhulg.github.io/tags/jenkins/"}]},{"title":"Hadoop笔记（二）","text":"hadoop mac上安装记录hadoop 概述 Apache Hadoop 的框架最核心的设计就是：HDFS 和 MapReduce。HDFS 为海量的数据提供了存储，而 MapReduce 则为海量的数据提供了计算。 引入设想一下这样的应用场景。我有一个100M的数据库备份的sql文件。我现在想在不导入到数据库的情况下直接用grep操作通过正则过滤出我想要的内容。例如：某个表中含有相同关键字的记录那么有几种方式,一种是直接用linux的命令grep还有一种就是通过编程来读取文件,然后对每行数据进行正则匹配得到结果好了现在是100M的数据库备份。上述两种方法都可以轻松应对。 那么如果是1G,1T甚至1PB的数据呢,上面2种方法还能行得通吗？答案是不能。毕竟单台服务器的性能总有其上限。那么对于这种超大数据文件怎么得到我们想要的结果呢？ 有种方法就是分布式计算,分布式计算的核心就在于利用分布式算法把运行在单台机器上的程序扩展到多台机器上并行运行。从而使数据处理能力成倍增加。但是这种分布式计算一般对编程人员要求很高,而且对服务器也有要求。导致了成本变得非常高。 Haddop就是为了解决这个问题诞生的。Haddop可以很轻易的把很多linux的廉价pc组成分布式结点,然后编程人员也不需要知道分布式算法之类,只需要根据mapreduce的规则定义好接口方法,剩下的就交给Haddop。它会自动把相关的计算分布到各个结点上去,然后得出结果。 例如上述的例子：Hadoop要做的事首先把1PB的数据文件导入到HDFS中,然后编程人员定义好map和reduce,也就是把文件的行定义为key,每行的内容定义为value,然后进行正则匹配,匹配成功则把结果通过reduce聚合起来返回。Hadoop就会把这个程序分布到N个结点去并行的操作。 那么原本可能需要计算好几天,在有了足够多的结点之后就可以把时间缩小到几小时之内。 这也就是所谓的大数据云计算了。如果还是不懂的话再举个简单的例子 比如1亿个1相加得出计算结果,我们很轻易知道结果是1亿。但是计算机不知道。那么单台计算机处理的方式做一个一亿次的循环每次结果+1 那么分布式的处理方式则变成我用1万台计算机,每个计算机只需要计算1万个1相加然后再有一台计算机把1万台计算机得到的结果再相加从而得到最后的结果。 理论上讲,计算速度就提高了1万倍。当然上面可能是一个不恰当的例子。但所谓分布式,大数据,云计算大抵也就是这么回事了。 一，安装和文件配置 brew install hadoop 编辑hadoop-env.sh (单机式) 在 /usr/local/Cellar/hadoop/2.8.2/libexec/etc/hadoop 123# export HADOOP_OPTS=&quot;$HADOOP_OPTS -Djava.net.preferIPv4Stack=true&quot; 替换成export HADOOP_OPTS=&quot;$HADOOP_OPTS -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc=&quot; 编辑Core-site.xml (也在上个地址) ,贴入下方配置 1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/local/Cellar/hadoop/hdfs/tmp&lt;/value&gt; &lt;description&gt;A base for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 编辑mapred-site.xml（也在该目录下，有模板文件,贴入如下配置） 123456&lt;configuration&gt;&lt;property&gt;&lt;name&gt;mapred.job.tracker&lt;/name&gt;&lt;value&gt;localhost:9010&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; 编辑hdfs-site.xml(文件位置同上) 123456&lt;configuration&gt;&lt;property&gt;&lt;name&gt;dfs.replication&lt;/name&gt;&lt;value&gt;1&lt;/value&gt;&lt;/property&gt;&lt;/configuration 二， 配置环境 vim ~/.bash_profile 添加配置（如果添加到.profile下则每次使用需要 source ~/.profile,推荐配置到./bash_profile 下） 配置完可以使用hstart 和hstop启动hadoop了（看下下边配置里hstart对应的相关启动sh） 12alias hstart=&quot;/usr/local/Cellar/hadoop/2.8.2/sbin/start-dfs.sh;/usr/local/Cellar/hadoop/2.8.2/sbin/start-yarn.sh&quot;alias hstop=&quot;/usr/local/Cellar/hadoop/2.8.2/sbin/stop-yarn.sh;/usr/local/Cellar/hadoop/2.8.2/sbin/stop-dfs.sh&quot; 初始化Hadoop Cluster（在本地系统中format HDFS(Hadoop Distributed File System)）在hadoop-2.8.2路径里面运行 1$./bin/hdfs namenode -format 允许远程登录在“系统偏好”-&gt; “分享” -&gt; 打勾“远程登录”（“System Preferences” -&gt; “Sharing”-&gt; “Remote Login”）授权SSH Keys要让电脑接收远程登录，就要先报备一下这个ssh key： 1$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys 试着登录一下： 123$ ssh localhost输入密码，出现：Last login: Thu Apr 6 18:39:55 2017 from ::1 说明远程登录成功。好了，退出 1$ exit 启动和关闭12hstarthstop 查看是否启动成功1234通过访问以下网址查看hadoop是否启动成功Resource Manager: http://localhost:50070JobTracker: http://localhost:8088Specific Node Information: http://localhost:8042 三，运行demo 配置HDFS路径, hadoop-2.8.2路径里面运行 123$ bin/hdfs dfs -mkdir /user$ bin/hdfs dfs -mkdir /user/&#123;username&#125; 路径名字自己设定，我这里方便管理用的user名称。 Copy the input files into the distributed filesystem:(把本地 etc/hadoop 下的一些文件上传到 HDFS的 input 中) 1$bin/hdfs dfs -put libexec/etc/hadoop input 执行,在上传的数据中使用 MapReduce 运行 grep， 计算以dfs开头的单词出现的次数，结果保存到 output 中。 1$bin/hadoop jar libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar grep input output &apos;dfs[a-z.]+&apos; 查看 1$ bin/hdfs dfs -cat output/* 通过web也查看结果 mac 上下载结果是出现无法下载http://bogon:50075/xxxxx,替换bogon为localhost","path":"posts/880.html","date":"12-05","excerpt":"","tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://zhulg.github.io/tags/hadoop/"}]},{"title":"Elasticsearch 问题记录","text":"错误日志：field “name” was indexed without position data; cannot run PhraseQuery 123456789101112131415161718java.lang.IllegalStateException: field &quot;name&quot; was indexed without position data; cannot run PhraseQuery (phrase=name:&quot;bbc ddr&quot;) at org.apache.lucene.search.PhraseQuery$PhraseWeight.scorer(PhraseQuery.java:411) at org.apache.lucene.search.Weight.bulkScorer(Weight.java:160) at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:666) at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:473) at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:388) at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:108) at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:247) at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:261) at org.elasticsearch.action.search.SearchTransportService$6.messageReceived(SearchTransportService.java:331) at org.elasticsearch.action.search.SearchTransportService$6.messageReceived(SearchTransportService.java:328) at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:627) at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:748) 问题与描述解决方法一致：https://github.com/elastic/elasticsearch/issues/4475","path":"posts/57643.html","date":"12-01","excerpt":"","tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://zhulg.github.io/tags/Elasticsearch/"}]},{"title":"Hadoop笔记（一）","text":"Hadoop是使用Java编写，允许分布在集群，使用简单的编程模型的计算机大型数据集处理的Apache的开源框架。 Hadoop框架应用工程提供跨计算机集群的分布式存储和计算的环境。 Hadoop是专为从单一服务器到上千台机器扩展，每个机器都可以提供本地计算和存储。 Hadoop可运行于一般的商用服务器上，具有高容错、高可靠性、高扩展性等特点.特别适合写一次，读多次的场景 hadoop架构组成（粗略版本）Hadoop的架构，Hadoop主要有两个层次：加工/计算层(MapReduce)，存储层(Hadoop分布式文件系统)。 The project includes these modules： 1234Hadoop Common: The common utilities that support the other Hadoop modules.Hadoop Distributed File System (HDFS™): A distributed file system that provides high-throughput access to application data.Hadoop YARN: A framework for job scheduling and cluster resource management.（分布式资源管理）Hadoop MapReduce: A YARN-based system for parallel processing of large data sets. 与 Apache Hadoop 的相关项目包括： 1234567891011Ambari：一个基于Web 的工具，用于配置、管理和监控的 Apache Hadoop 集群，其中包括支持 Hadoop HDFS、Hadoop MapReduce、Hive、HCatalog、HBase、ZooKeeper、Oozie、Pig 和 Sqoop。Ambari 还提供了仪表盘查看集群的健康，如热图，并能够以用户友好的方式来查看的 MapReduce、Pig 和 Hive 应用，方便诊断其性能。Avro：数据序列化系统。Cassandra：可扩展的、无单点故障的多主数据库。Chukwa：数据采集系统，用于管理大型分布式系统。HBase：一个可扩展的分布式数据库，支持结构化数据的大表存储。(有关 HBase 的内容，会在后面章节讲述)Hive：数据仓库基础设施，提供数据汇总以及特定的查询。Mahout：一种可扩展的机器学习和数据挖掘库。Pig：一个高层次的数据流并行计算语言和执行框架。Spark：Hadoop 数据的快速和通用计算引擎。Spark 提供了简单和强大的编程模型用以支持广泛的应用，其中包括 ETL、机器学习、流处理和图形计算。(有关 Spark 的内容，会在后面章节讲述)TEZ：通用的数据流编程框架，建立在 Hadoop YARN 之上。它提供了一个强大而灵活的引擎来执行任意 DAG 任务，以实现批量和交互式数据的处理。TEZ 正在被 Hive、Pig 和 Hadoop 生态系统中其他框架所采用，也可以通过其他商业软件（例如 ETL 工具），以取代的 Hadoop MapReduce 作为底层执行引擎。ZooKeeper：一个高性能的分布式应用程序协调服务。 hadoop如何工作（入门理解版本） 建立重配置，处理大规模处理服务器这是相当昂贵的，但是作为替代，可以联系许多普通电脑采用单CPU在一起，作为一个单一功能的分布式系统，实际上，集群机可以平行读取数据集，并提供一个高得多的吞吐量。此外，这样便宜不到一个高端服务器价格。因此使用Hadoop跨越集群和低成本的机器上运行是一个不错不选择。 Hadoop运行整个计算机集群代码。这个过程包括以下核心任务由 Hadoop 执行： 12345678数据最初分为目录和文件。文件分为128M和64M（128M最好）统一大小块。然后这些文件被分布在不同的群集节点，以便进一步处理。HDFS，本地文件系统的顶端﹑监管处理。块复制处理硬件故障。检查代码已成功执行。执行发生映射之间，减少阶段的排序。发送排序的数据到某一计算机。为每个作业编写的调试日志。 hadoop 安装和配置入门 参见hadoop安装笔记另一篇 hadoop fs 查看相关用法 hadoop 操作模式，本地一般是模拟分布式模式 123本地/独立模式：下载Hadoop在系统中，默认情况下之后，它会被配置在一个独立的模式，用于运行Java程序。模拟分布式模式：这是在单台机器的分布式模拟。Hadoop守护每个进程，如 hdfs, yarn, MapReduce 等，都将作为一个独立的java程序运行。这种模式对开发非常有用。完全分布式模式：这种模式是完全分布式的最小两台或多台计算机的集群。我们使用这种模式在未来的章节中。 HDFS架构 HDFS遵循主从架构，从上图可以看出有nameNode和dataNode，block等组成 名称节点 - Namenode 12345名称节点是包含GNU/Linux操作系统和软件名称节点的普通硬件。它是一个可以在商品硬件上运行的软件。具有名称节点系统作为主服务器，它执行以下任务：管理文件系统命名空间。任何有关文件系统的改变都会被NameNode记录下来.规范客户端对文件的访问。它也执行文件系统操作，如重命名，关闭和打开的文件和目录。 数据节点 - Datanode 123Datanode具有GNU/Linux操作系统和软件Datanode的普通硬件。对于集群中的每个节点(普通硬件/系统)，有一个数据节点。这些节点管理数据存储在它们的系统。数据节点上的文件系统执行的读写操作，根据客户的请求。还根据名称节点的指令执行操作，如块的创建，删除和复制。 块 1一般用户数据存储在HDFS文件。在一个文件系统中的文件将被划分为一个或多个段和/或存储在个人数据的节点。这些文件段被称为块。换句话说，数据的HDFS可以读取或写入的最小量被称为一个块。缺省的块大小为64MB，但它可以增加按需要在HDFS配置来改变。 文件系统元数据的持久存储(Metadata) 12HDFS文件系统的元数据信息被存储在NameNode节点上.NameNode节点使用事物日志(叫做EditLog)来持久记录发生在文件系统上面每个变化,:创建文件会在EditLog中插入一条记录,改变副本因子也会新增一条新的记录.NameNode会使用本地文件系统来保存这个EditLog内容.整个HDFS文件系统的命名空间,数据块与文件的映射关系,文件系统的各个属性都被存放在一个叫做FsImage的文件中,这个FsImage文件也放在NameNode节点的本地文件系统中.NameNode会维护整个文件系统的命名空间和文件块的映射关系在内存中 HDFS的目标 故障检测和恢复：由于HDFS包括大量的普通硬件，部件故障频繁。因此HDFS应该具有快速和自动故障检测和恢复机制。 巨大的数据集：HDFS有数百个集群节点来管理其庞大的数据集的应用程序。 数据硬件：请求的任务，当计算发生不久的数据可以高效地完成。涉及巨大的数据集特别是它减少了网络通信量，并增加了吞吐量。 Moving Computation is Cheaper than Moving Data HDFS常用命令 格式化配置HDFS文件系统，打开NameNode(HDFS服务器)，然后执行以下命令。$ hadoop namenode -format hadoop fs 或者hadoop fs -help","path":"posts/37642.html","date":"11-30","excerpt":"","tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://zhulg.github.io/tags/hadoop/"}]},{"title":"大数据技术&机器学习储备知识点","text":"linux相关 123456789101112131415linux系统简介与安装linux常用命令–文件操作linux常用命令–用户管理与权限linux常用命令–系统管理linux常用命令–免密登陆配置与网络管理linux上常用软件安装linux本地yum源配置及yum软件安装linux防火墙配置linux高级文本处理命令cut、sed、awklinux定时任务crontabshell编程shell编程–基本语法shell编程–流程控制shell编程–函数shell编程–综合案例–自动化部署脚本 redis 123456redis和nosql简介redis客户端连接redis的string类型数据结构操作及应用-对象缓存redis的list类型数据结构操作及应用案例-任务调度队列redis的hash及set数据结构操作及应用案例-购物车redis的sortedset数据结构操作及应用案例-排行榜 布式协调服务zookeeper 12345678zookeeper简介及应用场景zookeeper集群安装部署zookeeper的数据节点与命令行操作zookeeper的java客户端基本操作及事件监听zookeeper核心机制及数据节点zookeeper应用案例–分布式共享资源锁zookeeper应用案例–服务器上下线动态感知zookeeper的数据一致性原理及leader选举机制 java&amp; Rpc 12345RPC原理学习Nio原理学习Netty常用API学习轻量级RPC框架需求分析及原理分析轻量级RPC框架开发 Hadoop 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061hadoop背景介绍分布式系统概述离线数据分析流程介绍集群搭建集群使用初步HDFS增强HDFS的概念和特性HDFS的shell(命令行客户端)操作HDFS的工作机制NAMENODE的工作机制java的api操作开发shell采集脚本MAPREDUCE详解自定义hadoop的RPC框架Mapreduce编程规范及示例编写Mapreduce程序运行模式及debug方法mapreduce程序运行模式的内在机理mapreduce运算框架的主体工作流程自定义对象的序列化方法MapReduce编程案例MAPREDUCE增强Mapreduce排序自定义partitionerMapreduce的combinermapreduce工作机制详解MAPREDUCE实战maptask并行度机制-文件切片maptask并行度设置倒排索引共同好友federation介绍和hive使用Hadoop的HA机制HA集群的安装部署集群运维测试之Datanode动态上下线集群运维测试之Namenode状态切换管理集群运维测试之数据块的balanceHA下HDFS-API变化hive简介hive架构hive安装部署hvie初使用hive增强和flume介绍HQL-DDL基本语法HQL-DML基本语法HIVE的joinHIVE 参数配置HIVE 自定义函数和TransformHIVE 执行HQL的实例分析HIVE最佳实践注意点HIVE优化策略HIVE实战案例Flume介绍Flume的安装部署采集目录到HDFS采集文件到HDFS Storm从入门到精通 12345678910111213141516Storm是什么Storm架构分析Storm架构分析Storm编程模型、Tuple源码、并发度分析Storm WordCount案例及常用Api分析Storm集群部署实战Storm+Kafka+Redis业务指标计算Storm源码下载编译Strom集群启动及源码分析Storm任务提交及源码分析Storm数据发送流程分析Storm通信机制分析Storm消息容错机制及源码分析Storm多stream项目分析编写自己的流式任务执行框架Storm上下游及架构集成 消息队列 12345678910Kakfa核心组件Kafka集群部署实战及常用命令Kafka配置文件梳理Kakfa JavaApi学习Kafka文件存储机制分析Redis基础及单机环境部署Redis数据结构及典型案例Flume快速入门Flume+Kafka+Storm+Redis整合内存计算Spark scala编程 123456789101112131415161718scala编程介绍scala相关软件安装scala基础语法scala方法和函数scala函数式编程特点scala数组和集合scala编程练习（单机版WordCount）scala面向对象scala模式匹配actor编程介绍option和偏函数实战：actor的并发WordCount柯里化隐式转换AKKA与RPCAkka并发编程框架RPC编程实战 Spark快速入门 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354spark介绍spark环境搭建RDD简介RDD的转换和动作实战：RDD综合练习RDD高级算子自定义Partitioner实战：网站访问次数广播变量实战：根据IP计算归属地自定义排序利用JDBC RDD实现数据导入导出WorldCount执行流程详解RDD详解RDD依赖关系RDD缓存机制RDD的Checkpoint检查点机制Spark任务执行过程分析RDD的Stage划分Spark-Sql应用Spark-SQLSpark结合HiveDataFrame实战：Spark-SQL和DataFrame案例SparkStreaming应用实战Spark-Streaming简介Spark-Streaming编程实战：StageFulWordCountFlume结合Spark StreamingKafka结合Spark Streaming窗口函数ELK技术栈介绍ElasticSearch安装和使用Storm架构分析Storm编程模型、Tuple源码、并发度分析Storm WordCount案例及常用Api分析Spark核心源码解析Spark源码编译Spark远程debugSpark任务提交行流程源码分析Spark通信流程源码分析SparkContext创建过程源码分析DriverActor和ClientActor通信过程源码分析Worker启动Executor过程源码分析Executor向DriverActor注册过程源码分析Executor向Driver注册过程源码分析DAGScheduler和TaskScheduler源码分析Shuffle过程源码分析Task执行过程源码分析 机器学习算法 1234567891011121314151617181920212223242526python及numpy库机器学习简介机器学习与pythonpython语言–快速入门python语言–数据类型详解python语言–流程控制语句python语言–函数使用python语言–模块和包phthon语言–面向对象python机器学习算法库–numpy机器学习必备数学知识–概率论knn分类算法–算法原理knn分类算法–代码实现knn分类算法–手写字识别案例lineage回归分类算法–算法原理lineage回归分类算法–算法实现及demo朴素贝叶斯分类算法–算法原理朴素贝叶斯分类算法–算法实现朴素贝叶斯分类算法–垃圾邮件识别应用案例kmeans聚类算法–算法原理kmeans聚类算法–算法实现kmeans聚类算法–地理位置聚类应用决策树分类算法–算法原理决策树分类算法–算法实现","path":"posts/59666.html","date":"11-28","excerpt":"","tags":[{"name":"python","slug":"python","permalink":"https://zhulg.github.io/tags/python/"},{"name":"机器学习","slug":"机器学习","permalink":"https://zhulg.github.io/tags/机器学习/"},{"name":"大数据","slug":"大数据","permalink":"https://zhulg.github.io/tags/大数据/"}]},{"title":"Awk常用记录","text":"AWK记录 AWK是一种处理文本文件的语言，是一个强大的文本分析工具 AWK工作原理1awk &apos;BEGIN&#123; commands &#125; pattern&#123; commands &#125; END&#123; commands &#125;&apos; 例如： 123456$ echo -e &quot;A line 1\\nA line 2&quot; | awk &apos;BEGIN&#123; print &quot;Start&quot; &#125; &#123; print &#125; END&#123; print &quot;End&quot; &#125;&apos;StartA line 1A line 2End 例如： 1234统计文件中的行数： awk &apos;END&#123; print NR &#125;&apos; filename 以上命令只使用了END语句块，在读入每一行的时，awk会将NR更新为对应的行号，当到达最后一行NR的值就是最后一行的行号，所以END语句块中的NR就是文件的行数。 创建log.txt文本内容如下：123451 hello, world2 this is a test3 Are you like awkThis&apos;s a test10 There are orange,apple,mongo 每行按空格或TAB分割，输出文本中的1项 123456$awk &apos;&#123;print $1&#125;&apos; log.txt123this&apos;s10 awk -F #-F相当于内置变量FS, 指定分割字符 123456789101112131415awk -F, &apos;&#123;print $1&#125;&apos; log.txt1 hello2 this is a test3 Are you like awkthis&apos;s a test10 There are orange============或者使用内建变量=================$ awk &apos;BEGIN&#123;FS=&quot;,&quot;&#125; &#123;print $1,$2&#125;&apos; log.txt1 hello world2 this is a test3 Are you like awkthis&apos;s a test10 There are orange apple awk -v 设置变量 123456$ awk -v a=1 &apos;&#123;print $1,$1+a&#125;&apos; log.txt1 22 33 4this&apos;s 110 11 awk -f {awk脚本} {文件名} 1$ awk -f cal.awk log.txt 运算符的支持 条件判断 1234awk &apos;$1&gt;2&apos; log.txt3 Are you like awkthis&apos;s a test10 There are orange,apple,mongo 多条件判断 过滤第一列大于2并且第二列等于’Are’的行 12awk &apos;$1&gt;2 &amp;&amp; $2==&quot;Are&quot; &#123;print $1,$2,$3&#125;&apos; log.txt3 Are you 内建变量(预定义变量) 12345678910111213$ awk &apos;&#123;print NR,FNR,$1,$2,$3&#125;&apos; log.txt1 1 2 this is2 2 3 Are you3 3 This&apos;s a test4 4 10 There are# 指定输出分割符$ awk &apos;&#123;print $1,$2,$5&#125;&apos; OFS=&quot; $ &quot; log.txt2 $ this $ test3 $ Are $ awkThis&apos;s $ a $10 $ There $ 使用正则，字符串匹配 123# 输出第二列包含 &quot;th&quot;，并打印第二列与第四列$ awk &apos;$2 ~ /th/ &#123;print $2,$4&#125;&apos; log.txtthis a 123456~ 表示模式开始。// 中是模式。# 输出包含&quot;re&quot; 的行$ awk &apos;/re/ &apos; log.txt---------------------------------------------3 Are you like awk10 There are orange,apple,mongo 忽略大小写 1234$ awk &apos;BEGIN&#123;IGNORECASE=1&#125; /this/&apos; log.txt---------------------------------------------2 this is a testThis&apos;s a test 模式取反 12345678910$ awk &apos;$2 !~ /th/ &#123;print $2,$4&#125;&apos; log.txt---------------------------------------------Are likeaThere orange,apple,mongo$ awk &apos;!/th/ &#123;print $2,$4&#125;&apos; log.txt---------------------------------------------Are likeaThere orange,apple,mongo awk脚本1234关于awk脚本，我们需要注意两个关键词BEGIN和END。BEGIN&#123; 这里面放的是执行前的语句 &#125;END &#123;这里面放的是处理完所有的行后要执行的语句 &#125;&#123;这里面放的是处理每一行时要执行的语句&#125; 假设有这么一个文件（学生成绩表）： 123456$ cat score.txtMarry 2143 78 84 77Jack 2321 66 78 45Tom 2122 48 77 71Mike 2537 87 97 95Bob 2415 40 57 62 我们的awk脚本如下： 123456789101112131415161718192021222324$ cat cal.awk#!/bin/awk -f#运行前BEGIN &#123; math = 0 english = 0 computer = 0 printf &quot;NAME NO. MATH ENGLISH COMPUTER TOTAL\\n&quot; printf &quot;---------------------------------------------\\n&quot;&#125;#运行中&#123; math+=$3 english+=$4 computer+=$5 printf &quot;%-6s %-6s %4d %8d %8d %8d\\n&quot;, $1, $2, $3,$4,$5, $3+$4+$5&#125;#运行后END &#123; printf &quot;---------------------------------------------\\n&quot; printf &quot; TOTAL:%10d %8d %8d \\n&quot;, math, english, computer printf &quot;AVERAGE:%10.2f %8.2f %8.2f\\n&quot;, math/NR, english/NR, computer/NR&#125; 我们来看一下执行结果： 1234567891011$ awk -f cal.awk score.txtNAME NO. MATH ENGLISH COMPUTER TOTAL---------------------------------------------Marry 2143 78 84 77 239Jack 2321 66 78 45 189Tom 2122 48 77 71 196Mike 2537 87 97 95 279Bob 2415 40 57 62 159--------------------------------------------- TOTAL: 319 393 350AVERAGE: 63.80 78.60 70.00 参考链接： http://man.linuxde.net/awk https://coolshell.cn/articles/9070.html http://www.runoob.com/linux/linux-comm-awk.html","path":"posts/39087.html","date":"11-20","excerpt":"","tags":[{"name":"Tools","slug":"Tools","permalink":"https://zhulg.github.io/tags/Tools/"}]},{"title":"Shell常用点记录","text":"Shell中的常用字符串截取。 假设有变量 var=http://www.aaa.com/123.htm 123451. # 号截取，删除左边字符，保留右边字符。echo $&#123;var#*//&#125;其中 var 是变量名，# 号是运算符，*// 表示从左边开始删除第一个 // 号及左边的所有字符即删除 http://结果是 ：www.aaa.com/123.htm 123452. ## 号截取，删除左边字符，保留右边字符。echo $&#123;var##*/&#125;##*/ 表示从左边开始删除最后（最右边）一个 / 号及左边的所有字符即删除 http://www.aaa.com/结果是 123.htm 12343. %号截取，删除右边字符，保留左边字符echo $&#123;var%/*&#125;%/* 表示从右边开始，删除第一个 / 号及右边的字符结果是：http://www.aaa.com 12344. %% 号截取，删除右边字符，保留左边字符echo $&#123;var%%/*&#125;%%/* 表示从右边开始，删除最后（最左边）一个 / 号及右边的字符结果是：http: 12345. 从左边第几个字符开始，及字符的个数echo $&#123;var:0:5&#125;其中的 0 表示左边第一个字符开始，5 表示字符的总个数。结果是：http: 12346. 从左边第几个字符开始，一直到结束。echo $&#123;var:7&#125;其中的 7 表示左边第8个字符开始，一直到结束。结果是 ：www.aaa.com/123.htm 12347. 从右边第几个字符开始，及字符的个数echo $&#123;var:0-7:3&#125;其中的 0-7 表示右边算起第七个字符开始，3 表示字符的个数。结果是：123 123458. 从右边第几个字符开始，一直到结束。echo $&#123;var:0-7&#125;表示从右边第七个字符开始，一直到结束。结果是：123.htm注：（左边的第一个字符是用 0 表示，右边的第一个字符用 0-1 表示）","path":"posts/32296.html","date":"11-15","excerpt":"","tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhulg.github.io/tags/Linux/"}]},{"title":"Mac Minikube本地集群","text":"Minikube 本地集群 Minikube可以在任意主机上运行单节点的小型集群，这个工具默认安装和配置了一个Linux VM，Docker和Kubernetes的相关组件，并且提供Dashboard。目前支持在Linux, OS X及Windows上安装 Minikube是一个本地的kubernetes Minitube项目地址：https://github.com/kubernetes/minikube 1,本机环境监测Minikube要求在BIOS中对VT-x/AMD-v进行了虚拟化，如果已经设置了，则命令执行后会有以下内容输出： 123$ sysctl -a | grep machdep.cpu.features | grep VMXmachdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 PCLMULQDQ DTES64 MON DSCPL VMX EST TM2 SSSE3 FMA CX16 TPR PDCM SSE4.1 SSE4.2 x2APIC MOVBE POPCNT AES PCID XSAVE OSXSAVE SEGLIM64 TSCTMR AVX1.0 RDRAND F16C 2,安装虚拟机驱动 在OS X上支持xhyve driver、VirtualBox、VMware Fusion多种虚拟驱动 3,安装Minikube brew cask install minikube minikube version （监测成功） 4,打开虚拟机5，minikube 启动1234567891011121314$minikube startStarting local Kubernetes v1.8.0 cluster...Starting VM...Downloading Minikube ISO 140.01 MB / 140.01 MB [============================================] 100.00% 0sGetting VM IP address...Moving files into cluster...Downloading localkube binary 148.56 MB / 148.56 MB [============================================] 100.00% 0sSetting up certs...Connecting to cluster...Setting up kubeconfig...Starting cluster components...Kubectl is now configured to use the cluster. 6，kubectl get nodes 查看nodes####7， 部署应用前 由于墙的原因，Minitube运行需要了的一些镜像是不能被下载的。故需要先解决下gcr.io的访问 minikube ssh （登录到虚拟机，下载需要的K8S镜像） 一个比较恶心的过程，使用阿里云进行下载需要的镜像 查看缺失的镜像，可以exit退出ssh.回到本机 minikube logs 从日志里查看。 1234567891011docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.7.0docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.7.0 gcr.io/google_containers/kubernetes-dashboard-amd64:v1.7.0docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/k8s-dns-sidecar-amd64:1.14.5docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/k8s-dns-sidecar-amd64:1.14.5 gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.5docker pull registry.cn-hangzhou.aliyuncs.com/outman_google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.5docker tag registry.cn-hangzhou.aliyuncs.com/outman_google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.5 gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.5docker pull registry.cn-hangzhou.aliyuncs.com/outman_google_containers/k8s-dns-kube-dns-amd64:1.14.5docker tag registry.cn-hangzhou.aliyuncs.com/outman_google_containers/k8s-dns-kube-dns-amd64:1.14.5 gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.5 以上缺失就继续从log查看pull失败原因，再从阿里云拉起镜像，用tag映射下。 docker images 可以查看下载的镜像 1234567891011121314151617docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEgcr.io/google_containers/k8s-dns-sidecar-amd64 1.14.5 fed89e8b4248 6 weeks ago 41.8MBregistry.cn-hangzhou.aliyuncs.com/google_containers/k8s-dns-sidecar-amd64 1.14.5 fed89e8b4248 6 weeks ago 41.8MBregistry.cn-hangzhou.aliyuncs.com/outman_google_containers/k8s-dns-kube-dns-amd64 1.14.5 512cd7425a73 6 weeks ago 49.4MBgcr.io/google_containers/k8s-dns-kube-dns-amd64 1.14.5 512cd7425a73 6 weeks ago 49.4MBgcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64 1.14.5 459944ce8cc4 6 weeks ago 41.4MBregistry.cn-hangzhou.aliyuncs.com/outman_google_containers/k8s-dns-dnsmasq-nanny-amd64 1.14.5 459944ce8cc4 6 weeks ago 41.4MBgcr.io/google-containers/kubernetes-dashboard-amd64 v1.7.0 284ec2f8ed6c 6 weeks ago 128MBgcr.io/google_containers/kubernetes-dashboard-amd64 v1.7.0 284ec2f8ed6c 6 weeks ago 128MBregistry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64 v1.7.0 284ec2f8ed6c 6 weeks ago 128MBgcr.io/google-containers/kube-addon-manager v6.4-beta.2 0a951668696f 4 months ago 79.2MBregistry.cn-hangzhou.aliyuncs.com/google_containers/kube-addon-manager v6.4-beta.2 0a951668696f 4 months ago 79.2MBgcr.io/google_containers/echoserver 1.4 a90209bb39e3 17 months ago 140MBregistry.cn-hangzhou.aliyuncs.com/acs/echoserver 1.4 a90209bb39e3 17 months ago 140MBgcr.io/google_containers/pause-amd64 3.0 99e59f495ffa 18 months ago 747kBregistry.cn-hangzhou.aliyuncs.com/google-containers/pause-amd64 3.0 99e59f495ffa 18 months ago 747kB 8,启动一个echoserver pod12$ kubectl run hello-minikube --image=gcr.io/google_containers/echoserver:1.4 --port=8080deployment &quot;hello-minikube&quot; created 通过NodePort暴露的服务12$ kubectl expose deployment hello-minikube --type=NodePortservice &quot;hello-minikube&quot; exposed 9,查看pods状态1234kubectl get podsNAME READY STATUS RESTARTS AGEhello-8649f955b6-c54tx 1/1 Running 0 22hhello-minikube-5bc754d4cd-zbrh6 1/1 Running 0 9h mikubectl get pod -o wide –all-namespaces(查看所有命名空间) 123456NAMESPACE NAME READY STATUS RESTARTS AGE IP NODEdefault hello-8649f955b6-c54tx 1/1 Running 0 22h 172.17.0.2 minikubedefault hello-minikube-5bc754d4cd-zbrh6 1/1 Running 0 9h 172.17.0.3 minikubekube-system kube-addon-manager-minikube 1/1 Running 0 23h 192.168.99.100 minikubekube-system kube-dns-6fc954457d-htd94 3/3 Running 5 9h 172.17.0.5 minikubekube-system kubernetes-dashboard-tkhjw 1/1 Running 0 9h 172.17.0.4 minikube 10, curl $(minikube service hello-minikube –url) 测试服务###11，minikube dashboard(启动观察页) Minikube自带了Kubernetes Dashboard。要浏览这个界面，可以使用内置的minikube dashboard命令。 12$ minikube dashboardOpening kubernetes dashboard in default browser... 12,过程中注意问题记录 镜像下载，代理过程翻墙不能解决，最后在虚拟机上通过阿里下载所需要的镜像，通过tag隐射。 不正常需要查看kubectl get pods –all-namespaces pods情况 minikube logs 查看过程中的日志，定位问题 最后启动dashboard过程，注意自己是否有代理，否则起不起来 常用命令 kubectl get nodes 查看工作节点 参考文章 http://blog.csdn.net/yjk13703623757/article/details/71381361 参考文章 http://blog.csdn.net/aixiaoyang168/article/details/78331847?locationNum=10&amp;fps=1 (参考文章) 13，基本概念和指令 Kubernetes 集群由两种类型的资源组成：master 和 Nodes。 master是集群的调度节点，nodes则是应用程序实际运行的工作节点。 类似于nginx的 master 和 worker。 部署应用时需要创建deployment。每个deployment 会根据指定的副本数，创建相应的pod来托管我们的应用实例。 Pod可以理解为应用实例特定的逻辑主机，表示一个或多个容器组和这些容器的共享资源，包共用卷、唯一的集群IP和容器运行的信息，如端口等。 Node是kubernetes的工作机器（物理机或虚拟机）。Node由master管理，可以在一个node上部署多个pod。 每个node至少需要两种组件，kubelet 和 容器运行时（docker）。 kubelet是负责master和所有节点间的通信进程，管理机器上运行的pod和容器。容器运行时负责从registry拉取镜像，解包镜像并运行应用实例。 kubectl 有一系列指令管理实例的运行情况。 1234567891011121314151617// 查看deploymentkubectl get deployments// 删除deployment，会自动删除相应podskubectl delete deployment &lt;部署名&gt;// 查看pods// 查看当前namespace下的podskubectl get pods// 查看所有podskubectl get pods --all-namespaces// 查看pods的具体信息kubectl describe pod &lt;pod name&gt;//特定namespace下的，需要指定namespacekubectl describe pod &lt;pod name&gt; --namespace=kube-system// 查看pod日志kubectl logs pod &lt;pod name&gt;// 进入podkubectl exec -it &lt;pod name&gt; bash","path":"posts/27685.html","date":"11-08","excerpt":"","tags":[{"name":"K8S","slug":"K8S","permalink":"https://zhulg.github.io/tags/K8S/"}]},{"title":"K8s核心概念","text":"kubernetes核心概念 Kubernetes（k8s）是自动化容器操作的开源平台，这些操作包括部署，调度和节点集群间扩展。如果你曾经用过Docker容器技术部署容器，那么可以将Docker看成Kubernetes内部使用的低级别组件。 Kubernetes可以： 12345自动化容器的部署和复制随时扩展或收缩容器规模将容器组织成组，并且提供容器间的负载均衡很容易地升级应用程序容器的新版本提供容器弹性，如果容器失效就替换它，等等... K8s架构图 Master master是集群的控制节点，负责整个集群的管理和控制。master节点可以运行在物理机或虚拟机中，因为它是整个集群的“大脑”，非常重要，所以要保证它的可用性与可靠性。可以把它独占一个物理机，或者放到虚拟机中，用master集群来保证其可靠性。 k8s master由三个组件(进程)组成： 123kube-apiserver: 提供http rest接口的服务进程，对k8s里面的所有资源进行增、删、改、查等操作。也是集群控制的入口；kube-controler-manager: k8s里所有资源对象的自动控制中心，比如各个node节点的状态、pod的状态等；kube-scheduler: 负责资源调度； node 除了master，k8s集群中的其他节点是node节点,也是实际的工作点。node节点可以是一台物理机或者虚拟机。node节点是k8s集群中的工作负载节点，master会把一些任务调度到node节点上进行。当某个node出现故障时，master会把这个节点上的任务转移到其他节点上","path":"posts/18975.html","date":"11-03","excerpt":"","tags":[{"name":"K8S","slug":"K8S","permalink":"https://zhulg.github.io/tags/K8S/"}]},{"title":"springboot整合Apache Shiro","text":"Shiro的记录 在Java领域一般有Spring Security、Apache Shiro等安全框架，但是由于Spring Security过于庞大和复杂，大多数公司会选择Apache Shiro来使用。 Apache Shiro是一个功能强大、灵活的，开源的安全框架。它可以干净利落地处理身份验证、授权、企业会话管理和加密。 Apache Shiro是一个全面的、蕴含丰富功能的安全框架。Authentication（认证）, Authorization（授权）, Session Management（会话管理）, Cryptography（加密）被 Shiro 框架的开发团队称之为应用安全的四大基石。那么就让我们来看看它们吧： 1234Authentication（认证）：用户身份识别，通常被称为用户“登录”Authorization（授权）：访问控制。比如某个用户是否具有某个操作的使用权限。Session Management（会话管理）：特定于用户的会话管理,甚至在非web 或 EJB 应用程序。Cryptography（加密）：在对数据源使用加密算法加密的同时 Shiro 配置要配置的是ShiroConfig类，Apache Shiro 核心通过 Filter 来实现，就好像SpringMvc 通过DispachServlet 来主控制一样。既然是使用 Filter 一般也就能猜到，是通过URL规则来进行过滤和权限校验，所以我们需要定义一系列关于URL的规则和访问权限。 http://www.cnblogs.com/ityouknow/p/7089177.html参考记录","path":"posts/37485.html","date":"10-24","excerpt":"","tags":[{"name":"springboot","slug":"springboot","permalink":"https://zhulg.github.io/tags/springboot/"}]},{"title":"Java后端一般架构","text":"Java后端一般架构 MVC框架：从十年前流行的Struts1、2到现在最为推崇的SpringMVC、Jersey以及国人开发的JFinal、阿里的WebX等等，这些框架尤其是后面流行的这些都是各有千秋的。选型的主要因素是看你的团队是否有一个对某框架能够做二次开发、定制的人在。很多时候，针对这些通用的框架，你是需要做一些特定的开发才能满足特定的需求的。比如，很多团队传递参数使用的都是UnderScore的命名法(下划线连接单词)，但是Java中确是使用LowCamel命名的。对于SpringMVC，可以通过注解的alias来指定，但这样需要对每一个参数都要指定alias有点效率太低，此外ModelAttribute也不支持别名，更好的方式是在框架层面统一对参数做Camel命名的转换达到目的。 IOC框架：ioc带来的好处无须多言。目前Java中最为流行的Spring自诞生就天然支持IOC。 ORM框架：MyBatis是目前最为流行的orm框架。此外，Spring ORM中提供的JdbcTemplate也很不错。当然，对于分库分表、主从分离这些需求，一般就需要实现自己的ORM框架来支持了，像阿里的tddl。此外，为了在服务层面统一解决分库分表、主从分离、主备切换、缓存、故障恢复等问题，很多公司都是有自己的数据库中间件的，比如阿里的Cobar、360的Atlas、网易的DDB，还有官方提供的MySQL Proxy以及开源的MyCat、kingshard和收费的oneproxy。目前，线上有一定规模使用的应该是kingshard，当然如果不缺钱也可以上oneproxy。 缓存框架：缓存框架主要指的是对redis、memcached这些缓存服务器的操作统一封装，一般使用Spring的RedisTemplate即可，也可以使用jedis做自己的封装，支持客户端分布式方案、主从等。 性能检测框架：对于线上的JavaEE应用，需要有一个统一的框架集成到每一个业务中检测每一个请求、方法调用、jdbc连接、redis连接等的耗时、状态等。 搜索引擎: 搜索引擎也是后端应用中一个很关键的组件，尤其是对内容类、电商类的应用，通过关键词、关键字搜索内容、商品是一个很常见的用户场景。比较成熟的开源搜索引擎有Solr和Elasticsearch，很多中小型互联网公司搜索引擎都是基于这两个开源系统搭建的。它们都是基于Lucence来实现的，不同之处主要在于termIndex的存储、分布式架构的支持等等。 消息队列:软件的组织结构，从开始的面向组件到SOA、SAAS是一个逐渐演变的过程。而到了今天微服务盛行的时代，你都不好意思说自己的系统只是单一的一个系统而没有解耦成一个个service。当然，小的系统的确没有拆分的必要性，但一个复杂的系统拆成一个个service做微服务架构确实是不得不做的事情。那么问题就来了，service之间的通信如何来做呢？使用什么协议？通过什么方式调用？都是需要考虑的问题。 文件存储: 不管是业务应用、依赖的后端服务还是其他的各种服务，最终还是要依赖于底层文件存储的。通常来说，文件存储需要满足的特性有：可靠性、容灾性、稳定性，即要保证存储的数据不会轻易丢失，即使发生故障也能够有回滚方案，也要保证高可用率。在底层可以采用传统的RAID作为解决方案，再上一层，目前hadoop的hdfs则是最为普遍的分布式文件存储方案，当然还有NFS、Samba这种共享文件系统也提供了简单的分布式存储的特性。 统一认证中心: 统一认证中心，主要是对app用户、内部用户、app等的认证服务，包括用户的注册、登录验证、token鉴权内部信息系统用户的管理和登录鉴权App的管理，包括app的secret生成，app信息的验证(如验证接口签名)等。之所以需要统一认证中心，就是为了能够集中对这些所有app都会用到的信息进行管理，也给所有应用提供统一的认证服务。尤其是在有很多业务需要共享用户数据的时候，构建一个统一认证中心是非常必要的。此外，通过统一认证中心构建移动app的单点登录也是水到渠成的事情(模仿web的机制，将认证后的信息加密存储到本地磁盘中供多个app使用)。 SSO单点登录系统: 目前很多大的在线web网站都是有单点登录系统的，通俗的来说就是只需要一次用户登录，就能够进入多个业务应用(权限可以不相同)，非常方便用户的操作。而在移动互联网公司中，内部的各种管理、信息系统同样也需要单点登录系统。目前，比较成熟的、用的最多的单点登录系统应该是耶鲁大学开源的CAS. 统一配置中心: 在Java后端应用中，一种读写配置比较通用的方式就是将配置文件写在propeties、yaml、HCON文件中，修改的时候只需要更新文件重新部署即可，可以做到不牵扯代码层面改动的目的。统一配置中心，则是基于这种方式之上的统一对所有业务或者基础后端服务的相关配置文件进行管理的统一服务 服务治理框架: 对于外部API调用或者客户端对后端api的访问，可以使用http协议或者说restful(当然也可以直接通过最原始的socket来调用)。但对于内部服务间的调用，一般都是通过RPC机制来调用的。目前主流的RPC协议有： 1234RMIHessianThriftDubbo 这些RPC协议各有优劣点，需要针对业务需求做出相应的最好的选择。 统一调度中心: 在很多业务中，定时调度是一个非常普遍的场景，比如定时去抓取数据、定时刷新订单的状态等。通常的做法就是针对各自的业务依赖Linux的cron机制或者java中的quartz。统一调度中心则是对所有的调度任务进行管理，这样能够统一对调度集群进行调优、扩展、任务管理等。azkaban和oozie是hadoop的流式工作管理引擎，也可以作为统一调度中心来使用。当然，你也可以使用cron或者quartz来实现自己的统一调度中心。根据cron表达式调度任务动态修改、停止、删除任务支持任务工作流：比如一个任务完成之后再执行下一个任务任务支持脚本、代码、url等多种形式任务执行的日志记录、故障报警对于Java的quartz这里需要说明一下：这个quartz需要和spring quartz区分，后者是spring对quartz框架的简单实现也是目前使用的最多的一种调度方式。但是，其并没有做高可用集群的支持。而quartz虽然有集群的支持，但是配置起来非常复杂。现在很多方案都是使用zookeeper来实现spring quartz集群的。 统一日志服务: 日志是开发过程必不可少的东西。有时候，打印日志的时机、技巧是很能体现出工程师编码水平的。毕竟，日志是线上服务能够定位、排查异常最为直接的信息。通常的，将日志分散在各个业务中非常不方便对问题的管理和排查。统一日志服务则使用单独的日志服务器记录日志，各个业务通过统一的日志框架将日志输出到日志服务器上。可以通过实现log4j后者logback的appender来实现统一日志框架，然后通过RPC调用将日志打印到日志服务器上。","path":"posts/7571.html","date":"10-23","excerpt":"","tags":[{"name":"springboot","slug":"springboot","permalink":"https://zhulg.github.io/tags/springboot/"}]},{"title":"Docker知识点记录","text":"Docker概念点 镜像（Image）可以认为：镜像 = 操作系统 + 运行环境 + 应用程序。譬如，我们可以将 Centos7 操作系统、JVM 和 Java 应用程序做成一个镜像。我们交付的软件不再是 zip 包或者 war 包，而是镜像。Docker 镜像技术实现了应用程序运行环境与主机环境的无关性。 容器（Container）容器是镜像的运行态。通过 docker run 命令即可快速的基于镜像创建一个或多个容器。 镜像仓库（Registry）在项目或者产品的不断迭代过程中，应用的各版本镜像存储在镜像仓库中，类似于代码仓库 for source code 或 Maven 仓库 for Jar file。 Docker理念和使用 Docker 的理念为“Build, Ship and Run Any App, Anywhere”，通过容器和镜像的特性让 DevOps 变得容易，但 Docker 的前景，更在于支持分布式、服务化设计，实现一系列可独立开发、独立部署和独立扩展的服务组合，以保证业务的灵活性和稳定性。 当前 AWS、微软、阿里云、IBM、Redhat、VMware、华为、Intel 等各大公有云和私有云提供商都不约而同地大力投资 Docker，实际上就是认可了这样的趋势。 利用 Docker 搭建微服务架构，就需要了解一些必需的 Docker 知识，比如镜像构建、容器创建、容器编排、集群管理、文件存储、容器网络、容器监控、容器日志。 拿一个包含 ABC 组件的微服务系统为例，我们会利用持续集成工具（例如 Jenkins）创建镜像，并将镜像推送到镜像仓库中（例如 Docker Registry，Harbor），再利用编排工具（例如 Docker Compose）创建并启动容器. 容器启动后，ABC 组件就会随着容器一起启动，这时就需要考虑 ABC 组件的数据文件如何持久化存储，分布在不同主机上的组件如何网络通信（Docker 容器默认不能跨主机通信），容器资源使用情况如何监控，容器日志如何查看 Docker安装 使用 Homebrew 安装，Homebrew 的 Cask 已经支持 Docker for Mac，因此可以很方便的使用 Homebrew Cask 来进行安装：brew cask install docker 1234567安装后查看：docker --versionDocker version 1.13.0, build 49bf474docker-compose --versiondocker-compose version 1.10.0, build 4bd6f1adocker-machine --versiondocker-machine version 0.9.0, build 15fd4c7 使用Docker优势 环境依赖隔离 计算机资源隔离Docker 利用 Linux 的名称空间 (Namesaces)、控制组 (Contorl groups)、Union 文件系统和容器格式 (Container format) 实现了资源（例如 CPU、内存、IO 等）的隔离，保证同一台主机上的多个应用不会互相抢占资源。 迁移方便 版本管理更便捷之前，对于版本的管理，更多考虑的源代码级的，比如开个 Branch 或打个 Tag。现在，版本是一个包含了运行环境和程序包的镜像。在上线失败的时候，可以很快回滚到之前的版本。 编排的支持 微服务架构下，一个系统包含多个程序包，而多个程序包之间是有依赖关系的。Docker 编排工具可以帮助管理这些依赖关系，从而达到一键创建整个系统的目的 常用命令 命令 解释 docker images 列表本地所有镜像 docker search 关键词 在Docker Hub中搜索镜像 docker pull 镜像名称 下载Docker镜像 docker rmi 镜像id 删除Docker镜像。加参数-f表示强制删除。 docker run 镜像名称 启动Docker镜像 docker ps 列表所有运行中的Docker容器。该命令参数比较多，-a：列表所有容器；-f：过滤；-q 只列表容器的id。 docker version 查看Docker版本信息 docker info 查看Docker系统信息，例如：CPU、内存、容器个数等等 docker kill 容器id 杀死id对应容器 docker start / stop / restart 容器id 启动、停止、重启指定容器 docker build -t 标签名称 目录 构建Docker镜像，-t 表示指定一个标签 docker tag 为镜像打标签 docker run 应该是我们最常用的命令了(docker run -d -p 8080:8080 xxxx) 参数 解释 -d 后台运行 -P 随机端口映射 -p 指定端口映射 格式：ip:hostPort:containerPort ip::containerPort hostPort:containerPort containerPort 批量删除Docker中已经停止的容器1234#显示所有的容器，过滤出Exited状态的容器，取出这些容器的ID，sudo docker ps -a|grep Exited|awk &apos;&#123;print $1&#125;&apos;#查询所有的容器，过滤出Exited状态的容器，列出容器ID，删除这些容器sudo docker rm `docker ps -a|grep Exited|awk &apos;&#123;print $1&#125;&apos;` Docker部署springcloud项目 dockerfile文件的构成,如下dockerfile 123456FROM frolvlad/alpine-oraclejdk8:slimVOLUME /tmpADD eureka-server-0.0.1-SNAPSHOT.jar app.jar#RUN bash -c &apos;touch /app.jar&apos;ENTRYPOINT [&quot;java&quot;,&quot;-Djava.security.egd=file:/dev/./urandom&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;]EXPOSE 8761 docker file编写指令： 1234FROM FROM &lt;image&gt; FROM &lt;image&gt;:&lt;tag&gt; FROM &lt;image&gt; &lt;digest&gt; FROM指令必须指定且需要在Dockerfile其他指令的前面，指定的基础image可以是官方远程仓库中的，也可以位于本地仓库。后续的指令都依赖于该指令指定的image。当在同一个Dockerfile中建立多个镜像时，可以使用多个FROM指令。 VOLUME 格式为：VOLUME [“/data”]使容器中的一个目录具有持久化存储数据的功能，该目录可以被容器本身使用，也可以共享给其他容器。当容器中的应用有持久化数据的需求时可以在Dockerfile中使用该指令。 ADD从src目录复制文件到容器的dest。其中src可以是Dockerfile所在目录的相对路径，也可以是一个URL，还可以是一个压缩包 ENTRYPOINT指定Docker容器启动时执行的命令，可以多次设置，但是只有最后一个有效。ENTRYPOINT: 执行项目 app.jar 。为了缩短 Tomcat 启动时间，添加一个系统属性指向 /dev/urandom 作为 Entropy Source。 EXPOSE为Docker容器设置对外的端口号。在启动时，可以使用-p选项或者-P选项做映射。 docker&amp;springboot 构建命令 mvn package docker:build 构建镜像 docker run -p 8761: 8761 -t forezp/eureka-server 运行镜像 参考例子 http://blog.csdn.net/forezp/article/details/70198649 docker Compose Dockerfile 可以让用户管理一个单独的容器，那么如果我要管理多个容器呢，例如：我需要管理一个Web应用的同时还要加上其后端的数据库服务容器呢？Compose就是这样的一个工具。让我们看下官网对Compose的定义： Compose 是一个用于定义和运行多容器的Docker应用的工具。使用Compose，你可以在一个配置文件（yaml格式）中配置你应用的服务，然后使用一个命令，即可创建并启动配置中引用的所有服务","path":"posts/26571.html","date":"10-21","excerpt":"","tags":[{"name":"docker","slug":"docker","permalink":"https://zhulg.github.io/tags/docker/"}]},{"title":"Springcloud-Sleuth记录","text":"SpringCloud Sleuth记录 Spring Cloud Sleuth为Spring Cloud提供了分布式追踪方案背景 对系统进行全链路的监控是非常有必要的。在单体应用中，传统的方式是软件开发者，通过自定义日志的level，日志文件的方式记录单体应用的运行日志。从而排查线上系统出现运行过慢，出现故障，异常等问题，但是在微服务架构或分布式系统中，一个系统被拆分成了A、B、C、D、E等多个服务，而每个服务可能又有多个实例组成集群，采用上诉定位问题的方式就行不通了，你充其量就知道某个服务是应用的瓶颈，但中间发生了什么你完全不知道。而且问题的查询，因为有海量各种各样的日志等文件，导致追溯定位问题等极其不方便。因此需要全链路监控系统的收集，上报，对海量日志实时计算生成，监控告警，视图报表，帮助开发人员快速定位问题。 服务追踪分析 一个由微服务构成的应用系统由N个服务实例组成，通过REST请求或者RPC协议等来通讯完成一个业务流程的调用。对于入口的一个调用可能需要有多个后台服务协同完成，链路上任何一个调用超时或出错都可能造成前端请求的失败。服务的调用链也会越来越长，并形成一个树形的调用链。 针对服务化应用全链路追踪的问题，Google发表了Dapper论文，介绍了他们如何进行服务追踪分析。其基本思路是在服务调用的请求和响应中加入ID，标明上下游请求的关系。利用这些信息，可以可视化地分析服务调用链路和服务间的依赖关系。 Spring Cloud Sleuth Spring Cloud Sleuth就是APM(Application Performance Monitor),全链路监控的APM的一部分，如果要完整的使用该组件需要自己定制化或者和开源的系统集成，例如:ZipKin。 APM（Application Performance Monitor）这个领域最近异常火热,例如淘宝鹰眼Eagle Eyes，点评的CAT，微博的Watchman，twitter的Zipkin zipkin是基于goole的google-Dapper实现。 ###ZipKin的架构 collector 收集器 storage 存储 api 查询api ui 界面 ####zipkin存储 zipkin存储默认使用inMemory 支持存储模式 1234inMemorymysqlCassandraElasticsearch ####ZipKin数据模型 Trace：一组代表一次用户请求所包含的spans，其中根span只有一个。 Span： 一组代表一次HTTP/RPC请求所包含的annotations。 annotation：包括一个值，时间戳，主机名(留痕迹)。 几个时间 cs：客户端发起请求，标志Span的开始 sr：服务端接收到请求，并开始处理内部事务，其中sr - cs则为网络延迟和时钟抖动 ss：服务端处理完请求，返回响应内容，其中ss - sr则为服务端处理请求耗时 cr：客户端接收到服务端响应内容，标志着Span的结束，其中cr - ss则为网络延迟和时钟抖动H","path":"posts/53406.html","date":"10-18","excerpt":"","tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://zhulg.github.io/tags/springcloud/"}]},{"title":"Springcloud-Gateway记录","text":"SpringCloud Gateway相关点 在微服务架构中，后端服务往往不直接开放给调用端，而是通过一个API网关根据请求的url，路由到相应的服务。 当添加API网关后，在第三方调用端和服务提供方之间就创建了一面墙，这面墙直接与调用方通信进行权限控制，后将请求均衡分发给后台服务端。 Spring Cloud Zuul springcloud zull 路由是微服务架构的不可或缺的一部分，提供动态路由，监控，弹性，安全等的边缘服务。Zuul是Netflix出品的一个基于JVM路由和服务端的负载均衡器。 使用方式1，简单使用 单实例配置：通过一组zuul.routes.&lt;route&gt;.path与zuul.routes.&lt;route&gt;.url参数对的方式配置，&lt;route&gt;是相关的服务名：比如: 123#这里的配置表示，访问/user/** 直接重定向到http://xxxx/**zuul.routes.user-service.path=/user-service/**zuul.routes.user-service.url=http://localhost:8080/ ####2，服务化方式，通过对于的服务名称 通过一组zuul.routes.&lt;route&gt;.path与zuul.routes.&lt;route&gt;.serviceId参数对的方式配置 12zuul.routes.user-service.path=/user-service/**zuul.routes.user-service.serviceId=user-service ####3，简洁的配置方式 zuul.routes.&lt;serviceId&gt;=&lt;path&gt;，其中用来指定路由的具体服务名，用来配置匹配的请求表达式。比如下面的例子，它的路由规则等价于上面通过path与serviceId组合使用的配置方式 1zuul.routes.user-service=/user-service/** 4,默认的配置，网关的默认路由规则 如果后端服务多达十几个的时候，每一个都这样配置也挺麻烦的，spring cloud zuul已经帮我们做了默认配置。默认情况下，Zuul会代理所有注册到Eureka Server的微服务，并且Zuul的路由规则如下：http://ZUUL_HOST:ZUUL_PORT/微服务在Eureka上的serviceId/**会被转发到serviceId对应的微服务。 在Spring Cloud Netflix中，Zuul巧妙的整合了Eureka来实现面向服务的路由。实际上，我们可以直接将API网关也看做是Eureka服务治理下的一个普通微服务应用。它除了会将自己注册到Eureka服务注册中心上之外，也会从注册中心获取所有服务以及它们的实例清单。所以，在Eureka的帮助下，API网关服务本身就已经维护了系统中所有serviceId与实例地址的映射关系。当有外部请求到达API网关的时候，根据请求的URL路径找到最佳匹配的path规则，API网关就可以知道要将该请求路由到哪个具体的serviceId上去。由于在API网关中已经知道serviceId对应服务实例的地址清单，那么只需要通过Ribbon的负载均衡策略，直接在这些清单中选择一个具体的实例进行转发就能完成路由工作了。 Zuul的更常用方式：我们对于Zuul的第一印象通常是这样的：它包含了对请求的路由和过滤两个功能，其中路由功能负责将外部请求转发到具体的微服务实例上，是实现外部访问统一入口的基础；而过滤器功能则负责对请求的处理过程进行干预，是实现请求校验、服务聚合等功能的基础。然而实际上，路由功能在真正运行时，它的路由映射和请求转发都是由几个不同的过滤器完成的。其中，路由映射主要通过pre类型的过滤器完成，它将请求路径与配置的路由规则进行匹配，以找到需要转发的目标地址；而请求转发的部分则是由route类型的过滤器来完成，对pre类型过滤器获得的路由地址进行转发。所以，过滤器可以说是Zuul实现API网关功能最为核心的部件，每一个进入Zuul的HTTP请求都会经过一系列的过滤器处理链得到请求响应并返回给客户端。 过滤器的使用 在Spring Cloud Zuul中实现的过滤器必须包含4个基本特征：过滤类型、执行顺序、执行条件、具体操作。这些元素看着似乎非常的熟悉，实际上它就是ZuulFilter接口中定义的四个抽象方法 实现方式： 12345678910111213141,过滤类实现ZuulFilter接口2，实现主要的4个方法 @Override public String filterType() &#123; &#125; @Override public int filterOrder() &#123; &#125; @Override public boolean shouldFilter() &#123; &#125; @Override public Object run() &#123; &#125; filterType：该函数需要返回一个字符串来代表过滤器的类型，而这个类型就是在HTTP请求过程中定义的各个阶段。在Zuul中默认定义了四种不同生命周期的过滤器类型，具体如下： 1234pre：可以在请求被路由之前调用。routing：在路由请求时候被调用。post：在routing和error过滤器之后被调用。error：处理请求时发生错误时被调用。 filterOrder：通过int值来定义过滤器的执行顺序，数值越小优先级越高。 shouldFilter：返回一个boolean类型来判断该过滤器是否要执行。我们可以通过此方法来指定过滤器的有效范围。 run：过滤器的具体逻辑。在该函数中，我们可以实现自定义的过滤逻辑，来确定是否要拦截当前的请求，不对其进行后续的路由，或是在请求路由返回结果之后，对处理结果做一些加工等。 项目中的多个filter类时，根据order的顺序进行执行，数值越小优先级越高。数值可以相同。这些顺序都依赖于filterType的类型。 先类型后顺序。","path":"posts/16737.html","date":"10-17","excerpt":"","tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://zhulg.github.io/tags/springcloud/"}]},{"title":"Springcloud Hystrix记录点","text":"SpringCloud-Hystrix记录点 背景 1雪崩效应:在微服务架构中通常会有多个服务层调用，基础服务的故障可能会导致级联故障，进而造成整个系统不可用的情况，这种现象被称为服务雪崩效应。服务雪崩效应是一种因“服务提供者”的不可用导致“服务消费者”的不可用,并将不可用逐渐放大的过程 Hystrix特性1.断路器机制 断路器很好理解, 当Hystrix Command请求后端服务失败数量超过一定比例(默认50%), 断路器会切换到开路状态(Open). 这时所有请求会直接失败而不会发送到后端服务. 断路器保持在开路状态一段时间后(默认5秒), 自动切换到半开路状态(HALF-OPEN). 这时会判断下一次请求的返回情况, 如果请求成功, 断路器切回闭路状态(CLOSED), 否则重新切换到开路状态(OPEN). Hystrix的断路器就像我们家庭电路中的保险丝, 一旦后端服务不可用, 断路器会直接切断请求链, 避免发送大量无效请求影响系统吞吐量, 并且断路器有自我检测并恢复的能力. 2.Fallback Fallback相当于是降级操作. 对于查询操作, 我们可以实现一个fallback方法, 当请求后端服务出现异常的时候, 可以使用fallback方法返回的值. fallback方法的返回值一般是设置的默认值或者来自缓存. 3.资源隔离 在Hystrix中, 主要通过线程池来实现资源隔离. 通常在使用的时候我们会根据调用的远程服务划分出多个线程池. 例如调用产品服务的Command放入A线程池, 调用账户服务的Command放入B线程池. 这样做的主要优点是运行环境被隔离开了. 这样就算调用服务的代码存在bug或者由于其他原因导致自己所在线程池被耗尽时, 不会对系统的其他服务造成影响. 但是带来的代价就是维护多个线程池会对系统带来额外的性能开销. 如果是对性能有严格要求而且确信自己调用服务的客户端代码不会出问题的话, 可以使用Hystrix的信号模式(Semaphores)来隔离资源. Ribbon 客户端负载均衡的工具包 使用Ribbon方式的熔断 在pox.xml文件中加入： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 在程序的入口类加@EnableHystrix： 12345678910111213141516@SpringBootApplication@EnableDiscoveryClient@EnableHystrixpublic class ServiceRibbonApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ServiceRibbonApplication.class, args); &#125; @Bean @LoadBalanced RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; Feign中使用断路器 Spring Cloud Feign还扩展了对Spring MVC注解的支持，同时还整合了Ribbon和Eureka来提供均衡负载的HTTP客户端实现 feign是自带断路器的，并且是已经打开了。如果使用feign不想用断路器的话，可以在配置文件中关闭它，配置如下： 1feign.hystrix.enabled=false 只需要在SchedualServiceHi接口的注解中加上fallback的指定类就行了如：示例 12345@FeignClient(value = &quot;service-hi&quot;,fallback = SchedualServiceHiHystric.class)public interface SchedualServiceHi &#123; @RequestMapping(value = &quot;/hi&quot;,method = RequestMethod.GET) String sayHiFromClientOne(@RequestParam(value = &quot;name&quot;) String name);&#125; Hystrix-dashboard和Turbine Hystrix-dashboard是一款针对Hystrix进行实时监控的工具，通过Hystrix Dashboard我们可以在直观地看到各Hystrix Command的请求响应时间, 请求成功率等数据。但是只使用Hystrix Dashboard的话, 你只能看到单个应用内的服务信息, 这明显不够. 我们需要一个工具能让我们汇总系统内多个服务的数据并显示到Hystrix Dashboard上, 这个工具就是Turbine. 使用hystrix-dashboard 1, 添加依赖 12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix-dashboard&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;这三个包必须添加 2、启动类 12345678910111213启动类添加启用Hystrix Dashboard和熔断器@SpringBootApplication@EnableDiscoveryClient@EnableFeignClients@EnableHystrixDashboard@EnableCircuitBreakerpublic class ConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConsumerApplication.class, args); &#125;&#125; 3、启动工程后访问 http://localhost:9001/hystrix 看到面板 默认的集群监控：通过URLhttp://turbine-hostname:port/turbine.stream开启，实现对默认集群的监控。 指定的集群监控：通过URLhttp://turbine-hostname:port/turbine.stream?cluster=[clusterName]开启，实现对clusterName集群的监控。单体应用的监控：通过URLhttp://hystrix-app:port/hystrix.stream开启，实现对具体某个服务实例的监控。 Delay：该参数用来控制服务器上轮询监控信息的延迟时间，默认为2000毫秒，我们可以通过配置该属性来降低客户端的网络和CPU消耗。 Title：该参数对应了上图头部标题Hystrix Stream之后的内容，默认会使用具体监控实例的URL，我们可以通过配置该信息来展示更合适的标题。 4,输入http://localhost:9001/hystrix.stream看到图形介绍 实心圆：共有两种含义。它通过颜色的变化代表了实例的健康程度，如下图所示，它的健康度从绿色、黄色、橙色、红色递减。该实心圆除了颜色的变化之外，它的大小也会根据实例的请求流量发生变化，流量越大该实心圆就越大。所以通过该实心圆的展示，我们就可以在大量的实例中快速的发现故障实例和高压力实例。 曲线：用来记录2分钟内流量的相对变化，我们可以通过它来观察到流量的上升和下降趋势。 ###Turbine 在复杂的分布式系统中，相同服务的节点经常需要部署上百甚至上千个，很多时候，运维人员希望能够把相同服务的节点状态以一个整体集群的形式展现出来，这样可以更好的把握整个系统的状态。 为此，Netflix提供了一个开源项目（Turbine）来提供把多个hystrix.stream的内容聚合为一个数据源供Dashboard展示。 配置文件 12345spring.application.name=hystrix-dashboard-turbineserver.port=8001turbine.appConfig=node01,node02turbine.aggregator.clusterConfig= defaultturbine.clusterNameExpression= new String(&quot;default&quot;) eureka.client.serviceUrl.defaultZone=http://localhost:8000/eureka/ turbine.appConfig ：配置Eureka中的serviceId列表，表明监控哪些服务turbine.aggregator.clusterConfig ：指定聚合哪些集群，多个使用”,”分割，默认为default。可使用http://…/turbine.stream?cluster={clusterConfig之一}访问turbine.clusterNameExpression ： clusterNameExpression指定集群名称，默认表达式appName；此时：turbine.aggregator.clusterConfig需要配置想要监控的应用名称； 当clusterNameExpression: default时，turbine.aggregator.clusterConfig可以不写，因为默认就是default； 当clusterNameExpression: metadata[‘cluster’]时，假设想要监控的应用配置了eureka.instance.metadata-map.cluster: ABC，则需要配置，同时turbine.aggregator.clusterConfig: ABC","path":"posts/47604.html","date":"10-16","excerpt":"","tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://zhulg.github.io/tags/springcloud/"}]},{"title":"Nginx配置文件","text":"nginx配置文件说明123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136#定义Nginx运行的用户和用户组#user nobody; #nginx进程数，建议设置为等于CPU总核心数。worker_processes 1; #全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#进程文件#pid logs/nginx.pid;#工作模式与连接数上限events &#123; #单个进程最大连接数（最大连接数=连接数*进程数） worker_connections 1024;&#125;#设定http服务器http &#123; #文件扩展名与文件类型映射表 include mime.types; #默认文件类型 default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改 成off。 sendfile on; #防止网络阻塞 #tcp_nopush on; #长连接超时时间，单位是秒 #keepalive_timeout 0; keepalive_timeout 65; #开启gzip压缩输出 #gzip on; #虚拟主机的配置 server &#123; #监听端口 listen 80; #域名可以有多个，用空格隔开 server_name localhost; #默认编码 #charset utf-8; #定义本虚拟主机的访问日志 #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125;","path":"posts/42566.html","date":"09-30","excerpt":"","tags":[{"name":"nginx","slug":"nginx","permalink":"https://zhulg.github.io/tags/nginx/"}]},{"title":"Springcloud架构和技术点","text":"SpringCloud架构图 外部或者内部的非Spring Cloud项目都统一通过API网关（Zuul）来访问内部服务. 网关接收到请求后，从注册中心（Eureka）获取可用服务 由Ribbon进行均衡负载后，分发到后端的具体实例 微服务之间通过Feign进行通信处理业务 Hystrix负责处理服务超时熔断 Turbine监控服务间的调用和熔断相关指标 SpringCloud相关技术点","path":"posts/56314.html","date":"09-29","excerpt":"","tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://zhulg.github.io/tags/springcloud/"}]},{"title":"Redis常用场景","text":"Redis的特点Redis 与其他 key - value 缓存产品有以下三个特点： 123 · Redis 支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 · Redis 不仅仅支持简单的 key-value 类型的数据，同时还提供 list ， set ， zset ， hash 等数据结构的存储。 · Redis 支持数据的备份，即 master-slave 模式的数据备份。 Redis的优势：1234 · 性能极高 – Redis 能读的速度是 110000 次 /s, 写的速度是 81000 次 /s · 丰富的数据类型 – Redis 支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。 · 原子 – Redis 的所有操作都是原子性的，同时 Redis 还支持对几个操作全并后的原子性执行。 · 丰富的特性 – Redis 还支持 publish/subscribe, 通知 , key 过期等等特性。 常见使用场景: 会话缓存（Session Cache)最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。 全页缓存（FPC）除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC 队列Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作 排行榜/计数器&lt;brRedis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构","path":"posts/23891.html","date":"09-19","excerpt":"","tags":[{"name":"redis","slug":"redis","permalink":"https://zhulg.github.io/tags/redis/"}]},{"title":"Mac Elasticsearch","text":"1,Mac安装Elasticsearch Elasticsearch 是一个基于 Apache Lucene(TM) 的开源搜索引擎。被认为是迄今为止最先进、性能最好的、功能最全的搜索引擎库。并通过简单的 RESTful API 来隐藏 Lucene 的复杂性，从而让全文搜索变得简单。 mac 安装 1brew install elasticsearch 安装结果 123456789101112131415==&gt; Downloading https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.0.tar.gz######################################################################## 100.0%==&gt; CaveatsData: /usr/local/var/elasticsearch/elasticsearch_zhulianggang/Logs: /usr/local/var/log/elasticsearch/elasticsearch_zhulianggang.logPlugins: /usr/local/opt/elasticsearch/libexec/plugins/Config: /usr/local/etc/elasticsearch/plugin script: /usr/local/opt/elasticsearch/libexec/bin/elasticsearch-pluginTo have launchd start elasticsearch now and restart at login: brew services start elasticsearchOr, if you don&apos;t want/need a background service you can just run: elasticsearch==&gt; Summary🍺 /usr/local/Cellar/elasticsearch/5.6.0: 104 files, 35.9MB, built in 15 minutes 21 seconds 安装信息查询 1brew info elasticsearch 启动（不想后台运行的话） 1elasticsearch 查看 http://127.0.0.1:9200/ 2,安装可视化插件 elasticsearch-head1234git clone git://github.com/mobz/elasticsearch-head.gitcd elasticsearch-headnpm installnpm run start 其中 npm install 可能失败。失败执行 npm install grunt –save-dev 访问 http://localhost:9100/ 查看可视化 Elasticsearch。 下次启动可以直接npm run start 3,修改配置文件（为了允许 elasticsearch-head 运行时的跨域） Elasticsearch 配置文件，即 config/elasticsearch.yml。这里我们需要在配置中增加以下配置，为了允许 elasticsearch-head 运行时的跨域： 123 # allow originhttp.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; 运行一般在后台起守护线程启动 Elasticsearch，在命令行加入 -d 指定。自然，也可以加入 -p ，可将进程 ID 记录到文件中。cd 到/usr/local目录 1./bin/elasticsearch -d 访问 http://localhost:9200/ 要关闭 Elasticsearch 进程，需要通过 ps 找到对应的 pid，在 kill pid 即可。 12ps aux |grep elasticsearchkill -7 pid 4,Java代码方式创建索引1234567891011121314151617181920//1,索引创建elasticSearch.getClient().admin().indices().prepareCreate(indices).execute().actionGet();//2,Mapping 构建XContentBuilder builder = XContentFactory.jsonBuilder().startObject().startObject(mappingType).startObject(&quot;properties&quot;)......endObject().endObject().endObject();//3,创建使用mapping(mapping 在 Elasticsearch 中的作用就是约束。)//mapping用于数据类型声明, Mapping它定义了 Type 的属性，指定分词器。如：//&quot;id&quot;: &#123; &quot;index&quot;: &quot;not_analyzed&quot;, &quot;type&quot;: &quot;string&quot;&#125;PutMappingRequest mapping = Requests.putMappingRequest(indices) .type(mappingType).source(builder);elasticSearch.getClient().admin().indices().putMapping(mapping).actionGet(); //4,批量放入索引数据（一般循环里使用bulkRequest.add）BulkRequestBuilder bulkRequest = client.prepareBulk(); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;name&quot;, &quot;Jack&quot;); IndexRequest request = client.prepareIndex(&quot;dept&quot;, &quot;employee&quot;,&quot;3433&quot;).setSource(map).request(); bulkRequest.add(request);","path":"posts/3639.html","date":"09-13","excerpt":"","tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://zhulg.github.io/tags/Elasticsearch/"}]},{"title":"Springcloud 网关服务记录","text":"###SpringCloud 网关记录 1, 注册相关服务到eureka 1234当我们这里构建的api-gateway应用启动并注册到eureka之后，服务网关会发现上面我们启动的两个服务eureka-client和eureka-consumer，这时候Zuul就会创建两个路由规则。每个路由规则都包含两部分，一部分是外部请求的匹配规则，另一部分是路由的服务ID。针对当前示例的情况，Zuul会创建下面的两个路由规则：转发到eureka-client服务的请求规则为：/eureka-client/**转发到eureka-consumer服务的请求规则为：/eureka-consumer/** 2,通过api-gateway 地址访问，默认已经进行路由 3,在api-gateway里有配置zuul对应的映射路径： 1234567891011121314151617spring: application: name: api-gatewayserver: port: 1101zuul: routes: api-a: path: /api-a/** serviceId: eureka-clienteureka: client: serviceUrl: defaultZone: http://localhost:8001/eureka/ 4,所以有上边里的zuul里的routers配置，可以通过api-gateway里配置的映射路径进行访问","path":"posts/56664.html","date":"09-07","excerpt":"","tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://zhulg.github.io/tags/springcloud/"}]},{"title":"Nginx安装记录","text":"Mac安装Nginx 使用brew安装nginx 1brew install nginx 启动Nginx 1brew services start nginx 版本查看 1nginx -v 关闭Nginx 1brew services stop nginx 重新加载,（修改配置后进行重新加载即可） 1nginx -s reload 相关安装文件路径(可进行更改) 123/usr/local/etc/nginx/nginx.conf （配置文件路径）/usr/local/var/www （服务器默认路径）/usr/local/Cellar/nginx/1.12.1 （安装路径） Nginx 常用场景： 反向代理： 1反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。简单来说就是真实的服务器不能直接被外部网络访问，所以需要一台代理服务器，而代理服务器能被外部网络访问的同时又跟真实服务器在同一个网络环境，当然也可能是同一台服务器，端口不同而已 负载均衡 1负载均衡也是Nginx常用的一个功能，负载均衡其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。简单而言就是当有2台或以上服务器时，根据规则随机的将请求分发到指定的服务器上处理，负载均衡配置一般都需要同时配置反向代理，通过反向代理跳转到负载均衡。而Nginx目前支持自带3种负载均衡策略，还有2种常用的第三方策略 http服务器 1Nginx本身也是一个静态资源的服务器，当只有静态资源的时候，就可以使用Nginx来做服务器，同时现在也很流行动静分离，就可以通过Nginx来实现 正向代理 1正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理。当你需要把你的服务器作为代理服务器的时候，可以用Nginx来实现正向代理，但是目前Nginx有一个问题，那么就是不支持HTTPS ....","path":"posts/54142.html","date":"09-06","excerpt":"","tags":[{"name":"nginx","slug":"nginx","permalink":"https://zhulg.github.io/tags/nginx/"}]},{"title":"Springcloud Consul Mac安装","text":"Spring cloud Consul安装 Consul 是 HashiCorp 公司推出的开源工具，用于实现分布式系统的服务发现与配置 它包含多个组件，但是作为一个整体，在微服务架构中为我们的基础设施提供服务发现和服务配置的工具 与其他分布式服务注册与发现的方案，Consul的方案更“一站式”，内置了服务注册与发现框 架、分布一致性协议实现、健康检查、Key/Value存储、多数据中心方案，不再需要依赖其他工具（比如ZooKeeper等） Mac下安装使用 下载 1brew install consul 启动 1consul agent -dev 启动后可以配合springboot工程进行注册 启动后： 注册服务提供client端：(启动自己springboot工程client端) 服务消费端:（启动自己springboot工程consumer端）","path":"posts/60822.html","date":"08-23","excerpt":"","tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://zhulg.github.io/tags/springcloud/"}]},{"title":"","text":"Apache Camel Camel 是一个开源的企业应用集成框架。 它采用URI来描述各种组件，这样你可以很方便地与各种传输或者消息模块进行交互，比如HTTP、 ActiveMQ、JMS、JBI、SCA、MINA或CXF Bus API。这些模块是采用可插拔的方式进行工作的。Apache Camel拥有小巧、依赖少等特点，能够很容易将其集成在各种Java应用中。 其核心的思想就是从一个from源头得到数据,通过processor处理,再发到一个to目的的 在企业系统集成中做路由,流程控制一个非常好的框架 Apache Camel的常用组件 Message: 是Camel中一个基本的包含数据和路由的实体，Camel中消息以及数据都是以message类型进行传递 1,header：message中包含头信息，存放在header中 2,body：路由中消息和数据传输的实际内容存放在body中 3,fault flag：错误标记，使用来标记正常或者错误的标记 Exchange：是路由之间传递消息，通信，交换数据的抽象，用来传递，交换数据 1, Exchange ID：每次交换数据的时候都会产生一个Exchange ID 2, MEP ：一个类似InOnly或者InOut的消息交换模式。当模式是InOnly的时候，消息交换中 只包含IN-Message 3, Exception：在路由过程中出现的异常 4, Properties：类似与message 的headers ，但是他们将持续到整个exchange结束，Camel还可能利用他们进行一些特殊的通信。 5, IN-Message：输入消息，在对消息处理之前，首先需要获取上个endpoint节点的消息 6, OUT-Message：输出消息，向下一个endpoint传输的消息 Endpoint 是Camel路由中的通道端点，可以发送和接受消息，在Camel中Endpoint使用URI来配置。在运行时Camel通过获取URL来查找到对应的组件。端点的功能强大、全面而且又可维护 Component 是一些Endpoints URI的集合。他们通过连接码来链接（例如file:,jms:），而且作为一个endpoint的工厂。现在Camel中有超过80个Component。也可以通过扩展类来实现自己的Component Route 路由，它定义了Message如何在一个系统中传输的真实路径或者通道。路由引擎自身并不暴露给开发者，但是开发者可以自己定义路由，并且需要信任引擎可以完成复杂的传输工作。每个路由都有一个唯一的标识符，用来记录日志、调试、监控，以及启动或者停止路由。路由也有一个输入的Message，因此他们也有效的链接到一个输入端点。路由定义了一种领域特有的语言（DSL）。Camel提供了java、scala和基于xml的Route-DSL。 Processor 是一个消息接受者和消息通信的处理器。当然，Processor是Route的一个元素，可用来消息格式转换或者其他的一些变换。在路由传输消息的过程中，有时候需要对消息和数据进行处理在传输到下一个Endpoint中，Processor中就定义了一系列消息处理的过程 架构原理图","path":"posts/53101.html","date":"08-16","excerpt":"","tags":[{"name":"springboot","slug":"springboot","permalink":"https://zhulg.github.io/tags/springboot/"}]},{"title":"Springboot部署","text":"Springboot部署阿里云 环境准备 123451,mac下准备ssh shell2,准备云服务地址3,使用ssh shell 登录服务地址4,构建服务端运行环境5,部署springboot项目 环境安装记录： java 环境安装：采用先下载到本地，在scp到远程服务器(直接服务器上下载后无法解压成功，其下载是个html压缩包，不是真实jdk) 1scp jdk-8u144-linux-x64.tar.gz root@120.76.xxx.xxx:/root/zhulg/jdk/jdk-8u144-linux-x64.tar.gz 后续输入密码 解压 1tar -zxvf jdk-xxxxx 环境变量配置:系统环境变量 vi /etc/environment 添加以下内容 123PATH=&quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:$JAVA_HOME/bin&quot;export CLASSPATH=.:$JAVA_HOME/lib:$JAVA_HOME/jre/libexport JAVA_HOME=/root/jdk/jdk1.8.0_144 用户环境变量: vi /etc/profile 添加以下内容 1234export JAVA_HOME=/root/sdk/jdk1.8.0_141export JRE_HOME=$JAVA_HOME/jreexport CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATHexport PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH 生效以上配置：source /etc/profile source /etc/environment 查看Java是否安装好：java -version or java 可以安装其他需要的环境 springboot demo部署 使用sftp放到服务器 java -jar xxx.jar 启动springboot 要保证关闭shell应用在后台一直能运行 1231,vim start.sh 添加 java -jar xxx,jar2,chmod 777 start.sh3,nohup ./start.sh 查看和关闭应用 12345查看其对应的进程号 netstat -anp | grep 80关闭sid的端口，即关闭应用kill sid","path":"posts/27748.html","date":"08-15","excerpt":"","tags":[{"name":"springboot","slug":"springboot","permalink":"https://zhulg.github.io/tags/springboot/"}]},{"title":"Springcloud Eureka注册中心集群","text":"Eureka集群注册 Eureka注册中心提供关键的服务，如果是单点话，遇到故障就是毁灭性的。在一个分布式系统中，服务注册中心是最重要的基础部分，理应随时处于可以提供服务的状态。为了维持其可用性，使用集群是很好的解决方案。 Eureka通过互相注册的方式来实现高可用的部署。集群注册步骤 1、创建application-peer1.properties，作为peer1服务中心的配置，并将serviceUrl指向peer2 1234567spring.application.name=eureka-serverserver.port=8000#在集群注册时会有,否则服务显示unavailable-replicaseureka.client.register-with-eureka=trueeureka.client.fetch-registry=trueeureka.instance.hostname=peer1eureka.client.serviceUrl.defaultZone=http://peer2:8001/eureka/ 2、创建application-peer2.properties，作为peer2服务中心的配置，并将serviceUrl指向peer1 123456spring.application.name=eureka-serverserver.port=8001eureka.client.register-with-eureka=trueeureka.client.fetch-registry=trueeureka.instance.hostname=peer2eureka.client.serviceUrl.defaultZone=http://peer1:8000/eureka/ 3、host转换在hosts文件中加入如下配置 12127.0.0.1 peer1 127.0.0.1 peer2 4、打包启动,依次执行下面命令 1234mvn clean package分别以peer1和peeer2 配置信息启动eurekajava -jar eureka-server-1.0.0.jar --spring.profiles.active=peer1java -jar eureka-server-1.0.0.jar --spring.profiles.active=peer2 5,启动 http://localhost:8001/ 6,异常备注，开始折腾了很久，遇到什么权限没有，端口不能访问时。需要把服务彻底关掉，开启服务peer1时可能会有错误，原因服务没起来忽略即可。出去下上图说明已经建立成功。多个集群同理配置。7，在MAC 环境下网上很多demo端口为1001之类的，在mac上端口会占用失败，继采用8001端口。","path":"posts/17105.html","date":"08-10","excerpt":"","tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://zhulg.github.io/tags/springcloud/"}]},{"title":"Springcloud包含子项目","text":"关于SpringCloud和SpringBoot SpringCloud: 微服务工具包，为开发者提供了在分布式系统的配置管理、服务发现、断路器、智能路由、微代理、控制总线等开发工具包。 Spring Boot: 旨在简化创建产品级的 Spring 应用和服务，简化了配置文件，使用嵌入式web服务器，含有诸多开箱即用微服务功能 关于SpringCloud子项目 Spring Cloud Config：配置管理开发工具包，可以让你把配置放到远程服务器，目前支持本地存储、Git以及Subversion。 Spring Cloud Bus：事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与Spring Cloud Config联合实现热部署。 Spring Cloud Netflix：针对多种Netflix组件提供的开发工具包，其中包括Eureka、Hystrix、Zuul、Archaius等。 Netflix Eureka：云端负载均衡，一个基于 REST 的服务，用于定位服务，以实现云端的负载均衡和中间层服务器的故障转移。 Netflix Hystrix：容错管理工具，旨在通过控制服务和第三方库的节点,从而对延迟和故障提供更强大的容错能力。 Netflix Zuul：边缘服务工具，是提供动态路由，监控，弹性，安全等的边缘服务。 Netflix Archaius：配置管理API，包含一系列配置管理API，提供动态类型化属性、线程安全配置操作、轮询框架、回调机制等功能。 Spring Cloud for Cloud Foundry：通过Oauth2协议绑定服务到CloudFoundry，CloudFoundry是VMware推出的开源PaaS云平台。 Spring Cloud Sleuth：日志收集工具包，封装了Dapper,Zipkin和HTrace操作。 Spring Cloud Data Flow：大数据操作工具，通过命令行方式操作数据流。 Spring Cloud Security：安全工具包，为你的应用程序添加安全控制，主要是指OAuth2。 Spring Cloud Consul：封装了Consul操作，consul是一个服务发现与配置工具，与Docker容器可以无缝集成。 Spring Cloud Zookeeper：操作Zookeeper的工具包，用于使用zookeeper方式的服务注册和发现。 Spring Cloud Stream：数据流操作开发包，封装了与Redis,Rabbit、Kafka等发送接收消息。 Spring Cloud CLI：基于 Spring Boot CLI，可以让你以命令行方式快速建立云组件。","path":"posts/25087.html","date":"08-08","excerpt":"","tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://zhulg.github.io/tags/springcloud/"}]},{"title":"Springcloud Eureka","text":"关于Eureka Eureka，是 Spring Cloud Eureka 的简称，是 Spring Cloud Netflix 组件之一。Spring Cloud Netflix 中核心的组件包括了服务治理（Eureka），服务容断（Hystrix），路由（Zuul）和客户端负载均衡（Ribbon）等 它提供了完整的Service Registry和Service Discovery实现。也是springcloud体系中最重要最核心的组件之一。 Eureka由两个组件组成：Eureka服务器和Eureka客户端。Eureka服务器用作服务注册服务器。Eureka客户端是一个java客户端，用来简化与服务器的交互、作为轮询负载均衡器，并提供服务的故障切换支持。Netflix在其生产环境中使用的是另外的客户端，它提供基于流量、资源利用率以及出错状态的加权负载均衡。 Eureka 架构图 Eureka Server：提供服务注册和发现 Service Provider：服务提供方，将自身服务注册到Eureka，从而使服务消费方能够找到 Service Consumer：服务消费方，从Eureka获取注册服务列表，从而能够消费服务","path":"posts/23872.html","date":"08-08","excerpt":"","tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://zhulg.github.io/tags/springcloud/"}]},{"title":"rabbitMQ安装记录","text":"安装 1brew install rabbitmq 启动 1rabbitmq-server 查看 1浏览器输入localhost：15672,账号密码全输入guest","path":"posts/46741.html","date":"08-07","excerpt":"","tags":[{"name":"springboot","slug":"springboot","permalink":"https://zhulg.github.io/tags/springboot/"}]},{"title":"Springboot里几个常用注解","text":"Spring里几个常用注解区别 注解 用途 @Controller 处理http请求 @RestController spring 4 新加注解，@RestController = @Controller + @ResponseBody @RequestMapping 配置url映射 @PathVariable 获取url中的数据 @RequestParam 获取请求参数的值 @GetMapping 组合注解 ( @RequestMapping(value = “/hello” , method = RequestMethod.GET) 等价于 @GegMapping(“/hello”) @RestController和Controller都在类上注解 @Controller 用于页面的跳转（return “index”）跳转到index页面去，否则返回的内容就是字符串 “index” 当类使用@Controller注解，而对应的接口方法需要返回JSON，XML或自定义mediaType内容到页面，则需要在对应的方法上加上@ResponseBody注解。 以下代码不跳转 12345678@RestControllerpublic class HelloController &#123; @RequestMapping(&quot;/hello&quot;) public String hello() &#123; return &quot;Hello World&quot;; &#125;&#125; 以下代码进行跳转 12345678910111213141516@Controllerpublic class HelloController &#123; //当使用@Controller，想要返回内容。则添加@ResponseBody @ResponseBody @RequestMapping(&quot;/hello&quot;) public String hello() &#123; return &quot;Hello World&quot;; &#125; @RequestMapping(&quot;/&quot;) public String index(ModelMap map) &#123; map.addAttribute(&quot;host&quot;, &quot;hello jason&quot;); return &quot;index&quot;; &#125;&#125;","path":"posts/6507.html","date":"08-04","excerpt":"","tags":[{"name":"springboot","slug":"springboot","permalink":"https://zhulg.github.io/tags/springboot/"}]},{"title":"Python3 K-近邻算法实现","text":"Python3实现K-近邻算法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990import numpy as npimport operator# 函数说明:创建数据集# Parameters:# 无# Returns:# group - 数据集# labels - 分类标签def createDataSet(): #四组二维特征 group = np.array([[1,101],[5,89],[108,5],[115,8]]) #四组特征的标签 labels = [&apos;爱情片&apos;,&apos;爱情片&apos;,&apos;动作片&apos;,&apos;动作片&apos;] return group, labels# 函数说明:kNN算法,分类器# # Parameters:# inX - 用于分类的数据(测试集)# dataSet - 用于训练的数据(训练集)# labes - 分类标签# k - kNN算法参数,选择距离最小的k个点# Returns:# sortedClassCount[0][0] - 分类结果 def classify0(inX, dataSet, labels, k): print(&quot;开始查看下dataSet&quot;) print(dataSet) #numpy函数shape[0]返回dataSet的行数 dataSetSize = dataSet.shape[0] print(&quot;查看下得到的行数：&quot;) print(dataSetSize) #在列向量方向上重复inX共1次(横向)，行向量方向上重复inX共dataSetSize次(纵向) dataSettemp = np.tile(inX, (dataSetSize, 1)) print(&quot;查看下dataSettemp：&quot;) print(dataSettemp) diffMat = dataSettemp - dataSet print(&quot;查看下diffMat：&quot;) print(diffMat) #二维特征相减后平方 sqDiffMat = diffMat**2 print(&quot;二维特征相减后平方:&quot;) print(sqDiffMat) #sum()所有元素相加，sum(0)列相加，sum(1)行相加 sqDistances = sqDiffMat.sum(axis=1) print(&quot;um()所有元素相加，sum(0)列相加，sum(1)行相加:&quot;) print(sqDistances) #开方，计算出距离 distances = sqDistances**0.5 print(&quot;开方，计算出距离:&quot;) print(distances) #返回distances中元素从小到大排序后的索引值 sortedDistIndices = distances.argsort() print(&quot;sortedDistIndices:&quot;) print(sortedDistIndices) #定一个记录类别次数的字典 classCount = &#123;&#125; for i in range(k): #取出前k个元素的类别 voteIlabel = labels[sortedDistIndices[i]] print(voteIlabel) #dict.get(key,default=None),字典的get()方法,返回指定键的值,如果值不在字典中返回默认值。 #计算类别次数 classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1 #python3中用items()替换python2中的iteritems() #key=operator.itemgetter(1)根据字典的值进行排序 #key=operator.itemgetter(0)根据字典的键进行排序 #reverse降序排序字典 sortedClassCount = sorted(classCount.items(),key=operator.itemgetter(1),reverse=True) #返回次数最多的类别,即所要分类的类别 #排序后是个二维的list类型 print(&quot;排序后结果：&quot;) print(sortedClassCount) return sortedClassCount[0][0]if __name__ == &apos;__main__&apos;: #创建数据集 group, labels = createDataSet() #测试集 test = [101,20] #kNN分类 test_class = classify0(test, group, labels, 3) #打印分类结果 print(test_class)","path":"posts/29486.html","date":"08-03","excerpt":"","tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://zhulg.github.io/tags/机器学习/"}]},{"title":"Mongodb介绍","text":"SQL 和 NoSQL 的区别 SQL (Structured Query Language) 数据库，指关系型数据库 - 主要代表：SQL Server，Oracle，MySQL(开源)，PostgreSQL(开源)。 NoSQL（Not Only SQL）泛指非关系型数据库 - 主要代表：MongoDB，Redis，CouchDB。 一般将NoSQL数据库分为四大类：键值(Key-Value)存储数据库、列存储数据库、文档型数据库和图形(Graph)数据库 今天我们可以通过第三方平台（如：Google,Facebook等）可以很容易的访问和抓取数据。用户的个人信息，社交网络，地理位置，用户生成的数据和用户操作日志已经成倍的增加。我们如果要对这些用户数据进行挖掘，那SQL数据库已经不适合这些应用了, NoSQL数据库的发展也却能很好的处理这些大的数据 关系型与非关系型数据库 非关系型数据库的优势： 12性能NOSQL是基于键值对的，可以想象成表中的主键和值的对应关系，而且不需要经过SQL 层的解析，所以性能非常高。可扩展性同样也是因为基于键值对，数据之间没有耦合性，所以非常容易水平扩展。 关系型数据库的优势： 12复杂查询可以用SQL语句方便的在一个表以及多个表之间做非常复杂的数据查询。事务支持使得对于安全性能很高的数据访问要求得以实现. MongoDB是什么 MongoDB 是由C++语言编写的，是一个基于分布式文件存储的开源数据库系统。在高负载的情况下，添加更多的节点，可以保证服务器性能。MongoDB 旨在为WEB应用提供可扩展的高性能数据存储解决方案。MongoDB 将数据存储为一个文档，数据结构由键值(key=&gt;value)对组成。MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档，数组及文档数组。 MongoDB是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。他支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型。 Mac安装mongodb1brew install mongodb 1234567891011==&gt; Downloading https://homebrew.bintray.com/bottles/mongodb-3.4.6.sierra.bottle.tar.gz######################################################################## 100.0%==&gt; Pouring mongodb-3.4.6.sierra.bottle.tar.gz==&gt; Using the sandbox==&gt; CaveatsTo have launchd start mongodb now and restart at login: brew services start mongodbOr, if you don&apos;t want/need a background service you can just run: mongod --config /usr/local/etc/mongod.conf==&gt; Summary🍺 /usr/local/Cellar/mongodb/3.4.6: 18 files, 266.9MB \\ 按照以上安装成功提示启动 连接到mongodb 1mongo","path":"posts/49782.html","date":"08-02","excerpt":"","tags":[{"name":"springboot相关","slug":"springboot相关","permalink":"https://zhulg.github.io/tags/springboot相关/"}]},{"title":"机器学习，K-近邻算法","text":"K-近邻算法 k近邻法(k-nearest neighbor, k-NN)是1967年由Cover T和Hart P提出的一种基本分类与回归方法。 它的工作原理是：存在一个样本数据集（训练集），并且我们知道每一数据与目标变量的对应关系，输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中最相近的分类标签，一般来说，我们只选择样本集中前k个最相似的数据，通常k为不大于20的整数，最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。 K近邻算法思想和算法步骤 12345计算已知类别数据集中的点与当前点之间的距离；按照距离递增次序排序；选取与当前点距离最小的k个点；确定前k个点所在类别的出现频率；返回前k个点所出现频率最高的类别作为当前点的预测分类。 经典举例根据电影镜头判断电影类别，电影6属于什么类型，就需要进行一算距离，二排序，三取值 电影名称 打斗镜头 接吻镜头 电影类型 电影1 3 102 爱情 电影2 4 105 爱情 电影3 10 200 爱情 电影4 200 10 动作 电影5 201 18 动作 电影6 38 39 ？ K近邻的应用代码后续记录到github上","path":"posts/28699.html","date":"07-31","excerpt":"","tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://zhulg.github.io/tags/机器学习/"}]},{"title":"Mac Python机器学习相关包安装","text":"python3 安装Numpy,scipy,matplotlib Mac系统 python3.3及更高版本个版本内置了pip包管理器，终端可以快速安装相关包 1sudo pip3 install numpy 1sudo pip3 install scipy 1sudo pip3 install matplotlib","path":"posts/23709.html","date":"07-30","excerpt":"","tags":[{"name":"python","slug":"python","permalink":"https://zhulg.github.io/tags/python/"},{"name":"机器学习","slug":"机器学习","permalink":"https://zhulg.github.io/tags/机器学习/"}]},{"title":"Mac安装zookeeper记录","text":"brew install zookeeper 安装后配置文件位置：/usr/local/etc/zookeeper 配置文件路径： /usr/local/etc/zookeeper/zoo.cfg 配置文件相关说明 12345678910111213141516171819202122232425262728# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial# synchronization phase can takeinitLimit=10# The number of ticks that can pass between# sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just# example sakes.dataDir=/usr/local/var/run/zookeeper/data# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the# administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1 相关参数说明： 1234567891011tickTime：ZK中的一个时间单元。ZK中所有时间都是以这个时间单元为基础，进行整数倍配置的。例如，session的最小超时时间是2*tickTime。initLimit：Follower在启动过程中，会从Leader同步所有最新数据，然后确定自己能够对外服务的起始状态。Leader允许F在initLimit时间内完成这个工作。通常情况下，我们不用太在意这个参数的设置。如果ZK集群的数据量确实很大了，F在启动的时候，从Leader上同步数据的时间也会相应变长，因此在这种情况下，有必要适当调大这个参数了。(No Java system property)syncLimit：在运行过程中，Leader负责与ZK集群中所有机器进行通信，例如通过一些心跳检测机制，来检测机器的存活状态。如果L发出心跳包在syncLimit之后，还没有从F那里收到响应，那么就认为这个F已经不在线了。注意：不要把这个参数设置得过大，否则可能会掩盖一些问题。(No Java system property)dataDir：存储快照文件snapshot的目录。默认情况下，事务日志也会存储在这里。建议同时配置参数dataLogDir, 事务日志的写性能直接影响zk性能。clientPort： 客户端连接server的端口，即对外服务端口，一般设置为2181吧。server.x=[hostname]:nnnnn[:nnnnn]：这里的x是一个数字，与myid文件中的id是一致的。右边可以配置两个端口，第一个端口用于F和L之间的数据同步和其它通信，第二个端口用于Leader选举过程中投票通信。 启动和停止/usr/local/Cellar/zookeeper/3.4.10/bin$目录下： 12./zkServer start./zkServer stop 以上为单机配置。配置同时也支持多机组成集群来提供服务。 Zookeeper 还支持另外一种伪集群的方式，也就是可以在一台物理机上运行多个 Zookeeper 实例。后续使用时更新记录。","path":"posts/23207.html","date":"07-28","excerpt":"","tags":[{"name":"分布式/集群","slug":"分布式-集群","permalink":"https://zhulg.github.io/tags/分布式-集群/"}]},{"title":"SOA与分布式相关术语","text":"SOA: 面向服务的架构（SOA）是一个组件模型，它将应用程序的不同功能单元（称为服务）通过这些服务之间定义良好的接口和契约联系起来。接口是采用中立的方式进行定义的，它应该独立于实现服务的硬件平台、操作系统和编程语言。这使得构建在各种各样的系统中的服务可以以一种统一和通用的方式进行交互。 DUBBO: 是一个分布式服务框架，致力于提供高性能和透明化的RPC远程服务调用方案. RPC: 是指远程过程调用，也就是说两台服务器A，B，一个应用部署在A服务器上，想要调用B服务器上应用提供的函数/方法，由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义和传达调用的数据 ZooKeeper: 是Apache软件基金会的一个软件项目，他为大型分布式计算提供开源的分布式配置服务、同步服务和命名注册。 它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。ZooKeeper曾经是Hadoop的一个子项目，但现在是一个独立的顶级项目。 dubbo与springboot使用一个系统用作客户端，一个系统则充当服务端。服务端要把自己的接口定义提供给客户端，客户端将接口定义在spring中的bean。客户端可以直接使用这个bean，就好像这些接口的实现也是在自己代码里一样。客户端和服务端启动的时候都会把自己的机器IP注册到zookeeper上。客户端会把zk上的服务端ip拉到磁盘上，并记录哪些ip提供哪些服务（服务端启动的时候暴露给zk）。然后调用的时候客户端会根据ip调用服务端的服务，这时候即使zk挂掉也没关系。","path":"posts/9798.html","date":"07-28","excerpt":"","tags":[{"name":"分布式/集群","slug":"分布式-集群","permalink":"https://zhulg.github.io/tags/分布式-集群/"}]},{"title":"分布式与集群","text":"分布式与集群的理解 规范定义分布式系统是一组电脑（computer），通过网络相互链接传递消息与通信后并协调它们的行为而形成的系统。组件之间彼此进行交互以实现一个共同的目标。把需要进行大量计算的工程数据分区成小块，由多台计算机分别计算，再上传运算结果后，将结果统一合并得出数据结论的科学。计算机集群简称集群是一种计算机系统，它通过一组松散集成的计算机软件和/或硬件连接起来高度紧密地协作完成计算工作。在某种意义上，他们可以被看作是一台计算机。集群系统中的单个计算机通常称为节点，通常通过局域网连接，但也有其它的可能连接方式。集群计算机通常用来改进单个计算机的计算速度和/或可靠性。 简单记忆分布式：一个业务分拆多个子业务，部署在不同的服务器上集群：同一个业务，部署在多个服务器上 通俗理解小饭店原来只有一个厨师，切菜洗菜备料炒菜全干。后来客人多了，厨房一个厨师忙不过来，又请了个厨师，两个厨师都能炒一样的菜，这两个厨师的关系是集群。为了让厨师专心炒菜，把菜做到极致，又请了个配菜师负责切菜，备菜，备料，厨师和配菜师的关系是分布式，一个配菜师也忙不过来了，又请了个配菜师，两个配菜师关系是集群","path":"posts/50577.html","date":"07-27","excerpt":"","tags":[{"name":"分布式/集群","slug":"分布式-集群","permalink":"https://zhulg.github.io/tags/分布式-集群/"}]},{"title":"机器学习入门","text":"机器学习路线 Machine Learning in action，中文版本叫“机器学习实践”。(数学知识随时恶补) Andrew Ng老师的machine learning的课程。（一定要耐着性子过一遍甚至是几面这个课程） 周志华老师的西瓜书《机器学习》和李航老师的《统计学习方法》 准备制定相关的学习路线与应用方向结合学习。（做大数据分析的，去学spark，Hadoop。图模型，深度学习…自然语言处理、图像识别、语音识别等等）","path":"posts/62760.html","date":"07-27","excerpt":"","tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://zhulg.github.io/tags/机器学习/"}]},{"title":"Mac安装redis","text":"Mac使用brew安装redis 下载redis 1brew install redis 启动服务 1brew services start redis 进入redis 1redis-cli 停止服务 1brew services stop redis 常用配置含义 12345678910111213141516171819# REDIS (RedisProperties)# Redis数据库索引（默认为0）spring.redis.database=0# Redis服务器地址spring.redis.host=localhost# Redis服务器连接端口spring.redis.port=6379# Redis服务器连接密码（默认为空）spring.redis.password=# 连接池最大连接数（使用负值表示没有限制）spring.redis.pool.max-active=8# 连接池最大阻塞等待时间（使用负值表示没有限制）spring.redis.pool.max-wait=-1# 连接池中的最大空闲连接spring.redis.pool.max-idle=8# 连接池中的最小空闲连接spring.redis.pool.min-idle=0# 连接超时时间（毫秒）spring.redis.timeout=0 Redis是一个使用ANSI C编写的开源、支持网络、基于内存、可选持久性的键值对存储数据库， 是一个高性能的 key-value 数据库。GitHub 地址：https://github.com/antirez/redis","path":"posts/56043.html","date":"07-26","excerpt":"","tags":[{"name":"redis","slug":"redis","permalink":"https://zhulg.github.io/tags/redis/"}]},{"title":"spring/SpringMVC/SpringBoot/Springcloud概念","text":"Spring和SpringMVC是什么关系 spring是一个IoC容器实现，后来逐步将各种功能模块集成到IoC这个框架下，包括事物、日志、缓存等。以前SSH就是以Spring的IoC容器为核心，衔接Struts和Hibernate来搭建应用。 SpringMVC出来了，作为Spring的一个子项目，与Spring的IoC容器配合起来更简便，逐步淘汰Struts。 SpringMVC基于spring实现，基于DispatcherServle实现分发器，最终把这个框架引导起来，进行其自己的逻辑处理,代替了struts. SpringBoot spring boot是在spring 4.0提倡约定优于配置，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置 Spring boot与Spring cloud 是什么关系 Spring Boot就是一个内嵌Web服务器（tomcat/jetty）的可执行程序的框架。你开发的web应用不需要作为war包部署到web服务器中，而是作为一个可执行程序，启动时把Web服务器配置好，加载起来。 Spring Boot比较适合微服务部署方式，不再是把一堆应用放到一个Web服务器下，重启Web服务器会影响到其他应用，而是每个应用独立使用一个Web服务器，重启动和更新都很容易。 Spring Cloud是一套微服务开发和治理框架，来自Netflex的OSS，包含了微服务运行的功能，比如远程过程调用，动态服务发现，负载均衡，限流等。(byzhihu) spring与springboot与springcloud关系 spring -&gt; spring booot &gt; spring cloud Spring boot 是 Spring 的一套快速配置脚手架，可以基于spring boot 快速开发单个微服务， Spring Cloud是一个基于Spring Boot实现的云应用开发工具；Spring boot专注于快速、方便集成的单个个体，Spring Cloud是关注全局的服务治理框架 Spring Cloud很大的一部分是基于Spring boot来实现。 Spring boot可以离开Spring Cloud独立使用开发项目，但是Spring Cloud离不开Spring boot，属于依赖的关系。","path":"posts/21634.html","date":"07-25","excerpt":"","tags":[{"name":"springboot","slug":"springboot","permalink":"https://zhulg.github.io/tags/springboot/"}]},{"title":"Jpa/hibernate/spring Data/spring Data Jpa都是什么","text":"什么是JPA JPA全称Java Persistence API.JPA通过JDK 5.0注解或XML描述对象－关系表的映射关系，并将运行期的实体对象持久化到数据库中。 JPA(Java Persistence API)是Sun官方提出的Java持久化规范。它为Java开发人员提供了一种对象/关系映射工具来管理Java应用中的关系数据。 什么是Hibernate Hibernate是一个开放源代码的对象关系映射框架，它对JDBC进行了非常轻量级的对象封装，它将POJO与数据库表建立映射关系，是一个全自动的orm框架，hibernate可以自动生成SQL语句，自动执行，使得Java程序员可以随心所欲的使用对象编程思维来操纵数据库 什么是Spring Data Spring Data是一个用于简化数据库访问，并支持云服务的开源框架。其主要目标是使得数据库的访问变得方便快捷，并支持map-reduce框架和云计算数据服务。此外，它还支持基于关系型数据库的数据服务，如Oracle RAC等。对于拥有海量数据的项目，可以用Spring Data来简化项目的开发，就如Spring Framework对JDBC、ORM的支持一样，Spring Data会让数据的访问变得更加方便。 什么是Spring Data JPA Spring Data JPA可以极大的简化JPA的写法，可以在几乎不用写实现的情况下，实现对数据的访问和操作。除了CRUD外，还包括如分页、排序等一些常用的功能。 Spring Data是一个开源框架，而在这个框架中Spring Data JPA只是这个框架中的一个模块，所以名称才叫Spring Data JPA。如果单独使用JPA开发，你会发现这个代码量和使用JDBC开发一样有点烦人，所以Spring Data JPA的出现就是为了简化JPA的写法，让你只需要编写一个接口继承一个类就能实现CRUD操作了。","path":"posts/4061.html","date":"07-22","excerpt":"","tags":[{"name":"spring","slug":"spring","permalink":"https://zhulg.github.io/tags/spring/"}]}]}